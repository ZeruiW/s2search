{"id": 3266, "s2_id": "59fe8e0a31a591362c177c930c116de464e5ee09", "title": "Computing the Inverse Mellin Transform of Holonomic Sequences using Kovacic's Algorithm", "abstract": "We describe how the extension of a solver for linear differential equations by Kovacic's algorithm helps to improve a method to compute the inverse Mellin transform of holonomic sequences. The method is implemented in the computer algebra package HarmonicSums.", "venue": "ArXiv", "authors": ["Jakob  Ablinger"], "year": 2018, "n_citations": 22}
{"id": 10624, "s2_id": "8edae1cd34bbc80b19d399a6bb8743c88f5f6774", "title": "Experimental Evaluation of a Method to Simplify Expressions", "abstract": "We present a method to simplify expressions in the context of an equational theory. The basic ideas and concepts of the method have been presented previously elsewhere but here we tackle the difficult task of making it efficient in practice, in spite of its great generality. We first recall the notion of a collection of structures, which allows us to manipulate very large (possibly infinite) sets of terms as a whole, i.e., without enumerating their elements. Then we use this tool to construct algorithms to simplify expressions. We give various reasons why it is difficult to make these algorithms precise and efficient. We then propose a number of approches to solve the raised issues. Finally, and importantly, we provide a detailed experimental evaluation of the method and a comparison of several variants of it. Although the method is completely generic, we use (arbitrary, not only two-level) boolean expressions as the application field for these experiments because impressive simplifications can be obtained in spite of the hardness of the problem.", "venue": "ArXiv", "authors": ["Baudouin Le Charlier"], "year": 2020, "n_citations": 0}
{"id": 15699, "s2_id": "28b64bac3fdfbbeaff4ca213158af4511c1ed470", "title": "Bohemian Upper Hessenberg Toeplitz Matrices", "abstract": "We look at Bohemian matrices, specifically those with entries from $\\{-1, 0, {+1}\\}$. More, we specialize the matrices to be upper Hessenberg, with subdiagonal entries $1$. Even more, we consider Toeplitz matrices of this kind. Many properties remain after these specializations, some of which surprised us. Focusing on only those matrices whose characteristic polynomials have maximal height allows us to explicitly identify these polynomials and give a lower bound on their height. This bound is exponential in the order of the matrix.", "venue": "ArXiv", "authors": ["Eunice Y. S. Chan", "Robert M. Corless", "Laureano  Gonz\u00e1lez-Vega", "J. Rafael Sendra", "Juana  Sendra", "Steven E. Thornton"], "year": 2018, "n_citations": 2}
{"id": 16537, "s2_id": "cecb8d59ece4e26dcb9ed14e304870239e8ccd1f", "title": "Symbolic Integration of Hyperexponential 1-Forms", "abstract": "Let H be a hyperexponential function in n variables x=(x1,\u2026,xn) with coefficients in a field \u211a , [\u211a :\u211a ] < \u221e, and \u03c9 a rational differential 1-form. Assume that H\u00f8mega is closed and H transcendental. We prove using Schanuel conjecture that there exist a univariate function f and multivariate rational functions F,R such that \u222b H\u03c9= f(F(x))+H(x)R(x). We present an algorithm to compute this decomposition. This allows us to present an algorithm to construct a basis of the cohomology of differential 1-forms with coefficients in H\u211a [x,1/(SD)] for a given H, D being the denominator of dH/H and S \u2208 \u211a [x] a square free polynomial. As an application, we generalize a result of Singer on differential equations on the plane: whenever it admits a Liouvillian first integral I but no Darbouxian first integral, our algorithm gives a rational variable change linearising the system.", "venue": "ISSAC", "authors": ["Thierry  Combot"], "year": 2019, "n_citations": 0}
{"id": 19007, "s2_id": "28601a2ffff7218c48184ae9682412ef9d749fd6", "title": "Monodromy Solver: Sequential and Parallel", "abstract": "We describe, study, and experiment with an algorithm for finding all solutions of systems of polynomial equations using homotopy continuation and monodromy. This algorithm follows the framework developed by Duff et al. (2018) and can operate in the presence of a large number of failures of the homotopy continuation subroutine. We give special attention to parallelization and probabilistic analysis of a model adapted to parallelization and failures. Apart from theoretical results, we developed a simulator that allows us to run a large number of experiments without recomputing the outcomes of the continuation subroutine.", "venue": "ISSAC", "authors": ["Nathan  Bliss", "Timothy  Duff", "Anton  Leykin", "Jeff  Sommars"], "year": 2018, "n_citations": 8}
{"id": 28124, "s2_id": "4831e3be467508f3cee2ba82687d03d8107a09bc", "title": "Computing Limits of Quotients of Multivariate Real Analytic Functions", "abstract": "We present an algorithm for computing limits of quotients of real analytic functions. The algorithm is based on computation of a bound on the \u0141ojasiewicz exponent and requires the denominator to have an isolated zero at the limit point.", "venue": "ArXiv", "authors": ["Adam  Strzebonski"], "year": 2021, "n_citations": 0}
{"id": 29172, "s2_id": "976440845e595b5a7635d36aa50ac5c597cd21f3", "title": "Decomposable sparse polynomial systems", "abstract": "The Macaulay2 package DecomposableSparseSystems implements methods for studying and numerically solving decomposable sparse polynomial systems. We describe the structure of decomposable sparse systems and explain how the methods in this package may be used to exploit this structure, with examples.", "venue": "Journal of Software for Algebra and Geometry", "authors": ["Taylor  Brysiewicz", "Jose Israel Rodriguez", "Frank  Sottile", "Thomas  Yahl"], "year": 2021, "n_citations": 1}
{"id": 38864, "s2_id": "b4096f5e2765781a5f9aa1f6426b7520a173bb08", "title": "Tropical differential equations", "abstract": "Tropical differential equations are introduced and an algorithm is designed which tests solvability of a system of tropical linear differential equations within the complexity polynomial in the size of the system and in its coefficients. Moreover, we show that there exists a minimal solution, and the algorithm constructs it (in case of solvability). This extends a similar complexity bound established for tropical linear systems. In case of tropical linear differential systems in one variable a polynomial complexity algorithm for testing its solvability is designed. \nWe prove also that the problem of solvability of a system of tropical non-linear differential equations in one variable is $NP$-hard, and this problem for arbitrary number of variables belongs to $NP$. Similar to tropical algebraic equations, a tropical differential equation expresses the (necessary) condition on the dominant term in the issue of solvability of a differential equation in power series.", "venue": "Adv. Appl. Math.", "authors": ["Dima  Grigoriev"], "year": 2017, "n_citations": 10}
{"id": 41121, "s2_id": "8e6ebc553eb7489349ac983b671ee3b2f5fbc778", "title": "Misfortunes of a mathematicians' trio using Computer Algebra Systems: Can we trust?", "abstract": "Computer algebra systems are a great help for mathematical research but sometimes unexpected errors in the software can also badly affect it. As an example, we show how we have detected an error of Mathematica computing determinants of matrices of integer numbers: not only it computes the determinants wrongly, but also it produces different results if one evaluates the same determinant twice.", "venue": "ArXiv", "authors": ["Antonio J. Dur\u00e1n Guarde\u00f1o", "Mario  P\u00e9rez", "Juan Luis Varona"], "year": 2013, "n_citations": 15}
{"id": 46170, "s2_id": "fb6dec8424205fe83d5b4f721ce34caf2707eefb", "title": "Rigorous high-precision computation of the Hurwitz zeta function and its derivatives", "abstract": "We study the use of the Euler-Maclaurin formula to numerically evaluate the Hurwitz zeta function \u03b6(s, a) for s,a\u2208\u2102$s, a \\in \\mathbb {C}$, along with an arbitrary number of derivatives with respect to s, to arbitrary precision with rigorous error bounds. Techniques that lead to a fast implementation are discussed. We present new record computations of Stieltjes constants, Keiper-Li coefficients and the first nontrivial zero of the Riemann zeta function, obtained using an open source implementation of the algorithms described in this paper.", "venue": "Numerical Algorithms", "authors": ["Fredrik  Johansson"], "year": 2014, "n_citations": 33}
{"id": 56185, "s2_id": "2f5817888823a9c58e178738746410424ba3bc4f", "title": "Representing ($q$-)hypergeometric products and mixed versions in difference rings", "abstract": "In recent years, Karr's difference field theory has been extended to the so-called $R\\Pi\\Sigma$-extensions in which one can represent not only indefinite nested sums and products that can be expressed by transcendental ring extensions, but one can also handle algebraic products of the form $\\alpha^n$ where $\\alpha$ is a root of unity. In this article we supplement this summation theory substantially by the following building block. We provide new algorithms that represent a finite number of hypergeometric or mixed $(q_1,...,q_e)$-multibasic hypergeometric products in such a difference ring. This new insight provides a complete summation machinery that enables one to formulate such products and indefinite nested sums defined over such products in $R\\Pi\\Sigma$-extensions fully automatically. As a side-product, one obtains compactified expressions where the products are algebraically independent among each other, and one can solve the zero-recognition problem for such products.", "venue": "ArXiv", "authors": ["Evans Doe Ocansey", "Carsten  Schneider"], "year": 2017, "n_citations": 10}
{"id": 59522, "s2_id": "3ef24a64a27260147dfcac8d12b2650d1d194179", "title": "Efficient Exact Verification of Binarized Neural Networks", "abstract": "We present a new system, EEV, for verifying binarized neural networks (BNNs). We formulate BNN verification as a Boolean satisfiability problem (SAT) with reified cardinality constraints of the form $y = (x_1 + \\cdots + x_n \\le b)$, where $x_i$ and $y$ are Boolean variables possibly with negation and $b$ is an integer constant. We also identify two properties, specifically balanced weight sparsity and lower cardinality bounds, that reduce the verification complexity of BNNs. EEV contains both a SAT solver enhanced to handle reified cardinality constraints natively and novel training strategies designed to reduce verification complexity by delivering networks with improved sparsity properties and cardinality bounds. We demonstrate the effectiveness of EEV by presenting the first exact verification results for $\\ell_{\\infty}$-bounded adversarial robustness of nontrivial convolutional BNNs on the MNIST and CIFAR10 datasets. Our results also show that, depending on the dataset and network architecture, our techniques verify BNNs between a factor of ten to ten thousand times faster than the best previous exact verification techniques for either binarized or real-valued networks.", "venue": "NeurIPS", "authors": ["Kai  Jia", "Martin  Rinard"], "year": 2020, "n_citations": 10}
{"id": 72416, "s2_id": "d92b3c14bf64a787611a5b35231ad6ba6ba5e179", "title": "An efficient implementation of the algorithm computing the Borel-fixed points of a Hilbert scheme", "abstract": "Borel-fixed ideals play a key role in the study of Hilbert schemes. Indeed each component and each intersection of components of a Hilbert scheme contains at least one Borel-fixed point, i.e. a point corresponding to a subscheme defined by a Borel-fixed ideal. Moreover Borel-fixed ideals have good combinatorial properties, which make them very interesting in an algorithmic perspective. In this paper, we propose an implementation of the algorithm computing all the saturated Borel-fixed ideals with number of variables and Hilbert polynomial assigned, introduced from a theoretical point of view in the paper \"Segment ideals and Hilbert schemes of points\", Discrete Mathematics 311 (2011).", "venue": "ISSAC", "authors": ["Paolo  Lella"], "year": 2012, "n_citations": 19}
{"id": 78508, "s2_id": "80b9f3b3765b9f33af172423de1508933e096d0b", "title": "Stieltjes moment sequences for pattern-avoiding permutations", "abstract": "A small set of combinatorial sequences have coefficients that can be represented as moments of a nonnegative measure on $[0, \\infty)$. Such sequences are known as Stieltjes moment sequences. They have a number of nice properties, such as log-convexity, which are useful to rigorously bound their growth constant from below. \nThis article focuses on some classical sequences in enumerative combinatorics, denoted $Av(\\mathcal{P})$, and counting permutations of $\\{1, 2, \\ldots, n \\}$ that avoid some given pattern $\\mathcal{P}$. For increasing patterns $\\mathcal{P}=(12\\ldots k)$, we recall that the corresponding sequences, $Av(123\\ldots k)$, are Stieltjes moment sequences, and we explicitly find the underlying density function, either exactly or numerically, by using the Stieltjes inversion formula as a fundamental tool. \nWe first illustrate our approach on two basic examples, $Av(123)$ and $Av(1342)$, whose generating functions are algebraic. We next investigate the general (transcendental) case of $Av(123\\ldots k)$, which counts permutations whose longest increasing subsequences have length at most $k-1$. We show that the generating functions of the sequences $\\, Av(1234)$ and $\\, Av(12345)$ correspond, up to simple rational functions, to an order-one linear differential operator acting on a classical modular form given as a pullback of a Gaussian $\\, _2F_1$ hypergeometric function, respectively to an order-two linear differential operator acting on the square of a classical modular form given as a pullback of a $\\, _2F_1$ hypergeometric function. \nWe demonstrate that the density function for the Stieltjes moment sequence $Av(123\\ldots k)$ is closely, but non-trivially, related to the density attached to the distance traveled by a walk in the plane with $k-1$ unit steps in random directions. \nFinally, we study the challenging case of the $Av(1324)$ sequence and give compelling numerical evidence that this too is a Stieltjes moment sequence. Accepting this, we show how rigorous lower bounds on the growth constant of this sequence can be constructed, which are stronger than existing bounds. A further unproven assumption leads to even better bounds, which can be extrapolated to give an estimate of the (unknown) growth constant.", "venue": "Electron. J. Comb.", "authors": ["Alin  Bostan", "Andrew Elvey Price", "Anthony John Guttmann", "Jean-Marie  Maillard"], "year": 2020, "n_citations": 4}
{"id": 92460, "s2_id": "cbab0b1346e790e6eff61c01c765e27df3fcc5e2", "title": "Constructive Arithmetics in Ore Localizations of Domains", "abstract": "Abstract For a non-commutative domain R and a multiplicatively closed set S the (left) Ore localization of R at S exists if and only if S satisfies the (left) Ore property. Since the concept has been introduced by Ore back in the 1930's, Ore localizations have been widely used in theory and in applications. We investigate the arithmetics of the localized ring S \u2212 1 R from both theoretical and practical points of view. We show that the key component of the arithmetics is the computation of the intersection of a left ideal with a submonoid S of R. It is not known yet whether there exists an algorithmic solution of this problem in general. Still, we provide such solutions for cases where S is equipped with additional structure by distilling three most frequently occurring types of Ore sets. We introduce the notion of the (left) saturation closure and prove that it is a canonical form for (left) Ore sets in R. We provide an implementation of arithmetics over the ubiquitous G-algebras in Singular:Plural and discuss questions arising in this context. Numerous examples illustrate the effectiveness of the proposed approach.", "venue": "J. Symb. Comput.", "authors": ["Johannes  Hoffmann", "Viktor  Levandovskyy"], "year": 2020, "n_citations": 2}
{"id": 105860, "s2_id": "d95b0934e86d8dfbda1ffda991634c2067cca4cd", "title": "Elimination-based certificates for triangular equivalence and rank profiles", "abstract": "Abstract In this paper, we give novel certificates for triangular equivalence and rank profiles. These certificates enable somebody to verify the row or column rank profiles or the whole rank profile matrix faster than recomputing them, with a negligible overall overhead. We first provide quadratic time and space non-interactive certificates saving the logarithmic factors of previously known ones. Then we propose interactive certificates for the same problems whose Monte Carlo verification complexity requires a small constant number of matrix-vector multiplications, a linear space, and a linear number of extra field operations, with a linear number of interactions. As an application we also give an interactive protocol, certifying the determinant or the signature of dense matrices, faster for the Prover than the best previously known one. Finally we give linear space and constant round certificates for the row or column rank profiles.", "venue": "J. Symb. Comput.", "authors": ["Jean-Guillaume  Dumas", "Erich  Kaltofen", "David  Lucas", "Cl\u00e9ment  Pernet"], "year": 2020, "n_citations": 0}
{"id": 108745, "s2_id": "13997f4d1989bfe27779fa9775bc0a9a01ee138f", "title": "ParFORM: Parallel Version of the Symbolic Manipulation Program FORM", "abstract": "After an introduction to the sequential version of FORM and the mechanisms behind, we report on the status of our project of parallelization. We have now a parallel version of FORM running on Cluster- and SMP-architectures. This version can be used to run arbitrary FORM programs in parallel.", "venue": "ArXiv", "authors": ["M.  Tentyukov", "D.  Fliegner", "M.  Frank", "A.  Onischenko", "A.  Retey", "H. M. Staudenmaier", "J. A. M. Vermaseren"], "year": 2004, "n_citations": 21}
{"id": 110707, "s2_id": "4e2f80270e278b548966ffab31c4ce28c2914042", "title": "Simplifying products of fractional powers of powers", "abstract": "Most computer algebra systems incorrectly simplify <i>z</i> -- <i>z</i>/\u221a<i>w</i><sup>2</sup> 1/<i>w</i><sup>3</sup> -- <i>w</i>\u221a<i>w</i><sup>2</sup> to 0 rather than to 0/0. The reasons for this are: <ol><li>The default simplification does not succeed in simplifying the denominator to 0.</li> <li>There is a rule that 0 is the result of 0 divided by anything that does not simplify to either 0 or 0/0.</li></ol>.\n Many of these systems have more powerful optional transformation and general purpose simplification functions. However that is unlikely to help this example even if one of those functions can simplify the denominator to 0, because the input to those functions is the result of <i>default</i> simplification, which has already incorrectly simplified the overall ratio to 0. Try it on your computer algebra systems!\n This article describes how to simplify products of the form <i>w</i><sup>\u03b1</sup> (<i>w</i><sup>\u03b21</sup>) <sup>\u03bb1</sup> ... (<i>w</i><sup>\u03b2<i>n</i></sup>) <sup>\u03bb<i>n</i></sup> correctly and well, where <i>w</i> is any real or complex expression and the exponents are rational numbers.\n It might seem that correct good simplification of such a restrictive expression class must already be published and/or built into at least one widely used computer-algebra system, but apparently this issue has been overlooked. Default and relevant optional simplification was tested with 86 examples on 5 systems with <i>n</i> = 1. Using a spectrum from the most serious flaw being a result that is not equivalent to the input somewhere to the least serious being not rationalizing a denominator when that does not cause a more serious flaw, the overall percentage of most flaw types is alarming.", "venue": "ACCA", "authors": ["David R. Stoutemyer"], "year": 2013, "n_citations": 1}
{"id": 119863, "s2_id": "566ea202975c17b1b82367edf07f2ecaba2cfee3", "title": "Choosing a Variable Ordering for Truth-Table Invariant Cylindrical Algebraic Decomposition by Incremental Triangular Decomposition", "abstract": "Cylindrical algebraic decomposition (CAD) is a key tool for solving problems in real algebraic geometry and beyond. In recent years a new approach has been developed, where regular chains technology is used to first build a decomposition in complex space. We consider the latest variant of this which builds the complex decomposition incrementally by polynomial and produces CADs on whose cells a sequence of formulae are truth-invariant. Like all CAD algorithms the user must provide a variable ordering which can have a profound impact on the tractability of a problem. We evaluate existing heuristics to help with the choice for this algorithm, suggest improvements and then derive a new heuristic more closely aligned with the mechanics of the new algorithm.", "venue": "ICMS", "authors": ["Matthew  England", "Russell J. Bradford", "James H. Davenport", "David J. Wilson"], "year": 2014, "n_citations": 22}
{"id": 124986, "s2_id": "9975c10be5ded1ac14adbe113b98bad209268e7e", "title": "How to generate all possible rational Wilf-Zeilberger pairs?", "abstract": "A Wilf\u2013Zeilberger pair (F, G) in the discrete case satisfies the equation \n \n$$\\displaystyle F(n+1, k) - F(n, k) = G(n, k+1) - G(n, k). $$ \n \nWe present a structural description of all possible rational Wilf\u2013Zeilberger pairs and their continuous and mixed analogues.", "venue": "Algorithms and Complexity in Mathematics, Epistemology, and Science", "authors": ["Shaoshi  Chen"], "year": 2019, "n_citations": 2}
{"id": 133268, "s2_id": "a55c5533a061832668b306e022053bfc6f16528f", "title": "Satisfying KBO Constraints", "abstract": "This paper presents two new approaches to prove termination of rewrite systems with the Knuth-Bendix order efficiently. The constraints for the weight function and for the precedence are encoded in (pseudo-)propositional logic and the resulting formula is tested for satisfiability. Any satisfying assignment represents a weight function and a precedence such that the induced Knuth-Bendix order orients the rules of the encoded rewrite system from left to right.", "venue": "RTA", "authors": ["Harald  Zankl", "Aart  Middeldorp"], "year": 2007, "n_citations": 16}
{"id": 142506, "s2_id": "d2529f1bfa7358878d6c8d01f2a84b4ff138b0b1", "title": "Automatic Library Generation for Modular Polynomial Multiplication", "abstract": "Polynomial multiplication is a key algorithm underlying computer algebra systems (CAS) and its efficient implementation is crucial for the performance of CAS. In this paper we design and implement algorithms for polynomial multiplication using approaches based the fast Fourier transform (FFT) and the truncated Fourier transform (TFT). We improve on the state-of-the-art in both theoretical and practical performance. The {\\SPIRAL} library generation system is extended and used to automatically generate and tune the performance of a polynomial multiplication library that is optimized for memory hierarchy, vectorization and multi-threading, using new and existing algorithms. The performance tuning has been aided by the use of automation where many code choices are generated and intelligent search is utilized to find the \"best\" implementation on a given architecture. The performance of autotuned implementations is comparable to, and in some cases better than, the best hand-tuned code.", "venue": "ArXiv", "authors": ["Lingchuan  Meng"], "year": 2016, "n_citations": 0}
{"id": 146800, "s2_id": "1e0af4bcc44a37b052bd600742416fe9d596b999", "title": "Univariate Polynomial Real Root Isolation: Continued Fractions Revisited", "abstract": "We present algorithmic, complexity and implementation results concerning real root isolation of integer univariate polynomials using the continued fraction expansion of real numbers. We improve the previously known bound by a factor of d\u03c4, where d is the polynomial degree and \u03c4 bounds the coefficient bitsize, thus matching the current record complexity for real root isolation by exact methods. Namely, the complexity bound is \u03bf~ B (d 4 \u03c4 2 ) using a standard bound on the expected bitsize of the integers in the continued fraction expansion. We show how to compute the multiplicities within the same complexity and extend the algorithm to non square-free polynomials. Finally, we present an efficient open-source C++ implementation in the algebraic library SYNAPS, and illustrate its efficiency as compared to other available software. We use polynomials with coefficient bitsize up to 8000 and degree up to 1000.", "venue": "ESA", "authors": ["Elias P. Tsigaridas", "Ioannis Z. Emiris"], "year": 2006, "n_citations": 44}
{"id": 151755, "s2_id": "aeb46e6e39872d9ec0d1805933326e11e79488c5", "title": "Computing isolated orbifolds in weighted flag varieties", "abstract": "Given a weighted flag variety $w\\Sigma(\\mu,u)$ corresponding to chosen fixed parameters $\\mu$ and $u$, we present an algorithm to compute lists of all possible projectively Gorenstein $n$-folds, having canonical weight $k$ and isolated orbifold points, appearing as weighted complete intersections in $w\\Sigma(\\mu,u) $ or some projective cone(s) over $w\\Sigma(\\mu,u)$. We apply our algorithm to compute lists of interesting classes of polarized 3-folds with isolated orbifold points in the codimension 8 weighted $G_2$ variety. We also show the existence of some families of log-terminal $\\mathbb Q$-Fano 3-folds in codimension 8 by explicitly constructing them as quasilinear sections of a weighted $G_2$-variety.", "venue": "J. Symb. Comput.", "authors": ["Muhammad Imran Qureshi"], "year": 2017, "n_citations": 11}
{"id": 152149, "s2_id": "e5e1d698ad1dc84f6d4d678ef0aac2284a892b6a", "title": "Sparse multivariate factorization by mean of a few bivariate factorizations", "abstract": "We describe an algorithm to factor sparse multivariate polynomials using O(d) bivariate factorizations where d is the number of variables. This algorithm is implemented in the Giac/Xcas computer algebra system.", "venue": "ArXiv", "authors": ["Bernard  Parisse"], "year": 2016, "n_citations": 0}
{"id": 153268, "s2_id": "8b957c00fd640446464a062307efee0a46ea0778", "title": "Root Separation for Trinomials", "abstract": "We give a separation bound for the complex roots of a trinomial $f \\in \\mathbb{Z}[X]$. The logarithm of the inverse of our separation bound is polynomial in the size of the sparse encoding of $f$; in particular, it is polynomial in $\\log (\u00b0f)$. It is known that no such bound is possible for 4-nomials (polynomials with 4 monomials). For trinomials, the classical results (which are based on the degree of $f$ rather than the number of monomials) give separation bounds that are exponentially this http URL an algorithmic application, we show that the number of real roots of a trinomial $f$ can be computed in time polynomial in the size of the sparse encoding of~$f$. The same problem is open for 4-nomials.", "venue": "J. Symb. Comput.", "authors": ["Pascal  Koiran"], "year": 2019, "n_citations": 9}
{"id": 157847, "s2_id": "f4f10093cd4c1229d812e1465bbeeb9c92555ffa", "title": "A uniform approach to constraint-solving for lists, multisets, compact lists, and sets", "abstract": "Lists, multisets, and sets are well-known data structures whose usefulness is widely recognized in various areas of computer science. They have been analyzed from an axiomatic point of view with a parametric approach in Dovier et al. [1998], where the relevant unification algorithms have been developed. In this article, we extend these results considering more general constraints, namely, equality and membership constraints and their negative counterparts.", "venue": "TOCL", "authors": ["Agostino  Dovier", "Carla  Piazza", "Gianfranco  Rossi"], "year": 2008, "n_citations": 20}
{"id": 159199, "s2_id": "5c5014a850e6b0645d18a001ae39fd1f72b669b9", "title": "Lacunaryx: computing bounded-degree factors of lacunary polynomials", "abstract": "In this paper, we report on an implementation in the free software M<scp>athemagix</scp> [9] of lacunary factorization algorithms, distributed as a library called L<scp>acunaryx</scp>. These algorithms take as input a polynomial in sparse representation, that is as a list of nonzero monomials, and an integer <i>d</i>, and compute its degree-<i>d</i> factors.<sup>2</sup> The complexity of these algorithms is polynomial in the <i>sparse size</i> of the input polynomial and <i>d</i>: The sparse size of a polynomial [EQUATION] logwhere the <i>h</i>(\u00b7) denotes the <i>height</i> of a rational number, that is the maximum of the absolute values of its numerator and denominator.", "venue": "ACCA", "authors": ["Bruno  Grenet"], "year": 2016, "n_citations": 2}
{"id": 170610, "s2_id": "ac271b2f62e7902246e072dbd27936542a1cede2", "title": "On Solving Pentadiagonal Linear Systems via Transformations", "abstract": "Many authors studied numeric algorithms for solving the linear systems of the pentadiagonal type. The well-known Fast Pentadiagonal System Solver algorithm is an example of such algorithms. The current article are described new numeric and symbolic algorithms for solving pentadiagonal linear systems via transformations. New algorithms are natural generalization of the work presented in [Moawwad El- Mikkawy and Faiz Atlan, Algorithms for Solving Linear Systems of Equations of Tridiagonal Type via Transformations, Applied Mathematics, 2014, 5, 413-422]. The symbolic algorithms remove the cases where the numeric algorithms fail. The computational cost of our algorithms is given. Some examples are given in order to illustrate the effectiveness of the proposed algorithms. All of the experiments are performed on a computer with the aid of programs written in MATLAB.", "venue": "ArXiv", "authors": ["A. A. Karawia"], "year": 2014, "n_citations": 12}
{"id": 174666, "s2_id": "15b0ebe1d6b6e77ee6a650be1ff2e916d3dbe728", "title": "A proof of Hilbert's theorem on ternary quartic forms with the ladder technique", "abstract": "This paper proposes a totally constructive approach for the proof of Hilbert's theorem on ternary quartic forms. The main contribution is the ladder technique, with which the Hilbert's theorem is proved vividly.", "venue": "ArXiv", "authors": ["Jia  Xu", "Yong  Yao"], "year": 2017, "n_citations": 1}
{"id": 177179, "s2_id": "f96cbc930dffee25ce34174768c80390f064725f", "title": "Algorithms for Zero-Dimensional Ideals Using Linear Recurrent Sequences", "abstract": "Inspired by Faugere and Mou's sparse FGLM algorithm, we show how using linear recurrent multi-dimensional sequences can allow one to perform operations such as the primary decomposition of an ideal, by computing the annihilator of one or several such sequences.", "venue": "CASC", "authors": ["Vincent  Neiger", "Hamid  Rahkooy", "\u00c9ric  Schost"], "year": 2017, "n_citations": 3}
{"id": 184248, "s2_id": "7d519941070067aaf0caed658a7280bc10abc8ba", "title": "Near Optimal Subdivision Algorithms for Real Root Isolation", "abstract": "Isolating real roots of a square-free polynomial in a given interval is a fundamental problem. Subdivision based algorithms are a standard approach to solve this problem. E.g., Sturm's method,or various algorithms based on the Descartes's rule of signs. For isolating all the real roots of a degree n polynomial with root separation \u03c3, the subdivision tree size of most of these algorithms is bounded by O(log 1/\u03c3) (assume \u03c3 < 1). Recently Sagraloff (2012) and Sagraloff-Mehlhorn (2013) have developed algorithms that combine subdivision with Newton iteration to reduce the size of the subdivision tree to O(n (log (nlog 1/\u03c3))). Their algorithms and analysis crucially depend on the terminating predicates. We describe a subroutine that improves the running time of any subdivision algorithm for real root isolation. The subdivision tree size of our algorithm using predicates based on the Descartes's rule of signs is bounded by O(nlog n). Our analysis differs in two key aspects from earlier approaches. First, we use the general technique of continuous amortization from Burr-Krahmer-Yap (2009), and hence the analysis extends to other predicates; and second, we use the geometry of clusters of roots instead of root bounds.", "venue": "ISSAC", "authors": ["Vikram  Sharma", "Prashant  Batra"], "year": 2015, "n_citations": 7}
{"id": 185451, "s2_id": "08c22be98fe8ddc5c274ddb2fbf284b6f579c309", "title": "In-depth comparison of the Berlekamp - Massey - Sakata and the Scalar-FGLM algorithms: the non adaptive variants", "abstract": "The Berlekamp--Massey--Sakata algorithm and the Scalar-FGLM algorithm both compute the ideal of relations of a multidimensional linear recurrent sequence.Whenever quering a single sequence element is prohibitive, the bottleneck of these algorithms becomes the computation of all the needed sequence terms. As such, having adaptive variants of these algorithms, reducing the number of sequence queries, becomes mandatory.A native adaptive variant of the Scalar-FGLM algorithm was presented by its authors, the so-called Adaptive Scalar-FGLM algorithm.In this paper, our first contribution is to make the Berlekamp--Massey--Sakata algorithm more efficient by making it adaptive to avoid some useless relation test-ings. This variant allows us to divide by four in dimension 2 and by seven in dimension 3 the number of basic operations performed on some sequence family.Then, we compare the two adaptive algorithms. We show that their behaviors differ in a way that it is not possible to tweak one of the algorithms in order to mimic exactly the behavior of the other. We detail precisely the differences and the similarities of both algorithms and conclude that in general the Adaptive Scalar-FGLM algorithm needs fewer queries and performs fewer basic operations than the Adaptive Berlekamp--Massey--Sakata algorithm.We also show that these variants are always more efficient than the original algorithms.", "venue": "J. Symb. Comput.", "authors": ["J\u00e9r\u00e9my  Berthomieu", "Jean-Charles  Faug\u00e8re"], "year": 2020, "n_citations": 4}
{"id": 186894, "s2_id": "999e19d1632e4fd5950b7a9f8f78a10e21cda421", "title": "SymbolicData: SDEval - Benchmarking for Everyone", "abstract": "In this paper we will present SDeval, a software project that contains tools for creating and running benchmarks with a focus on problems in computer algebra. It is built on top of the Symbolic Data project, able to translate problems in the database into executable code for various computer algebra systems. The included tools are designed to be very flexible to use and to extend, such that they can be utilized even in contexts of other communities. With the presentation of SDEval, we will also address particularities of benchmarking in the field of computer algebra. Furthermore, with SDEval, we provide a feasible and automatizable way of reproducing benchmarks published in current research works, which appears to be a difficult task in general due to the customizability of the available programs. We will simultaneously present the current developments in the Symbolic Data project.", "venue": "ArXiv", "authors": ["Albert  Heinle", "Viktor  Levandovskyy", "Andreas  Nareike"], "year": 2013, "n_citations": 6}
{"id": 187340, "s2_id": "8737f369447d0e8d485394a19c0ed4c832696b76", "title": "Sparse Polynomial Interpolation with Finitely Many Values for the Coefficients", "abstract": "In this paper, we give new sparse interpolation algorithms for black box polynomial f whose coefficients are from a finite set. In the univariate case, we recover f from one evaluation of f(a) for a sufficiently large number a. In the multivariate case, we introduce the modified Kronecker substitution to reduce the interpolation of a multivariate polynomial to the univariate case. Both algorithms have polynomial bit-size complexity.", "venue": "CASC", "authors": ["Qiao-Long  Huang", "Xiao-Shan  Gao"], "year": 2017, "n_citations": 7}
{"id": 191571, "s2_id": "0fcf8d05994fb0dce13bd86a304ed110d607761b", "title": "Multistationarity and Bistability for Fewnomial Chemical Reaction Networks", "abstract": "Bistability and multistationarity are properties of reaction networks linked to switch-like responses and connected to cell memory and cell decision making. Determining whether and when a network exhibits bistability is a hard and open mathematical problem. One successful strategy consists of analyzing small networks and deducing that some of the properties are preserved upon passage to the full network. Motivated by this, we study chemical reaction networks with few chemical complexes. Under mass action kinetics, the steady states of these networks are described by fewnomial systems, that is polynomial systems having few distinct monomials. Such systems of polynomials are often studied in real algebraic geometry by the use of Gale dual systems. Using this Gale duality, we give precise conditions in terms of the reaction rate constants for the number and stability of the steady states of families of reaction networks with one non-flow reaction.", "venue": "Bulletin of mathematical biology", "authors": ["Elisenda  Feliu", "Martin  Helmer"], "year": 2019, "n_citations": 5}
{"id": 192184, "s2_id": "04954cc284168a4e4b16610c6221a70b34342005", "title": "A Numerical Algorithm for Zero Counting. I: Complexity and Accuracy", "abstract": "We describe an algorithm to count the number of distinct real zeros of a polynomial (square) system f. The algorithm performs O(log([email\u00a0protected](f))) iterations (grid refinements) where n is the number of polynomials (as well as the dimension of the ambient space), D is a bound on the polynomials' degree, and @k(f) is a condition number for the system. Each iteration uses an exponential number of operations. The algorithm uses finite-precision arithmetic and a major feature of our results is a bound for the precision required to ensure that the returned output is correct which is polynomial in n and D and logarithmic in @k(f). The algorithm parallelizes well in the sense that each iteration can be computed in parallel polynomial time in n, logD and log(@k(f)).", "venue": "J. Complex.", "authors": ["Felipe  Cucker", "Teresa  Krick", "Gregorio  Malajovich", "Mario  Wschebor"], "year": 2008, "n_citations": 37}
{"id": 192479, "s2_id": "ff26330f9eb879cbc94f15c041a29fb64db63546", "title": "Evaluation of binomial double sums involving absolute values", "abstract": "We show that double sums of the form \n \n$$\\displaystyle \\sum _{i,j=-n} ^{n} |i^sj^t(i^k-j^k)^\\beta | \\binom {2n} {n+i} \\binom {2n} {n+j} $$ \n \ncan always be expressed in terms of a linear combination of just four functions, namely \\(\\binom {4n}{2n}\\), \\({\\binom {2n}n}^2\\), \\(4^n\\binom {2n}n\\), and 16n, with coefficients that are rational in n. We provide two different proofs: one is algorithmic and uses the second author\u2019s computer algebra package Sigma; the second is based on complex contour integrals. In many instances, these results are extended to double sums of the above form where \\(\\binom {2n}{n+j}\\) is replaced by \\(\\binom {2m}{m+j}\\) with independent parameter m.", "venue": "ArXiv", "authors": ["Christian  Krattenthaler", "Carsten  Schneider"], "year": 2016, "n_citations": 4}
{"id": 195431, "s2_id": "8a8332a0d82a208aef62bccf5a10d324c98db799", "title": "A new algorithm for irreducible decomposition of representations of finite groups", "abstract": "An algorithm for irreducible decomposition of representations of finite groups over fields of characteristic zero is described. The algorithm uses the fact that the decomposition induces a partition of the invariant inner product into a complete set of mutually orthogonal projectors. By expressing the projectors through the basis elements of the centralizer ring of the representation, the problem is reduced to solving systems of quadratic equations. The current implementation of the algorithm is able to split representations of dimensions up to hundreds of thousands. Examples of calculations are given.", "venue": "Journal of Physics: Conference Series", "authors": ["Vladimir V. Kornyak"], "year": 2019, "n_citations": 3}
{"id": 196180, "s2_id": "6456dbe628cfaaa4fca06182686c6227bee91952", "title": "Regular cylindrical algebraic decomposition", "abstract": "We show that a strong well-based cylindrical algebraic decomposition P of a bounded semi-algebraic set is a regular cell decomposition, in any dimension and independently of the method by which P is constructed. Being well-based is a global condition on P that holds for the output of many widely used algorithms. We also show the same for S of dimension at most 3 and P a strong cylindrical algebraic decomposition that is locally boundary simply connected: this is a purely local extra condition.", "venue": "Journal of the London Mathematical Society", "authors": ["James H. Davenport", "A. F. Locatelli", "G. K. Sankaran"], "year": 2019, "n_citations": 1}
{"id": 201697, "s2_id": "62b1d761efc49a49852d1f13d79f7f94f7a47c71", "title": "MultiplexNet: Towards Fully Satisfied Logical Constraints in Neural Networks", "abstract": "We propose a novel way to incorporate expert knowledge into the training of deep neural networks. Many approaches encode domain constraints directly into the network architecture, requiring non-trivial or domain-specific engineering. In contrast, our approach, called MultiplexNet, represents domain knowledge as a logical formula in disjunctive normal form (DNF) which is easy to encode and to elicit from human experts. It introduces a Categorical latent variable that learns to choose which constraint term optimizes the error function of the network and it compiles the constraints directly into the output of existing learning algorithms. We demonstrate the efficacy of this approach empirically on several classical deep learning tasks, such as density estimation and classification in both supervised and unsupervised settings where prior knowledge about the domains was expressed as logical constraints. Our results show that the MultiplexNet approach learned to approximate unknown distributions well, often requiring fewer data samples than the alternative approaches. In some cases, MultiplexNet finds better solutions than the baselines; or solutions that could not be achieved with the alternative approaches. Our contribution is in encoding domain knowledge in a way that facilitates inference that is shown to be both efficient and general; and critically, our approach guarantees 100% constraint satisfaction in a network\u2019s output.", "venue": "ArXiv", "authors": ["Nicholas  Hoernle", "Rafael-Michael  Karampatsis", "Vaishak  Belle", "Ya'akov  Gal"], "year": 2021, "n_citations": 1}
{"id": 206503, "s2_id": "319f0ab928cbaea2a8fc2adb1ebfda77cddc00c8", "title": "Theorema 2.0: A Graphical User Interface for a Mathematical Assistant System", "abstract": "Theorema2.0stands fora re-designincludinga completere-implementationofthe Theoremasystem,which was originallydesigned, developed,and implementedby Bruno Buchbergerand his Theoremagroup at RISC. In this paper, we present the \ufb01rst prototype of a graphical user interface (GUI) forthe new system. It heavily relies on powerful interactive capabilities introduced in recent releasesof the underlying Mathematica system, most importantly the possibility of having dynamic objectsconnected to interface elements like sliders, menus, check-boxes, radio-buttons and the like. Allthese features are fully integrated into the Mathematica programming environment and allow theimplementation of a modern user interface.", "venue": "UITP", "authors": ["Wolfgang  Windsteiger"], "year": 2012, "n_citations": 21}
{"id": 206906, "s2_id": "10c355180b54fbbab5fd942a5048357f23966643", "title": "Subquadratic-Time Algorithms for Normal Bases", "abstract": "For any finite Galois field extension K/F , with Galois group G = Gal (K/F) , there exists an element $$\\alpha \\in $$ \u03b1 \u2208 K whose orbit $$G\\cdot\\alpha$$ G \u00b7 \u03b1 forms an F -basis of K . Such an $$\\alpha$$ \u03b1 is called a normal element , and $$G\\cdot\\alpha$$ G \u00b7 \u03b1 is a normal basis . We introduce a probabilistic algorithm for testing whether a given $$\\alpha \\in$$ \u03b1 \u2208 K is normal, when G is either a finite abelian or a metacyclic group. The algorithm is based on the fact that deciding whether $$\\alpha$$ \u03b1 is normal can be reduced to deciding whether $$\\sum_{g \\in G} g(\\alpha)g \\in$$ \u2211 g \u2208 G g ( \u03b1 ) g \u2208 K [ G ] is invertible; it requires a slightly subquadratic number of operations. Once we know that $$\\alpha$$ \u03b1 is normal, we show how to perform conversions between the power basis of K/F and the normal basis with the same asymptotic cost.", "venue": "Comput. Complex.", "authors": ["Mark  Giesbrecht", "Armin  Jamshidpey", "\u00c9ric  Schost"], "year": 2021, "n_citations": 1}
{"id": 207397, "s2_id": "ab14f9d6096955cf8ac367909599a7ad6709e9e5", "title": "Freeness and invariants of rational plane curves", "abstract": "Given a parameterization \u03c6 of a rational plane curve C, we study some invariants of C via \u03c6. We first focus on the characterization of rational cuspidal curves, in particular we establish a relation between the discriminant of the pull-back of a line via \u03c6, the dual curve of C and its singular points. Then, by analyzing the pull-backs of the global differential forms via \u03c6, we prove that the (nearly) freeness of a rational curve can be tested by inspecting the Hilbert function of the kernel of a canonical map. As a by product, we also show that the global Tjurina number of a rational curve can be computed directly from one of its parameterization, without relying on the computation of an equation of C.", "venue": "Math. Comput.", "authors": ["Laurent  Bus\u00e9", "Alexandru  Dimca", "Gabriel  Sticlaru"], "year": 2020, "n_citations": 0}
{"id": 212776, "s2_id": "b401b75cd8a539b7f58dba33c1608caeec89c9fe", "title": "An algorithm for computing Grobner basis and the complexity evaluation", "abstract": "In this paper, we suggest a new efficient algorithm in order to compute S-polynomial reduction rapidly in the known algorithm for computing Grobner bases, and compare the complexity with others.", "venue": "ArXiv", "authors": ["Yong-Jin  Kim", "Hyon-Song  Paek", "Nam-Chol  Kim", "Chong-Il  Byon"], "year": 2015, "n_citations": 0}
{"id": 213246, "s2_id": "6c018b1585e015ba5f7803b730414156bec41785", "title": "Effects Without Monads: Non-determinism - Back to the Meta Language", "abstract": "We reflect on programming with complicated effects, recalling an undeservingly forgotten alternative to monadic programming and checking to see how well it can actually work in modern functional languages. We adopt and argue the position of factoring an effectful program into a first-order effectful DSL with a rich, higher-order 'macro' system. Not all programs can be thus factored. Although the approach is not general-purpose, it does admit interesting programs. The effectful DSL is likewise rather problem-specific and lacks general-purpose monadic composition, or even functions. On the upside, it expresses the problem elegantly, is simple to implement and reason about, and lends itself to non-standard interpretations such as code generation (compilation) and abstract interpretation. A specialized DSL is liable to be frequently extended; the experience with the tagless-final style of DSL embedding shown that the DSL evolution can be made painless, with the maximum code reuse. We illustrate the argument on a simple but representative example of a rather complicated effect -- non-determinism, including committed choice. Unexpectedly, it turns out we can write interesting non-deterministic programs in an ML-like language just as naturally and elegantly as in the functional-logic language Curry -- and not only run them but also statically analyze, optimize and compile. The richness of the Meta Language does, in reality, compensate for the simplicity of the effectful DSL. The key idea goes back to the origins of ML as the Meta Language for the Edinburgh LCF theorem prover. Instead of using ML to build theorems, we now build (DSL) programs.", "venue": "ML/OCaml", "authors": ["Oleg  Kiselyov"], "year": 2017, "n_citations": 6}
{"id": 213612, "s2_id": "5fa8a418480972e30476387ed8a065517fd6c5c7", "title": "An Unified Definition of Data Mining", "abstract": "Since many years, theoretical concepts of Data Mining have been developed and improved. Data Mining has become applied to many academic and industrial situations, and recently, soundings of public opinion about privacy have been carried out. However, a consistent and standardized definition is still missing, and the initial explanation given by Frawley et al. has pragmatically often changed over the years. Furthermore, alternative terms like Knowledge Discovery have been conjured and forged, and a necessity of a Data Warehouse has been endeavoured to persuade the users. In this work, we pick up current definitions and introduce an unified definition that covers existing attempted explanations. For this, we appeal to the natural original of chemical states of aggregation.", "venue": "ArXiv", "authors": ["Christoph  Schommer"], "year": 2008, "n_citations": 11}
{"id": 216822, "s2_id": "17a4067700e16f7bdd169093a907d22cbae6814b", "title": "Convergence analysis of particle swarm optimization using stochastic Lyapunov functions and quantifier elimination", "abstract": "This paper adds to the discussion about theoretical aspects of particle swarm stability by proposing to employ stochastic Lyapunov functions and to determine the convergence set by quantifier elimination. We present a computational procedure and show that this approach leads to reevaluation and extension of previously know stability regions for PSO using a Lyapunov approach under stagnation assumptions.", "venue": "ArXiv", "authors": ["Maximilian  Gerwien", "Rick  Vosswinkel", "Hendrik  Richter"], "year": 2020, "n_citations": 1}
{"id": 217558, "s2_id": "cbb185d7e4b5d1e2a6b89f19d1bf91953a0e3bf3", "title": "Visualizing Planar and Space Implicit Real Algebraic Curves with Singularities", "abstract": "This paper presents a new method for visualizing implicit real algebraic curves inside a bounding box in the 2-D or 3-D ambient space based on numerical continuation and critical point methods. The underlying techniques work also for tracing space curve in higher-dimensional space. Since the topology of a curve near a singular point of it is not numerically stable, the authors trace only the curve outside neighborhoods of singular points and replace each neighborhood simply by a point, which produces a polygonal approximation that is e-close to the curve. Such an approximation is more stable for defining the numerical connectedness of the complement of the projection of the curve in \u211d 2 , which is important for applications such as solving bi-parametric polynomial systems. The algorithm starts by computing three types of key points of the curve, namely the intersection of the curve with small spheres centered at singular points, regular critical points of every connected components of the curve, as well as intersection points of the curve with the given bounding box. It then traces the curve starting with and in the order of the above three types of points. This basic scheme is further enhanced by several optimizations, such as grouping singular points in natural clusters, tracing the curve by a try-and-resume strategy and handling \u201cpseudo singular points\u201d. The effectiveness of the algorithm is illustrated by numerous examples. This manuscript extends the proposed preliminary results that appeared in CASC 2018.", "venue": "J. Syst. Sci. Complex.", "authors": ["Changbo  Chen", "Wenyuan  Wu", "Yong  Feng"], "year": 2020, "n_citations": 3}
{"id": 219107, "s2_id": "97fc65fca91c4e1442e14181a12f76b984a9505a", "title": "Bringing Together Dynamic Geometry Software and the Graphics Processing Unit", "abstract": "We equip dynamic geometry software (DGS) with a user-friendly method that enables massively parallel calculations on the graphics processing unit (GPU). This interplay of DGS and GPU opens up various applications in education and mathematical research. The GPU-aided discovery of mathematical properties, interactive visualizations of algebraic surfaces (raycasting), the mathematical deformation of images and footage in real-time, and computationally demanding numerical simulations of PDEs are examples from the long and versatile list of new domains that our approach makes accessible within a DGS. We ease the development of complex (mathematical) visualizations and provide a rapid-prototyping scheme for general-purpose computations (GPGPU). \nThe possibility to program both CPU and GPU with the use of only one high-level (scripting) programming language is a crucial aspect of our concept. We embed shader programming seamlessly within a high-level (scripting) programming environment. The aforementioned requires the symbolic process of the transcompilation of a high-level programming language into shader programming language for GPU and, in this article, we address the challenge of the automatic translation of a high-level programming language to a shader language of the GPU. To maintain platform independence and the possibility to use our technology on modern devices, we focus on a realization through WebGL.", "venue": "ArXiv", "authors": ["Aaron  Montag", "J\u00fcrgen  Richter-Gebert"], "year": 2018, "n_citations": 5}
{"id": 221025, "s2_id": "0748d09d48a98923e88154d7c22e81869b96ace9", "title": "Effective differential Nullstellensatz for ordinary DAE systems with constant coefficients", "abstract": "We give upper bounds for the differential Nullstellensatz in the case of ordinary systems of differential algebraic equations over any field of constants $K$ of characteristic $0$. Let $\\vec{x}$ be a set of $n$ differential variables, $\\vec{f}$ a finite family of differential polynomials in the ring $K\\{\\vec{x}\\}$ and $f\\in K\\{\\vec{x}\\}$ another polynomial which vanishes at every solution of the differential equation system $\\vec{f}=0$ in any differentially closed field containing $K$. Let $d:=\\max\\{\\deg(\\vec{f}), \\deg(f)\\}$ and $\\epsilon:=\\max\\{2,{\\rm{ord}}(\\vec{f}), {\\rm{ord}}(f)\\}$. We show that $f^M$ belongs to the algebraic ideal generated by the successive derivatives of $\\vec{f}$ of order at most $L = (n\\epsilon d)^{2^{c(n\\epsilon)^3}}$, for a suitable universal constant $c>0$, and $M=d^{n(\\epsilon +L+1)}$. The previously known bounds for $L$ and $M$ are not elementary recursive.", "venue": "J. Complex.", "authors": ["Lisi  D'Alfonso", "Gabriela  Jeronimo", "Pablo  Solern\u00f3"], "year": 2014, "n_citations": 17}
{"id": 228686, "s2_id": "4695282c824addc031fee351d71711abb0b7bc2a", "title": "Ranking Facts for Explaining Answers to Elementary Science Questions", "abstract": "In multiple-choice exams, students select one answer from among typically four choices and can explain why they made that particular choice. Students are good at understanding natural language questions and based on their domain knowledge can easily infer the question\u2019s answer by \u2018connecting the dots\u2019 across various pertinent facts. Considering automated reasoning for elementary science question answering (Clark et al. 2018), we address the novel task of generating explanations for answers from human-authored facts (Jansen and Ustalov 2019). For this, we examine the practically scalable framework of feature-rich support vector machines leveraging domain-targeted, hand-crafted features. Explanations are created from a humanannotated set of nearly 5,000 candidate facts in the WorldTree corpus (Jansen et al. 2018). Our aim is to obtain better matches for valid facts of an explanation for the correct answer of a question over the available fact candidates. To this end, our features offer a comprehensive linguistic and semantic unification paradigm. The machine learning problem is the preference ordering of facts, for which we test pointwise regression versus pairwise learning-to-rank. Our contributions, originating from comprehensive evaluations against nine existing systems, are: (1) a case study in which two preference ordering approaches are systematically compared, and where the pointwise approach is shown to outperform the pairwise approach, thus adding to the existing survey of observations (Kamishima et al. 2010; Melnikov et al. 2016) on this topic; (2) since our system outperforms a highly-effective TF-IDF-based IR technique (Chia et al. 2019) by 3.5 and 4.9 points on the development and test sets, respectively, it demonstrates some of the further task improvement possibilities (e.g., in terms of an efficient learning algorithm, semantic features) on this task; (3) it is a practically competent approach that can outperform some variants of BERT-based reranking models (Banerjee 2019; Chia et al. 2019); and (4) the human-engineered features make it an interpretable machine learning model for the task.", "venue": "ArXiv", "authors": ["Jennifer  D'Souza", "Isaiah Onando Mulang'", "Soeren  Auer"], "year": 2021, "n_citations": 0}
{"id": 230674, "s2_id": "e09049cab2dc0523fe111eb22fcb833559181b88", "title": "Harmonic Sums and Polylogarithms Generated by Cyclotomic Polynomials", "abstract": "The computation of Feynman integrals in massive higher order perturbative calculations in renormalizable Quantum Field Theories requires extensions of multiply nested harmonic sums, which can be generated as real representations by Mellin transforms of Poincare- iterated integrals including denominators of higher cyclotomic polynomials. We derive the cyclotomic harmonic polylogarithms and harmonic sums and study their algebraic and structural relations. The analytic continuation of cyclotomic harmonic sums to complex values of N is performed using analytic representations. We also consider special values of the cyclotomic harmonic polylogarithms at argument x = 1, resp., for the cyclotomic harmonic sums at N \u2192 \u221e, which are related to colored multiple zeta values, deriving various of their relations, based on the stuffle and shuffle alge bras and three multiple ar- gument relations. We also consider infinite generalized nested harmonic sums at roots of unity which are related to the infinite cyclotomic harmonic sums. Basis representations are derived for weight w = 1,2 sums up to cyclotomy l = 20.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein", "Carsten  Schneider"], "year": 2011, "n_citations": 235}
{"id": 232679, "s2_id": "2f186913ae49aa9fb9c15e4e02235e530230d527", "title": "On rational definite summation", "abstract": "We present a partial proof of van Hoeij-Abramov conjecture about the algorithmic possibility of computation of finite sums of rational functions. The theoretical results proved in this paper provide an algorithm for computation of a large class of sums $ S(n) = \\sum_{k=0}^{n-1}R(k,n)$.", "venue": "ArXiv", "authors": ["Sergey P. Tsarev"], "year": 2004, "n_citations": 0}
{"id": 233787, "s2_id": "4893d49e2dcd87a2c9ac43463f61e6816f819c65", "title": "On Newton\u2013Raphson Iteration for Multiplicative Inverses Modulo Prime Powers", "abstract": "We study algorithms for the fast computation of modular inverses. Newton-Raphson iteration over p-adic numbers gives a recurrence relation computing modular inverse modulo pm, that is logarithmic in m. We solve the recurrence to obtain an explicit formula for the inverse. Then, we study different implementation variants of this iteration and show that our explicit formula is interesting for small exponent values but slower or large exponent, say of more than 700 bits. Overall, we thus propose a hybrid combination of our explicit formula and the best asymptotic variants. This hybrid combination yields then a constant factor improvement, also for large exponents.", "venue": "IEEE Transactions on Computers", "authors": ["Jean-Guillaume  Dumas"], "year": 2014, "n_citations": 12}
{"id": 251543, "s2_id": "864726301629a48553432de0a3f2d546a77ffcfd", "title": "Root Refinement for Real Polynomials", "abstract": "We consider the problem of approximating all real roots of a square-free polynomial $f$. Given isolating intervals, our algorithm refines each of them to a width of $2^{-L}$ or less, that is, each of the roots is approximated to $L$ bits after the binary point. Our method provides a certified answer for arbitrary real polynomials, only considering finite approximations of the polynomial coefficients and choosing a suitable working precision adaptively. In this way, we get a correct algorithm that is simple to implement and practically efficient. Our algorithm uses the quadratic interval refinement method; we adapt that method to be able to cope with inaccuracies when evaluating $f$, without sacrificing its quadratic convergence behavior. We prove a bound on the bit complexity of our algorithm in terms of the degree of the polynomial, the size and the separation of the roots, that is, parameters exclusively related to the geometric location of the roots. Our bound is near optimal and significantly improves previous work on integer polynomials. Furthermore, it essentially matches the best known theoretical bounds on root approximation which are obtained by very sophisticated algorithms. We also investigate the practical behavior of the algorithm and demonstrate how closely the practical performance matches our asymptotic bounds.", "venue": "ArXiv", "authors": ["Michael  Kerber", "Michael  Sagraloff"], "year": 2011, "n_citations": 5}
{"id": 252374, "s2_id": "4f1a372c735bff678827fcb70d66b640c6c24597", "title": "Castelnuovo\u2013Mumford Regularity and Computing the de Rham Cohomology of Smooth Projective Varieties", "abstract": "We describe a parallel polynomial time algorithm for computing the topological Betti numbers of a smooth complex projective variety X. It is the first single exponential time algorithm for computing the Betti numbers of a significant class of complex varieties of arbitrary dimension. Our main theoretical result is that the Castelnuovo\u2013Mumford regularity of the sheaf of differential p-forms on X is bounded by\u00a0p(em+1)D, where e, m, and D are the maximal codimension, dimension, and degree, respectively, of all irreducible components of X. It follows that, for a union V of generic hyperplane sections in X, the algebraic de Rham cohomology of X\u2216V is described by differential forms with poles along V of single exponential order. By covering X with sets of this type and using a \u010cech process, we obtain a similar description of the de Rham cohomology of\u00a0X, which allows its efficient computation. Furthermore, we give a parallel polynomial time algorithm for testing whether a projective variety is smooth.", "venue": "Found. Comput. Math.", "authors": ["Peter  Scheiblechner"], "year": 2012, "n_citations": 9}
{"id": 261135, "s2_id": "667c847510693f536fa2186bbdf4f4be1dbfbaa9", "title": "Real root finding for low rank linear matrices", "abstract": "We consider $$m \\times s$$ m \u00d7 s matrices (with $$m\\ge s$$ m \u2265 s ) in a real affine subspace of dimension n . The problem of finding elements of low rank in such spaces finds many applications in information and systems theory, where low rank is synonymous of structure and parsimony. We design computer algebra algorithms, based on advanced methods for polynomial system solving, to solve this problem efficiently and exactly: the input are the rational coefficients of the matrices spanning the affine subspace as well as the expected maximum rank, and the output is a rational parametrization encoding a finite set of points that intersects each connected component of the low rank real algebraic set. The complexity of our algorithm is studied thoroughly. It is polynomial in $$\\left( {\\begin{array}{c}n+m(s-r)\\\\ n\\end{array}}\\right) $$ n + m ( s - r ) n . It improves on the state-of-the-art in computer algebra and effective real algebraic geometry. Moreover, computer experiments show the practical efficiency of our approach.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2019, "n_citations": 1}
{"id": 263280, "s2_id": "4ecc68bcec0ffbb1f0e32ff7728f58fac2a04498", "title": "Efficiently and Effectively Recognizing Toricity of Steady State Varieties", "abstract": "We consider the problem of testing whether the points in a complex or real variety with non-zero coordinates form a multiplicative group or, more generally, a coset of a multiplicative group. For the coset case, we study the notion of shifted toric varieties which generalizes the notion of toric varieties. This requires a geometric view on the varieties rather than an algebraic view on the ideals. We present algorithms and computations on 129 models from the BioModels repository testing for group and coset structures over both the complex numbers and the real numbers. Our methods over the complex numbers are based on Grobner basis techniques and binomiality tests. Over the real numbers we use first-order characterizations and employ real quantifier elimination. In combination with suitable prime decompositions and restrictions to subspaces it turns out that almost all models show coset structure. Beyond our practical computations, we give upper bounds on the asymptotic worst-case complexity of the corresponding problems by proposing single exponential algorithms that test complex or real varieties for toricity or shifted toricity. In the positive case, these algorithms produce generating binomials. In addition, we propose an asymptotically fast algorithm for testing membership in a binomial variety over the algebraic closure of the rational numbers.", "venue": "Math. Comput. Sci.", "authors": ["Dima  Grigoriev", "Alexandru  Iosif", "Hamid  Rahkooy", "Thomas  Sturm", "Andreas  Weber"], "year": 2021, "n_citations": 6}
{"id": 265895, "s2_id": "d632e7ffadb4d2eb32516176e1d1e42d353f559e", "title": "OpenMath and SMT-LIB", "abstract": "OpenMath and SMT-LIB are languages with very different origins, but both \"represent mathematics\". We describe SMT-LIB for the OpenMath community and consider adaptations for both languages to support the growing SC-Square initiative.", "venue": "ArXiv", "authors": ["James H. Davenport", "Matthew  England", "Roberto  Sebastiani", "Patrick  Trentin"], "year": 2018, "n_citations": 0}
{"id": 268041, "s2_id": "eaefb66b37142df6be047d6a5f310ae63391503b", "title": "Bounds for Substituting Algebraic Functions into D-finite Functions", "abstract": "It is well known that the composition of a D-finite function with an algebraic function is again D-finite. We give the first estimates for the orders and the degrees of annihilating operators for the compositions. We find that the analysis of removable singularities leads to an order-degree curve which is much more accurate than the order-degree curve obtained from the usual linear algebra reasoning.", "venue": "ISSAC", "authors": ["Manuel  Kauers", "Gleb  Pogudin"], "year": 2017, "n_citations": 1}
{"id": 270945, "s2_id": "124ec0fb2778118bc44d80137606e9a26fab0141", "title": "Symbolic Solutions of Simultaneous First-order PDEs in One Unknown", "abstract": "We propose and implement an algorithm for solving an overdetermined system of partial differential equations in one unknown. Our approach relies on Bour-Mayer method to determine compatibility conditions via Jacobi-Mayer brackets. We solve compatible systems recursively by imitating what one would do with pen and paper: Solve one equation, substitute the solution into the remaining equations and iterate the process until the equations of the system are exhausted. The method we employ for assessing the consistency of the underlying system differs from the traditional use of differential Gr\\\"obner bases yet seems more efficient and straightforward to implement. We are not aware of a computer algebra system that adopts the procedure we advocate in this work.", "venue": "ArXiv", "authors": ["C\u00e9lestin Wafo Soh"], "year": 2017, "n_citations": 0}
{"id": 273622, "s2_id": "499d949a497c9d55fb6d5651538f9a16777f5e5b", "title": "A Case Study for $$\\zeta (4)$$", "abstract": "Using symbolic summation tools in the setting of difference rings, we prove a two-parametric identity that relates rational approximations to $\\zeta(4)$.", "venue": "Transcendence in Algebra, Combinatorics, Geometry and Number Theory", "authors": ["Carsten  Schneider", "Wadim  Zudilin"], "year": 2021, "n_citations": 0}
{"id": 276099, "s2_id": "72e5532bf27171070e40e24daee4b6d855acc5ff", "title": "Transforming ODEs and PDEs with radical coefficients into rational coefficients", "abstract": "We present an algorithm that transforms, if possible, a given ODE or PDE with radical function coefficients into one with rational coefficients by means of a rational change of variables. It also applies to systems of linear ODEs. It is based on previous work on reparametrization of radical algebraic varieties.", "venue": "ArXiv", "authors": ["Jorge  Caravantes", "J. Rafael Sendra", "David  Sevilla", "Carlos  Villarino"], "year": 2020, "n_citations": 0}
{"id": 281355, "s2_id": "2db95d5639a13035a35934691d7521a376189c46", "title": "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual\" from \"Reasoning\"", "abstract": "Visual reasoning tasks such as visual question answering (VQA) require an interplay of visual perception with reasoning about the question semantics grounded in perception. Various benchmarks for reasoning across language and vision like VQA, VCR and more recently GQA for compositional question answering facilitate scientific progress from perception models to visual reasoning. However, recent advances are still primarily driven by perception improvements (e.g. scene graph generation) rather than reasoning. Neuro-symbolic models such as Neural Module Networks bring the benefits of compositional reasoning to VQA, but they are still entangled with visual representation learning, and thus neural reasoning is hard to improve and assess on its own. To address this, we propose (1) a framework to isolate and evaluate the reasoning aspect of VQA separately from its perception, and (2) a novel top-down calibration technique that allows the model to answer reasoning questions even with imperfect perception. To this end, we introduce a differentiable first-order logic formalism for VQA that explicitly decouples question answering from visual perception. On the challenging GQA dataset, this framework is used to perform in-depth, disentangled comparisons between well-known VQA models leading to informative insights regarding the participating models as well as the task.", "venue": "ICML", "authors": ["Saeed  Amizadeh", "Hamid  Palangi", "Oleksandr  Polozov", "Yichen  Huang", "Kazuhito  Koishida"], "year": 2020, "n_citations": 22}
{"id": 282278, "s2_id": "4f7676eefb5b374abc9e7c76e805dce301c3acd3", "title": "The implicit equation of a canal surface", "abstract": "A canal surface is an envelope of a one-parameter family of spheres. In this paper we present an efficient algorithm for computing the implicit equation of a canal surface generated by a rational family of spheres. By using Laguerre and Lie geometries, we relate the equation of the canal surface to the equation of a dual variety of a certain curve in 5-dimensional projective space. We define the @m-basis for arbitrary dimension and give a simple algorithm for its computation. This is then applied to the dual variety, which allows us to deduce the implicit equations of the dual variety, the canal surface and any offset to the canal surface.", "venue": "J. Symb. Comput.", "authors": ["Marc  Dohm", "Severinas  Zube"], "year": 2009, "n_citations": 18}
{"id": 282585, "s2_id": "b822eeb47ed3c4310c4d776c66bbc7d5e5622775", "title": "TCTL Inevitability Analysis of Dense-Time Systems", "abstract": "Inevitability properties in branching temporal logics are of the syntax \u2200\u25ca\u03c6, where \u03c6 is an arbitrary (timed) CTL formula. Such inevitability properties in dense-time logics can be analyzed with greatest fixpoint calculation. We present algorithms to model-check inevitability properties both with and without non-Zeno computation requirement. We discuss a technique for early decision on greatest fixpoint calculation. Our algorithms come with a d-parameter for the measurement of timeprogress. We have experimented with various issues, which may affect the performance of TCTL inevitability analysis. Specifically, we report the performance of our implementation w.r.t. various d-parameter values and with or without the non-Zeno computation requirement in the evaluation of greatest fixpoints. We have also experimented with safe abstration techniques for model-checking TCTL inevitability properties. Analysis of experiment data helps clarify how various techniques can be used to improve verification of inevitability properties.", "venue": "CIAA", "authors": ["Farn  Wang", "Geng-Dian  Hwang", "Fang  Yu"], "year": 2003, "n_citations": 14}
{"id": 288111, "s2_id": "53d46c97ed47687ece94c07f6647f766892a930f", "title": "Faster Sparse Interpolation of Straight-Line Programs", "abstract": "We give a new probabilistic algorithm for interpolating a \"sparse\" polynomial f given by a straight-line program. Our algorithm constructs an approximation f * of f, such that f '\u2014' f * probably has at most half the number of terms of f, then recurses on the difference f '\u2014' f *. Our approach builds on previous work by Garg and Schost (2009), and Giesbrecht and Roche (2011), and is asymptotically more efficient in terms of the total cost of the probes required than previous methods, in many cases.", "venue": "CASC", "authors": ["Andrew  Arnold", "Mark  Giesbrecht", "Daniel S. Roche"], "year": 2013, "n_citations": 21}
{"id": 291541, "s2_id": "d57f2fe2f58031ef98561de38791677ec54a4d1e", "title": "Computation of unirational fields (extended abstract)", "abstract": "In this paper we present an algorithm for computing all algebraic intermediate subfields in a separably generated unirational field extension (which in particular includes the zero characteristic case). One of the main tools is Groebner bases theory. Our algorithm also requires computing computing primitive elements and factoring over algebraic extensions. Moreover, the method can be extended to finitely generated K-algebras.", "venue": "ArXiv", "authors": ["Jaime  Gutierrez", "David  Sevilla"], "year": 2008, "n_citations": 0}
{"id": 298407, "s2_id": "87cf95837caa79df66a5f014dfa8bf5bd2102293", "title": "Functional framework for representing and transforming quantum channels", "abstract": "We develop a framework which aims to simplify the analysis of quantum states and quantum operations by harnessing the potential of function programming paradigm. We show that the introduced framework allows a seamless manipulation of quantum channels, in particular to convert between different representations of quantum channels, and thus that the use of functional programming concepts facilitates the manipulation of abstract objects used in the language of quantum theory. \nFor the purpose of our presentation we will use Mathematica computer algebra system. This choice is motivated twofold. First, it offers a rich programming language based on the functional paradigm. Second, this programming language is combined with powerful symbolic and numeric manipulation capabilities.", "venue": "ArXiv", "authors": ["Jaroslaw Adam Miszczak"], "year": 2013, "n_citations": 1}
{"id": 309703, "s2_id": "faf860e256d288f9e53d66d96d80079e5a411ffa", "title": "Computing critical points for invariant algebraic systems", "abstract": "Let $\\KK$ be a field and $\\phi$, $\\f = (f_1, \\ldots, f_s)$ in $\\KK[x_1, \\dots, \n x_n]$ be multivariate polynomials (with $s < n$) invariant under the action of \n $\\Sc_n$, the group of permutations of $\\{1, \\dots, n\\}$. We consider the \n problem of computing the points at which $\\f$ vanish and the Jacobian matrix \n associated to $\\f, \\phi$ is rank deficient provided that this set is finite. \n We exploit the invariance properties of the input to split the \n solution space according to the orbits of $\\Sc_n$. This allows us \n to design an algorithm which gives a triangular description of the \n solution space and which runs in time polynomial in $d^s$, \n ${{n+d}\\choose{d}}$ and $\\binom{n}{s+1}$ where $d$ is the maximum \n degree of the input polynomials. When $d,s$ are fixed, this is \n polynomial in $n$ while when $s$ is fixed and $d \\simeq n$ this \n yields an exponential speed-up with respect to the usual polynomial \n system solving algorithms.", "venue": "ArXiv", "authors": ["Jean-Charles  Faug\u00e8re", "George  Labahn", "Mohab Safey El Din", "\u00c9ric  Schost", "Thi Xuan Vu"], "year": 2020, "n_citations": 2}
{"id": 313470, "s2_id": "37038930c5b8c773728ee75531c44b9c7527f687", "title": "Complexity Estimates for Fourier-Motzkin Elimination", "abstract": "In this paper, we propose a new method for removing all the redundant inequalities generated by Fourier-Motzkin elimination. This method is based on an improved version of Balas' work and can also be used to remove all the redundant inequalities in the input system. Moreover, our method only uses arithmetic operations on matrices and avoids resorting to linear programming techniques. Algebraic complexity estimates and experimental results show that our method outperforms alternative approaches, in particular those based on linear programming and simplex algorithm.", "venue": "CASC", "authors": ["Rui-Juan  Jing", "Marc Moreno Maza", "Delaram  Talaashrafi"], "year": 2020, "n_citations": 2}
{"id": 320609, "s2_id": "6a4dfd7abb4f8e1263be4ea97e2d4ce1e7c7e73c", "title": "Recognizing implicitly given rational canal surfaces", "abstract": "It is still a challenging task of today to recognize the type of a given algebraic surface which is described only by its implicit representation. In~this paper we will investigate in more detail the case of canal surfaces that are often used in geometric modelling, Computer-Aided Design and technical practice (e.g. as blending surfaces smoothly joining two parts with circular ends). It is known that if the squared medial axis transform is a rational curve then so is also the corresponding surface. However, starting from a polynomial it is not known how to decide if the corresponding algebraic surface is rational canal surface or not. Our goal is to formulate a simple and efficient algorithm whose input is a~polynomial with the coefficients from some subfield of real numbers and the output is the answer whether the surface is a rational canal surface. In the affirmative case we also compute a rational parameterization of the squared medial axis transform which can be then used for finding a rational parameterization of the implicitly given canal surface.", "venue": "J. Symb. Comput.", "authors": ["Jan  Vrsek", "Miroslav  L\u00e1vicka"], "year": 2016, "n_citations": 3}
{"id": 322778, "s2_id": "f007fa8a3795f33fa29c23452c3bf31676535252", "title": "Need Polynomial Systems Be Doubly-Exponential?", "abstract": "Polynomial Systems, or at least their algorithms, have the reputation of being doubly-exponential in the number of variables [Mayr and Mayer, 1982], [Davenport and Heintz, 1988]. Nevertheless, the Bezout bound tells us that that number of zeros of a zero-dimensional system is singly-exponential in the number of variables. How should this contradiction be reconciled? \nWe first note that [Mayr and Ritscher, 2013] shows that the doubly exponential nature of Gr\\\"{o}bner bases is with respect to the dimension of the ideal, not the number of variables. This inspires us to consider what can be done for Cylindrical Algebraic Decomposition which produces a doubly-exponential number of polynomials of doubly-exponential degree. \nWe review work from ISSAC 2015 which showed the number of polynomials could be restricted to doubly-exponential in the (complex) dimension using McCallum's theory of reduced projection in the presence of equational constraints. We then discuss preliminary results showing the same for the degree of those polynomials. The results are under primitivity assumptions whose importance we illustrate.", "venue": "ICMS", "authors": ["James H. Davenport", "Matthew  England"], "year": 2016, "n_citations": 7}
{"id": 323886, "s2_id": "64494f19df28de5a65cb7700757898777efebedf", "title": "The module isomorphism problem for finite rings and related results", "abstract": "Let R be a finite ring and let M,N be two finite left R-modules. We present two distinct deterministic algorithms that decide in polynomial time whether or not M and N are isomorphic, and if they are, exhibit an isomorphism. As by-products, we are able to determine the largest isomorphic common direct summand between two modules and the minimum number of generators of a module. By not requiring R to contain a field, avoiding computation of the Jacobson radical and not distinguishing between large and small characteristic, both algorithms constitute improvements to known results. We have not attempted to implement either of the two algorithms, but have no reason to believe they would not perform well in practice. Moreover, the second algorithm represents an interesting object per se, due to its structure and the techniques it employs. A common approach to this type of problems is to reduce to the semisimple case and then \u201clift\u201d. In our algorithm, we work as if the ring were semisimple and we have a list, S1, . . . , St, of candidates for the isomorphism classes of simple modules composing it. During the running of the algorithm, we allow ourselves to be contradicted in our assumption about the simplicity of the Si, in which case we update our list, quotient the ring by an appropriate two-sided nilpotent ideal and start again. If we are not contradicted, we may still draw conclusions. In this way, there is always a side-exit available and what forces an output in polynomial time is that we cannot take the side-exit too many times.", "venue": "ACCA", "authors": ["Iuliana Ciocanea Teodorescu"], "year": 2015, "n_citations": 1}
{"id": 329381, "s2_id": "94df2bfb711b017a9b83177c21cfaeecebbf58b0", "title": "On the computation of the HNF of a module over the ring of integers of a number field", "abstract": "Abstract We present a variation of the modular algorithm for computing the Hermite normal form of an O K -module presented by Cohen (1996) , where O K is the ring of integers of a number field K. An approach presented in Cohen (1996) based on reductions modulo ideals was conjectured to run in polynomial time by Cohen, but so far, no such proof was available in the literature. In this paper, we present a modification of the approach of Cohen (1996) to prevent the coefficient swell and we rigorously assess its complexity with respect to the size of the input and the invariants of the field K.", "venue": "J. Symb. Comput.", "authors": ["Jean-Fran\u00e7ois  Biasse", "Claus  Fieker", "Tommy  Hofmann"], "year": 2017, "n_citations": 13}
{"id": 338022, "s2_id": "fd284aca2429ce5807aec701b1594e71182c1341", "title": "Efficient edge-skeleton computation for polytopes defined by oracles", "abstract": "In general dimension, there is no known total polynomial algorithm for either convex hull or vertex enumeration, i.e. an algorithm whose complexity depends polynomially on the input and output sizes. It is thus important to identify problems and polytope representations for which total polynomial-time algorithms can be obtained. We offer the first total polynomial-time algorithm for computing the edge-skeleton-including vertex enumeration-of a polytope given by an optimization or separation oracle, where we are also given a superset of its edge directions. We also offer a space-efficient variant of our algorithm by employing reverse search. All complexity bounds refer to the (oracle) Turing machine model. There is a number of polytope classes naturally defined by oracles; for some of them neither vertex nor facet representation is obvious. We consider two main applications, where we obtain (weakly) total polynomial-time algorithms: Signed Minkowski sums of convex polytopes, where polytopes can be subtracted provided the signed sum is a convex polytope, and computation of secondary, resultant, and discriminant polytopes. Further applications include convex combinatorial optimization and convex integer programming, where we offer a new approach, thus removing the complexity's exponential dependence in the dimension.", "venue": "J. Symb. Comput.", "authors": ["Ioannis Z. Emiris", "Vissarion  Fisikopoulos", "Bernd  G\u00e4rtner"], "year": 2016, "n_citations": 8}
{"id": 338513, "s2_id": "573346e895bc5305a8e708d421dad801c67c91a8", "title": "Diagonal asymptotics for symmetric rational functions via ACSV", "abstract": "We consider asymptotics of power series coefficients of rational functions of the form $1/Q$ where $Q$ is a symmetric multilinear polynomial. We review a number of such cases from the literature, chiefly concerned either with positivity of coefficients or diagonal asymptotics. We then analyze coefficient asymptotics using ACSV (Analytic Combinatorics in Several Variables) methods. While ACSV sometimes requires considerable overhead and geometric computation, in the case of symmetric multilinear rational functions there are some reductions that streamline the analysis. Our results include diagonal asymptotics across entire classes of functions, for example the general 3-variable case and the Gillis-Reznick-Zeilberger (GRZ) case, where the denominator in terms of elementary symmetric functions is $1 - e_1 + c e_d$ in any number $d$ of variables. The ACSV analysis also explains a discontinuous drop in exponential growth rate for the GRZ class at the parameter value $c = (d-1)^{d-1}$, previously observed for $d=4$ only by separately computing diagonal recurrences for critical and noncritical values of $c$.", "venue": "AofA", "authors": ["Yuliy  Baryshnikov", "Stephen  Melczer", "Robin  Pemantle", "Armin  Straub"], "year": 2018, "n_citations": 8}
{"id": 339980, "s2_id": "a31e6460c3e4cdb76dcc900f095210cae8f5ba4a", "title": "Comprehensive Optimization of Parametric Kernels for Graphics Processing Units", "abstract": "This work deals with the optimization of computer programs targeting Graphics Processing Units (GPUs). The goal is to lift, from programmers to optimizing compilers, the heavy burden of determining program details that are dependent on the hardware characteristics. The expected benefit is to improve robustness, portability and efficiency of the generated computer programs. We address these requirements by: (1) treating machine and program parameters as unknown symbols during code generation, and (2) generating optimized programs in the form of a case discussion, based on the possible values of the machine and program parameters. By taking advantage of recent advances in the area of computer algebra, preliminary experimentation yield promising results.", "venue": "ArXiv", "authors": ["Xiaohui  Chen", "Marc Moreno Maza", "Jeeva  Paudel", "Ning  Xie"], "year": 2018, "n_citations": 0}
{"id": 342534, "s2_id": "452a11ac25cbe110ba068a7be3a0ca9154866e66", "title": "Fast Computation of Shifted Popov Forms of Polynomial Matrices via Systems of Modular Polynomial Equations", "abstract": "We give a Las Vegas algorithm which computes the shifted Popov form of an m x m nonsingular polynomial matrix of degree d in expected ~O(m\u03c9 d) field operations, where \u03c9 is the exponent of matrix multiplication and ~O(\u00b7) indicates that logarithmic factors are omitted. This is the first algorithm in ~O(m\u03c9 d) for shifted row reduction with arbitrary shifts. Using partial linearization, we reduce the problem to the case d \u2264 \u2308 \u03c3/m \u2309 where \u03c3 is the generic determinant bound, with \u03c3 / m bounded from above by both the average row degree and the average column degree of the matrix. The cost above becomes ~O(m\u03c9 \u2308 \u03c3/m \u2309), improving upon the cost of the fastest previously known algorithm for row reduction, which is deterministic. Our algorithm first builds a system of modular equations whose solution set is the row space of the input matrix, and then finds the basis in shifted Popov form of this set. We give a deterministic algorithm for this second step supporting arbitrary moduli in ~O(m\u03c9-1 \u03c3) field operations, where m is the number of unknowns and \u03c3 is the sum of the degrees of the moduli. This extends previous results with the same cost bound in the specific cases of order basis computation and M-Pade approximation, in which the moduli are products of known linear factors.", "venue": "ISSAC", "authors": ["Vincent  Neiger"], "year": 2016, "n_citations": 19}
{"id": 343940, "s2_id": "058502a7737573d4bc2c293dbf676168c8eeb628", "title": "Extension of the functionality of the symbolic program FORM by external software", "abstract": "We describe the implementation of facilities for the communication with external resources in the Symbolic Manipulation System FORM. This is done according to the POSIX standards defined for the UNIX operating system. We present a number of examples that illustrate the increased power due to these new capabilities.", "venue": "Comput. Phys. Commun.", "authors": ["M.  Tentyukov", "J. A. M. Vermaseren"], "year": 2007, "n_citations": 26}
{"id": 352466, "s2_id": "c3f9c4550099332fe95d64781bbf83cbb725e947", "title": "Time and space efficient generators for quasiseparable matrices", "abstract": "The class of quasiseparable matrices is defined by the property that any submatrix entirely below or above the main diagonal has small rank, namely below a bound called the order of quasiseparability. These matrices arise naturally in solving PDE's for particle interaction with the Fast Multi-pole Method (FMM), or computing generalized eigenvalues. From these application fields, structured representations and algorithms have been designed in numerical linear algebra to compute with these matrices in time linear in the matrix dimension and either quadratic or cubic in the quasiseparability order. Motivated by the design of the general purpose exact linear algebra library LinBox, and by algorithmic applications in algebraic computing, we adapt existing techniques introduce novel ones to use quasiseparable matrices in exact linear algebra, where sub-cubic matrix arithmetic is available. In particular, we will show, the connection between the notion of quasiseparability and the rank profile matrix invariant, that we have introduced in 2015. It results in two new structured representations, one being a simpler variation on the hierarchically semiseparable storage, and the second one exploiting the generalized Bruhat decomposition. As a consequence, most basic operations, such as computing the quasiseparability orders, applying a vector, a block vector, multiplying two quasiseparable matrices together, inverting a quasiseparable matrix, can be at least as fast and often faster than previous existing algorithms.", "venue": "J. Symb. Comput.", "authors": ["Cl\u00e9ment  Pernet", "Arne  Storjohann"], "year": 2018, "n_citations": 8}
{"id": 354361, "s2_id": "d1dd18173d3e6dfb6d872cfa93066ab741e8423d", "title": "On affine tropical F5 algorithms", "abstract": "Let K be a field equipped with a valuation. Tropical varieties over K can be defined with a theory of Grobner bases taking into account the valuation of K. Because of the use of the valuation, the theory of tropical Grobner bases has proved to provide settings for computations over polynomial rings over a p-adic field that are more stable than that of classical Grobner bases. Beforehand, these strategies were only available for homogeneous polynomi-als. In this article, we extend the F5 strategy to a new definition of tropical Grobner bases in an affine setting. We also provide a competitor with an adaptation of the F4 strategy to tropical Grobner bases computations. We provide numerical examples to illustrate time-complexity and p-adic stability of this tropical F5 algorithm. We also illustrate its merits as a first step before an FGLM algorithm to compute (classical) lex bases over p-adics. \nThis article is an extended version of: https://hal.archives-ouvertes.fr/hal-01792165", "venue": "J. Symb. Comput.", "authors": ["Tristan  Vaccon", "Thibaut  Verron", "Kazuhiro  Yokoyama"], "year": 2021, "n_citations": 1}
{"id": 356084, "s2_id": "fedeb25c204829de3de89dee89cd3b416af9154e", "title": "Deeply Integrating C11 Code Support into Isabelle/PIDE", "abstract": "We present a framework for C code in C11 syntax deeply integrated into the Isabelle/PIDE development environment. Our framework provides an abstract interface for verification back-ends to be plugged-in independently. Thus, various techniques such as deductive program verification or white-box testing can be applied to the same source, which is part of an integrated PIDE document model. Semantic back-ends are free to choose the supported C fragment and its semantics. In particular, they can differ on the chosen memory model or the specification mechanism for framing conditions. \nOur framework supports semantic annotations of C sources in the form of comments. Annotations serve to locally control back-end settings, and can express the term focus to which an annotation refers. Both the logical and the syntactic context are available when semantic annotations are evaluated. As a consequence, a formula in an annotation can refer both to HOL or C variables. \nOur approach demonstrates the degree of maturity and expressive power the Isabelle/PIDE subsystem has achieved in recent years. Our integration technique employs Lex and Yacc style grammars to ensure efficient deterministic parsing. We present two case studies for the integration of (known) semantic back-ends in order to validate the design decisions for our back-end interface.", "venue": "F-IDE@FM", "authors": ["F.  Tuong", "B.  Wolff"], "year": 2019, "n_citations": 5}
{"id": 357648, "s2_id": "8cafad1eb93ee9a9654db0452b5e2f1bed393730", "title": "Faster Tensor Canonicalization", "abstract": "Abstract The Butler\u2013Portugal algorithm for obtaining the canonical form of a tensor expression, by permuting its n index labels with respect to slot symmetries and dummy-index renaming, suffers, in certain cases with a high degree of symmetry, from O ( n ! ) explosion in both computation time and memory. We present a modified algorithm which alleviates this problem in the most common cases \u2013 tensor expressions with subsets of indices which are totally symmetric or totally antisymmetric \u2013 in polynomial time. We also present an implementation of the label-renaming mechanism which improves upon that of the original Butler\u2013Portugal algorithm, thus providing a significant speed increase for the average case as well as the highly-symmetric special case. The worst-case behavior remains O ( n ! ) , although it occurs in more limited situations less likely to appear in actual computations. We comment on possible strategies to take if the nature of a computation should make these situations more likely.", "venue": "Comput. Phys. Commun.", "authors": ["Benjamin E. Niehoff"], "year": 2018, "n_citations": 3}
{"id": 361954, "s2_id": "197648edf602c8726fee32bca0d1a0d68e608204", "title": "Arjun: An Efficient Independent Support Computation Technique and its Applications to Counting and Sampling", "abstract": "Given a Boolean formula \u03c6 over the set of variables X and a projection set P \u2286 X, a subset of variables I is independent support of P if two solutions agree on I, then they also agree on P . The notion of independent support is related to the classical notion of definability dating back to 1901, and have been studied over the decades. Recently, the computational problem of determining independent support for a given formula has attained importance owing to the crucial importance of independent support for hashing-based counting and sampling techniques. In this paper, we design an efficient and scalable independent support computation technique that can handle formulas arising from real-world benchmarks. Our algorithmic framework, called Arjun, employs implicit and explicit definability notions, and is based on a tight integration of gate-identification techniques and assumption-based framework. We demonstrate that augmenting the state of the art model counter ApproxMC4 and sampler UniGen3 with Arjun leads to significant performance improvements. In particular, ApproxMC4 augmented with Arjun counts 387 more benchmarks out of 1896 while UniGen3 augmented with Arjun samples 319 more benchmarks within the same time limit.", "venue": "ArXiv", "authors": ["Mate  Soos", "Kuldeep S. Meel"], "year": 2021, "n_citations": 1}
{"id": 364083, "s2_id": "16196feaaa5d8d5ae5236cbfefc141687c58adb7", "title": "Algorithm to enumerate superspecial Howe curves of genus 4", "abstract": "A Howe curve is a curve of genus $4$ obtained as the fiber product over $\\mathbf{P}^1$ of two elliptic curves. Any Howe curve is canonical. This paper provides an efficient algorithm to find superspecial Howe curves and that to enumerate their isomorphism classes. We discuss not only an algorithm to test the superspeciality but also an algorithm to test isomorphisms for Howe curves. Our algorithms are much more efficient than conventional ones proposed by the authors so far for general canonical curves. We show the existence of a superspecial Howe curve in characteristic $7<p\\le 331$ and enumerate the isomorphism classes of superspecial Howe curves in characteristic $p\\le 53$, by executing our algorithms over the computer algebra system Magma.", "venue": "Open Book Series", "authors": ["Momonari  Kudo", "Shushi  Harashita"], "year": 2020, "n_citations": 0}
{"id": 364426, "s2_id": "ae2a9ee66691e2b5f41432f1c20152ba5483e2bb", "title": "The Complexity of Cylindrical Algebraic Decomposition with Respect to Polynomial Degree", "abstract": "Cylindrical algebraic decomposition (CAD) is an important tool for working with polynomial systems, particularly quantifier elimination. However, it has complexity doubly exponential in the number of variables. The base algorithm can be improved by adapting to take advantage of any equational constraints (ECs): equations logically implied by the input. Intuitively, we expect the double exponent in the complexity to decrease by one for each EC. In ISSAC 2015 the present authors proved this for the factor in the complexity bound dependent on the number of polynomials in the input. However, the other term, that dependent on the degree of the input polynomials, remained unchanged.", "venue": "CASC", "authors": ["Matthew  England", "James H. Davenport"], "year": 2016, "n_citations": 22}
{"id": 365501, "s2_id": "eba2e3cb226ead8c990ccd75932a261b03404ba6", "title": "Composing and Factoring Generalized Green's Operators and Ordinary Boundary Problems", "abstract": "We consider solution operators of linear ordinary boundary problems with \u201ctoo many\u201d boundary conditions, which are not always solvable. These generalized Green\u2019s operators are a certain kind of generalized inverses of differential operators. We answer the question when the product of two generalized Green\u2019s operators is again a generalized Green\u2019s operator for the product of the corresponding differential operators and which boundary problem it solves. Moreover, we show that\u2014provided a factorization of the underlying differential operator\u2014a generalized boundary problem can be factored into lower order problems corresponding to a factorization of the respective Green\u2019s operators. We illustrate our results by examples using the Maple package IntDiffOp, where the presented algorithms are implemented.", "venue": "AADIOS", "authors": ["Anja  Korporal", "Georg  Regensburger"], "year": 2012, "n_citations": 4}
{"id": 367397, "s2_id": "e56c47ca37d0e5c525190e88974f52618e77c801", "title": "Koszul-type determinantal formulas for families of mixed multilinear systems", "abstract": "Effective computation of resultants is a central problem in elimination theory and polynomial system solving. Commonly, we compute the resultant as a quotient of determinants of matrices and we say that there exists a determinantal formula when we can express it as a determinant of a matrix whose elements are the coefficients of the input polynomials. We study the resultant in the context of mixed multilinear polynomial systems, that is multilinear systems with polynomials having different supports, on which determinantal formulas were not known. We construct determinantal formulas for two kind of multilinear systems related to the Multiparameter Eigenvalue Problem (MEP): first, when the polynomials agree in all but one block of variables; second, when the polynomials are bilinear with different supports, related to a bipartite graph. We use the Weyman complex to construct Koszul-type determinantal formulas that generalize Sylvester-type formulas. We can use the matrices associated to these formulas to solve square systems without computing the resultant. The combination of the resultant matrices with the eigenvalue and eigenvector criterion for polynomial systems leads to a new approach for solving MEP.", "venue": "SIAM Journal on Applied Algebra and Geometry", "authors": ["Mat'ias R. Bender", "Jean-Charles  Faugere", "Angelos  Mantzaflaris", "Elias  Tsigaridas"], "year": 2021, "n_citations": 1}
{"id": 368634, "s2_id": "4da0b91b9ef9b1359ed2d2413aae3cc793001e38", "title": "FORM version 4.2", "abstract": "We introduce FORM 4.2, a new minor release of the symbolic manipulation toolkit. We demonstrate several new features, such as a new pattern matching option, new output optimization, and automatic expansion of rational functions.", "venue": "ArXiv", "authors": ["Ben  Ruijl", "Takahiro  Ueda", "J. A. M. Vermaseren"], "year": 2017, "n_citations": 47}
{"id": 373022, "s2_id": "10e5ac2872881aa931c16a5695ad67edcd1e7079", "title": "On Compatibility of Discrete Relations", "abstract": "An approach to compatibility analysis of systems of discrete relations is proposed. Unlike the Grobner basis technique, the proposed scheme is not based on the polynomial ring structure. It uses more primitive set-theoretic and topological concepts and constructions. We illustrate the approach by application to some two-state cellular automata. In the two-state case the Grobner basis method is also applicable, and we compare both approaches.", "venue": "CASC", "authors": ["Vladimir V. Kornyak"], "year": 2005, "n_citations": 15}
{"id": 377733, "s2_id": "2418ba09dceb3c8cd182d23e963d004b6a940b80", "title": "Solving Partial Order Constraints for LPO Termination", "abstract": "This paper introduces a new kind of propositional encoding for reasoning about partial orders. The symbols in an unspecified partial order are viewed as variables which take integer values and are interpreted as indices in the order. For a partial order statement on n symbols each index is represented in \u2308log2n\u2309 propositional variables and partial order constraints between symbols are modeled on the bit representations. We illustrate the application of our approach to determine LPO termination for term rewrite systems. Experimental results are unequivocal, indicating orders of magnitude speedups in comparison with current implementations for LPO termination. The proposed encoding is general and relevant to other applications which involve propositional reasoning about partial orders.", "venue": "RTA", "authors": ["Michael  Codish", "Vitaly  Lagoon", "Peter J. Stuckey"], "year": 2006, "n_citations": 47}
{"id": 381313, "s2_id": "9320e293def0d60377ee41e41851bb3923f280d7", "title": "On division polynomial PIT and supersingularity", "abstract": "For an elliptic curve E over a finite field $$\\mathbb {F}_q$$Fq, where q is a prime power, we propose new algorithms for testing the supersingularity of E. Our algorithms are based on the polynomial identity testing problem for the p-th division polynomial of E. In particular, an efficient algorithm using points of high order on E is given.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Javad  Doliskani"], "year": 2018, "n_citations": 2}
{"id": 381955, "s2_id": "16bccf8952c41da0887945dfbdc7748ef869cdee", "title": "Matrix-F5 algorithms over finite-precision complete discrete valuation fields", "abstract": "Abstract Let ( f 1 , \u2026 , f s ) \u2208 Q p [ X 1 , \u2026 , X n ] s be a sequence of homogeneous polynomials with p-adic coefficients. Such system may happen, for example, in arithmetic geometry. Yet, since Q p is not an effective field, classical algorithm does not apply. We provide a definition for an approximate Grobner basis with respect to a monomial order w. We design a strategy to compute such a basis, when precision is enough and under the assumption that the input sequence is regular and the ideals \u3008 f 1 , \u2026 , f i \u3009 are weakly-w-ideals. The conjecture of Moreno-Socias states that for the grevlex ordering, such sequences are generic. Two variants of that strategy are available, depending on whether one leans more on precision or time-complexity. For the analysis of these algorithms, we study the loss of precision of the Gauss row-echelon algorithm, and apply it to an adapted Matrix-F5 algorithm. Numerical examples are provided. Moreover, the fact that under such hypotheses, Grobner bases can be computed stably has many applications. Firstly, the mapping sending ( f 1 , \u2026 , f s ) to the reduced Grobner basis of the ideal they span is differentiable, and its differential can be given explicitly. Secondly, these hypotheses allow to perform lifting on the Grobner bases, from Z / p k Z to Z / p k + k \u2032 Z or Z . Finally, asking for the same hypotheses on the highest-degree homogeneous components of the entry polynomials allows to extend our strategy to the affine case.", "venue": "J. Symb. Comput.", "authors": ["Tristan  Vaccon"], "year": 2017, "n_citations": 10}
{"id": 386121, "s2_id": "a80eb4cde343605ce064e9cf1521687f5201208f", "title": "On the parameterized complexity of associative and commutative unification", "abstract": "This article studies the parameterized complexity of the unification problem with associative, commutative, or associative-commutative functions with respect to the parameter \"number of variables\". It is shown that if every variable occurs only once then both of the associative and associative-commutative unification problems can be solved in polynomial time, but that in the general case, both problems are W 1 -hard even when one of the two input terms is variable-free. For commutative unification, an algorithm whose time complexity depends exponentially on the number of variables is presented; moreover, if a certain conjecture is true then the special case where one input term is variable-free belongs to FPT. Some related results are also derived for a natural generalization of the classic string and tree edit distance problems that allows variables.", "venue": "Theor. Comput. Sci.", "authors": ["Tatsuya  Akutsu", "Jesper  Jansson", "Atsuhiro  Takasu", "Takeyuki  Tamura"], "year": 2017, "n_citations": 0}
{"id": 391731, "s2_id": "14e9c11416ab10a5a617d747a35386b6ed2634bb", "title": "Computing Igusa's Local Zeta Functions of Univariate Polynomials, and Linear Feedback Shift Registers", "abstract": "We give a polynomial time algorithm for computing the Igusa local zeta function $Z(s,f)$ attached to a polynomial $f(x)\\in \\QTR{Bbb}{Z}[x]$, in one variable, with splitting field $\\QTR{Bbb}{Q}$, and a prime number $p$. We also propose a new class of Linear Feedback Shift Registers based on the computation of Igusa's local zeta function.", "venue": "ArXiv", "authors": ["W. A. Zuniga-Galindo"], "year": 2003, "n_citations": 13}
{"id": 396668, "s2_id": "751911ae1e54e7937fedc506fe9d73db95e3e962", "title": "Minimal solutions of the rational interpolation problem", "abstract": "We explore connections between the approach of solving the rational interpolation problem via resolutions of ideals and syzygies with the standard method provided by the Extended Euclidean Algorithm. As a consequence, we obtain explicit descriptions for solutions of \"minimal\" degrees in terms of the degrees of elements appearing in the EEA. This allows us to describe the minimal degree in a $\\mu$-basis of a polynomial planar parametrization in terms of a \"critical\" degree arising in the EEA.", "venue": "Revista de la Uni\u00f3n Matem\u00e1tica Argentina", "authors": ["Teresa Cortadellas Ben\u00edtez", "Carlos  D'Andrea", "M. Eulalia Montoro"], "year": 2020, "n_citations": 0}
{"id": 398442, "s2_id": "d0c2a12bd72b19bd3b7ea71246073cd0d5f55604", "title": "Computing with B-series", "abstract": "We present BSeries.jl, a Julia package for the computation and manipulation of B-series, which are a versatile theoretical tool for understanding and designing discretizations of differential equations. We give a short introduction to the theory of B-series and associated concepts and provide examples of their use, including method composition and backward error analysis. The associated software is highly performant and makes it possible to work with B-series of high order.", "venue": "ArXiv", "authors": ["David I. Ketcheson", "Hendrik  Ranocha"], "year": 2021, "n_citations": 0}
{"id": 398883, "s2_id": "c797b15db9ae1a49e4130d4d52336697d64d6e52", "title": "Resultants over principal Artinian rings", "abstract": "The resultant of two univariate polynomials is an invariant of great importance in commutative algebra and vastly used in computer algebra systems. Here we present an algorithm to compute it over Artinian principal rings with a modified version of the Euclidean algorithm. Using the same strategy, we show how the reduced resultant and a pair of Bezout coefficient can be computed. Particular attention is devoted to the special case of $\\mathbf{Z}/n\\mathbf{Z}$, where we perform a detailed analysis of the asymptotic cost of the algorithm. Finally, we illustrate how the algorithms can be exploited to improve ideal arithmetic in number fields and polynomial arithmetic over $p$-adic fields.", "venue": "ArXiv", "authors": ["Claus  Fieker", "Tommy  Hofmann", "Carlo  Sircana"], "year": 2020, "n_citations": 0}
{"id": 403090, "s2_id": "4cc7e916e69f76e9589b2985d036de4c11a47b6a", "title": "Trace Logic for Inductive Loop Reasoning", "abstract": "We propose trace logic, an instance of many-sorted first-order logic, to automate the partial correctness verification of programs containing loops. Trace logic generalizes semantics of program locations and captures loop semantics by encoding properties at arbitrary timepoints and loop iterations. We guide and automate inductive loop reasoning in trace logic by using generic trace lemmas capturing inductive loop invariants. Our work is implemented in the Rapid framework, by extending and integrating superposition-based first-order reasoning within Rapid. We successfully used Rapid to prove correctness of many programs whose functional behavior are best summarized in the first-order theories of linear integer arithmetic, arrays and inductive data types.", "venue": "2020 Formal Methods in Computer Aided Design (FMCAD)", "authors": ["Pamina  Georgiou", "Bernhard  Gleiss", "Laura  Kov'acs"], "year": 2020, "n_citations": 4}
{"id": 405196, "s2_id": "d19d9d36d6d156eb7c756c19d7b134883c34039b", "title": "Algorithms for integrals of holonomic functions over domains defined by polynomial inequalities", "abstract": "A holonomic function is a differentiable or generalized function which satisfies a holonomic system of linear partial or ordinary differential equations with polynomial coefficients. The main purpose of this paper is to present algorithms for computing a holonomic system for the definite integral of a holonomic function with parameters over a domain defined by polynomial inequalities. If the integrand satisfies a holonomic difference-differential system including parameters, then a holonomic difference-differential system for the integral can also be computed. In the algorithms, holonomic distributions (generalized functions in the sense of L. Schwartz) are inevitably involved even if the integrand is a usual function.", "venue": "J. Symb. Comput.", "authors": ["Toshinori  Oaku"], "year": 2013, "n_citations": 20}
{"id": 408469, "s2_id": "261f302eedf27dc1c6a14b3932a5600218ca1504", "title": "How to compute the constant term of a power of a Laurent polynomial efficiently", "abstract": "We present an algorithm for efficient computation of the constant term of a power of a multivariate Laurent polynomial. The algorithm is based on univariate interpolation, does not require the storage of intermediate data and can be easily parallelized. As an application we compute the power series expansion of the principal period of some toric Calabi-Yau varieties and find previously unknown differential operators of Calabi-Yau type.", "venue": "ArXiv", "authors": ["Pavel  Metelitsyn"], "year": 2012, "n_citations": 3}
{"id": 409480, "s2_id": "dd429029a3c42dae2c4be9299188b5b1fe1416de", "title": "Interpolation and Model Checking for Nonlinear Arithmetic", "abstract": "We present a new model-based interpolation procedure for satisfiability modulo theories (SMT). The procedure uses a new mode of interaction with the SMT solver that we call solving modulo a model . This either extends a given partial model into a full model for a set of assertions or returns an explanation (a model interpolant) when no solution exists. This mode of interaction fits well into the model-constructing satisfiability (MCSAT) framework of SMT. We use it to develop an interpolation procedure for any MCSAT-supported theory. In particular, this method leads to an effective interpolation procedure for nonlinear real arithmetic. We evaluate the new procedure by integrating it into a model checker and comparing it with state-of-art model-checking tools for nonlinear arithmetic.", "venue": "CAV", "authors": ["Dejan  Jovanovi'c", "Bruno  Dutertre"], "year": 2021, "n_citations": 0}
{"id": 409608, "s2_id": "b6f1f6591f4ae553f787ec6a2f1f4d7c05f526f7", "title": "GPGCD, an Iterative Method for Calculating Approximate GCD, for Multiple Univariate Polynomials", "abstract": "We present an extension of our GPGCD method, an iterative method for calculating approximate greatest common divisor (GCD) of univariate polynomials, to multiple polynomial inputs. For a given pair of polynomials and a degree, our algorithm finds a pair of polynomials which has a GCD of the given degree and whose coefficients are perturbed from those in the original inputs, making the perturbations as small as possible, along with the GCD. In our GPGCD method, the problem of approximate GCD is transferred to a constrained minimization problem, then solved with the so-called modified Newton method, which is a generalization of the gradient-projection method, by searching the solution iteratively. In this paper, we extend our method to accept more than two polynomials with the real coefficients as an input.", "venue": "CASC", "authors": ["Akira  Terui"], "year": 2010, "n_citations": 2}
{"id": 418356, "s2_id": "9624eb047e63d546e9b921b92487c561fc0e8203", "title": "Towards Symbolic Factual Change in DEL", "abstract": "We extend symbolic model checking for Dynamic Epistemic Logic (DEL) with factual change. Our transformers provide a compact representation of action models with pre- and postconditions, for both S5 and the general case. The method can be implemented using binary decision diagrams and we expect it to improve model checking performance. As an example we give a symbolic representation of the Sally-Anne false belief task.", "venue": "ArXiv", "authors": ["Malvin  Gattinger"], "year": 2019, "n_citations": 1}
{"id": 427707, "s2_id": "5ca47a8dcb06ad584d01f12f18eee36a942159fd", "title": "Synthesizing Probabilistic Invariants via Doob's Decomposition", "abstract": "When analyzing probabilistic computations, a powerful approach is to first find a martingale---an expression on the program variables whose expectation remains invariant---and then apply the optional stopping theorem in order to infer properties at termination time. One of the main challenges, then, is to systematically find martingales. \nWe propose a novel procedure to synthesize martingale expressions from an arbitrary initial expression. Contrary to state-of-the-art approaches, we do not rely on constraint solving. Instead, we use a symbolic construction based on Doob's decomposition. This procedure can produce very complex martingales, expressed in terms of conditional expectations. \nWe show how to automatically generate and simplify these martingales, as well as how to apply the optional stopping theorem to infer properties at termination time. This last step typically involves some simplification steps, and is usually done manually in current approaches. We implement our techniques in a prototype tool and demonstrate our process on several classical examples. Some of them go beyond the capability of current semi-automatic approaches.", "venue": "CAV", "authors": ["Gilles  Barthe", "Thomas  Espitau", "Luis Mar\u00eda Ferrer Fioriti", "Justin  Hsu"], "year": 2016, "n_citations": 41}
{"id": 427856, "s2_id": "a8483549d619ff098036e16ef25a86b81b532e8a", "title": "Algorithmically generating new algebraic features of polynomial systems for machine learning", "abstract": "There are a variety of choices to be made in both computer algebra systems (CASs) and satisfiability modulo theory (SMT) solvers which can impact performance without affecting mathematical correctness. Such choices are candidates for machine learning (ML) approaches, however, there are difficulties in applying standard ML techniques, such as the efficient identification of ML features from input data which is typically a polynomial system. Our focus is selecting the variable ordering for cylindrical algebraic decomposition (CAD), an important algorithm implemented in several CASs, and now also SMT-solvers. We created a framework to describe all the previously identified ML features for the problem and then enumerated all options in this framework to automatically generation many more features. We validate the usefulness of these with an experiment which shows that an ML choice for CAD variable ordering is superior to those made by human created heuristics, and further improved with these additional features. We expect that this technique of feature generation could be useful for other choices related to CAD, or even choices for other algorithms with polynomial systems for input.", "venue": "ArXiv", "authors": ["Dorian  Florescu", "Matthew  England"], "year": 2019, "n_citations": 10}
{"id": 429343, "s2_id": "d1e28ae3f50d2b9425be46dbd1d509bce77e8113", "title": "Interactive certificate for the verification of Wiedemann's Krylov sequence: application to the certification of the determinant, the minimal and the characteristic polynomials of sparse matrices", "abstract": "Certificates to a linear algebra computation are additional data structures for each output, which can be used by a\u2014possibly randomized\u2014 verification algorithm that proves the correctness of each output. Wiede-mann's algorithm projects the Krylov sequence obtained by repeatedly multiplying a vector by a matrix to obtain a linearly recurrent sequence. The minimal polynomial of this sequence divides the minimal polynomial of the matrix. For instance, if the n\u00d7n input matrix is sparse with n 1+o(1) non-zero entries, the computation of the sequence is quadratic in the dimension of the matrix while the computation of the minimal polynomial is n 1+o(1) , once that projected Krylov sequence is obtained. In this paper we give algorithms that compute certificates for the Krylov sequence of sparse or structured n \u00d7 n matrices over an abstract field, whose Monte Carlo verification complexity can be made essentially linear. As an application this gives certificates for the determinant, the minimal and characteristic polynomials of sparse or structured matrices at the same cost.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Erich  Kaltofen", "Emmanuel  Thom\u00e9"], "year": 2015, "n_citations": 2}
{"id": 429515, "s2_id": "2633b473ab598a3de08030d846155b5e3c418c73", "title": "Implementation of a Near-Optimal Complex Root Clustering Algorithm", "abstract": "We describe Ccluster, a software for computing natural \\(\\varepsilon \\)-clusters of complex roots in a given box of the complex plane. This algorithm from Becker et al. (2016) is near-optimal when applied to the benchmark problem of isolating all complex roots of an integer polynomial. It is one of the first implementations of a near-optimal algorithm for complex roots. We describe some low level techniques for speeding up the algorithm. Its performance is compared with the well-known MPSolve library and Maple.", "venue": "ICMS", "authors": ["R\u00e9mi  Imbach", "Victor Y. Pan", "Chee-Keng  Yap"], "year": 2018, "n_citations": 24}
{"id": 429714, "s2_id": "3515c22a10626ac4f8ad2c19d27145b335a8b3cd", "title": "Robots, computer algebra and eight connected components", "abstract": "Answering connectivity queries in semi-algebraic sets is a longstanding and challenging computational issue with applications in robotics, in particular for the analysis of kinematic singularities. One task there is to compute the number of connected components of the complementary of the singularities of the kinematic map. Another task is to design a continuous path joining two given points lying in the same connected component of such a set. In this paper, we push forward the current capabilities of computer algebra to obtain computer-aided proofs of the analysis of the kinematic singularities of various robots used in industry. We first show how to combine mathematical reasoning with easy symbolic computations to study the kinematic singularities of an infinite family (depending on paramaters) modelled by the UR-series produced by the company \"Universal Robots\". Next, we compute roadmaps (which are curves used to answer connectivity queries) for this family of robots. We design an algorithm for \"solving\" positive dimensional polynomial system depending on parameters. The meaning of solving here means partitioning the parameter's space into semi-algebraic components over which the number of connected components of the semi-algebraic set defined by the input system is invariant. Practical experiments confirm our computer-aided proof and show that such an algorithm can already be used to analyze the kinematic singularities of the UR-series family. The number of connected components of the complementary of the kinematic singularities of generic robots in this family is 8.", "venue": "ISSAC", "authors": ["Jose  Capco", "Mohab Safey El Din", "Josef  Schicho"], "year": 2020, "n_citations": 1}
{"id": 430436, "s2_id": "02eb42a92f603cd0cea0bc6993950fcdcec135fc", "title": "Computing the real isolated points of an algebraic hypersurface", "abstract": "Let R be the field of real numbers. We consider the problem of computing the real isolated points of a real algebraic set in Rn given as the vanishing set of a polynomial system. This problem plays an important role for studying rigidity properties of mechanism in material designs. In this paper, we design an algorithm which solves this problem. It is based on the computations of critical points as well as roadmaps for answering connectivity queries in real algebraic sets. This leads to a probabilistic algorithm of complexity (nd)O (n log(n)) for computing the real isolated points of real algebraic hypersurfaces of degree d. It allows us to solve in practice instances which are out of reach of the state-of-the-art.", "venue": "ISSAC", "authors": ["Huu Phuoc Le", "Mohab Safey El Din", "Timo de Wolff"], "year": 2020, "n_citations": 2}
{"id": 436765, "s2_id": "2eb0b1b75e8d6c11a37fbc4bdd1703a83d9611cc", "title": "On the Complexity of Toric Ideals", "abstract": "We investigate the computational complexity of problems on toric ideals such as normal forms, Grobner bases, and Graver bases. We show that all these problems are strongly NP-hard in the general case. Nonetheless, we can derive efficient algorithms by taking advantage of the sparsity pattern of the matrix. We describe this sparsity pattern with a graph, and study the parameterized complexity of toric ideals in terms of graph parameters such as treewidth and treedepth. In particular, we show that the normal form problem can be solved in parameter-tractable time in terms of the treedepth. An important application of this result is in multiway ideals arising in algebraic statistics. We also give a parameter-tractable membership test to the reduced Grobner basis. This test leads to an efficient procedure for computing the reduced Grobner basis. Similar results hold for Graver bases computation.", "venue": "ArXiv", "authors": ["Diego  Cifuentes", "Shmuel  Onn"], "year": 2019, "n_citations": 0}
{"id": 437630, "s2_id": "8b658d58ae7b9c4b6700d8ff8715b5d19541e4c9", "title": "Pfaffian Systems of A-Hypergeometric Systems II - Holonomic Gradient Method", "abstract": "We give two efficient methods to derive Pfaffian systems for A-hypergeometric systems for the application to the holonomic gradient method for statistics. We utilize the Hilbert driven Buchberger algorithm and Macaulay type matrices in the two methods.", "venue": "ArXiv", "authors": ["Katsuyoshi  Ohara", "Nobuki  Takayama"], "year": 2015, "n_citations": 7}
{"id": 438116, "s2_id": "aa37594f2a8df99ffbaf8f182bed282a371ea3a7", "title": "Order-degree curves for hypergeometric creative telescoping", "abstract": "Creative telescoping applied to a bivariate proper hypergeometric term produces linear recurrence operators with polynomial coefficients, called telescopers. We provide bounds for the degrees of the polynomials appearing in these operators. Our bounds are expressed as curves in the (r, d)-plane which assign to every order r a bound on the degree d of the telescopers. These curves are hyperbolas, which reflect the phenomenon that higher order telescopers tend to have lower degree, and vice versa.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Manuel  Kauers"], "year": 2012, "n_citations": 29}
{"id": 450414, "s2_id": "2650879abdb95c4ca65f92b7ccea4935b2208a30", "title": "Decoding Interleaved Gabidulin Codes using Alekhnovich's Algorithm", "abstract": "We prove that Alekhnovich's algorithm can be used for row reduction of skew polynomial matrices. This yields an $O(\\ell^3 n^{(\\omega+1)/2} \\log(n))$ decoding algorithm for $\\ell$-Interleaved Gabidulin codes of length $n$, where $\\omega$ is the matrix multiplication exponent, improving in the exponent of $n$ compared to previous results.", "venue": "Electron. Notes Discret. Math.", "authors": ["Sven  Puchinger", "Sven  M\u00fcelich", "David  M\u00f6dinger", "Johan  Rosenkilde", "Martin  Bossert"], "year": 2017, "n_citations": 7}
{"id": 454962, "s2_id": "92001bd972a37ae9ea02736f1fcc7854ad2f4335", "title": "From Kepler to Newton: Explainable AI for Science Discovery", "abstract": "The Observation\u2013Hypothesis\u2013Prediction\u2013Experimentation loop paradigm for scientific research has been practiced by researchers for years towards scientific discoveries. However, with data explosion in both mega-scale and milli-scale scientific research, it has been sometimes very difficult to manually analyze the data and propose new hypothesis to drive the cycle for scientific discovery. In this paper, we discuss the role of Explainable AI in scientific discovery process by demonstrating an Explainable AI-based paradigm for science discovery. The key is to use Explainable AI to help derive data or model interpretations as well as scientific discoveries or insights. We show how computational and data-intensive methodology\u2014together with experimental and theoretical methodology\u2014can be seamlessly integrated for scientific research. To demonstrate the AI-based science discovery process, and to pay our respect to some of the greatest minds in human history, we show how Kepler\u2019s laws of planetary motion and the Newton\u2019s law of universal gravitation can be rediscovered by (Explainable) AI based on Tycho Brahe\u2019s astronomical observation data, whose works were leading the scientific revolution in the 16-17th century. This work also highlights the important role of Explainable AI (as compared to Blackbox AI) in science discovery to help humans prevent or better prepare for the possible technological singularity that may happen in the future.", "venue": "ArXiv", "authors": ["Zelong  Li", "Jianchao  Ji", "Yongfeng  Zhang"], "year": 2021, "n_citations": 0}
{"id": 463036, "s2_id": "68c4279c340f219465d4f6e9f7ab538b6280f61d", "title": "New Features in the Second Version of the Cadabra Computer Algebra System", "abstract": "In certain scientific domains, there is a need for tensor operations. To facilitate tensor computations, computer algebra systems are employed. In our research, we have been using Cadabra as the main computer algebra system for several years. Recently, an operable second version of this software was released. In\u00a0this version, a number of improvements were made that can be regarded as revolutionary ones. The most significant improvements are the implementation of component computations and the change in the ideology of the Cadabra\u2019s software mechanism as compared to the first version. This paper provides a brief overview of the key improvements in the Cadabra system.", "venue": "Programming and Computer Software", "authors": ["D. S.  Kulyabov", "A. V.  Korol\u2019kova", "L. A.  Sevast\u2019yanov"], "year": 2019, "n_citations": 2}
{"id": 466347, "s2_id": "f76179d895157ea3eb278ca9fdf1137832e7fadb", "title": "A modified block Lanczos algorithm with fewer vectors", "abstract": "The block Lanczos algorithm proposed by Peter Montgomery is an efficient means to tackle the sparse linear algebra problem which arises in the context of the number field sieve factoring algorithm and its predecessors. We present here a modified version of the algorithm, which incorporates several improvements: we discuss how to efficiently handle homogeneous systems and how to reduce the number of vectors stored in the course of the computation. We also provide heuristic justification for the success probability of our modified algorithm. While the overall complexity and expected number of steps of the block Lanczos is not changed by the modifications presented in this article, we expect these to be useful for implementations of the block Lanczos algorithm where the storage of auxiliary vectors sometimes has a non-negligible cost. 1 Linear systems for integer factoring For factoring a composite integer N, algorithms based on the technique of combination of congruences look for several pairs of integers (x, y) such that x 2 $\\not\\equiv$ y 2 mod N. This equality is hoped to be non trivial for at least one of the obtained pairs, letting gcd(x -- y, N) unveil a factor of the integer N. Several algorithms use this strategy: the CFRAC algorithm, the quadratic sieve and its variants, and the number field sieve. Pairs (x, y) as above are obtained by combining relations which have been collected as a step of these algorithms. Relations are written multiplicatively as a set of valuations. All the algorithms considered seek a multiplicative combination of these relations which can be rewritten as an equality of squares. This is achieved by solving a system of linear equations defined over F 2, where equations are parity constraints on", "venue": "IACR Cryptol. ePrint Arch.", "authors": ["Emmanuel  Thom\u00e9"], "year": 2016, "n_citations": 2}
{"id": 468312, "s2_id": "eee5aed1a3ebd9b1626bea709d98fd1c07532220", "title": "Fast Operations on Linearized Polynomials and their Applications in Coding Theory", "abstract": "This paper considers fast algorithms for operations on linearized polynomials. We propose a new multiplication algorithm for skew polynomials (a generalization of linearized polynomials) which has sub-quadratic complexity in the polynomial degree $s$, independent of the underlying field extension degree~$m$. We show that our multiplication algorithm is faster than all known ones when $s \\leq m$. Using a result by Caruso and Le Borgne (2017), this immediately implies a sub-quadratic division algorithm for linearized polynomials for arbitrary polynomial degree $s$. Also, we propose algorithms with sub-quadratic complexity for the $q$-transform, multi-point evaluation, computing minimal subspace polynomials, and interpolation, whose implementations were at least quadratic before. Using the new fast algorithm for the $q$-transform, we show how matrix multiplication over a finite field can be implemented by multiplying linearized polynomials of degrees at most $s=m$ if an elliptic normal basis of extension degree $m$ exists, providing a lower bound on the cost of the latter problem. Finally, it is shown how the new fast operations on linearized polynomials lead to the first error and erasure decoding algorithm for Gabidulin codes with sub-quadratic complexity.", "venue": "J. Symb. Comput.", "authors": ["Sven  Puchinger", "Antonia  Wachter-Zeh"], "year": 2018, "n_citations": 24}
{"id": 470903, "s2_id": "1952742fdd7f08ad939ad9aefd5d4e5292abc181", "title": "Analysis of the Conradi-Kahle Algorithm for Detecting Binomiality on Biological Models", "abstract": "We analyze the Conradi-Kahle Algorithm for detecting binomiality. We present experiments using two implementations of the algorithm in Macaulay2 and Maple on biological models and assess the performance of the algorithm on these models. We compare the two implementations with each other and with Gr\\\"obner bases computations up to their performance on these biological models.", "venue": "ArXiv", "authors": ["Alexandru  Iosif", "Hamid  Rahkooy"], "year": 2019, "n_citations": 5}
{"id": 473415, "s2_id": "9c5cbc16e99f28c04e670986450cbeea096cc67d", "title": "Improved Linear Parallel Interference Cancellers", "abstract": "In this paper, taking the view that a linear parallel interference canceller (LPIC) can be seen as a linear matrix filter, we propose new linear matrix filters that can result in improved bit error performance compared to other LPICs in the literature. The motivation for the proposed filters arises from the possibility of avoiding the generation of certain interference and noise terms in a given stage that would have been present in a conventional LPIC (CLPIC). In the proposed filters, we achieve such avoidance of the generation of interference and noise terms in a given stage by simply making the diagonal elements of a certain matrix in that stage equal to zero. Hence, the proposed filters do not require additional complexity compared to the CLPIC, and they can allow achieving a certain error performance using fewer LPIC stages. We also extend the proposed matrix filter solutions to a multicarrier DS-CDMA system, where we consider two types of receivers. In one receiver (referred to as Type-I receiver), LPIC is performed on each subcarrier first, followed by multicarrier combining (MCC). In the other receiver (called Type-II receiver), MCC is performed first, followed by LPIC. We show that in both Type-I and Type-II receivers, the proposed matrix filters outperform other matrix filters. Also, Type-II receiver performs better than Type-I receiver because of enhanced accuracy of the interference estimates achieved due to frequency diversity offered by MCC.", "venue": "IEEE Transactions on Wireless Communications", "authors": ["Thati  Srikanth", "K. Vishnu Vardhan", "Ananthanarayanan  Chockalingam", "Laurence B. Milstein"], "year": 2008, "n_citations": 1}
{"id": 474358, "s2_id": "9d0abce598e9526fbd5de3b442d58ab5923888ad", "title": "An efficient algorithm for factoring polynomials over algebraic extension field", "abstract": "An efficient algorithm is proposed for factoring polynomials over an algebraic extension field defined by a polynomial ring modulo a maximal ideal. If the maximal ideal is given by its Gr\u00f6bner basis, no extra Gr\u00f6bner basis computation is needed for factoring a polynomial over this extension field. Nothing more than linear algebraic technique is used to get a characteristic polynomial of a generic linear map. Then this polynomial is factorized over the ground field. From its factors, the factorization of the polynomial over the extension field is obtained. The algorithm has been implemented in Magma and computer experiments indicate that it is very efficient, particularly for complicated examples.", "venue": "ArXiv", "authors": ["Dingkang  Wang", "Yao  Sun"], "year": 2009, "n_citations": 7}
{"id": 475025, "s2_id": "25e8ea37bc8b941f697b88e57f0d6deef4c10f8f", "title": "Consistency and Completeness of Rewriting in the Calculus of Constructions", "abstract": "Adding rewriting to a proof assistant based on the Curry-Howard isomorphism, such as Coq, may greatly improve usability of the tool. Unfortunately adding an arbitrary set of rewrite rules may render the underlying formal system undecidable and inconsistent. While ways to ensure termination and confluence, and hence decidability of type-checking, have already been studied to some extent, logical consistency has got little attention so far. \n \nIn this paper we show that consistency is a consequence of canonicity, which in turn follows from the assumption that all functions defined by rewrite rules are complete. We provide a sound and terminating, but necessarily incomplete algorithm to verify this property. The algorithm accepts all definitions that follow dependent pattern matching schemes presented by Coquand and studied by McBride in his PhD thesis. Moreover, many definitions by rewriting containing rules which depart from standard pattern matching are also accepted.", "venue": "IJCAR", "authors": ["Daria  Walukiewicz-Chrzaszcz", "Jacek  Chrzaszcz"], "year": 2006, "n_citations": 4}
{"id": 479181, "s2_id": "805a985467c81e3390c61554594f08eecb882ca0", "title": "The Invar tensor package: Differential invariants of Riemann", "abstract": "Abstract The long standing problem of the relations among the scalar invariants of the Riemann tensor is computationally solved for all 6 \u22c5 10 23 objects with up to 12 derivatives of the metric. This covers cases ranging from products of up to 6 undifferentiated Riemann tensors to cases with up to 10 covariant derivatives of a single Riemann. We extend our computer algebra system Invar to produce within seconds a canonical form for any of those objects in terms of a basis. The process is as follows: (1) an invariant is converted in real time into a canonical form with respect to the permutation symmetries of the Riemann tensor; (2) Invar reads a database of more than 6 \u22c5 10 5 relations and applies those coming from the cyclic symmetry of the Riemann tensor; (3) then applies the relations coming from the Bianchi identity, (4) the relations coming from commutations of covariant derivatives, (5) the dimensionally-dependent identities for dimension 4, and finally (6) simplifies invariants that can be expressed as product of dual invariants. Invar runs on top of the tensor computer algebra systems xTensor (for Mathematica ) and Canon (for Maple ). Program summary Program title: Invar Tensor Package v2.0 Catalogue identifier: ADZK_v2_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/ADZK_v2_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 3\u2009243\u2009249 No. of bytes in distributed program, including test data, etc.: 939 Distribution format: tar.gz Programming language: Mathematica and Maple Computer: Any computer running Mathematica versions 5.0 to 6.0 or Maple versions 9 and 11 Operating system: Linux, Unix, Windows XP, MacOS RAM: 100 Mb Word size: 64 or 32 bits Supplementary material: The new database of relations is much larger than that for the previous version and therefore has not been included in the distribution. To obtain the Mathematica and Maple database files click on this link. Classification: 1.5, 5 Does the new version supersede the previous version?: Yes. The previous version (1.0) only handled algebraic invariants. The current version (2.0) has been extended to cover differential invariants as well. Nature of problem: Manipulation and simplification of scalar polynomial expressions formed from the Riemann tensor and its covariant derivatives. Solution method: Algorithms of computational group theory to simplify expressions with tensors that obey permutation symmetries. Tables of syzygies of the scalar invariants of the Riemann tensor. Reasons for new version: With this new version, the user can manipulate differential invariants of the Riemann tensor. Differential invariants are required in many physical problems in classical and quantum gravity. Summary of revisions: The database of syzygies has been expanded by a factor of 30. New commands were added in order to deal with the enlarged database and to manipulate the covariant derivative. Restrictions: The present version only handles scalars, and not expressions with free indices. Additional comments: The distribution file for this program is over 53 Mbytes and therefore is not delivered directly when download or Email is requested. Instead a html file giving details of how the program can be obtained is sent. Running time: One second to fully reduce any monomial of the Riemann tensor up to degree 7 or order 10 in terms of independent invariants. The Mathematica notebook included in the distribution takes approximately 5 minutes to run.", "venue": "Comput. Phys. Commun.", "authors": ["Jos\u00e9 M. Mart\u00edn-Garc\u00eda", "David  Yllanes", "Renato  Portugal"], "year": 2008, "n_citations": 65}
{"id": 479995, "s2_id": "0bc98bf66b58a2a0ace0ae51684bb15a63c07688", "title": "Inverse Inequality Estimates with Symbolic Computation", "abstract": "In the convergence analysis of numerical methods for solving partial differential equations (such as finite element methods) one arrives at certain generalized eigenvalue problems, whose maximal eigenvalues need to be estimated as accurately as possible. We apply symbolic computation methods to the situation of square elements and are able to improve the previously known upper bound, given in \"p- and hp-finite element methods\" (Schwab, 1998), by a factor of 8. More precisely, we try to evaluate the corresponding determinant using the holonomic ansatz, which is a powerful tool for dealing with determinants, proposed by Zeilberger in 2007. However, it turns out that this method does not succeed on the problem at hand. As a solution we present a variation of the original holonomic ansatz that is applicable to a larger class of determinants, including the one we are dealing with here. We obtain an explicit closed form for the determinant, whose special form enables us to derive new and tight upper resp. lower bounds on the maximal eigenvalue, as well as its asymptotic behaviour.", "venue": "Adv. Appl. Math.", "authors": ["Christoph  Koutschan", "Martin  Neum\u00fcller", "Silviu  Radu"], "year": 2016, "n_citations": 2}
{"id": 481204, "s2_id": "87fb330033f31c5e732e3569b235f725fa5d2212", "title": "Algorithms for Weighted Sums of Squares Decomposition of Non-negative Univariate Polynomials", "abstract": "It is well-known that every non-negative univariate real polynomial can be written as the sum of two polynomial squares with real coefficients. When one allows a weighted sum of finitely many squares instead of a sum of two squares, then one can choose all coefficients in the representation to lie in the field generated by the coefficients of the polynomial. \nIn this article, we describe, analyze and compare both from the theoretical and practical points of view, two algorithms computing such a weighted sums of squares decomposition for univariate polynomials with rational coefficients. \nThe first algorithm, due to the third author relies on real root isolation, quadratic approximations of positive polynomials and square-free decomposition but its complexity was not analyzed. We provide bit complexity estimates, both on runtime and output size of this algorithm. They are exponential in the degree of the input univariate polynomial and linear in the maximum bitsize of its complexity. This analysis is obtained using quantifier elimination and root isolation bounds. \nThe second algorithm, due to Chevillard, Harrison, Joldes and Lauter, relies on complex root isolation and square-free decomposition and has been introduced for certifying positiveness of polynomials in the context of computer arithmetics. Again, its complexity was not analyzed. We provide bit complexity estimates, both on runtime and output size of this algorithm, which are polynomial in the degree of the input polynomial and linear in the maximum bitsize of its complexity. This analysis is obtained using Vieta's formula and root isolation bounds. \nFinally, we report on our implementations of both algorithms. While the second algorithm is, as expected from the complexity result, more efficient on most of examples, we exhibit families of non-negative polynomials for which the first algorithm is better.", "venue": "J. Symb. Comput.", "authors": ["Victor  Magron", "Mohab Safey El Din", "Markus  Schweighofer"], "year": 2019, "n_citations": 17}
{"id": 481310, "s2_id": "2cabb8a7fa81dd65a234076e21b3acb98e211763", "title": "Arb: Efficient Arbitrary-Precision Midpoint-Radius Interval Arithmetic", "abstract": "Arb is a C library for arbitrary-precision interval arithmetic using the midpoint-radius representation, also known as ball arithmetic. It supports real and complex numbers, polynomials, power series, matrices, and evaluation of many special functions. The core number types are designed for versatility and speed in a range of scenarios, allowing performance that is competitive with non-interval arbitrary-precision types such as MPFR and MPC floating-point numbers. We discuss the low-level number representation, strategies for precision and error bounds, and the implementation of efficient polynomial arithmetic with interval coefficients.", "venue": "IEEE Transactions on Computers", "authors": ["Fredrik  Johansson"], "year": 2017, "n_citations": 94}
{"id": 489703, "s2_id": "2d0d2b9e7b3bca18a17b729b121d64544c2c6072", "title": "Fast evaluation of some p-adic transcendental functions", "abstract": "Special functions of a complex variable play a pivotal role in numerous questions arising from analysis, geometry, combinatorics and number theory. Examples include the link between the Riemann Z -function and the distribution of prime numbers, or the Birch and Swinnerton-Dyer conjecture which relates special values of !-functions to arithmetical invariants of elliptic curves. Being able to evaluate these functions at high precision is invaluable for computing invariants or testing conjectures, and work on fast algorithms for this task over the last decades often makes it possible nowadays to reach accuracies in the millions of digits [e.g., 12]. At the same time, mathematicians have realized that many complex special functions have interesting ?-adic analogues. A famous example is that of ?-adic !-functions, which encode subtle invariants of towers of number fields (via Iwasawa\u2019s theory) and, more generally, of algebraic varieties. The algorithmic counterpart of these questions also has attracted some interest. Efficient algorithms have been designed for computing the Morita ?-adic \u0393-function [22, \u00a76.2] and, more recently, ?-adic hypergeometric functions [1, 15] and some ?-adic !-functions [3]. On a different but closely related note, since the pioneering works of Kedlaya [14], much effort has been devoted to computing the matrix of the Frobenius acting on the cohomology of ?-adic algebraic varieties [e.g., 17, 23]. The present paper continues this dynamic and provides new efficient algorithms for evaluating many ?-adic elementary and special functions, including polylogarithms, hypergeometric functions and, more generally, solutions of \u201csmall\u201d ?-adic differential equations. In particular, our methods apply to the large class of matrices of the Frobenius acting on the cohomology of a fibration, since they satisfy differential equations of Picard-Fuchs type. An important feature of our algorithms is that they all run in quasi-linear time in the precision. This contrasts with most previous work where the complexity was at least quadratic. The main", "venue": "ArXiv", "authors": ["Xavier  Caruso", "Marc  Mezzarobba", "Nobuki  Takayama", "Tristan  Vaccon"], "year": 2021, "n_citations": 0}
{"id": 495900, "s2_id": "4c5e168b48c9b5afe261871e35b7bdf77a7a4676", "title": "On a non-archimedean broyden method", "abstract": "Newton's method is an ubiquitous tool to solve equations, both in the archimedean and non-archimedean settings --- for which it does not really differ. Broyden was the instigator of what is called \"quasi-Newton methods\". These methods use an iteration step where one does not need to compute a complete Jacobian matrix nor its inverse. We provide an adaptation of Broyden's method in a general non-archimedean setting, compatible with the lack of inner product, and study its Q and R convergence. We prove that our adapted method converges at least Q-linearly and R-superlinearly with R-order [EQUATION] in dimension m. Numerical data are provided.", "venue": "ISSAC", "authors": ["Xavier  Dahan", "Tristan  Vaccon"], "year": 2020, "n_citations": 0}
{"id": 498753, "s2_id": "052c55bf6acf011112b3b3246caa19fc246f3023", "title": "Methods for the construction of generators of algebraic curvature tensors", "abstract": "We demonstrate the use of several tools from Algebraic Combinatorics such as Young tableaux, symmetry operators, the Littlewood-Richardson rule and discrete Fourier transforms of symmetric groups in investigations of algebraic curvature tensors.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2005, "n_citations": 3}
{"id": 500945, "s2_id": "5e3dc43d33aec153e8c9cef8a57d1b0b255a63b3", "title": "Computing Unit Groups of Curves", "abstract": "The group of units modulo constants of an affine variety over an algebraically closed field is free abelian of finite rank. Computing this group is difficult but of fundamental importance in tropical geometry, where it is desirable to realize intrinsic tropicalizations. We present practical algorithms for computing unit groups of smooth curves of low genus. Our approach is rooted in divisor theory, based on interpolation in the case of rational curves and on methods from algebraic number theory in the case of elliptic curves.", "venue": "J. Symb. Comput.", "authors": ["Justin  Chen", "Sameera  Vemulapalli", "Leon  Zhang"], "year": 2021, "n_citations": 0}
{"id": 501855, "s2_id": "ec95cd9ff4ad8a678eb0e218e9461f44d78b2765", "title": "Orbital Graphs", "abstract": "We introduce orbital graphs and discuss some of their basic properties. Then we focus on their usefulness for search algorithms for permutation groups, including finding the intersection of groups and the stabilizer of sets in a group.", "venue": "ArXiv", "authors": ["Christopher  Jefferson", "Markus  Pfeiffer", "Rebecca  Waldecker"], "year": 2017, "n_citations": 0}
{"id": 502259, "s2_id": "212377c7f92c00f396042b3db79feb24ba0a2967", "title": "Extractions: Computable and Visible Analogues of Localizations for Polynomial Ideals", "abstract": "When studying local properties of a polynomial ideal, one usually needs a theoretic technique called localization. For most cases, in spite of its importance, the computation in a localized ring cannot be algorithmically preformed. On the other hand, the standard basis method is very effective for the computation in a special kind of localized rings, but for a general semigroup order the geometry of the localization of a positive-dimensional ideal is difficult to interpret. \nIn this paper, we introduce a new ideal operation called extraction. For an ideal $I$ in a polynomial ring $K[x_1,\\ldots,x_n]$ over a field $K$, we use another ideal $J$ to control the primary components of $I$ and the result $\\beta(I,J)$ is called the extraction of $I$ by $J$. It is still a polynomial ideal and has a concrete geometric meaning in $\\bar{K}^n$, i.e., we keep the branches of $\\textbf{V}(I) \\subset \\bar{K}^n$ that intersect with $\\textbf{V}(J) \\subset \\bar{K}^n$ and delete others, where $\\bar{K}$ is the algebraic closure of $K$. This is what we mean by visible. On the other hand, we can use the standard basis method to compute a localized ideal corresponding to $\\beta(I,J)$ without a complete primary decomposition, and can do further computation in the localized ring such as determining the membership problem of $\\beta(I,J)$. Moreover, we prove that extractions are as powerful as localizations in the sense that for any multiplicatively closed subset $S$ of $K[x_1,\\ldots,x_n]$ and any polynomial ideal $I$, there always exists a polynomial ideal $J$ such that $\\beta(I,J)=(S^{-1}I)^c$.", "venue": "ArXiv", "authors": ["Ye  Liang"], "year": 2015, "n_citations": 0}
{"id": 504540, "s2_id": "cc8cf387c35528e42874268cbab1f15d39758bbd", "title": "Object Oriented and Functional Programming for Symbolic Manipulation", "abstract": "The advantages of mixed approach with using different kinds of programming techniques for symbolic manipulation are discussed. The main purpose of approach offered is merge the methods of object oriented programming that convenient for presentation data and algorithms for user with advantages of functional languages for data manipulation, internal presentation, and portability of software.", "venue": "ArXiv", "authors": ["Alexander Yu. Vlasov"], "year": 1999, "n_citations": 1}
{"id": 505103, "s2_id": "e1a147ea760c178b527adf4e0b9c37b91ff20467", "title": "A modular architecture for transparent computation in Recurrent Neural Networks", "abstract": "Computation is classically studied in terms of automata, formal languages and algorithms; yet, the relation between neural dynamics and symbolic representations and operations is still unclear in traditional eliminative connectionism. Therefore, we suggest a unique perspective on this central issue, to which we would like to refer as transparent connectionism, by proposing accounts of how symbolic computation can be implemented in neural substrates. In this study we first introduce a new model of dynamics on a symbolic space, the versatile shift, showing that it supports the real-time simulation of a range of automata. We then show that the G\u00f6delization of versatile shifts defines nonlinear dynamical automata, dynamical systems evolving on a vectorial space. Finally, we present a mapping between nonlinear dynamical automata and recurrent artificial neural networks. The mapping defines an architecture characterized by its granular modularity, where data, symbolic operations and their control are not only distinguishable in activation space, but also spatially localizable in the network itself, while maintaining a distributed encoding of symbolic representations. The resulting networks simulate automata in real-time and are programmed directly, in the absence of network training. To discuss the unique characteristics of the architecture and their consequences, we present two examples: (i) the design of a Central Pattern Generator from a finite-state locomotive controller, and (ii) the creation of a network simulating a system of interactive automata that supports the parsing of garden-path sentences as investigated in psycholinguistics experiments.", "venue": "Neural Networks", "authors": ["Giovanni S. Carmantini", "Peter beim Graben", "Mathieu  Desroches", "Serafim  Rodrigues"], "year": 2017, "n_citations": 9}
{"id": 510929, "s2_id": "ecd42a31de5cfb30c1d08aeb64fb5a027fbde85e", "title": "A probabilistic algorithm for computing data-discriminants of likelihood equations", "abstract": "An algebraic approach to the maximum likelihood estimation problem is to solve a very structured parameterized polynomial system called likelihood equations that have finitely many complex (real or non-real) solutions. The only solutions that are statistically meaningful are the real solutions with positive coordinates. In order to classify the parameters (data) according to the number of real/positive solutions, we study how to efficiently compute the discriminants, say data-discriminants (DD), of the likelihood equations. We develop a probabilistic algorithm with three different strategies for computing DDs. Our implemented probabilistic algorithm based on Maple and FGb is more efficient than our previous version presented in ISSAC2015, and is also more efficient than the standard elimination for larger benchmarks. By applying RAGlib to a DD we compute, we give the real root classification of 3 by 3 symmetric matrix model.", "venue": "J. Symb. Comput.", "authors": ["Jose Israel Rodriguez", "Xiaoxian  Tang"], "year": 2017, "n_citations": 3}
{"id": 514865, "s2_id": "61515ed5a85fa0828491303c89eb745a1bf1505c", "title": "Reduction-Based Creative Telescoping for Fuchsian D-finite Functions", "abstract": "Abstract Continuing a series of articles in the past few years on creative telescoping using reductions, we adapt Trager's Hermite reduction for algebraic functions to fuchsian D-finite functions whose singularities have real exponents. We develop a reduction-based creative telescoping algorithm for this class of functions, thereby generalizing our recent reduction-based algorithm for algebraic functions, presented at ISSAC 2016.", "venue": "J. Symb. Comput.", "authors": ["Shaoshi  Chen", "Mark van Hoeij", "Manuel  Kauers", "Christoph  Koutschan"], "year": 2018, "n_citations": 23}
{"id": 519774, "s2_id": "2cdea20570bb1f21480cd037ba8770ef7c17fed0", "title": "On the complexity of the multivariate resultant", "abstract": "The multivariate resultant is a fundamental tool of computational algebraic geometry. It can in particular be used to decide whether a system of n homogeneous equations in n variables is satisfiable (the resultant is a polynomial in the system's coefficients which vanishes if and only if the system is satisfiable). In this paper, we investigate the complexity of computing the multivariate resultant. First, we study the complexity of testing the multivariate resultant for zero. Our main result is that this problem is NP-hard under deterministic reductions in any characteristic, for systems of low-degree polynomials with coefficients in the ground field (rather than in an extension). In null characteristic, we observe that this problem is in the Arthur-Merlin class AM if the generalized Riemann hypothesis holds true, while the best known upper bound in positive characteristic remains PSPACE. Second, we study the classical algorithms to compute the resultant. They usually rely on the computation of the determinant of an exponential-size matrix, known as Macaulay matrix. We show that this matrix belongs to a class of succinctly representable matrices, for which testing the determinant for zero is proved PSPACE-complete. This means that improving Canny's PSPACE upper bound requires either to look at the fine structure of the Macaulay matrix to find an ad hoc algorithm for computing its determinant, or to use altogether different techniques.", "venue": "J. Complex.", "authors": ["Bruno  Grenet", "Pascal  Koiran", "Natacha  Portier"], "year": 2013, "n_citations": 12}
{"id": 523848, "s2_id": "d45733f011e8221a2fe51c6b3e21ed64cf657475", "title": "LinBox Founding Scope Allocation, Parallel Building Blocks, and Separate Compilation", "abstract": "As a building block for a wide range of applications, computational exact linear algebra has to conciliate efficiency and genericity. The goal of the LinBox project is to address this problem in the design of an efficient general-purpose C++ opensource library for exact linear algebra over the integers, the rationals, and finite fields. Matrices can be either dense, sparse or black box (i.e. viewed as a linear operator, acting on vectors only). The library proposes a set of high level linear algebra solutions, such as the rank, the determinant, the solution of a linear system, the Smith normal form, the echelon form, the characteristic polynomial, etc.", "venue": "ICMS", "authors": ["Jean-Guillaume  Dumas", "Thierry  Gautier", "Cl\u00e9ment  Pernet", "B. David Saunders"], "year": 2010, "n_citations": 7}
{"id": 524803, "s2_id": "c624996023f6ad522c3877ed2ec8d6c301aae100", "title": "Using Alloy to model-check visual design notations", "abstract": "This paper explores the process of validation for the abstract syntax of a graphical notation. We define a unified specification for five of the UML diagrams used by the discovery method and, in this document, we illustrate how diagrams can be represented in Alloy and checked against our specification in order to know if these are valid under the discovery notation.", "venue": "Sixth Mexican International Conference on Computer Science (ENC'05)", "authors": ["Anthony J. H. Simons", "Carlos Alberto Fern\u00e1ndez y Fern\u00e1ndez"], "year": 2005, "n_citations": 8}
{"id": 528805, "s2_id": "2c0b3550e7e33addaeffba503f964669accd3647", "title": "Real Polynomial Root-Finding by Means of Matrix and Polynomial Iterations", "abstract": "Univariate polynomial root-finding is a classical subject, still important for modern computing. Frequently one seeks just the real roots of a polynomial with real coefficients. They can be approximated at a low computational cost if the polynomial has no nonreal roots, but for high degree polynomials, nonreal roots are typically much more numerous than the real ones. The challenge is known for a long time, and the subject has been intensively studied. Nevertheless, we produce some novel ideas and techniques and obtain dramatic acceleration of the known algorithms. In order to achieve our progress we exploit the correlation between the computations with matrices and polynomials, randomized matrix computations, and complex plane geometry, extend the techniques of the matrix sign iterations, and use the structure of the companion matrix of the input polynomial. The results of our extensive tests with benchmark polynomials and random matrices are quite encouraging. In particular in our tests the number of iterations required for convergence of our algorithms grew very slowly (if at all) as we increased the degree of the univariate input polynomials and the dimension of the input matrices from 64 to 1024.", "venue": "CASC", "authors": ["Victor Y. Pan"], "year": 2014, "n_citations": 4}
{"id": 529561, "s2_id": "6da88a096f9ac64de1717ddef3679525636fb6cf", "title": "Desingularization of First Order Linear Difference Systems with Rational Function Coefficients", "abstract": "It is well known that for a first order system of linear difference equations with rational function coefficients, a solution that is holomorphic in some left half plane can be analytically continued to a meromorphic solution in the whole complex plane. The poles stem from the singularities of the rational function coefficients of the system. Just as for differential equations, not all of these singularities necessarily lead to poles in solutions, as they might be what is called removable. In our work, we show how to detect and remove these singularities and further study the connection between poles of solutions and removable singularities. We describe two algorithms to (partially) desingularize a given difference system and present a characterization of removable singularities in terms of shifts of the original system.", "venue": "ISSAC", "authors": ["Moulay A. Barkatou", "Maximilian  Jaroschek"], "year": 2018, "n_citations": 2}
{"id": 532828, "s2_id": "a4646aa49ad1ed0bd191b45782d30ec9b17a1d58", "title": "Additive Decompositions in Primitive Extensions", "abstract": "This paper extends the classical Hermite-Ostrogradsky reduction for rational functions to more general functions in primitive extensions of certain types. For an element f in such an extension K , the extended reduction decomposes f as the sum of a derivative in K and another element r such that f has an antiderivative in K if and only if r=0; and f has an elementary antiderivative over K if and only if r is a linear combination of logarithmic derivatives over the constants when K is a logarithmic extension. Moreover, r is minimal in some sense. Additive decompositions may lead to reduction-based creative-telescoping methods for nested logarithmic functions, which are not necessarily D -finite.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Hao  Du", "Ziming  Li"], "year": 2018, "n_citations": 4}
{"id": 537904, "s2_id": "d473a5a15f4bac2667979156b67d69d75acaf795", "title": "A New Algorithm for Inverting General Cyclic Heptadiagonal Matrices Recursively", "abstract": "In this paper, we describe a reliable symbolic computational algorithm for inverting general cyclic heptadiagonal matrices by using parallel computing along with recursion. The algorithm is implementable to the Computer Algebra System(CAS) such as MAPLE, Matlab and Mathematica . An example is presented for the sake of illustration.", "venue": "ArXiv", "authors": ["A. A. Karawia"], "year": 2010, "n_citations": 2}
{"id": 555537, "s2_id": "3eb03562ba67b0cb6decb575f7d079ac43a9c2f5", "title": "Liaison linkages", "abstract": "The complete classification of hexapods - also known as Stewart Gough platforms - of mobility one is still open. To tackle this problem, we can associate to each hexapod of mobility one an algebraic curve, called the configuration curve. In this paper we establish an upper bound for the degree of this curve, assuming the hexapod is general enough. Moreover, we provide a construction of hexapods with curves of maximal degree, which is based on liaison, a technique used in the theory of algebraic curves.", "venue": "J. Symb. Comput.", "authors": ["Matteo  Gallet", "Georg  Nawratil", "Josef  Schicho"], "year": 2017, "n_citations": 5}
{"id": 556898, "s2_id": "0a241acc75007681fcd2fd7b815115ba591c9640", "title": "Computer-Assisted Proofs of Some Identities for Bessel Functions of Fractional Order", "abstract": "We employ computer algebra algorithms to prove a collection of identities involving Bessel functions with half-integer orders and other special functions. These identities appear in the famous Handbook of Mathematical Functions, as well as in its successor, the DLMF, but their proofs were lost. We use generating functions and symbolic summation techniques to produce new proofs for them.", "venue": "ArXiv", "authors": ["Stefan  Gerhold", "Manuel  Kauers", "Christoph  Koutschan", "Peter  Paule", "Carsten  Schneider", "Burkhard  Zimmermann"], "year": 2013, "n_citations": 0}
{"id": 562363, "s2_id": "806c5b72805eaf7ed2b9f13069ec972239cef9e1", "title": "Computation of the Adjoint Matrix", "abstract": "The best method for computing the adjoint matrix of an order n matrix in an arbitrary commutative ring requires O(n\u03b2+1/3 log n log log n) operations, provided that the complexity of the algorithm for multiplying two matrices is \u03b3n\u03b2+o(n\u03b2). For a commutative domain \u2013 and under the same assumptions \u2013 the complexity of the best method is 6\u03b3n\u03b2/(2\u03b2\u20132)+o(n\u03b2). In the present work a new method is presented for the computation of the adjoint matrix in a commutative domain. Despite the fact that the number of operations required is now 1.5 times more, than that of the best method, this new method permits a better parallelization of the computational process and may be successfully employed for computations in parallel computational systems.", "venue": "International Conference on Computational Science", "authors": ["Alkiviadis G. Akritas", "Gennadi I. Malaschonok"], "year": 2006, "n_citations": 7}
{"id": 564995, "s2_id": "9a5aa94e752912ecd86eed01006990026321b578", "title": "Improving multivariate Horner schemes with Monte Carlo tree search", "abstract": "Abstract Optimizing the cost of evaluating a polynomial is a classic problem in computer science. For polynomials in one variable, Horner\u2019s method provides a scheme for producing a computationally efficient form. For multivariate polynomials it is possible to generalize Horner\u2019s method, but this leaves freedom in the order of the variables. Traditionally, greedy schemes like most-occurring variable first are used. This simple textbook algorithm has given remarkably efficient results. Finding better algorithms has proved difficult. In trying to improve upon the greedy scheme we have implemented Monte Carlo tree search, a recent search method from the field of artificial intelligence. This results in better Horner schemes and reduces the cost of evaluating polynomials, sometimes by factors up to two.", "venue": "Comput. Phys. Commun.", "authors": ["Jan  Kuipers", "Aske  Plaat", "J. A. M. Vermaseren", "H. Jaap van den Herik"], "year": 2013, "n_citations": 28}
{"id": 565210, "s2_id": "7a6db835f3b3557cf976924aee9b99f21205a990", "title": "Learning selection strategies in Buchberger's algorithm", "abstract": "Studying the set of exact solutions of a system of polynomial equations largely depends on a single iterative algorithm, known as Buchberger's algorithm. Optimized versions of this algorithm are crucial for many computer algebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach to Buchberger's algorithm that uses reinforcement learning agents to perform S-pair selection, a key step in the algorithm. We then study how the difficulty of the problem depends on the choices of domain and distribution of polynomials, about which little is known. Finally, we train a policy model using proximal policy optimization (PPO) to learn S-pair selection strategies for random systems of binomial equations. In certain domains, the trained model outperforms state-of-the-art selection heuristics in total number of polynomial additions performed, which provides a proof-of-concept that recent developments in machine learning have the potential to improve performance of algorithms in symbolic computation.", "venue": "ICML", "authors": ["Dylan  Peifer", "Michael  Stillman", "Daniel  Halpern-Leistner"], "year": 2020, "n_citations": 9}
{"id": 566304, "s2_id": "33a6d16eb1fe68c23329fdb3627247367fe9c0b8", "title": "Error Correction in Fast Matrix Multiplication and Inverse", "abstract": "We present new algorithms to detect and correct errors in the product of two matrices, or the inverse of a matrix, over an arbitrary field. Our algorithms do not require any additional information or encoding other than the original inputs and the erroneous output. Their running time is softly linear in the number of nonzero entries in these matrices when the number of errors is sufficiently small, and they also incorporate fast matrix multiplication so that the cost scales well when the number of errors is large. These algorithms build on the recent result of Gasieniec et al (2017) on correcting matrix products, as well as existing work on verification algorithms, sparse low-rank linear algebra, and sparse polynomial interpolation.", "venue": "ISSAC", "authors": ["Daniel S. Roche"], "year": 2018, "n_citations": 3}
{"id": 567102, "s2_id": "cab166abcb32f1d2913587c43b28548f2823d730", "title": "Parallel computation of real solving bivariate polynomial systems by zero-matching method", "abstract": "We present a new algorithm for solving the real roots of a bivariate polynomial system @S={f(x,y),g(x,y)} with a finite number of solutions by using a zero-matching method. The method is based on a lower bound for the bivariate polynomial system when the system is non-zero. Moreover, the multiplicities of the roots of @S=0 can be obtained by the associated quotient ring technique and a given neighborhood. From this approach, the parallelization of the method arises naturally. By using a multidimensional matching method this principle can be generalized to the multivariate equation systems.", "venue": "Appl. Math. Comput.", "authors": ["Xiaolin  Qin", "Yong  Feng", "Jingwei  Chen", "Jingzhong  Zhang"], "year": 2013, "n_citations": 3}
{"id": 567437, "s2_id": "2cd26af8aafe92557c05be549d3ddc647d22f640", "title": "Kempe\u2019s Universality Theorem for Rational Space Curves", "abstract": "We prove that every bounded rational space curve of degree d and circularity c can be drawn by a linkage with $$ \\frac{9}{2} d-6c+1$$92d-6c+1 revolute joints. Our proof is based on two ingredients. The first one is the factorization theory of motion polynomials. The second one is the construction of a motion polynomial of minimum degree with given orbit. Our proof also gives the explicit construction of the linkage.", "venue": "Found. Comput. Math.", "authors": ["Zijia  Li", "Josef  Schicho", "Hans-Peter  Schr\u00f6cker"], "year": 2018, "n_citations": 11}
{"id": 570079, "s2_id": "001b81519d7d47d34883bac1479439d683822436", "title": "On Affine Tropical F5 Algorithms", "abstract": "Let K be a field equipped with a valuation. Tropical varieties over K can be defined with a theory of Gr\u00f6bner bases taking into account the valuation of K . Because of the use of the valuation, the theory of tropical Gr\u00f6bner bases has proved to provide settings for computations over polynomial rings over a p -adic field that are more stable than that of classical Gr\u00f6bner bases. Beforehand, these strategies were only available for homogeneous polynomials. In this article, we extend the F5 strategy to a new definition of tropical Gr\u00f6bner bases in an affine setting. We provide numerical examples to illustrate time-complexity and p -adic stability of this tropical F5 algorithm. We also illustrate its merits as a first step before an FGLM algorithm to compute (classical) lex bases over p -adics.", "venue": "ISSAC", "authors": ["Tristan  Vaccon", "Thibaut  Verron", "Kazuhiro  Yokoyama"], "year": 2018, "n_citations": 3}
{"id": 571725, "s2_id": "eef45080d18b8ec978bab13076e4b74ea2a03461", "title": "Determination and (re)parametrization of rational developable surfaces", "abstract": "The developable surface is an important surface in computer aided design, geometric modeling and industrial manufactory. It is often given in the standard parametric form, but it can also be in the implicit form which is commonly used in algebraic geometry. Not all algebraic developable surfaces have rational parametrizations. In this paper, the authors focus on the rational developable surfaces. For a given algebraic surface, the authors first determine whether it is developable by geometric inspection, and then give a rational proper parametrization in the affirmative case. For a rational parametric surface, the authors also determine the developability and give a proper reparametrization for the developable surface.", "venue": "J. Syst. Sci. Complex.", "authors": ["Li-Yong  Shen", "Sonia  P\u00e9rez-D\u00edaz"], "year": 2015, "n_citations": 6}
{"id": 574006, "s2_id": "66cd88c0e46a4d9c643191361b4cb7b2deb92bd9", "title": "A Short Note on Zero-error Computation for Algebraic Numbers by IPSLQ", "abstract": "The PSLQ algorithm is one of the most popular algorithm for finding nontrivial integer relations for several real numbers. In the present work, we present an incremental version of PSLQ. For some applications needing to call PSLQ many times, such as finding the minimal polynomial of an algebraic number without knowing the degree, the incremental PSLQ algorithm is more efficient than PSLQ, both theoretically and practically.", "venue": "ArXiv", "authors": ["Yong  Feng", "Jingwei  Chen", "Wenyuan  Wu"], "year": 2014, "n_citations": 0}
{"id": 574466, "s2_id": "76f69b481c3f26ecc4bc65119cac459c8e817bd0", "title": "Using Machine Learning to Decide When to Precondition Cylindrical Algebraic Decomposition with Groebner Bases", "abstract": "Cylindrical Algebraic Decomposition (CAD) is a key tool in computational algebraic geometry, particularly for quantifier elimination over real-closed fields. However, it can be expensive, with worst case complexity doubly exponential in the size of the input. Hence it is important to formulate the problem in the best manner for the CAD algorithm. One possibility is to precondition the input polynomials using Groebner Basis (GB) theory. Previous experiments have shown that while this can often be very beneficial to the CAD algorithm, for some problems it can significantly worsen the CAD performance. In the present paper we investigate whether machine learning, specifically a support vector machine (SVM), may be used to identify those CAD problems which benefit from GB preconditioning. We run experiments with over 1000 problems (many times larger than previous studies) and find that the machine learned choice does better than the human-made heuristic.", "venue": "2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)", "authors": ["Zongyan  Huang", "Matthew  England", "James H. Davenport", "Lawrence C. Paulson"], "year": 2016, "n_citations": 15}
{"id": 578363, "s2_id": "f364c3b88384968a7636e630de5933c59b0bb243", "title": "Data-Discriminants of Likelihood Equations", "abstract": "Maximum likelihood estimation (MLE) is a fundamental computational problem in statistics. The problem is to maximize the likelihood function with respect to given data on a statistical model. An algebraic approach to this problem is to solve a very structured parameterized polynomial system called likelihood equations. For general choices of data, the number of complex solutions to the likelihood equations is finite and called the ML-degree of the model. The only solutions to the likelihood equations that are statistically meaningful are the real/positive solutions. However, the number of real/positive solutions is not characterized by the ML-degree. We use discriminants to classify data according to the number of real/positive solutions of the likelihood equations. We call these discriminants data-discriminants (DD). We develop a probabilistic algorithm for computing DDs. Experimental results show that, for the benchmarks we have tried, the probabilistic algorithm is more efficient than the standard elimination algorithm. Based on the computational results, we discuss the real root classification problem for the 3 by 3 symmetric matrix~model.", "venue": "ISSAC", "authors": ["Jose Israel Rodriguez", "Xiaoxian  Tang"], "year": 2015, "n_citations": 11}
{"id": 578737, "s2_id": "3e92673b934f91ba251609a25b418e4a9ba700d8", "title": "CAD Adjacency Computation Using Validated Numerics", "abstract": "We present an algorithm for computation of cell adjacencies for well-based cylindrical algebraic decomposition. Cell adjacency information can be used to compute topological operations e.g. closure, boundary, connected components, and topological properties e.g. homology groups. Other applications include visualization and path planning. Our algorithm determines cell adjacency information using validated numerical methods similar to those used in CAD construction, thus computing CAD with adjacency information in time comparable to that of computing CAD without adjacency information. We report on implementation of the algorithm and present empirical data.", "venue": "ISSAC", "authors": ["Adam W. Strzebonski"], "year": 2017, "n_citations": 7}
{"id": 584364, "s2_id": "f72b84fd6f1074cf6e0ac08fb517acb1a7cce7a3", "title": "Reconstruction of surfaces with ordinary singularities from their silhouettes", "abstract": "We present algorithms for reconstructing, up to unavoidable projective automorphisms, surfaces with ordinary singularities in three dimensional space starting from their silhouette, or \"apparent contour\" - namely the branching locus of a projection on the plane - and the projection of their singular locus.", "venue": "SIAM J. Appl. Algebra Geom.", "authors": ["Matteo  Gallet", "Niels  Lubbes", "Josef  Schicho", "Jan  Vrsek"], "year": 2019, "n_citations": 2}
{"id": 585149, "s2_id": "7c77f9bed65a2bb8560514d0aa8546e83310111b", "title": "A proposal to first principles electronic structure calculation: Symbolic-Numeric method", "abstract": "This study proposes an approach toward the first principles electronic structure calculation with the aid of symbolic-numeric solving. The symbolic computation enables us to express the Hartree-Fock-Roothaan equation and the molecular integrals in analytic forms and approximate them as a set of polynomial equations. By use of the Grobner bases technique, the polynomial equations are transformed into other ones which have identical roots. The converted equations take more convenient forms which will simplify numerical procedures, from which we can derive necessary physical properties in order, in an a la carte way. This method enables us to solve the electronic structure calculation, the optimization of any kind, or the inverse problem as a forward problem in a unified way, in which there is no need for iterative self-consistent procedures with trials and errors.", "venue": "ArXiv", "authors": ["Akihito  Kikuchi"], "year": 2012, "n_citations": 0}
{"id": 585175, "s2_id": "dcd7db3ea1de58ac8e702a1f5ca3e340f60cef6d", "title": "The Hilbert scheme of points and its link with border basis", "abstract": "In this paper, we give new explicit representations of the Hilbert scheme of $\\mu$ points in $\\PP^{r}$ as a projective subvariety of a Grassmanniann variety. This new explicit description of the Hilbert scheme is simpler than the previous ones and global. It involves equations of degree $2$. We show how these equations are deduced from the commutation relations characterizing border bases. Next, we consider infinitesimal perturbations of an input system of equations on this Hilbert scheme and describe its tangent space. We propose an effective criterion to test if it is a flat deformation, that is if the perturbed system remains on the Hilbert scheme of the initial equations. This criterion involves in particular formal reduction with respect to border bases.", "venue": "ArXiv", "authors": ["Mariemi  Alonso", "J\u00e9r\u00f4me  Brachat", "Bernard  Mourrain"], "year": 2009, "n_citations": 10}
{"id": 589000, "s2_id": "8e7ab565d5ef36cdaf686b1866cc8db39510473f", "title": "Unified form language: A domain-specific language for weak formulations of partial differential equations", "abstract": "We present the Unified Form Language (UFL), which is a domain-specific language for representing weak formulations of partial differential equations with a view to numerical approximation. Features of UFL include support for variational forms and functionals, automatic differentiation of forms and expressions, arbitrary function space hierarchies for multifield problems, general differential operators and flexible tensor algebra. With these features, UFL has been used to effortlessly express finite element methods for complex systems of partial differential equations in near-mathematical notation, resulting in compact, intuitive and readable programs. We present in this work the language and its construction. An implementation of UFL is freely available as an open-source software library. The library generates abstract syntax tree representations of variational problems, which are used by other software libraries to generate concrete low-level implementations. Some application examples are presented and libraries that support UFL are highlighted.", "venue": "TOMS", "authors": ["Martin Sandve Aln\u00e6s", "Anders  Logg", "Kristian B. \u00d8lgaard", "Marie E. Rognes", "Garth N. Wells"], "year": 2014, "n_citations": 290}
{"id": 608407, "s2_id": "0319e5c5c2a0753a4c163bda1f638dc3d831e072", "title": "Computing Popov and Hermite Forms of Rectangular Polynomial Matrices", "abstract": "We consider the computation of two normal forms for matrices over the univariate polynomials: the Popov form and the Hermite form. For matrices which are square and nonsingular, deterministic algorithms with satisfactory cost bounds are known. Here, we present deterministic, fast algorithms for rectangular input matrices. The obtained cost bound for the Popov form matches the previous best known randomized algorithm, while the cost bound for the Hermite form improves on the previous best known ones by a factor which is at least the largest dimension of the input matrix.", "venue": "ISSAC", "authors": ["Vincent  Neiger", "Johan  Rosenkilde", "Grigory  Solomatov"], "year": 2018, "n_citations": 8}
{"id": 612653, "s2_id": "ae1a5f12f9626d6e57685416876b872a301fc1d2", "title": "On factorization and solution of multidimensional linear partial differential equations", "abstract": "We describe a method of obtaining closed-form complete solutions of certain second-order linear partial differential equations with more than two independent variables. This method generalizes the classical method of Laplace transformations of second-order hyperbolic equations in the plane and is based on an idea given by Ulisse Dini in 1902.", "venue": "ArXiv", "authors": ["Sergey P. Tsarev"], "year": 2006, "n_citations": 18}
{"id": 612797, "s2_id": "8e0df8bc12fa3cc7eed0ca91e2c1567bd676ca7c", "title": "A novel approach to integration by parts reduction", "abstract": "Abstract Integration by parts reduction is a standard component of most modern multi-loop calculations in quantum field theory. We present a novel strategy constructed to overcome the limitations of currently available reduction programs based on Laporta's algorithm. The key idea is to construct algebraic identities from numerical samples obtained from reductions over finite fields. We expect the method to be highly amenable to parallelization, show a low memory footprint during the reduction step, and allow for significantly better run-times.", "venue": "ArXiv", "authors": ["Andreas von Manteuffel", "Robert M. Schabinger"], "year": 2014, "n_citations": 138}
{"id": 615232, "s2_id": "c48a2408d3ff16836935275bab16947fefc00f1a", "title": "Faster arithmetic for number-theoretic transforms", "abstract": "We show how to improve the efficiency of the computation of fast Fourier transforms over F\"p where p is a word-sized prime. Our main technique is optimisation of the basic arithmetic, in effect decreasing the total number of reductions modulo p, by making use of a redundant representation for integers modulo p. We give performance results showing a significant improvement over [email\u00a0protected]?s NTL library.", "venue": "J. Symb. Comput.", "authors": ["David  Harvey"], "year": 2014, "n_citations": 62}
{"id": 617150, "s2_id": "0a448600a220b07e923d59716cb182000aae2d47", "title": "A test for monomial containment", "abstract": "Abstract We present an algorithm based on triangular sets to decide whether a given ideal in the polynomial ring contains a monomial.", "venue": "J. Symb. Comput.", "authors": ["Simon  Keicher", "Thomas  Kremer"], "year": 2017, "n_citations": 0}
{"id": 619492, "s2_id": "1184c8f3204e2762298bf7170ff942da4a3758be", "title": "The 1958 Pekeris-Accad-WEIZAC Ground-Breaking Collaboration that Computed Ground States of Two-Electron Atoms (and its 2010 Redux)", "abstract": "In order to appreciate how well off we mathematicians and scientists are today, with extremely fast hardware and lots and lots of memory, as well as with powerful software, both for numeric and symbolic computation, it may be a good idea to go back to the early days of electronic computers and compare how things went then. We have chosen, as a case study, a problem that was considered a huge challenge at the time. Namely, we looked at C.L. Pekeris's seminal 1958 work on the ground state energies of two-electron atoms. We went through all the computations ab initio with today's software and hardware, with a special emphasis on the symbolic computations which in 1958 had to be made by hand, and which nowadays can be automated and generalized.", "venue": "ArXiv", "authors": ["Christoph  Koutschan", "Doron  Zeilberger"], "year": 2010, "n_citations": 6}
{"id": 619854, "s2_id": "650334c867d4350fa6818d69e271daa0cdc74d03", "title": "Computing effectively stabilizing controllers for a class of nD systems", "abstract": "In this paper, we study the internal stabilizability and internal stabilization problems for multidimensional (nD) systems. Within the fractional representation approach, a multidimen-sional system can be studied by means of matrices with entries in the integral domain of structurally stable rational fractions, namely the ring of rational functions which have no poles in the closed unit polydisc U n = {z = (z 1 ,. .. , z n) \u2208 C n | |z 1 | 1,. .. , |z n | 1}. It is known that the internal stabilizability of a multidimensional system can be investigated by studying a certain polynomial ideal I = p 1 ,. .. , p r that can be explicitly described in terms of the transfer matrix of the plant. More precisely the system is stabilizable if and only if V (I) = {z \u2208 C n | p 1 (z) = \u00b7 \u00b7 \u00b7 = p r (z) = 0} \u2229 U n = \u2205. In the present article, we consider the specific class of linear nD systems (which includes the class of 2D systems) for which the ideal I is zero-dimensional, i.e., the p i 's have only a finite number of common complex zeros. We propose effective symbolic-numeric algorithms for testing if V (I) \u2229 U n = \u2205, as well as for computing, if it exists, a stable polynomial p \u2208 I which allows the effective computation of a stabilizing controller. We illustrate our algorithms through an example and finally provide running times of prototype implementations for 2D and 3D systems.", "venue": "ArXiv", "authors": ["Yacine  Bouzidi", "Thomas  Cluzeau", "Guillaume  Moroz", "Alban  Quadrat"], "year": 2018, "n_citations": 2}
{"id": 620508, "s2_id": "ab02c62e1cb04ff22cd871d71c340791117990f4", "title": "Whitehead method and Genetic Algorithms", "abstract": "In this paper we discuss a genetic version (GWA) of the Whitehead's algorithm, which is one of the basic algorithms in combinatorial group theory. It turns out that GWA is surprisingly fast and outperforms the standard Whitehead's algorithm in free groups of rank >= 5. Experimenting with GWA we collected an interesting numerical data that clarifies the time-complexity of the Whitehead's Problem in general. These experiments led us to several mathematical conjectures. If confirmed they will shed light on hidden mechanisms of Whitehead Method and geometry of automorphic orbits in free groups.", "venue": "ArXiv", "authors": ["Alexei D. Miasnikov", "Alexei G. Myasnikov"], "year": 2003, "n_citations": 19}
{"id": 621250, "s2_id": "1e910927c579c967e1317c9b22d8cd08e11e79f8", "title": "Fast computation of power series solutions of systems of differential equations", "abstract": "We propose algorithms for the computation of the first N terms of a vector (or a full basis) of power series solutions of a linear system of differential equations at an ordinary point, using a number of arithmetic operations that is quasi-linear with respect to N. Similar results are also given in the non-linear case. This extends previous results obtained by Brent and Kung for scalar differential equations of order 1 and 2.", "venue": "SODA '07", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Fran\u00e7ois  Ollivier", "Bruno  Salvy", "\u00c9ric  Schost", "Alexandre  Sedoglavic"], "year": 2007, "n_citations": 38}
{"id": 628496, "s2_id": "4cc58c23001f546d0c396c59b692737dbcfa3b1f", "title": "The Complexity of Computing all Subfields of an Algebraic Number Field", "abstract": "For a finite separable field extension K/k, all subfields can be obtained by intersecting so-called principal subfields of K/k. In this work we present a way to quickly compute these intersections. If the number of subfields is high, then this leads to faster run times and an improved complexity.", "venue": "J. Symb. Comput.", "authors": ["Jonas  Szutkoski", "Mark van Hoeij"], "year": 2019, "n_citations": 4}
{"id": 632342, "s2_id": "724cb9c68a57136ce024865340c0a8e75aeef723", "title": "Generators of algebraic covariant derivative curvature tensors and Young symmetrizers", "abstract": "We show that the space of algebraic covariant derivative curvature tensors R' is generated by Young symmetrized tensor products W*U or U*W, where W and U are covariant tensors of order 2 and 3 whose symmetry classes are irreducible and characterized by the following pairs of partitions: {(2),(3)}, {(2),(2 1)} or {(1 1),(2 1)}. Each of the partitions (2), (3) and (1 1) describes exactly one symmetry class, whereas the partition (2 1) characterizes an infinite set S of irreducible symmetry classes. This set S contains exactly one symmetry class S_0 whose elements U can not play the role of generators of tensors R'. The tensors U of all other symmetry classes from S\\{S_0} can be used as generators for tensors R'. Foundation of our investigations is a theorem of S. A. Fulling, R. C. King, B. G. Wybourne and C. J. Cummins about a Young symmetrizer that generates the symmetry class of algebraic covariant derivative curvature tensors. Furthermore we apply ideals and idempotents in group rings C[Sr], the Littlewood-Richardson rule and discrete Fourier transforms for symmetric groups Sr. For certain symbolic calculations we used the Mathematica packages Ricci and PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2003, "n_citations": 12}
{"id": 641346, "s2_id": "9a09eb02f74afbecef064c321206200fa0a80c8f", "title": "On the Complexity of Solving Zero-Dimensional Polynomial Systems via Projection", "abstract": "Given a zero-dimensional polynomial system consisting of n integer polynomials in n variables, we propose a certified and complete method to compute all complex solutions of the system as well as a corresponding separating linear form l with coefficients of small bit size. For computing l, we need to project the solutions into one dimension along O(n) distinct directions but no further algebraic manipulations. The solutions are then directly reconstructed from the considered projections. The first step is deterministic, whereas the second step uses randomization, thus being Las Vegas. The theoretical analysis of our approach shows that the overall cost for the two problems considered above is dominated by the cost of carrying out the projections. We also give bounds on the bit complexity of our algorithms that are exclusively stated in terms of the number of variables, the total degree and the bitsize of the input polynomials.", "venue": "ISSAC", "authors": ["Cornelius  Brand", "Michael  Sagraloff"], "year": 2016, "n_citations": 7}
{"id": 649093, "s2_id": "88f7b68a0563313f50e387f335f500bd32d4b874", "title": "Q-adic transform revisited", "abstract": "We present an algorithm to perform a simultaneous modular reduction of several residues. This enables to compress polynomials into integers and perform several modular operations with machine integer arithmetic. The idea is to convert the X-adic representation of modular polynomials, with X an indeterminate, to a q-adic representation where q is an integer larger than the field characteristic. With some control on the different involved sizes it is then possible to perform some of the q-adic arithmetic directly with machine integers or floating points. Depending also on the number of performed numerical operations one can then convert back to the q-adic or X-adic representation and eventually mod out high residues. In this note we present a new version of both conversions: more tabulations and a way to reduce the number of divisions involved in the process are presented. The polynomial multiplication is then applied to arithmetic and linear algebra in small finite field extensions.", "venue": "ISSAC '08", "authors": ["Jean-Guillaume  Dumas"], "year": 2008, "n_citations": 8}
{"id": 649135, "s2_id": "1f953fbe6c7b1e4f60fa5644e27054a6b3c5a993", "title": "A Modal Logic for Termgraph Rewriting", "abstract": "We propose a modal logic tailored to describe graph transformations and discuss some of its properties. We focus on a particular class of graphs called termgraphs. They are first-order terms augmented with sharing and cycles. Termgraphs allow one to describe classical data-structures (possibly with pointers) such as doubly-linked lists, circular lists etc. We show how the proposed logic can faithfully describe (i) termgraphs as well as (ii) the application of a termgraph rewrite rule (i.e. matching and replacement) and (iii) the computation of normal forms with respect to a given rewrite system. We also show how the proposed logic, which is more expressive than propositional dynamic logic, can be used to specify shapes of classical data-structures (e.g. binary trees, circular lists etc.).", "venue": "ArXiv", "authors": ["Philippe  Balbiani", "Rachid  Echahed", "Andreas  Herzig"], "year": 2010, "n_citations": 0}
{"id": 652181, "s2_id": "c586284af1c6a4a7bd04247edc6c2c97bfd87152", "title": "A unified framework for equivalences in social networks", "abstract": "A key concern in network analysis is the study of social positions and roles of actors in a network. The notion of \"position\" refers to an equivalence class of nodes that have similar ties to other nodes, whereas a \"role\" is an equivalence class of compound relations that connect the same pairs of nodes. An open question in network science is whether it is possible to simultaneously perform role and positional analysis. Motivated by the principle of functoriality in category theory we propose a new method that allows to tie role and positional analysis together. We illustrate our methods on two well-studied data sets in network science.", "venue": "ArXiv", "authors": ["Nina  Otter", "Mason A. Porter"], "year": 2020, "n_citations": 0}
{"id": 652971, "s2_id": "fb1e36046a25d3c67af9c671abcdde126c7a188d", "title": "Nearly Optimal Sparse Polynomial Multiplication", "abstract": "In the sparse polynomial multiplication problem, one is asked to multiply two sparse polynomials <inline-formula> <tex-math notation=\"LaTeX\">$f$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$g$ </tex-math></inline-formula> in time that is proportional to the size of the input plus the size of the output. The polynomials are given via lists, <inline-formula> <tex-math notation=\"LaTeX\">$F$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$G$ </tex-math></inline-formula>, of their coefficients. Cole and Hariharan (STOC 02) have given a nearly optimal algorithm when the coefficients are positive, and Arnold and Roche (ISSAC 15) devised an algorithm running in time proportional to the \u201cstructural sparsity\u201d of the product, i.e. the set <inline-formula> <tex-math notation=\"LaTeX\">$\\mathrm {supp}(F) + \\mathrm {supp}(G)$ </tex-math></inline-formula>. The latter algorithm is particularly efficient when there are not \u201ctoo many cancellations\u201d of coefficients in the product. In this work we give a clean, nearly optimal algorithm for the sparse polynomial multiplication problem.", "venue": "IEEE Transactions on Information Theory", "authors": ["Vasileios  Nakos"], "year": 2020, "n_citations": 9}
{"id": 654468, "s2_id": "05a114c5c8aa9545b1eab7e675ee269225d264d1", "title": "Decreasing Diagrams and Relative Termination", "abstract": "In this paper we use the decreasing diagrams technique to show that a left-linear term rewrite system ${\\mathcal{R}}$ is confluent if all its critical pairs are joinable and the critical pair steps are relatively terminating with respect to ${\\mathcal{R}}$. We further show how to encode the rule-labeling heuristic for decreasing diagrams as a satisfiability problem. Experimental data for both methods are presented.", "venue": "IJCAR", "authors": ["Nao  Hirokawa", "Aart  Middeldorp"], "year": 2010, "n_citations": 1}
{"id": 657122, "s2_id": "39e683da705fa0f192f5c10b6602f5d9e9723b56", "title": "Combining Sub-Symbolic and Symbolic Methods for Explainability", "abstract": "Similarly to other connectionist models, Graph Neural Networks (GNNs) lack transparency in their decision-making. A number of sub-symbolic approaches have been developed to provide insights into the GNN decision making process. These are first important steps on the way to explainability, but the generated explanations are often hard to understand for users that are not AI experts. To overcome this problem, we introduce a conceptual approach combining sub-symbolic and symbolic methods for human-centric explanations, that incorporate domain knowledge and causality. We furthermore introduce the notion of fidelity as a metric for evaluating how close the explanation is to the GNN\u2019s internal decision making process. The evaluation with a chemical dataset and ontology shows the explanatory value and reliability of our method.", "venue": "RuleML+RR", "authors": ["Anna  Himmelhuber", "Stephan  Grimm", "Sonja  Zillner", "Mitchell  Joblin", "Martin  Ringsquandl", "Thomas  Runkler"], "year": 2021, "n_citations": 0}
{"id": 671264, "s2_id": "622a765c75626f631a386c206acb9ed613b9140d", "title": "Computation of gcd chain over the power of an irreducible polynomial", "abstract": "A notion of gcd chain has been introduced by the author at ISSAC 2017 for two univariate monic polynomials with coefficients in a ring R = k[x_1, ..., x_n ]/(T) where T is a primary triangular set of dimension zero. A complete algorithm to compute such a gcd chain remains challenging. This work treats completely the case of a triangular set T = (T_1 (x)) in one variable, namely a power of an irreducible polynomial. This seemingly \"easy\" case reveals the main steps necessary for treating the general case, and it allows to isolate the particular one step that does not directly extend and requires more care.", "venue": "ArXiv", "authors": ["Xavier  Dahan"], "year": 2018, "n_citations": 0}
{"id": 674269, "s2_id": "17cb378141416cd383b2b0c62b076caf306a4935", "title": "On some classes of irreducible polynomials", "abstract": "The aim of the paper is to produce new families of irreducible polynomials, generalizing previous results in the area. One example of our general result is that for a near-separated polynomial, i.e., polynomials of the form $F(x,y)=f_1(x)f_2(y)-f_2(x)f_1(y)$, then $F(x,y)+r$ is always irreducible for any constant $r$ different from zero. We also provide the biggest known family of HIP polynomials in several variables. These are polynomials $p(x_1,\\ldots,x_n) \\in K[x_1,\\ldots,x_n]$ over a zero characteristic field $K$ such that $p(h_1(x_1),\\ldots,h_n(x_n))$ is irreducible over $K$ for every $n$-tuple $h_1(x_1),\\ldots,h_n(x_n)$ of non constant one variable polynomials over $K$. The results can also be applied to fields of positive characteristic, with some modifications.", "venue": "J. Symb. Comput.", "authors": ["Jaime  Gutierrez", "Jorge Jim\u00e9nez Urroz"], "year": 2021, "n_citations": 2}
{"id": 675168, "s2_id": "1367bcf138c23bf58d5b66f1896320177b39749b", "title": "Can the Eureqa symbolic regression program, computer algebra and numerical analysis help each other?", "abstract": "The Eureqa symbolic regression program has recently received extensive press praise. A representative quote is \n\"There are very clever 'thinking machines' in existence today, such as Watson, the IBM computer that conquered Jeopardy! last year. But next to Eureqa, Watson is merely a glorified search engine.\" \nThe program was designed to work with noisy experimental data. However, if the data is generated from an expression for which there exists more concise equivalent expressions, sometimes some of the Eureqa results are one or more of those more concise equivalents. If not, perhaps one or more of the returned Eureqa results might be a sufficiently accurate approximation that is more concise than the given expression. Moreover, when there is no known closed form expression, the data points can be generated by numerical methods, enabling Eureqa to find expressions that concisely fit those data points with sufficient accuracy. In contrast to typical regression software, the user does not have to explicitly or implicitly provide a specific expression or class of expressions containiing unknown constants for the software to determine. \nIs Eureqa useful enough in these regards to provide an additional tool for experimental mathematics, computer algebra users and numerical analysis? Yes if used carefully. Can computer algebra and numerical methods help Eureqa? Definitely.", "venue": "ArXiv", "authors": ["David R. Stoutemyer"], "year": 2012, "n_citations": 12}
{"id": 677910, "s2_id": "2c09b6168fed0e9dbbfb4a6189e66006c27dfb69", "title": "On the design of an expert help system for computer algebra systems", "abstract": "REDUCE[2, 3], like many modern Computer Algebra Systems (CAS) (MACSYMA, MATHEMATICA, MAPLE, SCRATCHPAD to name a few), embodies a large amount of mathematical knowledge which is spread out through thousands of procedures in the source code of the system. Most of this knowledge is, however, in an implicit form almost inaccessible to the user, who would have to decipher the source files to recover it. Also, to profit from it one needs to know in addition the capabilities of these computing systems and how to operate them.", "venue": "SIGS", "authors": ["Renato P. dos Santos", "Waldir L. Roque"], "year": 1990, "n_citations": 2}
{"id": 692073, "s2_id": "c92a1c865a76e8c8c457b9e031abd3e7b7563756", "title": "A Novel Symbolic Type Neural Network Model- Application to River Flow Forecasting", "abstract": "In this paper we introduce a new symbolic type neural tree network called symbolic function network (SFN) that is based on using elementary functions to model systems in a symbolic form. The proposed formulation permits feature selection, functional selection, and flexible structure. We applied this model on the River Flow forecasting problem. The results found to be superior in both fitness and sparsity.", "venue": "ArXiv", "authors": ["George S. Eskander", "Amir F. Atiya"], "year": 2008, "n_citations": 1}
{"id": 692862, "s2_id": "bce8aa5729e3cdcacb9bb48303e0d860781cbeae", "title": "Fast polynomial evaluation and composition", "abstract": "The library \\emph{fast\\_polynomial} for Sage compiles multivariate polynomials for subsequent fast evaluation. Several evaluation schemes are handled, such as Horner, divide and conquer and new ones can be added easily. Notably, a new scheme is introduced that improves the classical divide and conquer scheme when the number of terms is not a pure power of two. Natively, the library handles polynomials over gmp big integers, boost intervals, python numeric types. And any type that supports addition and multiplication can extend the library thanks to the template design. Finally, the code is parallelized for the divide and conquer schemes, and memory allocation is localized and optimized for the different evaluation schemes. This extended abstract presents the concepts behind the \\emph{fast\\_polynomial} library. The sage package can be downloaded at \\url{http://trac.sagemath.org/sage_trac/ticket/13358}.", "venue": "ArXiv", "authors": ["Guillaume  Moroz"], "year": 2013, "n_citations": 3}
{"id": 701112, "s2_id": "2d0a8830794036e2b9bbd0d684599605f17eea36", "title": "The Berlekamp-Massey Algorithm via Minimal Polynomials", "abstract": "We present a recursive minimal polynomial theorem for finite sequences over a commutative integral domain $D$. This theorem is relative to any element of $D$. The ingredients are: the arithmetic of Laurent polynomials over $D$, a recursive 'index function' and simple mathematical induction. Taking reciprocals gives a 'Berlekamp-Massey theorem' i.e. a recursive construction of the polynomials arising in the Berlekamp-Massey algorithm, relative to any element of $D$. The recursive theorem readily yields the iterative minimal polynomial algorithm due to the author and a transparent derivation of the iterative Berlekamp-Massey algorithm. \nWe give an upper bound for the sum of the linear complexities of $s$ which is tight if $s$ has a perfect linear complexity profile. This implies that over a field, both iterative algorithms require at most $2\\lfloor \\frac{n^2}{4}\\rfloor$ multiplications.", "venue": "ArXiv", "authors": ["Graham H. Norton"], "year": 2010, "n_citations": 7}
{"id": 702624, "s2_id": "c711bbd5dff800bde9eeaf095885d6eb3b7a6af8", "title": "GAPS: Generator for Automatic Polynomial Solvers", "abstract": "Minimal problems in computer vision raise the demand of generating efficient automatic solvers for polynomial equation systems. Given a polynomial system repeated with different coefficient instances, the traditional Grobner basis or normal form based solution is very inefficient. Fortunately the Grobner basis of a same polynomial system with different coefficients is found to share consistent inner structure. By precomputing such structures offline, Grobner basis as well as the polynomial system solutions can be solved automatically and efficiently online. In the past decade, several tools have been released to generate automatic solvers for a general minimal problems. The most recent tool autogen from Larsson et al. is a representative of these tools with state-of-the-art performance in solver efficiency. GAPS wraps and improves autogen with more user-friendly interface, more functionality and better stability. We demonstrate in this report the main approach and enhancement features of GAPS. A short tutorial of the software is also included.", "venue": "ArXiv", "authors": ["Bo  Li", "Viktor  Larsson"], "year": 2020, "n_citations": 3}
{"id": 710743, "s2_id": "3b2a6fe4ecaff403f32766a4b60b03a7f01694d4", "title": "An echelon form of weakly infeasible semidefinite programs and bad projections of the psd cone", "abstract": "A weakly infeasible semidefinite program (SDP) has no feasible solution, but it has approximate solutions whose constraint violation is arbitrarily small. These SDPs are ill-posed and numerically often unsolvable. They are also closely related to \u201cbad\u201d linear projections that map the cone of positive semidefinite matrices to a nonclosed set. We describe a simple echelon form of weakly infeasible SDPs with the following properties: (i) it is obtained by elementary row operations and congruence transformations, (ii) it makes weak infeasibility evident, and (iii) it permits us to construct any weakly infeasible SDP or bad linear projection by an elementary combinatorial algorithm. Based on our echelon form we generate a library of computationally very difficult SDPs. Finally, we show that some SDPs in the literature are in our echelon form, for example, the SDP from the sum-of-squares relaxation of minimizing Motzkin\u2019s famous polynomial.", "venue": "ArXiv", "authors": ["G\u00e1bor  Pataki", "Aleksandr  Touzov"], "year": 2021, "n_citations": 0}
{"id": 712695, "s2_id": "e49e043dcd0eec91d16df305ea1317ec6074bd3e", "title": "Middle-Solving Grobner bases algorithm for cryptanalysis over finite fields", "abstract": "Algebraic cryptanalysis usually requires to recover the secret key by solving polynomial equations. Grobner bases algorithm is a well-known method to solve this problem. However, a serious drawback exists in the Grobner bases based algebraic attacks, namely, any information won't be got if we couldn't work out the Grobner bases of the polynomial equations system. In this paper, firstly, a generalized model of Grobner basis algorithms is presented, which provides us a platform to analyze and solve common problems of the algorithms. Secondly, we give and prove the degree bound of the polynomials appeared during the computation of Grobner basis after field polynomials is added. Finally, by detecting the temporary basis during the computation of Grobner bases and then extracting the univariate polynomials contained unique solution in the temporary basis, a heuristic strategy named Middle-Solving is presented to solve these polynomials at each iteration of the algorithm. Farther, two specific application mode of Middle-Solving strategy for the incremental and non-incremental Grobner bases algorithms are presented respectively. By using the Middle-Solving strategy, even though we couldn't work out the final Grobner bases, some information of the variables still leak during the computational process.", "venue": "ArXiv", "authors": ["Wansu  Bao", "Heliang  Huang"], "year": 2015, "n_citations": 0}
{"id": 715587, "s2_id": "610b27f6909c5450727edc53d1d15ea85fc09197", "title": "Twenty-Five Moves Suffice for Rubik's Cube", "abstract": "How many moves does it take to solve Rubik's Cube? Positions are known that require 20 moves, and it has already been shown that there are no positions that require 27 or more moves; this is a surprisingly large gap. This paper describes a program that is able to find solutions of length 20 or less at a rate of more than 16 million positions a second. We use this program, along with some new ideas and incremental improvements in other techniques, to show that there is no position that requires 26 moves.", "venue": "ArXiv", "authors": ["Tomas  Rokicki"], "year": 2008, "n_citations": 11}
{"id": 717695, "s2_id": "8c87bae0856b346e3de556f8ce0051aa9118c03f", "title": "The DEWCAD Project: Pushing Back the Doubly Exponential Wall of Cylindrical Algebraic Decomposition", "abstract": "This abstract seeks to introduce the ISSAC community to the DEWCAD project, which is based at Coventry University and the University of Bath, in the United Kingdom. The project seeks to push back the Doubly Exponential Wall of Cylindrical Algebraic Decomposition, through the integration of SAT/SMT technology, the extension of Lazard projection theory, and the development of new algorithms based on CAD technology but without producing CADs themselves. The project also seeks to develop applications of CAD and will focus on applications in the domains of economics and bio-network analysis.", "venue": "ISSAC 2021", "authors": ["R.  Bradford", "James H. Davenport", "Matthew  England", "A.  Sadeghimanesh", "A.  Uncu"], "year": 2021, "n_citations": 1}
{"id": 717993, "s2_id": "593695bfa96ca23d89b34f5c487e741ff5715ed9", "title": "Parameterized Type Definitions in Mathematica: Methods and Advantages", "abstract": "The theme of symbolic computation in algebraic categories has become of utmost importance in the last decade since it enables the automatic modeling of modern algebra theories. On this theoretical background, the present paper reveals the utility of the parameterized categorical approach by deriving a multivariate polynomial category (over various coefficient domains), which is used by our Mathematica implementation of Buchberger's algorithms for determining the Groebner basis. These implementations are designed according to domain and category parameterization principles underlining their advantages: operation protection, inheritance, generality, easy extendibility. In particular, such an extension of Mathematica, a widely used symbolic computation system, with a new type system has a certain practical importance. The approach we propose for Mathematica is inspired from D. Gruntz and M. Monagan's work in Gauss, for Maple.", "venue": "ArXiv", "authors": ["Alina  Andreica"], "year": 2002, "n_citations": 0}
{"id": 718583, "s2_id": "9fbc0e8528d97f1b480043cef32e89d826060432", "title": "Syzygies among reduction operators", "abstract": "We introduce the notion of syzygy for a set of reduction operators and relate it to the notion of syzygy for presentations of algebras. We give a method for constructing a linear basis of the space of syzygies for a set of reduction operators. We interpret these syzygies in terms of the confluence property from rewriting theory. This enables us to optimise the completion procedure for reduction operators based on a criterion for detecting useless reductions. We illustrate this criterion with an example of construction of commutative Gr{\\\"o}bner basis.", "venue": "Journal of Pure and Applied Algebra", "authors": ["Cyrille  Chenavier"], "year": 2019, "n_citations": 3}
{"id": 722371, "s2_id": "dc9160e4669a90f68ec7116c59166892346d7bb9", "title": "Characterizing Triviality of the Exponent Lattice of A Polynomial through Galois and Galois-Like Groups", "abstract": "The problem of computing \\emph{the exponent lattice} which consists of all the multiplicative relations between the roots of a univariate polynomial has drawn much attention in the field of computer algebra. As is known, almost all irreducible polynomials with integer coefficients have only trivial exponent lattices. However, the algorithms in the literature have difficulty in proving such triviality for a generic polynomial. In this paper, the relations between the Galois group (respectively, \\emph{the Galois-like groups}) and the triviality of the exponent lattice of a polynomial are investigated. The $\\bbbq$\\emph{-trivial} pairs, which are at the heart of the relations between the Galois group and the triviality of the exponent lattice of a polynomial, are characterized. An effective algorithm is developed to recognize these pairs. Based on this, a new algorithm is designed to prove the triviality of the exponent lattice of a generic irreducible polynomial, which considerably improves a state-of-the-art algorithm of the same type when the polynomial degree becomes larger. In addition, the concept of the Galois-like groups of a polynomial is introduced. Some properties of the Galois-like groups are proved and, more importantly, a sufficient and necessary condition is given for a polynomial (which is not necessarily irreducible) to have trivial exponent lattice.", "venue": "CASC", "authors": ["Tao  Zheng"], "year": 2020, "n_citations": 0}
{"id": 729187, "s2_id": "167aafea47e5debaf9681724a5eff4f510f9ec41", "title": "Toric Eigenvalue Methods for Solving Sparse Polynomial Systems", "abstract": "We consider the problem of computing homogeneous coordinates of points in a zero-dimensional subscheme of a compact toric variety $X$. Our starting point is a homogeneous ideal $I$ in the Cox ring of $X$, which gives a global description of this subscheme. It was recently shown that eigenvalue methods for solving this problem lead to robust numerical algorithms for solving (nearly) degenerate sparse polynomial systems. In this work, we give a first description of this strategy for non-reduced, zero-dimensional subschemes of $X$. That is, we allow isolated points with arbitrary multiplicities. Additionally, we investigate the regularity of $I$ to provide the first universal complexity bounds for the approach, as well as sharper bounds for weighted homogeneous, multihomogeneous and unmixed sparse systems, among others. We disprove a recent conjecture regarding the regularity and prove an alternative version. Our contributions are illustrated by several examples.", "venue": "ArXiv", "authors": ["Mat'ias R. Bender", "Simon  Telen"], "year": 2020, "n_citations": 4}
{"id": 729848, "s2_id": "47a978a697f7c1efe0d8d481bfe9fba3c723d1a7", "title": "Detecting Simultaneous Integer Relations for Several Real Vectors", "abstract": "An algorithm which either finds an nonzero integer vector m for given t real n-dimensional vectors x1,\ufffd\ufffd\ufffd , xt such that x T m = 0 or proves that no such integer vector with norm less than a given bound exists is presented in this paper. The cost of the algorithm is at mostO(n 4 + n 3 log\ufffd(X)) exact arithmetic operations in dimension n and the least Euclidean norm\ufffd(X) of such integer vectors. It matches the best complexity upper bound known for this problem. Experimental data show that the algorithm is better than an already existi ng algorithm in the literature. In application, the algorit hm is used to get a complete method for finding the minimal polyno mial of an unknown complex algebraic number from its approximation, which runs even faster than the corresponding Maple built-in function.", "venue": "ArXiv", "authors": ["Jingwei  Chen", "Yong  Feng", "Xiaolin  Qin", "Jingzhong  Zhang"], "year": 2010, "n_citations": 1}
{"id": 735279, "s2_id": "a3994701c3fd2cc69b44036415fb9bd836dbfd83", "title": "Sparse approaches for the exact distribution of patterns in long state sequences generated by a Markov source", "abstract": "We present two novel approaches for the computation of the exact distribution of a pattern in a long sequence. Both approaches take into account the sparse structure of the problem and are two-part algorithms. The first approach relies on a partial recursion after a fast computation of the second largest eigenvalue of the transition matrix of a Markov chain embedding. The second approach uses fast Taylor expansions of an exact bivariate rational reconstruction of the distribution. We illustrate the interest of both approaches on a simple toy example and two biological applications: the transcription factors of the Human Chromosome 10 and the PROSITE signatures of functional motifs in proteins. On these examples our methods demonstrate their complementarity and their ability to extend the domain of feasibility for exact computations in pattern problems to a new level.", "venue": "Theor. Comput. Sci.", "authors": ["Gr\u00e9gory  Nuel", "Jean-Guillaume  Dumas"], "year": 2013, "n_citations": 4}
{"id": 736631, "s2_id": "cd0e172ade67d95fbbecad7072b78c8031e2fe60", "title": "Abstract canonical inference", "abstract": "An abstract framework of canonical inference is used to explore how different proof orderings induce different variants of saturation and completeness. Notions like completion, paramodulation, saturation, redundancy elimination, and rewrite-system reduction are connected to proof orderings. Fairness of deductive mechanisms is defined in terms of proof orderings, distinguishing between (ordinary) \u201cfairness,\u201d which yields completeness, and \u201cuniform fairness,\u201d which yields saturation.", "venue": "TOCL", "authors": ["Maria Paola Bonacina", "Nachum  Dershowitz"], "year": 2007, "n_citations": 31}
{"id": 745026, "s2_id": "dbc53bdd95484baec8a75ad6f9178a3e022e9264", "title": "A note on Solving Parametric Polynomial Systems", "abstract": "Lazard and Rouillier in [9], by introducing the concept of discriminant variety, have described a new and efficient algorithm for solving parametric polynomial systems. In this paper we modify this algorithm, and we show that with our improvements the output of our algorithm is always minimal and it does not need to compute the radical of ideals.", "venue": "ArXiv", "authors": ["Asieh  Pourhaghani"], "year": 2011, "n_citations": 0}
{"id": 747064, "s2_id": "8c64201c6249a1afff35a616d1d98a0336ab8e50", "title": "Acronym-Meaning Extraction from Corpora Using Multi-Tape Weighted Finite-State Machines", "abstract": "The automatic extraction of acronyms and their meaning from corpora is an important sub-task of text mining. It can be seen as a special case of string alignment, where a text chunk is aligned with an acronym. Alternative alignments have different cost, and ideally the least costly one should give the correct meaning of the acronym. We show how this approach can be implemented by means of a 3-tape weighted finite-state machine (3-WFSM) which reads a text chunk on tape 1 and an acronym on tape 2, and generates all alternative alignments on tape 3. The 3-WFSM can be automatically generated from a simple regular expression. No additional algorithms are required at any stage. Our 3-WFSM has a size of 27 states and 64 transitions, and finds the best analysis of an acronym in a few milliseconds.", "venue": "ArXiv", "authors": ["Andr\u00e9  Kempe"], "year": 2006, "n_citations": 5}
{"id": 750409, "s2_id": "74ca4b6a7e11b1c7d21f97333c090795efc9060c", "title": "Nearly optimal computations with structured matrices", "abstract": "We estimate the Boolean complexity of multiplication of structured matrices by a vector and the solution of nonsingular linear systems of equations with these matrices. We study four basic and most popular classes, that is, Toeplitz, Hankel, Cauchy and Vandermonde matrices, for which the cited computational problems are equivalent to the task of polynomial multiplication and division and polynomial and rational multipoint evaluation and interpolation. The Boolean cost estimates for the latter problems have been obtained by Kirrinnis in [10], except for rational interpolation. We supply them now as well as the Boolean complexity estimates for the important problems of multiplication of transposed Vandermonde matrix and its inverse by a vector. All known Boolean cost estimates from [10] for such problems rely on using Kronecker product. This implies the d-fold precision increase for the d-th degree output, but we avoid such an increase by relying on distinct techniques based on employing FFT. Furthermore we simplify the analysis and make it more transparent by combining the representations of our tasks and algorithms both via structured matrices and via polynomials and rational functions. This also enables further extensions of our estimates to cover Trummer\u2019s important problem and computations with the popular classes of structured matrices that generalize the four cited basic matrix classes, as well as the transposed Vandermonde matrices. It is known that the solution of Toeplitz, Hankel, Cauchy, Vandermonde, and transposed Vandermonde linear systems of equations is generally prone to numerical stability problems, and numerical problems arise even for multiplication of Cauchy, Vandermonde, and transposed Vandermonde matrices by a vector. Thus our FFT-based results on the Boolean complexity of these important computations could be quite interesting because our estimates are reasonable even for more general classes of structured matrices, showing rather moderate growth of the complexity as the input size increases.", "venue": "Theor. Comput. Sci.", "authors": ["Victor Y. Pan", "Elias P. Tsigaridas"], "year": 2017, "n_citations": 7}
{"id": 751368, "s2_id": "603b696cd558940bf6f92405a3cd47e6e4714a8e", "title": "Mace4 Reference Manual and Guide", "abstract": "Mace4 is a program that searches for finite models of first-order formulas. For a given domain size, all instances of the formulas over the domain are constructed. The result is a set of ground clauses with equality. Then, a decision procedure based on ground equational rewriting is applied. If satisfiability is detected, one or more models are printed. Mace4 is a useful complement to first-order theorem provers, with the prover searching for proofs and Mace4 looking for countermodels, and it is useful for work on finite algebras. Mace4 performs better on equational problems than did our previous model-searching program Mace2.", "venue": "ArXiv", "authors": ["William  McCune"], "year": 2003, "n_citations": 133}
{"id": 752244, "s2_id": "6663774a376abf2c8c243f0aa6bbe7f0eee2bab6", "title": "The Potential and Challenges of CAD with Equational Constraints for SC-Square", "abstract": "Cylindrical algebraic decomposition (CAD) is a core algorithm within Symbolic Computation, particularly for quantifier elimination over the reals and polynomial systems solving more generally. It is now finding increased application as a decision procedure for Satisfiability Modulo Theories (SMT) solvers when working with non-linear real arithmetic. We discuss the potentials from increased focus on the logical structure of the input brought by the SMT applications and SC-Square project, particularly the presence of equational constraints. We also highlight the challenges for exploiting these: primitivity restrictions, well-orientedness questions, and the prospect of incrementality.", "venue": "MACIS", "authors": ["James H. Davenport", "Matthew  England"], "year": 2017, "n_citations": 0}
{"id": 752869, "s2_id": "91e1a3b9d570557ccd143af1692d0f4763f50767", "title": "Continued fraction expansion of real roots of polynomial systems", "abstract": "We present a new algorithm for isolating the real roots of a system of multivariate polynomials, given in the monomial basis. It is inspired by existing subdivision methods in the Bernstein basis; it can be seen as generalization of the univariate continued fraction algorithm or alternatively as a fully analog of Bernstein subdivision in the monomial basis. The representation of the subdivided domains is done through homographies, which allows us to use only integer arithmetic and to treat efficiently unbounded regions. We use univariate bounding functions, projection and preconditionning techniques to reduce the domain of search. The resulting boxes have optimized rational coordinates, corresponding to the first terms of the continued fraction expansion of the real roots. An extension of Vincent's theorem to multivariate polynomials is proved and used for the termination of the algorithm. New complexity bounds are provided for a simplified version of the algorithm. Examples computed with a preliminary C++ implementation illustrate the approach.", "venue": "SNC '09", "authors": ["Angelos  Mantzaflaris", "Bernard  Mourrain", "Elias P. Tsigaridas"], "year": 2009, "n_citations": 16}
{"id": 752874, "s2_id": "666a824f015c754f342ffde711a2de296d380f6b", "title": "Asymptotic Methods of ODEs: Exploring Singularities of the Second Kind", "abstract": "We develop symbolic methods of asymptotic approximations for solutions of linear ordinary differential equations and use to them stabilize numerical calculations. Our method follows classical analysis for first-order systems and higher-order scalar equations where growth behavior is expressed in terms of elementary functions. We then recast our equations in mollified form - thereby obtaining stability.", "venue": "ArXiv", "authors": ["Christopher J. Winfield"], "year": 2011, "n_citations": 1}
{"id": 755312, "s2_id": "61488c12218477a867af92e403fe764461cb4ada", "title": "On the computation of asymptotic critical values of polynomial maps and applications", "abstract": "Let f = (f1, . . . , fp) be a polynomial tuple in Q[z1, . . . , zn] and let d = max1\u2264i\u2264p deg fi. We consider the problem of computing the set of asymptotic critical values of the polynomial mapping, with the assumption that this mapping is dominant, f : z \u2208 K \u2192 (f1(z), . . . , fp(z)) \u2208 K where K is either R or C. This is the set of values c in the target space of f such that there exists a sequence of points (xi)i\u2208N for which f(xi) tends to c and \u2016xi\u2016\u03ba(df(xi)) tends to 0 when i tends to infinity where df is the differential of f and \u03ba is a function measuring the distance of a linear operator to the set of singular linear operators from K to K. Computing the union of the classical and asymptotic critical values allows one to put into practice generalisations of Ehresmann\u2019s fibration theorem. This leads to natural and efficient applications in polynomial optimisation and computational real algebraic geometry. Going back to previous works by Kurdyka, Orro and Simon, we design new algorithms to compute asymptotic critical values. Through randomisation, we introduce new geometric characterisations of asymptotic critical values. This allows us to dramatically reduce the complexity of computing such values to a cost that is essentially O(d) arithmetic operations in Q. We also obtain tighter degree bounds on a hypersurface containing the asymptotic critical values, showing that the degree is at most pn\u2212p+1(d\u2212 1)(d+ 1). Next, we show how to apply these algorithms to unconstrained polynomial optimisation problems and the problem of computing sample points per connected component of a semi-algebraic set defined by a single inequality/inequation. We report on the practical capabilities of our implementation of this algorithm. It shows how the practical efficiency surpasses the current state-of-the-art algorithms for computing asymptotic critical values by tackling examples that were previously out of reach.", "venue": "ArXiv", "authors": ["J'er'emy  Berthomieu", "Andrew  Ferguson", "Mohab Safey El Din"], "year": 2021, "n_citations": 0}
{"id": 755318, "s2_id": "94b8099efa2fcacddd0779ae4a540d4bd1334f62", "title": "A difference ring theory for symbolic summation\u2606", "abstract": "A summation framework is developed that enhances Karr's difference field approach. It covers not only indefinite nested sums and products in terms of transcendental extensions, but it can treat, e.g., nested products defined over roots of unity. The theory of the so-called R\u03a0\u03a3\u204e-extensions is supplemented by algorithms that support the construction of such difference rings automatically and that assist in the task to tackle symbolic summation problems. Algorithms are presented that solve parameterized telescoping equations, and more generally parameterized first-order difference equations, in the given difference ring. As a consequence, one obtains algorithms for the summation paradigms of telescoping and Zeilberger's creative telescoping. With this difference ring theory one gets a rigorous summation machinery that has been applied to numerous challenging problems coming, e.g., from combinatorics and particle physics.", "venue": "J. Symb. Comput.", "authors": ["Carsten  Schneider"], "year": 2016, "n_citations": 51}
{"id": 757425, "s2_id": "6cc2b2003f1cad6004f9eb20e24452edd5513b7a", "title": "Minimal Polynomials for the Coordinates of the Harborth Graph", "abstract": "The Harborth graph is the smallest known example of a 4-regular planar unit-distance graph. In this paper we give an analytical description of the coordinates of its vertices for a particular embedding in the Euclidean plane. More precisely, we show, how to calculate the minimal polynomials of the coordinates of its vertices (with the help of a computer algebra system), and list those. Furthermore some algebraic properties of these polynomials, and consequences to the structure of the Harborth graph are determined.", "venue": "ArXiv", "authors": ["Eberhard H.-A. Gerbracht"], "year": 2006, "n_citations": 8}
{"id": 762318, "s2_id": "93933fb206fe20f45172c4ee3370a9dfd4707606", "title": "Algorithms for Linearly Recurrent Sequences of Truncated Polynomials", "abstract": "Linear recurrent sequences are those whose elements are defined as linear combinations of preceding elements, and finding recurrence relations is a fundamental problem in computer algebra. In this paper, we focus on sequences whose elements are vectors over the ring \ud835\udd38=\ud835\udd42[x] /{xd} of truncated polynomials. Finding the ideal of their recurrence relations has applications such as the computation of minimal polynomials and determinants of sparse matrices over \ud835\udd38. We present three methods for finding this ideal: a Berlekamp-Massey-like approach due to Kurakin, one which computes the kernel of some block-Hankel matrix over \ud835\udd38 via a minimal approximant basis, and one based on bivariate Pad\u00e9 approximation. We propose complexity improvements for the first two methods, respectively by avoiding the computation of redundant relations and by exploiting the Hankel structure to compress the approximation problem. Then we confirm these improvements empirically through a C++ implementation, and we discuss the above-mentioned applications.", "venue": "ISSAC", "authors": ["Seung Gyu Hyun", "Vincent  Neiger", "\u00c9ric  Schost"], "year": 2021, "n_citations": 0}
{"id": 766367, "s2_id": "8bb91af28fe0c6f62bc549e15699a4a7c336b5a6", "title": "A Sparse Flat Extension Theorem for Moment Matrices", "abstract": "In this note we prove a generalization of the flat extension theorem of Curto and Fialkow for truncated moment matrices. It applies to moment matrices indexed by an arbitrary set of monomials and its border, assuming that this set is connected to 1. When formulated in a basis-free setting, this gives an equivalent result for truncated Hankel operators.", "venue": "ArXiv", "authors": ["Monique  Laurent", "Bernard  Mourrain"], "year": 2008, "n_citations": 8}
{"id": 767492, "s2_id": "7165d32cbcbdfc9fce592c65c5416de90a5adb80", "title": "Differential invariants of a Lie group action: Syzygies on a generating set", "abstract": "Given a group action, known by its infinitesimal generators, we exhibit a complete set of syzygies on a generating set of differential invariants. For that we elaborate on the reinterpretation of Cartan's moving frame by Fels and Olver [Fels, M., Olver, P.J., 1999. Moving coframes. II. Regularization and theoretical foundations. Acta Appl. Math. 55 (2), 127-208]. This provides constructive tools for exploring algebras of differential invariants.", "venue": "J. Symb. Comput.", "authors": ["Evelyne  Hubert"], "year": 2009, "n_citations": 46}
{"id": 767671, "s2_id": "7065aea778ee47ff29ee68a5380ab9a29605b6f9", "title": "Non-Linear Real Arithmetic Benchmarks Derived from Automated Reasoning in Economics", "abstract": "We consider problems originating in economics that may be solved automatically using mathematical software. We present and make freely available a new benchmark set of such problems. The problems have been shown to fall within the framework of non-linear real arithmetic, and so are in theory soluble via Quantifier Elimination (QE) technology as usually implemented in computer algebra systems. Further, they all can be phrased in prenex normal form with only existential quantifiers and so are also admissible to those Satisfiability Module Theory (SMT) solvers that support the QF_NRA logic. There is a great body of work considering QE and SMT application in science and engineering, but we demonstrate here that there is potential for this technology also in the social sciences.", "venue": "ArXiv", "authors": ["Casey B. Mulligan", "Russell J. Bradford", "James H. Davenport", "Matthew  England", "Zak  Tonks"], "year": 2018, "n_citations": 13}
{"id": 776811, "s2_id": "d13d1ad27e45aec81964b554546402cd845201fd", "title": "Smart Induction for Isabelle/HOL (System Description)", "abstract": "Proof assistants offer tactics to facilitate inductive proofs. However, it still requires human ingenuity to decide what arguments to pass to those induction tactics. To automate this process, we present smart_induct for Isabelle/HOL. Given an inductive problem in any problem domain, smart_induct lists promising arguments for the induct tactic without relying on a search. Our evaluation demonstrated smart_induct produces valuable recommendations across problem domains.", "venue": "ArXiv", "authors": ["Yutaka  Nagashima"], "year": 2020, "n_citations": 1}
{"id": 781572, "s2_id": "1e991893d7b4e1a4ff62920bef26e44ddc639d53", "title": "Computing Sparse Multiples of Polynomials", "abstract": "We consider the problem of finding a sparse multiple of a polynomial. Given f \u2208 F[x] of degree d, and a desired sparsity t, our goal is to determine if there exists a multiple h \u2208 F[x] of f such that h has at most t non-zero terms, and if so, to find such an h. When F=\u211a and t is constant, we give a polynomial-time algorithm in d and the size of coefficients in h. When F is a finite field, we show that the problem is at least as hard as determining the multiplicative order of elements in an extension field of F (a problem thought to have complexity similar to that of factoring integers), and this lower bound is tight when t = 2.", "venue": "ISAAC", "authors": ["Mark  Giesbrecht", "Daniel S. Roche", "Hrushikesh  Tilak"], "year": 2010, "n_citations": 2}
{"id": 786289, "s2_id": "a58c70855b3eb39b26de571e581320a8aef90802", "title": "First-Order Tests for Toricity", "abstract": "Motivated by problems arising with the symbolic analysis of steady state ideals in Chemical Reaction Network Theory, we consider the problem of testing whether the points in a complex or real variety with non-zero coordinates form a coset of a multiplicative group. That property corresponds to Shifted Toricity, a recent generalization of toricity of the corresponding polynomial ideal. The key idea is to take a geometric view on varieties rather than an algebraic view on ideals. Recently, corresponding coset tests have been proposed for complex and for real varieties. The former combine numerous techniques from commutative algorithmic algebra with Grobner bases as the central algorithmic tool. The latter are based on interpreted first-order logic in real closed fields with real quantifier elimination techniques on the algorithmic side. Here we take a new logic approach to both theories, complex and real, and beyond. Besides alternative algorithms, our approach provides a unified view on theories of fields and helps to understand the relevance and interconnection of the rich existing literature in the area, which has been focusing on complex numbers, while from a scientific point of view the (positive) real numbers are clearly the relevant domain in chemical reaction network theory. We apply prototypical implementations of our new approach to a set of 129 models from the BioModels repository.", "venue": "CASC", "authors": ["Hamid  Rahkooy", "Thomas  Sturm"], "year": 2020, "n_citations": 4}
{"id": 787249, "s2_id": "7f24ee55920a94ee27b524879178a34d4c14b7ee", "title": "Numeric Deduction in Symbolic Computation. Application to Normalizing Transformations", "abstract": "Algorithms of numeric (in exact arithmetic) deduction of analytical expressions, proposed and described by Shevchenko and Vasiliev (1993), are developed and implemented in a computer algebra code. This code is built as a superstructure for the computer algebra package by Shevchenko and Sokolsky (1993a) for normalization of Hamiltonian systems of ordinary differential equations, in order that high complexity problems of normalization could be solved. As an example, a resonant normal form of a Hamiltonian describing the hyperboloidal precession of a dynamically symmetric satellite is derived by means of the numeric deduction technique. The technique provides a considerable economy, about 30 times in this particular application, in computer memory consumption. It is naturally parallelizable. Thus the economy of memory consumption is convertible into a gain in computation speed.", "venue": "J. Symb. Comput.", "authors": ["Ivan I. Shevchenko"], "year": 1997, "n_citations": 2}
{"id": 788257, "s2_id": "adb1530f93859ba3363ad9adb73348b5da4e6695", "title": "On Probabilistic Term Rewriting", "abstract": "We study the termination problem for probabilistic term rewrite systems. We prove that the interpretation method is sound and complete for a strengthening of positive almost sure termination, when abstract reduction systems and term rewrite systems are considered. Two instances of the interpretation method\u2014polynomial and matrix interpretations\u2014are analyzed and shown to capture interesting and nontrivial examples when automated. We capture probabilistic computation in a novel way by means of multidistribution reduction sequences, thus accounting for both the nondeterminism in the choice of the redex and the probabilism intrinsic in firing each rule.", "venue": "FLOPS", "authors": ["Martin  Avanzini", "Ugo Dal Lago", "Akihisa  Yamada"], "year": 2018, "n_citations": 21}
{"id": 789702, "s2_id": "54a320dc664915ee2cd71adc4ab97655d8cb8dba", "title": "Formal Analysis of Galois Field Arithmetics - Parallel Verification and Reverse Engineering", "abstract": "Galois field (GF) arithmetic circuits find numerous applications in communications, signal processing, and security engineering. Formal verification techniques of GF circuits are scarce and limited to circuits with known bit positions of the primary inputs and outputs. They also require knowledge of the irreducible polynomial $P(x)$, which affects final hardware implementation. This paper presents a computer algebra technique that performs verification and reverse engineering of GF($2^m$) multipliers directly from the gate-level implementation. The approach is based on extracting a unique irreducible polynomial in a parallel fashion and proceeds in three steps: 1) determine the bit position of the output bits; 2) determine the bit position of the input bits; and 3) extract the irreducible polynomial used in the design. We demonstrate that this method is able to reverse engineer GF($2^m$) multipliers in \\textit{m} threads. Experiments performed on synthesized \\textit{Mastrovito} and \\textit{Montgomery} multipliers with different $P(x)$, including NIST-recommended polynomials, demonstrate high efficiency of the proposed method.", "venue": "ArXiv", "authors": ["Cunxi  Yu", "Maciej J. Ciesielski"], "year": 2018, "n_citations": 0}
{"id": 789729, "s2_id": "d6514328c54c268a2e27c2d4dda6072fac0f31d5", "title": "A Pommaret bases approach to the degree of a polynomial ideal", "abstract": "In this paper, we study first the relationship between Pommaret bases and Hilbert series. Given a finite Pommaret basis, we derive new explicit formulas for the Hilbert series and for the degree of the ideal generated by it which exhibit more clearly the influence of each generator. Then we establish a new dimension depending B\u00e9zout bound for the degree and use it to obtain a dimension depending bound for the ideal membership problem.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Bentolhoda  Binaei", "Amir  Hashemi", "Werner M. Seiler"], "year": 2017, "n_citations": 6}
{"id": 790851, "s2_id": "acb81e105f2a757ae2111c821202025cdb332f0f", "title": "Groebner bases of reaction networks with intermediate species", "abstract": "In this work we consider the computation of Groebner bases of the steady state ideal of reaction networks equipped with mass-action kinetics. Specifically, we focus on the role of intermediate species and the relation between the extended network (with intermediate species) and the core network (without intermediate species). \nWe show that a Groebner basis of the steady state ideal of the core network always lifts to a Groebner basis of the steady state ideal of the extended network by means of linear algebra, with a suitable choice of monomial order. As illustrated with examples, this contributes to a substantial reduction of the computation time, due mainly to the reduction in the number of variables and polynomials. We further show that if the steady state ideal of the core network is binomial, then so is the case for the extended network, as long as an extra condition is fulfilled. For standard networks, this extra condition can be visually explored from the network structure alone.", "venue": "Adv. Appl. Math.", "authors": ["AmirHosein  Sadeghimanesh", "Elisenda  Feliu"], "year": 2019, "n_citations": 4}
{"id": 792094, "s2_id": "eca5e4cfe3e72bdf70b13fecb76d8bda71694423", "title": "Nearly optimal computations with structured matrices", "abstract": "We estimate the Boolean complexity of multiplication of structured matrices by a vector and the solution of nonsingular linear systems of equations with these matrices. We study four basic and most popular classes, that is, Toeplitz, Hankel, Cauchy and Vandermonde matrices, for which the cited computational problems are equivalent to the task of polynomial multiplication and division and polynomial and rational multipoint evaluation and interpolation. The Boolean cost estimates for the latter problems have been obtained by Kirrinnis in [10], except for rational interpolation, and we supply them now. All known Boolean cost estimates from [10] for these problems rely on using Kronecker product. This implies the d-fold precision increase for the d-th degree output, but we avoid such an increase by relying on distinct techniques based on employing FFT. Furthermore we simplify the analysis and make it more transparent by combining the representations of our tasks and algorithms both via structured matrices and via polynomials and rational functions. This also enables further extensions of our estimates to cover Trummer's important problem and computations with the popular classes of structured matrices that generalize the four cited basic matrix classes.", "venue": "SODA '00", "authors": ["Victor Y. Pan"], "year": 2000, "n_citations": 56}
{"id": 794558, "s2_id": "74e07a00559e3da705b511bb20971d540262175b", "title": "Sparse Polynomial Interpolation Based on Diversification", "abstract": "We consider the problem of interpolating a sparse multivariate polynomial over a finite field, represented with a black box. Building on the algorithm of Ben-Or and Tiwari for interpolating polynomials over rings with characteristic zero, we develop a new Monte Carlo algorithm over the finite field by doing additional probes. To interpolate a polynomial $f\\in F_q[x_1,\\dots,x_n]$ with a partial degree bound $D$ and a term bound $T$, our new algorithm costs $O^\\thicksim(nT\\log ^2q+nT\\sqrt{D}\\log q)$ bit operations and uses $2(n+1)T$ probes to the black box. If $q\\geq O(nT^2D)$, it has constant success rate to return the correct polynomial. Compared with previous algorithms over general finite field, our algorithm has better complexity in the parameters $n,T,D$ and is the first one to achieve the complexity of fractional power about $D$, while keeping linear in $n,T$. A key technique is a randomization which makes all coefficients of the unknown polynomial distinguishable, producing a diverse polynomial. This approach, called diversification, was proposed by Giesbrecht and Roche in 2011. Our algorithm interpolates each variable independently using $O(T)$ probes, and then uses the diversification to correlate terms in different images. At last, we get the exponents by solving the discrete logarithms and obtain coefficients by solving a linear system. We have implemented our algorithm in Maple. Experimental results shows that our algorithm can applied to sparse polynomials with large degree. We also analyze the success rate of the algorithm.", "venue": "ArXiv", "authors": ["Qiao-Long  Huang"], "year": 2020, "n_citations": 0}
{"id": 800021, "s2_id": "a63cdc00820528fd0b6a9e987ad4112078b4eb16", "title": "A probabilistic and deterministic modular algorithm for computing Groebner basis over $\\Q$", "abstract": "Modular algorithm are widely used in computer algebra systems (CAS), for example to compute efficiently the gcd of multivariate polynomials. It is known to work to compute Groebner basis over $\\Q$, but it does not seem to be popular among CAS implementers. In this paper, I will show how to check a candidate Groebner basis (obtained by reconstruction of several Groebner basis modulo distinct prime numbers) with a given error probability, that may be 0 if a certified Groebner basis is desired. This algorithm is now the default algorithm used by the Giac/Xcas computer algebra system with competitive timings, thanks to a trick that can accelerate computing Groebner basis modulo a prime once the computation has been done modulo another prime.", "venue": "ArXiv", "authors": ["Bernard  Parisse"], "year": 2013, "n_citations": 4}
{"id": 806975, "s2_id": "30b1a4b1f39c9fa62e6cf0e7394dbb537e1703de", "title": "Unification modulo a partial theory of exponentiation", "abstract": "Modular exponentiation is a common mathematical operation in modern cryptography. This, along with modular multiplication at the base and exponent levels (to different moduli) plays an important role in a large number of key agreement protocols. In our earlier work, we gave many decidability as well as undecidability results for multiple equational theories, involving various properties of modular exponentiation. Here, we consider a partial subtheory focussing only on exponentiation and multiplication operators. Two main results are proved. The first result is positive, namely, that the unification problem for the above theory (in which no additional property is assumed of the multiplication operators) is decidable. The second result is negative: if we assume that the two multiplication operators belong to two different abelian groups, then the unification problem becomes undecidable.", "venue": "UNIF", "authors": ["Deepak  Kapur", "Andrew M. Marshall", "Paliath  Narendran"], "year": 2010, "n_citations": 1}
{"id": 809411, "s2_id": "89374f0ac7157f1d5c1ba4d278776c3ee261c35e", "title": "A Modular Extension for a Computer Algebra System", "abstract": "Abstract Computer algebra systems are complex software systems that cover a wide range of scientific and practical problems. However, the absolute coverage cannot be achieved. Often, it is required to create a user extension for an existing computer algebra system. In this case, the extensibility of the system should be taken into account. In this paper, we consider a technology for extending the SymPy computer algebra system with a low-level module that implements a random number generator.", "venue": "Programming and Computer Software", "authors": ["Migran N. Gevorkyan", "Anna V. Korolkova", "Dmitry S. Kulyabov", "Leonid A. Sevast'yanov"], "year": 2020, "n_citations": 1}
{"id": 812860, "s2_id": "9177e908b2fd41d3138cff31c9fb0d430965861b", "title": "Neural Analogical Matching", "abstract": "Analogy is core to human cognition. It allows us to solve problems based on prior experience, it governs the way we conceptualize new information, and it even influences our visual perception. The importance of analogy to humans has made it an active area of research in the broader field of artificial intelligence, resulting in data-efficient models that learn and reason in human-like ways. While analogy and deep learning have generally been studied independently of one another, the integration of the two lines of research seems like a promising step towards more robust and efficient learning techniques. As part of the first steps towards such an integration, we introduce the Analogical Matching Network: a neural architecture that learns to produce analogies between structured, symbolic representations that are largely consistent with the principles of Structure-Mapping Theory.", "venue": "AAAI", "authors": ["Maxwell  Crouse", "Constantine  Nakos", "Ibrahim  Abdelaziz", "Kenneth  Forbus"], "year": 2021, "n_citations": 5}
{"id": 814110, "s2_id": "bce3708ffab6563d9747fd323d15694c55603f57", "title": "A Note on the Space Complexity of Fast D-Finite Function Evaluation", "abstract": "We state and analyze a generalization of the \"truncation trick\" suggested by Gourdon and Sebah to improve the performance of power series evaluation by binary splitting. It follows from our analysis that the values of D-finite functions (i.e., functions described as solutions of linear differential equations with polynomial coefficients) may be computed with error bounded by 2\u2212p in time $\\mathrm{O} (p (\\lg p)^{3 + o (1)})$ and space O (p). The standard fast algorithm for this task, due to Chudnovsky and Chudnovsky, achieves the same time complexity bound but requires $\\mathrm\\Theta (p \\lg p)$ bits of memory.", "venue": "CASC", "authors": ["Marc  Mezzarobba"], "year": 2012, "n_citations": 5}
{"id": 816164, "s2_id": "aea8a06f4f6416f2430e27ef2231ab7b7fba4051", "title": "Uncomputably large integral points on algebraic plane curves?", "abstract": "We show that the decidability of an amplification of Hilbert's Tenth Problem in three variables implies the existence of uncomputably large integral points on certain algebraic curves. We obtain this as a corollary of a new positive complexity result: the Diophantine prefix \u2203\u2200\u2203 is generically decidable. This means that we give a precise geometric classification of those polynomials f\u2208Z[v,x,y] for which the question \n\u2203v\u2208Nsuchthat\u2200x\u2208N\u2203y\u2208Nwithf(v,x,y)=0? \nmay be undecidable, and we show that this set of polynomials is quite small in a rigorous sense. (The decidability of \u2203\u2200\u2203 was previously an open question.) We also show that if integral points on curves can be bounded effectively, then \u2203\u2203\u2200\u2203 is generically decidable as well. We thus obtain a connection between the decidability of certain Diophantine problems, height bounds for points on curves, and the geometry of certain complex surfaces and 3-folds.", "venue": "Theor. Comput. Sci.", "authors": ["J. Maurice Rojas"], "year": 2000, "n_citations": 5}
{"id": 819390, "s2_id": "665fda34d1c16b9379b2b326c08033d44e46a1d0", "title": "On the complexity of class group computations for large degree number fields", "abstract": "In this paper, we examine the general algorithm for class group computations, when we do not have a small defining polynomial for the number field. Based on a result of Biasse and Fieker, we simplify their algorithm, improve the complexity analysis and identify the optimal parameters to reduce the runtime. We make use of the classes $\\mathcal D$ defined in [GJ16] for classifying the fields according to the size of the extension degree and prove that they enable to describe all the number fields.", "venue": "ArXiv", "authors": ["Alexandre  G\u00e9lin"], "year": 2018, "n_citations": 3}
{"id": 837043, "s2_id": "cd398046511218e54ceaca096d8fc2812dc0ca9f", "title": "A Symbolic Summation Approach to Find Optimal Nested Sum Representations", "abstract": "We consider the following problem: Given a nested sum expression, find a sum representation such that the nested depth is minimal. We obtain a symbolic summation framework that solves this problem for sums defined, e.g., over hypergeometric, $q$-hypergeometric or mixed hypergeometric expressions. Recently, our methods have found applications in quantum field theory.", "venue": "ArXiv", "authors": ["Carsten  Schneider"], "year": 2009, "n_citations": 41}
{"id": 839477, "s2_id": "c4135fb88092f7eac0bba74047443ff8c2bafdca", "title": "The VLSAT-3 Benchmark Suite", "abstract": "This report presents VLSAT-3 (an acronym for \u201cVery Large Boolean SATisfiability problems\u201d), the third part of a benchmark suite to be used in scientific experiments and software competitions addressing SAT and SMT (Satisfiability Modulo Theories) solving issues. VLSAT-3 contains 1200 (600 satisfiable and 600 unsatisfiable) quantifier-free first-order logic formulas of increasing complexity, proposed in SMT-LIB format under a permissive Creative Commons license. More than 90% of these benchmarks have been used during the 16th International Satisfiability Modulo Theories Competition (SMT-COMP 2021). Key-words: benchmark suite, data set, SMT-LIB, Nested-Unit Petri Net, NUPN, Petri Net, Satisfiability Modulo Theories, SMT formula, SMT solver Le jeu de tests VLSAT-3 R\u00e9sum\u00e9 : VLSAT-3 (acronyme anglais de \u201ctr\u00e8s grands probl\u00e8mes de satisfaisabilit\u00e9 bool\u00e9enne\u201d) est le troisi\u00e8me volet d\u2019une suite de tests destin\u00e9e aux exp\u00e9rimentations scientifiques et aux comp\u00e9titions de logiciels pour la r\u00e9solution de probl\u00e8mes SAT et SMT (Satisfaisabilit\u00e9 Modulo des Th\u00e9ories). VLSAT-3 contient 1200 formules logiques (600 satisfaisables et 600 insatisfaisables) du premier ordre sans quantificateur, de complexit\u00e9 croissante, fournies en format SMT-LIB sous une licence Creative Commons permissive. Plus de 90% de ces tests ont \u00e9t\u00e9 utilis\u00e9s lors de la 16\u00e8me Comp\u00e9tition Internationale de Satisfaisabilit\u00e9 Modulo des Th\u00e9ories (SMT-COMP 2021). Mots-cl\u00e9s : ensemble de donn\u00e9es, formule SMT, Nested-Unit Petri Net, NUPN, r\u00e9seau de Petri, r\u00e9solveur SMT, satisfaisabilit\u00e9 modulo des th\u00e9ories, SMT-LIB, suite de tests The VLSAT-3 Benchmark Suite 3 1 Benchmark Description We previously published two test suites, named VLSAT-1 [2] and VLSAT-2 [3], containing SAT formulas. VLSAT-31 is a collection of 1200 SMT (Satisfiability Modulo Theories) formulas (i.e., first-order logic formulas), written in six different quantifier-free logic fragments. For each of these logic fragments, 100 satisfiable and 100 unsatisfiable formulas are provided, which results in 12 families containing 100 benchmarks each. Each formula is provided as a separate file, encoded in the SMT-LIB 2.6 format [1]. Each file is then compressed using bzip2 to save disk space and allow faster downloads. The 1200 formulas require 2.4 gigabytes of disk space and 132 megabytes when compressed using bzip2. The VLSAT-3 benchmarks are licensed under the CC-BY Creative Commons Attribution 4.0 International License2. 2 Scientific Context Interesting SMT formulas can be generated as a by-product of our recent work [4] on the decomposition of Petri nets into networks of automata, a problem that has been around since the early 70s. Concretely, we developed a tool chain that takes as input a Petri net (which must be ordinary, safe, and hopefully not too large) and produces as output a network of automata that execute concurrently and synchronize using shared transitions. Precisely, this network is expressed as a Nested-Unit Petri Net (NUPN) [5], i.e., an extension of a Petri net, in which places are grouped into sets (called units) that denote sequential components. A NUPN provides a proper structuring of its underlying Petri net, and enables formal verification tools to be more efficient in terms of memory and CPU time. Hence, the NUPN concept has been implemented in many tools and adopted by software competitions, such as the Model Checking Contest3 [9, 8] and the Rigorous Examination of Reactive Systems challenge4 [6, 10, 7]. Each NUPN generated by our tool chain is flat, meaning that its units are not recursively nested in each other, and unit-safe, meaning that each unit has at most one execution token at a time. Our tool chain works by reformulating concurrency constraints on Petri nets as logical problems, which can be later solved using third-party software, such as SAT solvers, SMT solvers, and tools for graph coloring and finding maximum cliques, depending on the chosen strategy [4]. When a strategy involving SMT solving is selected, the tool chain produces formulas to be processed by SMT solvers. The tool chain is solver-agnostic and supports six standard SMT logic fragments. 3 Structure of Formulas Each of our formulas was produced for a particular Petri net. A formula depends on four factors: \u2022 the set P of the places of the Petri net; \u2022 a concurrency relation \u2016 defined over P , such that p \u2016 p\u2032 iff both places p and p\u2032 may simultaneously have an execution token; 1https://cadp.inria.fr/resources/vlsat/3.html 2License terms available from http://creativecommons.org/licenses/by/4.0 3https://mcc.lip6.fr 4http://rers-challenge.org", "venue": "ArXiv", "authors": ["Pierre  Bouvier"], "year": 2021, "n_citations": 0}
{"id": 846474, "s2_id": "276ae77455e50fef739503c4a584abb8aae8939e", "title": "Knowledge-Based Automatic Generation of Partitioned Matrix Expressions", "abstract": "In a series of papers it has been shown that for many linear algebra operations it is possible to generate families of algorithms by following a systematic procedure. Although powerful, such a methodology involves complex algebraic manipulation, symbolic computations and pattern matching, making the generation a process challenging to be performed by hand. We aim for a fully automated system that from the sole description of a target operation creates multiple algorithms without any human intervention. Our approach consists of three main stages. The first stage yields the core object for the entire process, the Partitioned Matrix Expression (PME), which establishes how the target problem may be decomposed in terms of simpler sub-problems. In the second stage the PME is inspected to identify predicates, the Loop-Invariants, to be used to set up the skeleton of a family of proofs of correctness. In the third and last stage the actual algorithms are constructed so that each of them satisfies its corresponding proof of correctness. In this paper we focus on the first stage of the process, the automatic generation of Partitioned Matrix Expressions. In particular, we discuss the steps leading to a PME and the knowledge necessary for a symbolic system to perform such steps. We also introduce CLICK, a prototype system written in Mathematica that generates PMEs automatically.", "venue": "CASC", "authors": ["Diego  Fabregat-Traver", "Paolo  Bientinesi"], "year": 2011, "n_citations": 25}
{"id": 847060, "s2_id": "3608b958ced869c674877e3cba03f7b04befa775", "title": "Art: Abstraction Refinement-Guided Training for Provably Correct Neural Networks", "abstract": "Artificial Neural Networks (ANNs) have demonstrated remarkable utility in various challenging machine learning applications. While formally verified properties of their behaviors are highly desired, they have proven notoriously difficult to derive and enforce. Existing approaches typically formulate this problem as a post facto analysis process. In this paper, we present a novel learning framework that ensures such formal guarantees are enforced by construction. Our technique enables training provably correct networks with respect to a broad class of safety properties, a capability that goes well-beyond existing approaches, without compromising much accuracy. Our key insight is that we can integrate an optimization-based abstraction refinement loop into the learning process and operate over dynamically constructed partitions of the input space that considers accuracy and safety objectives synergistically. The refinement procedure iteratively splits the input space from which training data is drawn, guided by the efficacy with which such partitions enable safety verification. We have implemented our approach in a tool (ART) and applied it to enforce general safety properties on unmanned aviator collision avoidance system ACAS Xu dataset and the Collision Detection dataset. Importantly, we empirically demonstrate that realizing safety does not come at the price of much accuracy. Our methodology demonstrates that an abstraction refinement methodology provides a meaningful pathway for building both accurate and correct machine learning networks.", "venue": "2020 Formal Methods in Computer Aided Design (FMCAD)", "authors": ["Xuankang  Lin", "He  Zhu", "Roopsha  Samanta", "Suresh  Jagannathan"], "year": 2020, "n_citations": 10}
{"id": 849126, "s2_id": "c56b9ee1a32d4e25da6ed24a0c3f3556d9e26be2", "title": "Optimising Problem Formulation for Cylindrical Algebraic Decomposition", "abstract": "Cylindrical algebraic decomposition (CAD) is an important tool for the study of real algebraic geometry with many applications both within mathematics and elsewhere. It is known to have doubly exponential complexity in the number of variables in the worst case, but the actual computation time can vary greatly. It is possible to offer different formulations for a given problem leading to great differences in tractability. In this paper we suggest a new measure for CAD complexity which takes into account the real geometry of the problem. This leads to new heuristics for choosing: the variable ordering for a CAD problem, a designated equational constraint, and formulations for truth-table invariant CADs (TTICADs). We then consider the possibility of using Grobner bases to precondition TTICAD and when such formulations constitute the creation of a new problem.", "venue": "MKM/Calculemus/DML", "authors": ["Russell J. Bradford", "James H. Davenport", "Matthew  England", "David J. Wilson"], "year": 2013, "n_citations": 34}
{"id": 852707, "s2_id": "aced49e2eb028a552443fce2d94e7d8705e2d1e6", "title": "Design, Implementation and Evaluation of MTBDD based Fuzzy Sets and Binary Fuzzy Relations", "abstract": "For fast and efficient analysis of large sets of fuzzy data, elimination of redundancies in the memory representation is needed. We used MTBDDs as the underlying data-structure to represent fuzzy sets and binary fuzzy relations. This leads to elimination of redundancies in the representation, less computations, and faster analyses. We have also extended a BDD package (BuDDy) to support MTBDDs in general and fuzzy sets and relations in particular. Different fuzzy operations such as max, min and max-min composition were implemented based on our representation. Effectiveness of our representation is shown by applying it on fuzzy connectedness and image segmentation problem. Compared to a base implementation, the running time of our MTBDD based implementation was faster (in our test cases) by a factor ranging from 2 to 27. Also, when the MTBDD based data-structure was employed, the memory needed to represent the final results was improved by a factor ranging from 37.9 to 265.5.", "venue": "ArXiv", "authors": ["Hamid A. Toussi", "Bahram Sadeghi Bigham"], "year": 2014, "n_citations": 2}
{"id": 855732, "s2_id": "3531c14021d2528c0969cbbf31766e9f2f98e613", "title": "Proceedings Twelfth International Workshop on Graph Computational Models", "abstract": "This volume contains the post-proceedings of the Twelfth International Workshop on Graph Computation Models (GCM 2021). The workshop was part of STAF 2021 (Software Technologies: Applications and Foundations) as an online-workshop on 22nd June 2021. Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modelling in science, engineering and beyond, including computer science, biology, business process modelling, etc. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas.", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Berthold  Hoffmann", "Mark  Minas"], "year": 2021, "n_citations": 0}
{"id": 858997, "s2_id": "660ce66542ce533d7c053c127b96ec745b04286a", "title": "When is a Polynomial Ideal Binomial After an Ambient Automorphism?", "abstract": "Can an ideal\u00a0I in a polynomial ring $$\\Bbbk [\\mathbf {x}]$$k[x] over a field be moved by a change of coordinates into a position where it is generated by binomials $$\\mathbf {x}^\\mathbb A- \\lambda \\mathbf {x}^\\mathbf {b}$$xA-\u03bbxb with $$\\lambda \\in \\Bbbk $$\u03bb\u2208k, or by unital binomials (i.e., with $$\\lambda = 0$$\u03bb=0 or\u00a01)? Can a variety be moved into a position where it is toric? By fibering the G-translates of\u00a0I over an algebraic group\u00a0G acting on affine space, these problems are special cases of questions about a family\u00a0$$\\mathcal {I}$$I of ideals over an arbitrary base\u00a0B. The main results in this general setting are algorithms to find the locus of points in\u00a0B over which the fiber of\u00a0$$\\mathcal {I}$$Iis contained in the fiber of a second family\u00a0$$\\mathcal {I}'$$I\u2032 of ideals over\u00a0B;defines a variety of dimension at least\u00a0d;is generated by binomials; oris generated by unital binomials. A faster containment algorithm is also presented when the fibers of\u00a0$$\\mathcal {I}$$I are prime. The big-fiber algorithm is probabilistic but likely faster than known deterministic ones. Applications include the setting where a second group\u00a0T acts on affine space, in addition to\u00a0G, in which case algorithms compute the set of G-translates of\u00a0Iwhose stabilizer subgroups in\u00a0T have maximal dimension; orthat admit a faithful multigrading by\u00a0$$\\mathbb {Z}^r$$Zr of maximal rank\u00a0r. Even with no ambient group action given, the final application is an algorithm todecide whether a normal projective variety is abstractly toric. All of these loci in\u00a0B and subsets of\u00a0G are constructible.", "venue": "Found. Comput. Math.", "authors": ["Lukas  Katth\u00e4n", "Mateusz  Michalek", "Ezra  Miller"], "year": 2019, "n_citations": 4}
{"id": 864118, "s2_id": "21be666a2bcb5b15bd0c1a13bb799481baded933", "title": "A bound on the minimum of a real positive polynomial over the standard simplex", "abstract": "We consider the problem of bounding away from $0$ the minimum value $m$ taken by a polynomial $P \\in \\Z \\left[X_{1},\\dots,X_{k}\\right]$ over the standard simplex $\\Delta \\subset \\R^{k}$, assuming that $m>0$. Recent algorithmic developments in real algebraic geometry enable us to obtain a positive lower bound on $m$ in terms of the dimension $k$, the degree $d$ and the bitsize $\\tau$ of the coefficients of $P$. The bound is explicit, and obtained without any extra assumption on $P$, in contrast with previous results reported in the literature.", "venue": "ArXiv", "authors": ["Saugata  Basu", "Richard  Leroy", "Marie-Fran\u00e7oise  Roy"], "year": 2009, "n_citations": 12}
{"id": 867120, "s2_id": "bce4b9a1e535d4e84042f61f51ea7f9684db576a", "title": "Resultant-based Elimination in Ore Algebra", "abstract": "We consider resultant-based methods for elimination of indeterminates of Ore polynomial systems in Ore algebra. We start with defining the concept of resultant for bivariate Ore polynomials then compute it by the Dieudonn\u00e9 determinant of the polynomial coefficients. Additionally, we apply noncommutative versions of evaluation and interpolation techniques to the computation process to improve the efficiency of the method. The implementation of the algorithms will be performed in Maple to evaluate the performance of the approaches.", "venue": "ArXiv", "authors": ["Raqeeb  Rasheed"], "year": 2021, "n_citations": 0}
{"id": 868572, "s2_id": "2cbe57e611c2ad79d207ecc86f2b2fd42da2aeff", "title": "Factorization in categories of systems of linear partial differential equations", "abstract": "We start with elementary algebraic theory of factorization of linear ordinary differential equations developed in the period 1880-1930. After exposing these classical results we sketch more sophisticated algorithmic approaches developed in the last 20 years. \nThe main part of this paper is devoted to modern generalizations of the notion of factorization to the case of systems of linear partial differential equations and their relation with explicit solvability of nonlinear partial differential equations based on some constructions from the theory of abelian categories.", "venue": "ArXiv", "authors": ["Sergey P. Tsarev"], "year": 2008, "n_citations": 5}
{"id": 872866, "s2_id": "9e69ecbb6fbd026a627174a01e786d4dd8ecbba1", "title": "Cylindrical algebraic decompositions for boolean combinations", "abstract": "This article makes the key observation that when using cylindrical algebraic decomposition (CAD) to solve a problem with respect to a set of polynomials, it is not always the signs of those polynomials that are of paramount importance but rather the truth values of certain quantifier free formulae involving them. This motivates our definition of a Truth Table Invariant CAD (TTICAD). We generalise the theory of equational constraints to design an algorithm which will efficiently construct a TTICAD for a wide class of problems, producing stronger results than when using equational constraints alone. The algorithm is implemented fully in Maple and we present promising results from experimentation.", "venue": "ISSAC '13", "authors": ["Russell J. Bradford", "James H. Davenport", "Matthew  England", "Scott  McCallum", "David J. Wilson"], "year": 2013, "n_citations": 44}
{"id": 872962, "s2_id": "5b685770e8b33d57ea1d1eb3ce3823d9a7123279", "title": "Factorization of C-finite Sequences", "abstract": "We discuss how to decide whether a given C-finite sequence can be written nontrivially as a product of two other C-finite sequences.", "venue": "ArXiv", "authors": ["Manuel  Kauers", "Doron  Zeilberger"], "year": 2016, "n_citations": 1}
{"id": 873112, "s2_id": "963650a446297710d35195e3ebc3ab2a71e00150", "title": "Simulation-Based Reachability Analysis for High-Index Large Linear Differential Algebraic Equations", "abstract": "Reachability analysis is a fundamental problem for safety verification and falsification of Cyber-Physical Systems (CPS) whose dynamics follow physical laws usually represented as differential equations. In the last two decades, numerous reachability analysis methods and tools have been proposed for a common class of dynamics in CPS known as ordinary differential equations (ODE). However, there is lack of methods dealing with differential algebraic equations (DAE) which is a more general class of dynamics that is widely used to describe a variety of problems from engineering and science such as multibody mechanics, electrical cicuit design, incompressible fluids, molecular dynamics and chemcial process control. Reachability analysis for DAE systems is more complex than ODE systems, especially for high-index DAEs because they contain both a differential part (i.e., ODE) and algebraic constraints (AC). In this paper, we extend the recent scalable simulation-based reachability analysis in combination with decoupling techniques for a class of high-index large linear DAEs. In particular, a high-index linear DAE is first decoupled into one ODE and one or several AC subsystems based on the well-known Marz decoupling method ultilizing admissible projectors. Then, the discrete reachable set of the DAE, represented as a list of star-sets, is computed using simulation. Unlike ODE reachability analysis where the initial condition is freely defined by a user, in DAE cases, the consistency of the inititial condition is an essential requirement to guarantee a feasible solution. Therefore, a thorough check for the consistency is invoked before computing the discrete reachable set. Our approach sucessfully verifies (or falsifies) a wide range of practical, high-index linear DAE systems in which the number of state variables varies from several to thousands.", "venue": "ArXiv", "authors": ["Hoang-Dung  Tran", "Weiming  Xiang", "Nathaniel  Hamilton", "Taylor T. Johnson"], "year": 2018, "n_citations": 1}
{"id": 873119, "s2_id": "1b27d90d4b31228c6806c07e6524a47d128a97ac", "title": "On the Complexity of Exact Counting of Dynamically Irreducible Polynomials", "abstract": "We give an efficient algorithm to enumerate all sets of $r\\ge 1$ quadratic polynomials over a finite field, which remain irreducible under iterations and compositions.", "venue": "J. Symb. Comput.", "authors": ["Domingo  G\u00f3mez-P\u00e9rez", "L\u00e1szl\u00f3  M\u00e9rai", "Igor E. Shparlinski"], "year": 2020, "n_citations": 1}
{"id": 878714, "s2_id": "9e4ce56196fe74f16b3da80125650cd833eb18a5", "title": "FORM Matters: Fast Symbolic Computation under UNIX", "abstract": "We give a brief introduction to FORM, a symbolic programming language for massive batch operations, designed by Vermaseren. In particular, we stress various methods to efficiently use FORM under the UNIX operating system. Several scripts and examples are given, and suggestions on how to use the vim editor as development platform.", "venue": "ArXiv", "authors": ["Michael M. Tung"], "year": 2004, "n_citations": 6}
{"id": 885646, "s2_id": "997887cff41577752dc832e9475d5bb22c265093", "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning", "abstract": "Generative commonsense reasoning which aims to empower machines to generate sentences with the capacity of reasoning over a set of concepts is a critical bottleneck for text generation. Even the state-of-the-art pre-trained language generation models struggle at this task and often produce implausible and anomalous sentences. One reason is that they rarely consider incorporating the knowledge graph which can provide rich relational information among the commonsense concepts. To promote the ability of commonsense reasoning for text generation, we propose a novel knowledge graphaugmented pre-trained language generation model KG-BART, which encompasses the complex relations of concepts through the knowledge graph and produces more logical and natural sentences as output. Moreover, KG-BART can leverage the graph attention to aggregate the rich concept semantics that enhances the model generalization on unseen concept sets. Experiments on benchmark CommonGen dataset verify the effectiveness of our proposed approach by comparing with several strong pre-trained language generation models, particularly KG-BART outperforms BART by 15.98%, 17.49%, in terms of BLEU-3, 4. Moreover, we also show that the generated context by our model can work as background scenarios to benefit downstream commonsense QA tasks.", "venue": "AAAI", "authors": ["Ye  Liu", "Yao  Wan", "Lifang  He", "Hao  Peng", "Philip S. Yu"], "year": 2021, "n_citations": 27}
{"id": 886662, "s2_id": "77364f4e4e8d677d6cd6b8ec0398cdc29fc6dd19", "title": "Computing Puiseux Expansions at Cusps of the Modular Curve X0(N)", "abstract": "The goal in this preprint is to give an efficient algorithm to compute Puiseux expansions at cusps of X0(N). It is based on a relation with a hypergeometric function that holds for any N.", "venue": "ArXiv", "authors": ["Mark van Hoeij"], "year": 2013, "n_citations": 0}
{"id": 887921, "s2_id": "972f2d06356c79c22f2432922069ee2742d1d536", "title": "On the last fall degree of zero-dimensional Weil descent systems", "abstract": "Abstract In this article we will discuss a mostly theoretical framework for solving zero-dimensional polynomial systems. Complexity bounds are obtained for solving such systems using a new parameter, called the last fall degree, which does not depend on the choice of a monomial order. The method is similar to certain MutantXL algorithms, but our abstract formulation has advantages. For example, we can prove that the cryptographic systems multi-HFE and HFE are insecure. More generally, let k be a finite field of cardinality q n and let k \u2032 be the subfield of cardinality q. Let F \u2282 k [ X 0 , \u2026 , X m \u2212 1 ] be a finite subset generating a zero-dimensional ideal. We give an upper bound of the last fall degree of the Weil descent system of F from k to k \u2032 , which depends on q, m, the last fall degree of F , the degree of F and the number of solutions of F , but not on n. This shows that such Weil descent systems can be solved efficiently if n grows and the other parameters are fixed. In particular, one can apply these results to show a weakness in the cryptographic protocols HFE and multi-HFE.", "venue": "J. Symb. Comput.", "authors": ["Ming-Deh A. Huang", "Michiel  Kosters", "Yun  Yang", "Sze Ling Yeo"], "year": 2018, "n_citations": 10}
{"id": 894581, "s2_id": "23b0b12ae887f270903b2d3f05258ea745b01856", "title": "A recursive method for determining the one-dimensional submodules of Laurent-Ore modules", "abstract": "We present a method for determining the one-dimensional submodules of a Laurent-Ore module. The method is based on a correspondence between hyperexponential solutions of associated systems and one-dimensional submodules. The hyperexponential solutions are computed recursively by solving a sequence of first-order ordinary matrix equations. As the recursion proceeds, the matrix equations will have constant coefficients with respect to the operators that have been considered.", "venue": "ISSAC '06", "authors": ["Ziming  Li", "Michael F. Singer", "Min  Wu", "Dabin  Zheng"], "year": 2006, "n_citations": 13}
{"id": 895605, "s2_id": "6b94ce4858756f86ab2ee3f847633eed12fa9e3f", "title": "PHCpack in Macaulay2", "abstract": "The Macaulay2 package PHCpack provides an interface to PHCpack, a generalpurpose polynomial system solver that uses homotopy continuation. The main method is a numerical blackbox solver which is implemented for all Laurent systems. The package also provides a fast mixed volume computation, the ability to filter solutions, homotopy path tracking, and a numerical irreducible decomposition method. As the size of many problems in applied algebraic geometry often surpasses the capabilities of symbolic software, this package will be of interest to those working on problems involving large polynomial systems.", "venue": "ArXiv", "authors": ["Elizabeth  Gross", "Sonja  Petrovic", "Jan  Verschelde"], "year": 2011, "n_citations": 5}
{"id": 897483, "s2_id": "32dcc599664340a2ba6d32f75d33227cd908cb9a", "title": "Practical Groebner Basis Computation", "abstract": "We report on our experiences exploring state of the art Groebner basis computation. We investigate signature based algorithms in detail. We also introduce new practical data structures and computational techniques for use in both signature based Groebner basis algorithms and more traditional variations of the classic Buchberger algorithm. Our conclusions are based on experiments using our new freely available open source standalone C++ library.", "venue": "ArXiv", "authors": ["Bjarke Hammersholt Roune", "Michael Eugene Stillman"], "year": 2012, "n_citations": 1}
{"id": 898507, "s2_id": "0242ec415c5d2400931510372ac66c467e9ff1ec", "title": "Approximate substitutions and the normal ordering problem", "abstract": "In this paper, we show that the infinite generalised Stirling matrices associated with boson strings with one annihilation operator are projective limits of approximate substitutions, the latter being characterised by a finite set of algebraic equations.", "venue": "ArXiv", "authors": ["H.  Cheballah", "G\u00e9rard  Duchamp", "Karol A. Penson"], "year": 2008, "n_citations": 3}
{"id": 904828, "s2_id": "f7cc4a1f5c47e97c938284fcd01b20d1fc062013", "title": "Proceedings of the 9th International Workshop on Verification and Program Transformation", "abstract": "The previous VPT 2020 workshop was organized in honour of Professor Alberto Pettorossi on the occasion of his academic retirement from Universit\\`a di Roma Tor Vergata. Due to the pandemic the VPT 2020 meeting was cancelled but its proceeding have already appeared in the EPTCS 320 volume. The joint VPT-20-21 event has subsumed the original programme of VPT 2020 and provided an opportunity to meet and celebrate the achievements of Professor Alberto Pettorossi; its programme was further expanded with the newly submitted presentations for VPT 2021. The aim of the VPT workshop series is to provide a forum where people from the areas of program transformation and program verification can fruitfully exchange ideas and gain a deeper understanding of the interactions between those two fields.", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Alexei  Lisitsa", "Andrei P. Nemytykh"], "year": 2021, "n_citations": 0}
{"id": 908369, "s2_id": "6a18665fc29659bc7cb221878676eeb46df282cb", "title": "Low complexity algorithms for linear recurrences", "abstract": "We consider two kinds of problems: the computation of polynomial and rational solutions of linear recurrences with coefficients that are polynomials with integer coefficients; indefinite and definite summation of sequences that are hypergeometric over the rational numbers. The algorithms for these tasks all involve as an intermediate quantity an integer N (dispersion or root of an indicial polynomial) that is potentially exponential in the bit size of their input. Previous algorithms have a bit complexity that is at least quadratic in N. We revisit them and propose variants that exploit the structure of solutions and avoid expanding polynomials of degree N. We give two algorithms: a probabilistic one that detects the existence or absence of nonzero polynomial and rational solutions in O(\u221aN log2 N) bit operations; a deterministic one that computes a compact representation of the solution in O(N log3 N) bit operations. Similar speedups are obtained in indefinite and definite hypergeometric summation. We describe the results of an implementation.", "venue": "ISSAC '06", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Bruno  Salvy", "Thomas  Cluzeau"], "year": 2006, "n_citations": 18}
{"id": 910840, "s2_id": "fba02c6f52bd6f7ad33a05aea732c5414e103d8b", "title": "Approximation of dynamical systems using s-systems theory: application to biological systems", "abstract": "In this article we propose a new symbolic-numeric algorithm to find positive equilibria of a n-dimensional dynamical system. This algorithm uses a symbolic manipulation of ODE in order to give a local approximation of differential equations with power-law dynamics (S-systems). A numerical calculus is then performed to converge towards an equilibrium, giving at the same time a S-system approximating the initial system around this equilibrium. This algorithm has been applied to a real biological example in 14 dimensions which is a subsystem of a metabolic pathway in Arabidopsis Thaliana.", "venue": "ISSAC", "authors": ["Laurent  Tournier"], "year": 2005, "n_citations": 13}
{"id": 912808, "s2_id": "88c08f587d55a1d5d193ce41eda52ebd90fd3a99", "title": "Analyzing the Topology Types arising in a Family of Algebraic Curves Depending On Two Parameters", "abstract": "Given the implicit equation F(x, y, t, s) of a family of algebraic plane curves depending on the parameters t, s, we provide an algorithm for studying the topology types arising in the family. For this purpose, the algorithm computes a finite partition of the parameter space so that the topology type of the family stays invariant over each element of the partition. The ideas contained in the paper can be seen as a generalization of the ideas in [3], where the problem is solved for families of algebraic curves depending on one parameter, to the two-parameters case.", "venue": "ArXiv", "authors": ["Juan Gerardo Alc\u00e1zar"], "year": 2008, "n_citations": 0}
{"id": 915016, "s2_id": "8781ed9d762091b9d1fb3397afb130cfe67207dd", "title": "Efficient differentiable programming in a functional array-processing language", "abstract": "We present a system for the automatic differentiation (AD) of a higher-order functional array-processing language. The core functional language underlying this system simultaneously supports both source-to-source forward-mode AD and global optimisations such as loop transformations. In combination, gradient computation with forward-mode AD can be as efficient as reverse mode, and that the Jacobian matrices required for numerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be efficiently computed.", "venue": "Proc. ACM Program. Lang.", "authors": ["Amir  Shaikhha", "Andrew  Fitzgibbon", "Dimitrios  Vytiniotis", "Simon L. Peyton Jones", "Christoph  Koch"], "year": 2019, "n_citations": 28}
{"id": 919075, "s2_id": "efd8b9f1e3929312c8a89eb8dad39be5e29f5f72", "title": "Solving the \"Isomorphism of Polynomials with Two Secrets\" Problem for all Pairs of Quadratic Forms", "abstract": "We study the Isomorphism of Polynomial (IP2S) problem with m=2 homogeneous quadratic polynomials of n variables over a finite field of odd characteristic: given two quadratic polynomials (a, b) on n variables, we find two bijective linear maps (s,t) such that b=t . a . s. We give an algorithm computing s and t in time complexity O~(n^4) for all instances, and O~(n^3) in a dominant set of instances. \nThe IP2S problem was introduced in cryptography by Patarin back in 1996. The special case of this problem when t is the identity is called the isomorphism with one secret (IP1S) problem. Generic algebraic equation solvers (for example using Grobner bases) solve quite well random instances of the IP1S problem. For the particular cyclic instances of IP1S, a cubic-time algorithm was later given and explained in terms of pencils of quadratic forms over all finite fields; in particular, the cyclic IP1S problem in odd characteristic reduces to the computation of the square root of a matrix. \nWe give here an algorithm solving all cases of the IP1S problem in odd characteristic using two new tools, the Kronecker form for a singular quadratic pencil, and the reduction of bilinear forms over a non-commutative algebra. Finally, we show that the second secret in the IP2S problem may be recovered in cubic time.", "venue": "ArXiv", "authors": ["J\u00e9r\u00f4me  Pl\u00fbt", "Pierre-Alain  Fouque", "Gilles  Macario-Rat"], "year": 2014, "n_citations": 6}
{"id": 919661, "s2_id": "d2fa49799c124c794dc143e19f1da54c837972be", "title": "Apparent Singularities of D-finite Systems", "abstract": "We generalize the notions of singularities and ordinary points from linear ordinary differential equations to D-finite systems. Ordinary points of a D-finite system are characterized in terms of its formal power series solutions. We also show that apparent singularities can be removed like in the univariate case by adding suitable additional solutions to the system at hand. Several algorithms are presented for removing and detecting apparent singularities. In addition, an algorithm is given for computing formal power series solutions of a D-finite system at apparent singularities.", "venue": "J. Symb. Comput.", "authors": ["Shaoshi  Chen", "Manuel  Kauers", "Ziming  Li", "Yi  Zhang"], "year": 2019, "n_citations": 10}
{"id": 919970, "s2_id": "da9e3362f57cbc78cd7b1d4cebba645c0779ae20", "title": "An efficient algorithm for global interval solution of nonlinear algebraic equations and its GPGPU implementation", "abstract": "Solving nonlinear algebraic equations is a classic mathematics problem, and common in scientific researches and engineering applications. There are many numeric, symbolic and numeric-symbolic methods of solving (real) solutions. Unlucky, these methods are constrained by some factors, e.g., high complexity, slow serial calculation, and the notorious intermediate expression expansion. Especially when the count of variables is larger than six, the efficiency is decreasing drastically. In this paper, according to the property of physical world, we pay attention to nonlinear algebraic equations whose variables are in fixed constraints, and get meaningful real solutions. Combining with parallelism of GPGPU, we present an efficient algorithm, by searching the solution space globally and solving the nonlinear algebraic equations with real interval solutions. Furthermore, we realize the Hansen-Sengupta method on GPGPU. The experiments show that our method can solve many nonlinear algebraic equations, and the results are accurate and more efficient compared to traditional serial methods.", "venue": "ArXiv", "authors": ["Dang  Lin", "Liangyu  Chen"], "year": 2018, "n_citations": 0}
{"id": 921547, "s2_id": "4f26c91ab5402025e6a9e221ba459d61edb21c26", "title": "A Linear Algebra Approach for Detecting Binomiality of Steady State Ideals of Reversible Chemical Reaction Networks", "abstract": "Motivated by problems from Chemical Reaction Network Theory, we investigate whether steady state ideals of reversible reaction networks are generated by binomials. We take an algebraic approach considering, besides concentrations of species, also rate constants as indeterminates. This leads us to the concept of unconditional binomiality, meaning binomiality for all values of the rate constants. This concept is different from conditional binomiality that applies when rate constant values or relations among rate constants are given. We start by representing the generators of a steady state ideal as sums of binomials, which yields a corresponding coefficient matrix. On these grounds we propose an efficient algorithm for detecting unconditional binomiality. That algorithm uses exclusively elementary column and row operations on the coefficient matrix. We prove asymptotic worst case upper bounds on the time complexity of our algorithm. Furthermore, we experimentally compare its performance with other existing methods.", "venue": "CASC", "authors": ["Hamid  Rahkooy", "Thomas  Sturm"], "year": 2020, "n_citations": 4}
{"id": 922459, "s2_id": "0ade2b71e900c93e4812a72bcb997e47e7779c87", "title": "A correct proof of the heuristic GCD algorithm", "abstract": "In this note, we fill a gap in the proof of the heuristic GCD in the multivariate case made by Char, Geddes and Gonnet (JSC 1989) and give some additionnal information on this method.", "venue": "ArXiv", "authors": ["Bernard  Parisse"], "year": 2002, "n_citations": 0}
{"id": 927481, "s2_id": "5ff44dd897e7c4fa9b98066e326a2eeff634bc32", "title": "High\u2010performance SIMD modular arithmetic for polynomial evaluation", "abstract": "Two essential problems in computer algebra, namely polynomial factorization and polynomial greatest common divisor computation, can be efficiently solved thanks to multiple polynomial evaluations in two variables using modular arithmetic. In this article, we focus on the efficient computation of such polynomial evaluations on one single CPU core. We first show how to leverage SIMD (single instruction, multiple data) computing for modular arithmetic on AVX2 and AVX\u2010512 units, using both intrinsics and OpenMP compiler directives. Then we manage to increase the operational intensity and to exploit instruction\u2010level parallelism in order to increase the compute efficiency of these polynomial evaluations. All this results in the end to performance gains up to about 5x on AVX2 and 10x on AVX\u2010512.", "venue": "Concurr. Comput. Pract. Exp.", "authors": ["Pierre  Fortin", "Ambroise  Fleury", "Franccois  Lemaire", "Michael  Monagan"], "year": 2021, "n_citations": 5}
{"id": 929595, "s2_id": "c84b11611ec9c1ac2ddd648faf79ea2759936eab", "title": "Computing all Affine Solution Sets of Binomial Systems", "abstract": "To compute solutions of sparse polynomial systems efficiently we have to exploit the structure of their Newton polytopes. While the application of polyhedral methods naturally excludes solutions with zero components, an irreducible decomposition of a variety is typically understood in affine space, including also those components with zero coordinates. For the problem of computing solution sets in the intersection of some coordinate planes, the direct application of a polyhedral method fails, because the original facial structure of the Newton polytopes may alter completely when selected variables become zero. Our new proposed method enumerates all factors contributing to a generalized permanent and toric solutions as a special case of this enumeration. For benchmark problems such as the adjacent 2-by-2 minors of a general matrix, our methods scale much better than the witness set representations of numerical algebraic geometry.", "venue": "ArXiv", "authors": ["Danko  Adrovic", "Jan  Verschelde"], "year": 2014, "n_citations": 0}
{"id": 933198, "s2_id": "0b5c09434f8b020d5e5ae4b5b98ffb885d29ff0b", "title": "Fast integer multiplication using modular arithmetic", "abstract": "We give an O(N \u2022 log N \u2022 2O(log*N)) algorithm for multiplying two N-bit integers that improves the O(N \u2022 log N \u2022 log log N) algorithm by Sch\u00f6nhage-Strassen. Both these algorithms use modular arithmetic. Recently, F\u00fcrer gave an O(N \u2022 log N \u2022 2O(log*N)) algorithm which however uses arithmetic over complex numbers as opposed to modular arithmetic. In this paper, we use multivariate polynomial multiplication along with ideas from F\u00fcrer's algorithm to achieve this improvement in the modular setting. Our algorithm can also be viewed as a p-adic version of F\u00fcrer's algorithm. Thus, we show that the two seemingly different approaches to integer multiplication, modular and complex arithmetic, are similar.", "venue": "STOC", "authors": ["Anindya  De", "Piyush P. Kurur", "Chandan  Saha", "Ramprasad  Saptharishi"], "year": 2008, "n_citations": 55}
{"id": 940238, "s2_id": "dba9b6db8c416512ee9dfad709b06026998d12d4", "title": "A Curious Family of Binomial Determinants That Count Rhombus Tilings of a Holey Hexagon", "abstract": "Abstract We evaluate a curious determinant, first mentioned by George Andrews in 1980 in the context of descending plane partitions. Our strategy is to combine the famous Desnanot-Jacobi-Dodgson identity with automated proof techniques. More precisely, we follow the holonomic ansatz that was proposed by Doron Zeilberger in 2007. We derive a compact and nice formula for Andrews's determinant, and use it to solve a challenge problem that we posed in a previous paper. By noting that Andrews's determinant is a special case of a two-parameter family of determinants, we find closed forms for several one-parameter subfamilies. The interest in these determinants arises because they count cyclically symmetric rhombus tilings of a hexagon with several triangular holes inside.", "venue": "J. Comb. Theory, Ser. A", "authors": ["Christoph  Koutschan", "Thotsaporn  Thanatipanonda"], "year": 2019, "n_citations": 1}
{"id": 941003, "s2_id": "ec97ab7bb5d9a75fe25bd11269dd1410deacbdda", "title": "Provability in BI's Sequent Calculus is Decidable", "abstract": "The logic of Bunched Implications (BI) combines both additive and multiplicative connectives, which include two primitive intuitionistic implications. As a consequence, contexts in the sequent presentation are not lists, nor multisets, but rather tree-like structures called bunches. This additional complexity notwithstanding, the logic has a well-behaved metatheory admitting all the familiar forms of semantics and proof systems. However, the presentation of an effective proof-search procedure has been elusive since the logic\u2019s debut. We show that one can reduce the proof-search space for any given sequent to a primitive recursive set, the argument generalizing Gentzen\u2019s decidability argument for classical propositional logic and combining key features of Dyckhoff\u2019s contraction-elimination argument for intuitionistic logic. An effective proof-search procedure, and hence decidability of provability, follows as a corollary.", "venue": "ArXiv", "authors": ["Alexander  Gheorghiu", "Simon  Docherty", "David  Pym"], "year": 2021, "n_citations": 0}
{"id": 946381, "s2_id": "c0db5fb11cf843aa845685de77db0ffbbc990e4a", "title": "Binomial difference ideal and toric difference variety", "abstract": "In this paper, the concepts of binomial difference ideals and toric difference varieties are defined and their properties are proved. Two canonical representations for Laurent binomial difference ideals are given using the reduced Groebner basis of Z[x]-lattices and regular and coherent difference ascending chains, respectively. Criteria for a Laurent binomial difference ideal to be reflexive, prime, well-mixed, perfect, and toric are given in terms of their support lattices which are Z[x]-lattices. The reflexive, well-mixed, and perfect closures of a Laurent binomial difference ideal are shown to be binomial. Four equivalent definitions for toric difference varieties are presented. Finally, algorithms are given to check whether a given Laurent binomial difference ideal I is reflexive, prime, well-mixed, perfect, or toric, and in the negative case, to compute the reflexive, well-mixed, and perfect closures of I. An algorithm is given to decompose a finitely generated perfect binomial difference ideal as the intersection of reflexive prime binomial difference ideals.", "venue": "ACCA", "authors": ["Xiao-Shan  Gao", "Zhang  Huang", "Chun-Ming  Yuan"], "year": 2015, "n_citations": 4}
{"id": 947319, "s2_id": "37b5cfa3651ccdb7b8b681099f882056b77e04e7", "title": "A computer algebra user interface manifesto", "abstract": "Many computer algebra systems have more than 1000 built-in functions, making expertise difficult. Using mock dialog boxes, this article describes a proposed interactive general-purpose wizard for organizing optional transformations and allowing easy fine grain control over the form of the result -- even by amateurs. This wizard integrates ideas including: flexible subexpression selection; complete control over the ordering of variables and commutative operands, with wellchosen defaults; interleaving the choice of successively less main variables with applicable function choices to provide detailed control without incurring a combinatorial number of applicable alternatives at any one level; quick applicability tests to reduce the listing of inapplicable transformations; using an organizing principle to order the alternatives in a helpful manner; labeling quickly-computed alternatives in dialog boxes with a preview of their results, using ellipsis elisions if necessary or helpful; allowing the user to retreat from a sequence of choices to explore other branches of the tree of alternatives -- or to return quickly to branches already visited; allowing the user to accumulate more than one of the alternative forms; integrating direct manipulation into the wizard; and supporting not only the usual input-result pair mode, but also the useful alternative derivational and in situ replacement modes in a unified window.", "venue": "ACCA", "authors": ["David R. Stoutemyer"], "year": 2014, "n_citations": 0}
{"id": 948366, "s2_id": "1b6943fe83633e9ec37836338baff83e0073e5f1", "title": "MatchPy: A Pattern Matching Library", "abstract": "Pattern matching is a powerful tool for symbolic computations, based on the well-defined theory of term rewriting systems. Application domains include algebraic expressions, abstract syntax trees, and XML and JSON data. Unfortunately, no lightweight implementation of pattern matching as general and flexible as Mathematica exists for Python Mathics,MacroPy,patterns,PyPatt. Therefore, we created the open source module MatchPy which offers similar pattern matching functionality in Python using a novel algorithm which finds matches for large pattern sets more efficiently by exploiting similarities between patterns.", "venue": "ArXiv", "authors": ["Manuel  Krebber", "Henrik  Barthels", "Paolo  Bientinesi"], "year": 2017, "n_citations": 4}
{"id": 952470, "s2_id": "359f7025bc279f492602b207fce17c327ca4d657", "title": "A nonexistence certificate for projective planes of order ten with weight 15 codewords", "abstract": "Using techniques from the fields of symbolic computation and satisfiability checking we verify one of the cases used in the landmark result that projective planes of order ten do not exist. In particular, we show that there exist no projective planes of order ten that generate codewords of weight fifteen, a result first shown in 1973 via an exhaustive computer search. We provide a simple satisfiability (SAT) instance and a certificate of unsatisfiability that can be used to automatically verify this result for the first time. All previous demonstrations of this result have relied on search programs that are difficult or impossible to verify\u2014in fact, our search found partial projective planes that were missed by previous searches due to previously undiscovered bugs. Furthermore, we show how the performance of the SAT solver can be dramatically increased by employing functionality from a computer algebra system (CAS). Our SAT+CAS search runs significantly faster than all other published searches verifying this result.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Curtis  Bright", "Kevin  Cheung", "Brett  Stevens", "Dominique  Roy", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2020, "n_citations": 4}
{"id": 955147, "s2_id": "508bdcfa297c0a26a9878cbac8d31198cb278929", "title": "The assembly modes of rigid 11-bar linkages", "abstract": "Designing an m-bar linkage with a maximal number of assembly modes is important in robot kinematics, and has further applications in structural biology and computational geometry. A related question concerns the number of assembly modes of rigid mechanisms as a function of their nodes n, which is uniquely defined given m. Rigid 11-bar linkages, where n=7, are the simplest planar linkages for which these questions were still open. It will be proven that the maximal number of assembly modes of such linkages is exactly 56. The rigidity of a linkage is captured by a polynomial system derived from distance, or Cayley-Menger, matrices. The upper bound on the number of assembly modes is obtained as the mixed volume of a 5x5 system. An 11-bar linkage admitting 56 configurations is constructed using stochastic optimisation methods. This yields a general lower bound of $\\Omega(2.3^n)$ on the number of assembly modes, slightly improving the current record of $\\Omega(2.289^n)$, while the best known upper bound is roughly $4^n$. Our methods are straightforward and have been implemented in Maple. They are described in general terms illustrating the fact that they can be readily extended to other planar or spatial linkages. The main results have been reported in conference publication [EM11]. This version (2017) typesets correctly the last Figure 5 so as to include all 28 configurations modulo reflection.", "venue": "ArXiv", "authors": ["Ioannis Z. Emiris", "Guillaume  Moroz"], "year": 2010, "n_citations": 9}
{"id": 958094, "s2_id": "e8e231e48086f26e84dd8e4670264f036bf72cb7", "title": "Fast real and complex root-finding methods for well-conditioned polynomials", "abstract": "Given a polynomial ? of degree 3 and a bound ^ on a condition number of ? , we present the first root-finding algorithms that return all its real and complex roots with a number of bit operations quasi-linear in 3 log (^). More precisely, several condition numbers can be defined depending on the norm chosen on the coefficients of the polynomial. Let ? (G) = \u22113 :=0 0:G : = \u22113 :=0 \u221a(3 : ) 1:G : . We call the condition number associated with a perturbation of the 0: the hyperbolic condition number ^h , and the one associated with a perturbation of the 1: the elliptic condition number ^4 . For each of these condition numbers, we present algorithms that find the real and the complex roots of? in$ ( 3 log (3^) polylog(log(3^)) ) bit operations. Our algorithms are well suited for random polynomials since ^h (resp. ^4 ) is bounded by a polynomial in 3 with high probability if the 0: (resp. the 1: ) are independent, centered Gaussian variables of variance 1.", "venue": "ArXiv", "authors": ["Guillaume  Moroz"], "year": 2021, "n_citations": 0}
{"id": 960705, "s2_id": "449b92ae2b1c7a78c50610d4ca0312746ecf8b1a", "title": "Algorithms for computing triangular decompositions of polynomial systems", "abstract": "We propose new algorithms for computing triangular decompositions of polynomial systems incrementally. With respect to previous works, our improvements are based on a weakened notion of a polynomial GCD modulo a regular chain, which permits to greatly simplify and optimize the sub-algorithms. Extracting common work from similar expensive computations is also a key feature of our algorithms. In our experimental results the implementation of our new algorithms, realized with the RegularChains library in MAPLE, outperforms solvers with similar specifications by several orders of magnitude on sufficiently difficult problems.", "venue": "ISSAC '11", "authors": ["Changbo  Chen", "Marc Moreno Maza"], "year": 2011, "n_citations": 33}
{"id": 965136, "s2_id": "8ceecb2e8456032f27e2956047976b2f1a3384c2", "title": "Abstract Stobjs and Their Application to ISA Modeling", "abstract": "We introduce a new ACL2 feature, the abstract stobj, and show how to apply it to modeling the instruction set architecture of a microprocessor. Benefits of abstract stobjs over traditional (\"concrete\") stobjs can include faster execution, support for symbolic simulation, more efficient reasoning, and resilience of proof developments under modeling optimization.", "venue": "ACL2", "authors": ["Shilpi  Goel", "Warren A. Hunt", "Matt  Kaufmann"], "year": 2013, "n_citations": 20}
{"id": 965882, "s2_id": "d501e25131208372c7b8b2103774fc67765c6034", "title": "A Faster Solution to Smale's 17th Problem I: Real Binomial Systems", "abstract": "Suppose F:=(f_1,\u0142dots,f_n) is a system of random n-variate polynomials with f_i having degree \u0142eq\\!d_i and the coefficient of x^a_1 _1\\cdots x^a_n _n in f_i being an independent complex Gaussian of mean 0 and variance \\fracd_i! a_1!\\cdots a_n!\u0142eft(d_i-\\sum^n_j=1 a_j \\right)! . Recent progress on Smale's 17\u00feth Problem by Lairez --- building upon seminal work of Shub, Beltran, Pardo, B\u00fc rgisser, and Cucker --- has resulted in a deterministic algorithm that finds a single (complex) approximate root of F using just N^O(1) arithmetic operations on average, where N\\!:=\\!\\sum^n_i=1 \\frac(n+d_i)! n!d_i! (=n(n+\\max_i d_i)^O(\\min\\n,\\max_i d_i)\\ ) is the maximum possible total number of monomial terms for such an F. However, can one go faster when the number of terms is smaller, and we restrict to real coefficient and real roots? And can one still maintain average-case polynomial-time with more general probability measures? We show the answer is yes when F is instead a binomial system --- a case whose numerical solution is a key step in polyhedral homotopy algorithms for solving arbitrary polynomial systems. We give a deterministic algorithm that finds a real approximate root (or correctly decides there are none) using just O(n^3\u0142og^2(n\\max_i d_i)) arithmetic operations on average. Furthermore, our approach allows real Gaussians with arbitrary variance. We also discuss briefly the obstructions to maintaining average-case time polynomial in n\u0142og \\max_i d_i when F has more terms.", "venue": "ISSAC", "authors": ["Grigoris  Paouris", "Kaitlyn  Phillipson", "J. Maurice Rojas"], "year": 2019, "n_citations": 2}
{"id": 966414, "s2_id": "5867d896823303042200b6d0e992afc77ade48df", "title": "Residues and Telescopers for Rational Functions", "abstract": "We give necessary and sufficient conditions for the existenceof telescopers for rational functions of two variables in the continuous, discrete and q-discrete settings and characterize which operators can occur as telescopers. Using this latter characterization, we reprove results of Furstenberg and Zeilberger concerning diagonals of power series representing rational functions. The key concept behind these considerations is a generalization of the notion of residue in the continuous case to an analogous concept in the discrete and q-discrete cases.", "venue": "ArXiv", "authors": ["Shaoshi  Chen", "Michael F. Singer"], "year": 2012, "n_citations": 0}
{"id": 968568, "s2_id": "d6d8ba92121097e15ba2748b482e70f4b797efdf", "title": "Polynomial Linear System Solving with Random Errors: New Bounds and Early Termination Technique", "abstract": "This paper deals with the polynomial linear system solving with errors (PLSwE) problem. More specifically, we solve linear systems with univariate polynomial coefficients via an evaluation-interpolation technique assuming that errors can occur before the interpolation step. In this framework, the number of evaluations needed to recover the solution depends on the parameters of the linear system (degrees, size) and on the number of errors. Our work is part of a series of papers about PLSwE aiming to reduce this number of evaluations, which is crucial since it affects the complexity. We proved in [Guerrini et al., Proc. ISIT'19] that if errors are randomly distributed, the bound on the number of evaluations can be lowered with respect to the error rate. In this paper, following the approach of [Kaltofen et al., Proc. ISSAC'17], we improve the results of [Guerrini et al., Proc. ISIT'19] in two directions. First, we propose a new bound on the number of evaluations, lowering the dependency on the parameters of the linear system, based on the work of [Cabay, Proc. SYMSAC'71]. Second, we introduce an early termination strategy in order to handle the unnecessary increase of the number of evaluations due to the overestimation of the output degrees and of the number of errors.", "venue": "ISSAC", "authors": ["Eleonora  Guerrini", "Romain  Lebreton", "Ilaria  Zappatore"], "year": 2021, "n_citations": 0}
{"id": 970705, "s2_id": "e879ab770379b7c3dae915640a54a1ee5db904c7", "title": "Certifying solutions to overdetermined and singular polynomial systems over Q", "abstract": "This paper is concerned with certifying that a given point is near an exact root of an overdetermined or singular polynomial system with rational coefficients. The difficulty lies in the fact that consistency of overdetermined systems is not a continuous property. Our certification is based on hybrid symbolic-numeric methods to compute the exact \"rational univariate representation\" (RUR) of a component of the input system from approximate roots. For overdetermined polynomial systems with simple roots, we compute an initial RUR from approximate roots. The accuracy of the RUR is increased via Newton iterations until the exact RUR is found, which we certify using exact arithmetic. Since the RUR is well-constrained, we can use it to certify the given approximate roots using alpha-theory. To certify isolated singular roots, we use a determinantal form of the \"isosingular deflation\", which adds new polynomials to the original system without introducing new variables. The resulting polynomial system is overdetermined, but the roots are now simple, thereby reducing the problem to the overdetermined case. We prove that our algorithms have complexity that are polynomial in the input plus the output size upon successful convergence, and we use worst case upper bounds for termination when our iteration does not converge to an exact RUR. Examples are included to demonstrate the approach.", "venue": "J. Symb. Comput.", "authors": ["Tulay Ayyildiz Akoglu", "Jonathan D. Hauenstein", "\u00c1gnes  Sz\u00e1nt\u00f3"], "year": 2018, "n_citations": 18}
{"id": 977443, "s2_id": "ac43b75397db566462025ac568a9be8725c5a3ef", "title": "Metric problems for quadrics in multidimensional space", "abstract": "Given the equations of the first and the second order manifolds in R n , we construct the distance equation, i.e. a univariate algebraic equation one of the zeros of which (generically minimal positive) coincides with the square of the distance between these manifolds. To achieve this goal we employ Elimination Theory methods. In the frame of this approach we also deduce the necessary and sufficient algebraic conditions under which the manifolds intersect and propose an algorithm for finding the coordinates of their nearest points. The case of parameter dependent manifolds is also considered.", "venue": "J. Symb. Comput.", "authors": ["Alexei Yu. Uteshev", "Marina V. Yashina"], "year": 2015, "n_citations": 10}
{"id": 981491, "s2_id": "dfd63a93ff35f0adec2c310c251b8fe8fbf828de", "title": "A Quadratically Convergent Algorithm for Structured Low-Rank Approximation", "abstract": "Structured Low-Rank Approximation is a problem arising in a wide range of applications in Numerical Analysis and Engineering Sciences. Given an input matrix $$M$$M, the goal is to compute a matrix $$M'$$M\u2032 of given rank $$r$$r in a linear or affine subspace $$E$$E of matrices (usually encoding a specific structure) such that the Frobenius distance $$\\left\\| M-M' \\right\\| $$M-M\u2032 is small. We propose a Newton-like iteration for solving this problem, whose main feature is that it converges locally quadratically to such a matrix under mild transversality assumptions between the manifold of matrices of rank $$r$$r and the linear/affine subspace $$E$$E. We also show that the distance between the limit of the iteration and the optimal solution of the problem is quadratic in the distance between the input matrix and the manifold of rank $$r$$r matrices in $$E$$E. To illustrate the applicability of this algorithm, we propose a Maple implementation and give experimental results for several applicative problems that can be modeled by Structured Low-Rank Approximation: univariate approximate GCDs (Sylvester matrices), low-rank matrix completion (coordinate spaces) and denoising procedures (Hankel matrices).", "venue": "Found. Comput. Math.", "authors": ["\u00c9ric  Schost", "Pierre-Jean  Spaenlehauer"], "year": 2016, "n_citations": 24}
{"id": 983727, "s2_id": "b2010ec12fb582bd331c31c6c38d2476b4573ced", "title": "On generalizing Descartes' rule of signs to hypersurfaces", "abstract": "We give partial generalizations of the classical Descartes\u2019 rule of signs to multivariate polynomials (with real exponents), in the sense that we provide upper bounds on the number of connected components of the complement of a hypersurface in the positive orthant. In particular, we give conditions based on the geometrical configuration of the exponents and the sign of the coefficients that guarantee that the number of connected components where the polynomial attains a negative value is at most one or two. Our results fully cover the cases where such an upper bound provided by the univariate Descartes\u2019 rule of signs is one. This approach opens a new route to generalize Descartes\u2019 rule of signs to the multivariate case, differing from previous works that aim at counting the number of positive solutions of a system of multivariate polynomial equations.", "venue": "ArXiv", "authors": ["Elisenda  Feliu", "M'at'e L. Telek"], "year": 2021, "n_citations": 0}
{"id": 985902, "s2_id": "ed9799782c31180379f293a23e575c6423223a18", "title": "A refined difference field theory for symbolic summation", "abstract": "In this article we present a refined summation theory based on Karr's difference field approach. The resulting algorithms find sum representations with optimal nested depth. For instance, the algorithms have been applied successively to evaluate Feynman integrals from Perturbative Quantum Field Theory.", "venue": "J. Symb. Comput.", "authors": ["Carsten  Schneider"], "year": 2008, "n_citations": 101}
{"id": 987560, "s2_id": "40bfd5387da731c94c4680423ab35c8a2a9029fe", "title": "Relating $p$-Adic eigenvalues and the local Smith normal form", "abstract": "Abstract Conditions are established under which the p -adic valuations of the invariant factors (diagonal entries of the Smith form) of an integer matrix are equal to the p -adic valuations of the eigenvalues. It is then shown that this correspondence is the typical case for \u201cmost\u201d matrices; density counts are given for when this property holds, as well as easy transformations to this typical case.", "venue": "ArXiv", "authors": ["Mustafa  Elsheikh", "Mark  Giesbrecht"], "year": 2014, "n_citations": 3}
{"id": 989403, "s2_id": "1e5cafc436736a70a13b8c1d88f1a5a85d6b1a38", "title": "Generalization of Gabidulin Codes over Fields of Rational Functions", "abstract": "We transpose the theory of rank metric and Gabidulin codes to the case of fields which are not finite fields. The Frobenius automorphism is replaced by any element of the Galois group of a cyclic algebraic extension of a base field. We use our framework to define Gabidulin codes over the field of rational functions using algebraic function fields with a cyclic Galois group. This gives a linear subspace of matrices whose coefficients are rational function, such that the rank of each of this matrix is lower bounded, where the rank is comprised in term of linear combination with rational functions. We provide two examples based on Kummer and Artin-Schreier extensions.The matrices that we obtain may be interpreted as generating matrices of convolutional codes.", "venue": "ArXiv", "authors": ["Daniel  Augot"], "year": 2014, "n_citations": 11}
{"id": 990123, "s2_id": "470c7d70ab36ce452d788cabec5197ec687bb26e", "title": "A Graph Theoretical Approach for Testing Binomiality of Reversible Chemical Reaction Networks", "abstract": "We study binomiality of the steady state ideals of chemical reaction networks. Considering rate constants as indeterminates, the concept of unconditional binomiality has been introduced and an algorithm based on linear algebra has been proposed in a recent work for reversible chemical reaction networks, which has a polynomial time complexity upper bound on the number of species and reactions. In this article, using a modified version of species-reaction graphs, we present an algorithm based on graph theory which performs by adding and deleting edges and changing the labels of the edges in order to test unconditional binomiality. We have implemented our graph theoretical algorithm as well as the linear algebra one in Maple and made experiments on biochemical models. Our experiments show that the performance of the graph theoretical approach is similar to or better than the linear algebra approach, while it is drastically faster than Gr\u00f6bner basis and quantifier elimination methods.", "venue": "2020 22nd International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)", "authors": ["Hamid  Rahkooy", "Cristian Vargas Montero"], "year": 2020, "n_citations": 1}
{"id": 992222, "s2_id": "c373358f0acc7dbc6abe2da0d3c4b3bffb434143", "title": "A Correctness Result for Synthesizing Plans With Loops in Stochastic Domains", "abstract": "Finite-state controllers (FSCs), such as plans with loops, are powerful and compact representations of action selection widely used in robotics, video games and logistics. There has been steady progress on synthesizing FSCs in deterministic environments, but the algorithmic machinery needed for lifting such techniques to stochastic environments is not yet fully understood. While the derivation of FSCs has received some attention in the context of discounted expected reward measures, they are often solved approximately and/or without correctness guarantees. In essence, that makes it difficult to analyze fundamental concerns such as: do all paths terminate, and do the majority of paths reach a goal state? \nIn this paper, we present new theoretical results on a generic technique for synthesizing FSCs in stochastic environments, allowing for highly granular specifications on termination and goal satisfaction.", "venue": "Int. J. Approx. Reason.", "authors": ["Laszlo  Treszkai", "Vaishak  Belle"], "year": 2020, "n_citations": 4}
{"id": 995837, "s2_id": "51835b7b9f018ae7653fac887a4a2a2f76e5e6ad", "title": "Fairness in Machine Learning with Tractable Models", "abstract": "Machine Learning techniques have become pervasive across a range of different applications, and are now widely used in areas as disparate as recidivism prediction, consumer credit-risk analysis and insurance pricing. The prevalence of machine learning techniques has raised concerns about the potential for learned algorithms to become biased against certain groups. Many definitions have been proposed in the literature, but the fundamental task of reasoning about probabilistic events is a challenging one, owing to the intractability of inference. \nThe focus of this paper is taking steps towards the application of tractable models to fairness. Tractable probabilistic models have emerged that guarantee that conditional marginal can be computed in time linear in the size of the model. In particular, we show that sum product networks (SPNs) enable an effective technique for determining the statistical relationships between protected attributes and other training variables. If a subset of these training variables are found by the SPN to be independent of the training attribute then they can be considered `safe' variables, from which we can train a classification model without concern that the resulting classifier will result in disparate outcomes for different demographic groups. \nOur initial experiments on the `German Credit' data set indicate that this processing technique significantly reduces disparate treatment of male and female credit applicants, with a small reduction in classification accuracy compared to state of the art. We will also motivate the concept of \"fairness through percentile equivalence\", a new definition predicated on the notion that individuals at the same percentile of their respective distributions should be treated equivalently, and this prevents unfair penalisation of those individuals who lie at the extremities of their respective distributions.", "venue": "Knowl. Based Syst.", "authors": ["Michael  Varley", "Vaishak  Belle"], "year": 2021, "n_citations": 1}
{"id": 996395, "s2_id": "cdaf4e3288beab73f8e2c69c885b48b7ccd31ef8", "title": "GPGCD, an iterative method for calculating approximate GCD, for multiple univariate polynomials", "abstract": "We present an extension of our GPGCD method, an iterative method for calculating approximate greatest common divisor (GCD) of univariate polynomials, to multiple polynomial inputs. For a given pair of polynomials and a degree, our algorithm finds a pair of polynomials which has a GCD of the given degree and whose coefficients are perturbed from those in the original inputs, making the perturbations as small as possible, along with the GCD. In our GPGCD method, the problem of approximate GCD is transferred to a constrained minimization problem, then solved with the so-called modified Newton method, which is a generalization of the gradient-projection method, by searching the solution iteratively. In this paper, we extend our method to accept more than two polynomials with the real coefficients as an input.", "venue": "ACCA", "authors": ["Akira  Terui"], "year": 2011, "n_citations": 2}
{"id": 1003688, "s2_id": "8db00cdb71637940a6142c97c1c210b506206818", "title": "Verification protocols with sub-linear communication for polynomial matrix operations", "abstract": "We design and analyze new protocols to verify the correctness of various computations on matrices over the ring F[x] of univariate polynomials over a field F. For the sake of efficiency, and because many of the properties we verify are specific to matrices over a principal ideal domain, we cannot simply rely on previously-developed linear algebra protocols for matrices over a field. Our protocols are interactive, often randomized, and feature a constant number of rounds of communication between the Prover and Verifier. We seek to minimize the communication cost so that the amount of data sent during the protocol is significantly smaller than the size of the result being verified, which can be useful when combining protocols or in some multi-party settings. The main tools we use are reductions to existing linear algebra verification protocols and a new protocol to verify that a given vector is in the F[x]-row space of a given matrix.", "venue": "J. Symb. Comput.", "authors": ["David  Lucas", "Vincent  Neiger", "Cl'ement  Pernet", "Daniel S. Roche", "Johan  Rosenkilde"], "year": 2021, "n_citations": 0}
{"id": 1006656, "s2_id": "29b0d2f6e4138fce65acd19eb11de46e9e0985ba", "title": "Matrix-F5 algorithms over finite-precision complete discrete valuation fields", "abstract": "Let (<i>f</i><sub>1</sub>,..., <i>f</i><sub><i>s</i></sub>) \u2208 Q<sub><i>p</i></sub> [<i>X</i><sub>1</sub>,..., <i>X</i><sub><i>n</i></sub>]<sup><i>s</i></sup> be a sequence of homogeneous polynomials with <i>p</i>-adic coefficients. Such system may happen, for example, in arithmetic geometry. Yet, since A<sub><i>p</i></sub> is not an effective field, classical algorithm does not apply.\n We provide a definition for an approximate Gr\u00f6bner basis with respect to a monomial order <i>w</i>. We design a strategy to compute such a basis, when precision is enough and under the assumption that the input sequence is regular and the ideals \u27e8<i>f</i><sub>1</sub>,..., <i>f</i><sub><i>i</i></sub>\u27e9 are weakly-<i>w</i>-ideals. The conjecture of Moreno-Socias states that for the grevlex ordering, such sequences are generic.\n Two variants of that strategy are available, depending on whether one lean more on precision or time-complexity. For the analysis of these algorithms, we study the loss of precision of the Gauss row-echelon algorithm, and apply it to an adapted Matrix-F5 algorithm. Numerical examples are provided.", "venue": "ISSAC", "authors": ["Tristan  Vaccon"], "year": 2014, "n_citations": 5}
{"id": 1007662, "s2_id": "f91ea4f06987a954109089c10182d385ead4e82f", "title": "Isomorphisms of Algebraic Number Fields", "abstract": "Let $\\mathbb{Q}(\\alpha)$ and $\\mathbb{Q}(\\beta)$ be algebraic number fields. We describe a new method to find (if they exist) all isomorphisms, $\\mathbb{Q}(\\beta) \\rightarrow \\mathbb{Q}(\\alpha)$. The algorithm is particularly efficient if the number of isomorphisms is one.", "venue": "ArXiv", "authors": ["Mark van Hoeij", "Vivek  Pal"], "year": 2010, "n_citations": 4}
{"id": 1010112, "s2_id": "21cc7270ad6e83fbaa759acd94bcb27dce3c49cc", "title": "On the p-adic stability of the FGLM algorithm", "abstract": "Nowadays, many strategies to solve polynomial systems use the computation of a Grobner basis for the graded reverse lexicographical ordering, followed by a change of ordering algorithm to obtain a Grobner basis for the lexicographical ordering. The change of ordering algorithm is crucial for these strategies. We study the p-adic stability of the main change of ordering algorithm, FGLM. We show that FGLM is stable and give explicit upper bound on the loss of precision occuring in its execution. The variant of FGLM designed to pass from the grevlex ordering to a Grobner basis in shape position is also stable. Our study relies on the application of Smith Normal Form computations for linear algebra.", "venue": "ArXiv", "authors": ["Gu\u00e9na\u00ebl  Renault", "Tristan  Vaccon"], "year": 2016, "n_citations": 2}
{"id": 1018398, "s2_id": "7dc888bfc04aa93d4fbae08e6db61deeda8d45de", "title": "Parallelizing Deadlock Resolution in Symbolic Synthesis of Distributed Programs", "abstract": "Abstract : Previous work has shown that there are two major complexity barriers in the synthesis of fault-tolerant distributed programs, namely generation of fault-span, the set of states reachable in the presence of faults, and, resolving deadlock states, where the program has no outgoing transitions. Although symbolic techniques can improve the performance of synthesis algorithms by orders of magnitude, efficient heuristics are still needed to overcome the aforementioned obstacles. Thus, motivated by the idea of partitioning the transition relation of distributed programs across multiple threads, in this paper, we introduce an efficient parallel \"shared memory\" algorithm for resolving deadlock states in symbolic synthesis of distributed programs. In spite of notorious resistance of symbolic algorithms for parallelization, experimental results show that our parallel algorithm exhibits superlinear performance improvement.", "venue": "PDMC", "authors": ["Fuad  Abujarad", "Borzoo  Bonakdarpour", "Sandeep S. Kulkarni"], "year": 2009, "n_citations": 12}
{"id": 1019524, "s2_id": "64910c47a30a07829b28873c305fbe179390bf0d", "title": "Bit complexity for multi-homogeneous polynomial system solving - Application to polynomial minimization", "abstract": "Multi-homogeneous polynomial systems arise in many applications. We provide bit complexity estimates for solving them which, up to a few extra other factors, are quadratic in the number of solutions and linear in the height of the input system under some genericity assumptions. The assumptions essentially imply that the Jacobian matrix of the system under study has maximal rank at the solution set and that this solution set if finite. The algorithm is probabilistic and a probability analysis is provided. Next, we apply these results to the problem of optimizing a linear map on the real trace of an algebraic set. Under some genericity assumptions, we provide bit complexity estimates for solving this polynomial minimization problem.", "venue": "J. Symb. Comput.", "authors": ["Mohab Safey El Din", "\u00c9ric  Schost"], "year": 2018, "n_citations": 17}
{"id": 1024655, "s2_id": "71a40b84e31bc939639472f521bb993e8c6599ac", "title": "Automated Synthesis of Tableau Calculi", "abstract": "This paper presents a method for synthesising sound and complete tableau calculi. Given a specification of the formal semantics of a logic, the method generates a set of tableau inference rules that can then be used to reason within the logic. The method guarantees that the generated rules form a calculus which is sound and constructively complete. If the logic can be shown to admit finite filtration with respect to a well-defined first-order semantics then adding a general blocking mechanism provides a terminating tableau calculus. The process of generating tableau rules can be completely automated and produces, together with the blocking mechanism, an automated procedure for generating tableau decision procedures. For illustration we show the workability of the approach for a description logic with transitive roles and propositional intuitionistic logic.", "venue": "Log. Methods Comput. Sci.", "authors": ["Renate A. Schmidt", "Dmitry  Tishkovsky"], "year": 2011, "n_citations": 31}
{"id": 1049833, "s2_id": "21d1b3a422406dc7ec5144bb4282dad8c37ae69a", "title": "Creative Telescoping on Multiple Sums", "abstract": "We discuss the strategies and difficulties of determining a recurrence which a certain polynomial (in the form of a symbolic multiple sum) satisfies. The polynomial comes from an analysis of integral estimators derived via quasi-Monte Carlo methods.", "venue": "Math. Comput. Sci.", "authors": ["Christoph  Koutschan", "Elaine  Wong"], "year": 2021, "n_citations": 2}
{"id": 1055040, "s2_id": "07462865cc4d16596bdadfbcb7055cb62111897b", "title": "Gradual Sub-lattice Reduction and a New Complexity for Factoring Polynomials", "abstract": "We present a lattice algorithm specifically designed for some classical applications of lattice reduction. The applications are for lattice bases with a generalized knapsack-type structure, where the target vectors are boundably short. For such applications, the complexity of the algorithm improves traditional lattice reduction by replacing some dependence on the bit-length of the input vectors by some dependence on the bound for the output vectors. If the bit-length of the target vectors is unrelated to the bit-length of the input, then our algorithm is only linear in the bit-length of the input entries, which is an improvement over the quadratic complexity floating-point LLL algorithms. To illustrate the usefulness of this algorithm we show that a direct application to factoring univariate polynomials over the integers leads to the first complexity bound improvement since 1984. A second application is algebraic number reconstruction, where a new complexity bound is obtained as well.", "venue": "LATIN", "authors": ["Mark van Hoeij", "Andrew  Novocin"], "year": 2010, "n_citations": 2}
{"id": 1058204, "s2_id": "2b7d8b23a8315876aebf92a7ad37301445a10546", "title": "Classification of Angle-Symmetric 6R Linkage", "abstract": "Abstract In this paper, we consider a special kind of overconstrained 6R closed linkage which we call angle-symmetric 6R linkage. These are linkages with the property that the rotation angles are equal for each of the three pairs of opposite joints. We give a classification of these linkages. It turns out that there are three types. First, we have the linkages with line symmetry. The second type is new. The third type is related to cubic motion polynomials.", "venue": "ArXiv", "authors": ["Zijia  Li", "Josef  Schicho"], "year": 2013, "n_citations": 20}
{"id": 1060628, "s2_id": "2982cb3ce69313e784c8e3f09f54d93e54cb682f", "title": "Real Root Finding for Equivariant Semi-algebraic Systems", "abstract": "Let R be a real closed field. We consider basic semi-algebraic sets defined by n -variate equations/inequalities of s symmetric polynomials and an equivariant family of polynomials, all of them of degree bounded by 2d < n. Such a semi-algebraic set is invariant by the action of the symmetric group. We show that such a set is either empty or it contains a point with at most 2d-1 distinct coordinates. Combining this geometric result with efficient algorithms for real root finding (based on the critical point method), one can decide the emptiness of basic semi-algebraic sets defined by s polynomials of degree d in time (sn)O(d). This improves the state-of-the-art which is exponential in n . When the variables x1, \u0142dots, xn are quantified and the coefficients of the input system depend on parameters y1, \u0142dots, yt, one also demonstrates that the corresponding one-block quantifier elimination problem can be solved in time (sn)O(dt).", "venue": "ISSAC", "authors": ["Cordian  Riener", "Mohab Safey El Din"], "year": 2018, "n_citations": 5}
{"id": 1064292, "s2_id": "e97c4432369d98a6399a40241452ebb757957b25", "title": "The natural algorithmic approach of mixed trigonometric-polynomial problems", "abstract": "AbstractThe aim of this paper is to present a new algorithm for proving mixed trigonometric-polynomial inequalities of the form \n \u2211i=1n\u03b1ixpicosqixsinrix>0$$\\sum_{i=1}^{n}\\alpha _{i}x^{p_{i}} \\cos ^{q_{i}} x\\sin ^{r_{i}} x>0 $$ by reducing them to polynomial inequalities. Finally, we show the great applicability of this algorithm and, as an example, we use it to analyze some new rational (Pad\u00e9) approximations of the function cos2x and to improve a class of inequalities by Yang. The results of our analysis could be implemented by means of an automated proof assistant, so our work is a contribution to the library of automatic support tools for proving various analytic inequalities.", "venue": "Journal of inequalities and applications", "authors": ["Tatjana  Lutovac", "Branko  Malesevic", "Cristinel  Mortici"], "year": 2017, "n_citations": 33}
{"id": 1068110, "s2_id": "97e8e9a1500bd866ed98de7fccbd83972d4febac", "title": "A SAT+CAS Approach to Finding Good Matrices: New Examples and Counterexamples", "abstract": "We enumerate all circulant good matrices with odd orders divisible by 3 up to order 70. As a consequence of this we find a previously overlooked set of good matrices of order 27 and a new set of good matrices of order 57. We also find that circulant good matrices do not exist in the orders 51, 63, and 69, thereby finding three new counterexamples to the conjecture that such matrices exist in all odd orders. Additionally, we prove a new relationship between the entries of good matrices and exploit this relationship in our enumeration algorithm. Our method applies the SAT+CAS paradigm of combining computer algebra functionality with modern SAT solvers to efficiently search large spaces which are specified by both algebraic and logical constraints.", "venue": "AAAI", "authors": ["Curtis  Bright", "Dragomir Z. Dokovic", "Ilias S. Kotsireas", "Vijay  Ganesh"], "year": 2019, "n_citations": 8}
{"id": 1070267, "s2_id": "90b0a90fbb88b8031b036b721ed516f8389301a4", "title": "Neuro-Symbolic Inductive Logic Programming with Logical Neural Networks", "abstract": "Recent work on neuro-symbolic inductive logic programming has led to promising approaches that can learn explanatory rules from noisy, real-world data. While some proposals approximate logical operators with differentiable operators from fuzzy or real-valued logic that are parameter-free thus diminishing their capacity to fit the data, other approaches are only loosely based on logic making it difficult to interpret the learned \u201crules\u201d. In this paper, we propose learning rules with the recently proposed logical neural networks (LNN). Compared to others, LNNs offer strong connection to classical Boolean logic thus allowing for precise interpretation of learned rules while harboring parameters that can be trained with gradient-based optimization to effectively fit the data. We extend LNNs to induce rules in first-order logic. Our experiments on standard benchmarking tasks confirm that LNN rules are highly interpretable and can achieve comparable or higher accuracy due to their flexible parameterization.", "venue": "ArXiv", "authors": ["Prithviraj  Sen", "Breno W. S. R. de Carvalho", "Ryan  Riegel", "Alexander  Gray"], "year": 2021, "n_citations": 1}
{"id": 1071001, "s2_id": "99f7e99bcf89c6b81ad32380031955378b8c3b9d", "title": "Bounding the radii of balls meeting every connected component of semi-algebraic sets", "abstract": "We prove an explicit bound on the radius of a ball centered at the origin which is guaranteed to contain all bounded connected components of a semi-algebraic set S?Rk defined by a weak sign condition involving s polynomials in ZX1,?,Xk] having degrees at most d, and whose coefficients have bitsizes at most ?. Our bound is an explicit function of s,d,k and ?, and does not contain any undetermined constants. We also prove a similar bound on the radius of a ball guaranteed to intersect every connected component of S (including the unbounded components). While asymptotic bounds of the form 2?dO(k) on these quantities were known before, some applications require bounds which are explicit and which hold for all values of s,d,k and ?. The bounds proved in this paper are of this nature.", "venue": "J. Symb. Comput.", "authors": ["Saugata  Basu", "Marie-Fran\u00e7oise  Roy"], "year": 2010, "n_citations": 22}
{"id": 1071527, "s2_id": "a82af16a6a941229a949ad7f6339ce75af59cbea", "title": "An Explicit Solution to Post's Problem over the Reals", "abstract": "In the BSS model of real number computations we prove a concrete and explicit semi-decidable language to be undecidable yet not reducible from (and thus strictly easier than) the real Halting Language. This solution to Post's Problem over the reals significantly differs from its classical, discrete variant where advanced diagonalization techniques are only known to yield the existence of such intermediate Turing degrees. \n \nThen we strengthen the above result and show as well the existence of an uncountable number of incomparable semi-decidable Turing degrees below the real Halting problem in the BSS model. Again, our proof will give concrete such problems representing these different degrees.", "venue": "FCT", "authors": ["Klaus  Meer", "Martin  Ziegler"], "year": 2005, "n_citations": 3}
{"id": 1072577, "s2_id": "6771613a74280bda918bbe177d1abaac9f67d769", "title": "Criteria for the numerical constant recognition", "abstract": "The need for recognition of numerical (decimal, floating-point) constants in terms of elementary functions emerges in many areas of experimental mathematics, numerical analysis, computer algebra systems, model building, approximation and data compression. However, existing solutions are plagued by lack of any criteria distinguishing between random formula, matching literally decimal expansion (i.e. approximation) and probable \"exact\" (or at least probable) expression match in the sense of Occam's razor. In particular, convincing STOP criteria for search were never developed. In article, such a criteria, working in statistical sense, are provided. Recognition process can be viewed as (1) enumeration of all formulas in order of increasing Kolmogorov complexity (2) random process with appropriate statistical distribution (3) compression of a decimal string. All three approaches are remarkably consistent, and provide essentially the same limit for practical depth of search. Tested unique formulas count must not exceed 1/sigma, where sigma is relative numerical error of the target constant. Beyond that, further search is pointless, because, in the view of approach (1), number of equivalent expressions within error bounds grows exponentially; in view of (2), probability of random match approaches 1; in view of (3) compression ratio much smaller than 1.", "venue": "ArXiv", "authors": ["Andrzej  Odrzywolek"], "year": 2020, "n_citations": 0}
{"id": 1074972, "s2_id": "a8b5b79b58eb99fd2df7d27c11793deefeb4dec7", "title": "Chebyshev expansions for solutions of linear differential equations", "abstract": "A Chebyshev expansion is a series in the basis of Chebyshev polynomials of the first kind. When such a series solves a linear differential equation, its coefficients satisfy a linear recurrence equation. We interpret this equation as the numerator of a fraction of linear recurrence operators. This interpretation lets us give a simple view of previous algorithms, analyze their complexity, and design a faster one for large orders.", "venue": "ISSAC '09", "authors": ["Alexandre  Benoit", "Bruno  Salvy"], "year": 2009, "n_citations": 13}
{"id": 1077151, "s2_id": "b7abc8529e7a3098357f85b1764a5d6bf1004b6a", "title": "Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs - A MAPLE Package", "abstract": "There exist several methods for computing exact solutions of algebraic differential equations. Most of the methods, however, do not ensure existence and uniqueness of the solutions and might fail after several steps, or are restricted to linear equations. The authors have presented in previous works a method to overcome this problem for autonomous first order algebraic ordinary differential equations and formal Puiseux series solutions and algebraic solutions. In the first case, all solutions can uniquely be represented by a sufficiently large truncation and in the latter case by its minimal polynomial. The main contribution of this paper is the implementation, in a MAPLE package named FirstOrderSolve, of the algorithmic ideas presented therein. More precisely, all formal Puiseux series and algebraic solutions, including the generic and singular solutions, are computed and described uniquely. The computation strategy is to reduce the given differential equation to a simpler one by using local parametrizations and the already known degree bounds. keywords Maple, Symbolic computation, Algebraic differential equation, Formal Puiseux series solution, Algebraic solution.", "venue": "MC", "authors": ["Fran\u00e7ois  Boulier", "Jose  Cano", "Sebastian  Falkensteiner", "J. Rafael Sendra"], "year": 2020, "n_citations": 0}
{"id": 1081951, "s2_id": "78cbd8162307831dc5a35b157f8376d9622aa730", "title": "Synthesizing Switching Controllers for Hybrid Systems by Continuous Invariant Generation", "abstract": "We extend a template-based approach for synthesizing switching controllers for semi-algebraic hybrid systems, in which all expressions are polynomials. This is achieved by combining a QE (quantifier elimination)-based method for generating continuous invariants with a qualitative approach for predefining templates. Our synthesis method is relatively complete with regard to a given family of predefined templates. Using qualitative analysis, we discuss heuristics to reduce the numbers of parameters appearing in the templates. To avoid too much human interaction in choosing templates as well as the high computational complexity caused by QE, we further investigate applications of the SOS (sum-of-squares) relaxation approach and the template polyhedra approach in continuous invariant generation, which are both well supported by efficient numerical solvers.", "venue": "ArXiv", "authors": ["Deepak  Kapur", "Naijun  Zhan", "Hengjun  Zhao"], "year": 2013, "n_citations": 3}
{"id": 1082417, "s2_id": "e11577ed99c8257cec5db6fdd69efbfea083ee74", "title": "Stable polynomial division and essential normality of graded Hilbert modules", "abstract": "The purpose of this paper is to initiate a new attack on Arveson's resistant conjecture, that all graded submodules of the $d$-shift Hilbert module $H^2$ are essentially normal. We introduce the stable division property for modules (and ideals): a normed module $M$ over the ring of polynomials in $d$ variables has the stable division property if it has a generating set $\\{f_1, ..., f_k\\}$ such that every $h \\in M$ can be written as $h = \\sum_i a_i f_i$ for some polynomials $a_i$ such that $\\sum \\|a_i f_i\\| \\leq C\\|h\\|$. We show that certain classes of modules have this property, and that the stable decomposition $h = \\sum a_i f_i$ may be obtained by carefully applying techniques from computational algebra. We show that when the algebra of polynomials in $d$ variables is given the natural $\\ell^1$ norm, then every ideal is linearly equivalent to an ideal that has the stable division property. We then show that a module $M$ that has the stable division property (with respect to the appropriate norm) is $p$-essentially normal for $p > \\dim(M)$, as conjectured by Douglas. This result is used to give a new, unified proof that certain classes of graded submodules are essentially normal. Finally, we reduce the problem of determining whether all graded submodules of the $d$-shift Hilbert module are essentially normal, to the problem of determining whether all ideals generated by quadratic scalar valued polynomials are essentially normal.", "venue": "J. Lond. Math. Soc.", "authors": ["Orr  Shalit"], "year": 2011, "n_citations": 32}
{"id": 1088026, "s2_id": "e1c886c2211fd6a40e5eb42fd6b54e42c4a37735", "title": "Efficient Recognition of Graph Languages", "abstract": "Graph transformation is the rule-based modification of graphs, and is a discipline dating back to the 1970s. In general, to match the left-hand graph of a fixed rule within a host graph requires polynomial time, but to improve matching performance, Dorr proposed to equip rules and host graphs with distinguished root nodes. This model was implemented by Plump and Bak, but unfortunately, such rules are not invertible. We address this problem by defining rootedness using a partial function into a two-point set rather than pointing graphs with root nodes, meaning derivations are natural double pushouts. Moreover, we give a sufficient condition on rules to give constant time rule application on graphs of bounded degree, and that, the graph class of trees can be recognised in linear time, given an input graph of bounded degree. Finally, we define a new notion of confluence up to garbage and non-garbage critical pairs, showing it is sufficient to require strong joinability of only the non-garbage critical pairs to establish confluence up to garbage. Finally, this new result, presented for conventional graph transformation systems, can be lifted to our rooted setting by encoding node labels and rootedness as looped edges.", "venue": "ArXiv", "authors": ["Graham  Campbell", "Detlef  Plump"], "year": 2019, "n_citations": 3}
{"id": 1093751, "s2_id": "181a7943ff402b4266cff3a7c26df28efd380714", "title": "Efficient dot product over word-size finite fields", "abstract": "We want to achieve efficiency for the exact computation of the dot product of two vectors over word-size finite fields. We therefore compare the practical behaviors of a wide range of implementation techniques using different representations. The techniques used include oating point representations, discrete logarithms, tabulations, Montgomery reduction, delayed modulus.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas"], "year": 2004, "n_citations": 6}
{"id": 1095757, "s2_id": "358f32e9a5abe002c891c654cc381062689fd5db", "title": "Dual bases for noncommutative symmetric and quasi-symmetric functions via monoidal factorization", "abstract": "We propose effective constructions of dual bases for the noncommutative symmetric and quasi-symmetric functions. To this end, we use an effective variation of Schutzenberger's factorization adapted to the diagonal pairing between a graded space and its dual.", "venue": "J. Symb. Comput.", "authors": ["Van Chi\u00ean Bui", "G\u00e9rard  Duchamp", "Vincel Hoang Ngoc Minh", "Ladji  Kane", "Christophe  Tollu"], "year": 2016, "n_citations": 8}
{"id": 1103227, "s2_id": "877464d6003bc221d14d5a967a09e5d3e1af19cc", "title": "Projective isomorphisms between rational surfaces", "abstract": "We present a method for computing projective isomorphisms between rational surfaces that are given in terms of their parametrizations. The main idea is to reduce the computation of such projective isomorphisms to five base cases by modifying the parametric maps such that the components of the resulting maps have lower degree. Our method can be used to compute affine, Euclidean and Mobius isomorphisms between surfaces.", "venue": "Journal of Algebra", "authors": ["Bert  J\u00fcttler", "Niels  Lubbes", "Josef  Schicho"], "year": 2021, "n_citations": 0}
{"id": 1104328, "s2_id": "4e48176d9330dc7a78299d9ae3d3368342cdf97e", "title": "Algorithmic Verification of Linearizability for Ordinary Differential Equations", "abstract": "For a nonlinear ordinary differential equation solved with respect to the highest order derivative and rational in the other derivatives and in the independent variable, we devise two algorithms to check if the equation can be reduced to a linear one by a point transformation of the dependent and independent variables. The first algorithm is based on a construction of the Lie point symmetry algebra and on the computation of its derived algebra. The second algorithm exploits the differential Thomas decomposition and allows not only to test the linearizability, but also to generate a system of nonlinear partial differential equations that determines the point transformation and the coefficients of the linearized equation. The implementation of both algorithms is discussed and their application is illustrated using several examples.", "venue": "ISSAC", "authors": ["Dmitry A. Lyakhov", "Vladimir P. Gerdt", "Dominik Ludewig Michels"], "year": 2017, "n_citations": 13}
{"id": 1104377, "s2_id": "4c77ea9c98e214062b7701956bf1000ff7fddba2", "title": "Formal solutions of completely integrable Pfaffian systems with normal crossings", "abstract": "In this paper, we present an algorithm for computing a fundamental matrix of formal solutions of completely integrable Pfaffian systems with normal crossings in several variables. This algorithm is a generalization of a method developed for the bivariate case based on a combination of several reduction techniques and is partially2 implemented in the computer algebra system Maple.", "venue": "J. Symb. Comput.", "authors": ["Moulay A. Barkatou", "Maximilian  Jaroschek", "Suzy S. Maddah"], "year": 2017, "n_citations": 0}
{"id": 1111369, "s2_id": "e2ef027943196575edc96fd93cbc24a7cd27f350", "title": "FORM version 4.0", "abstract": "Abstract We present version 4.0 of the symbolic manipulation system Form . The most important new features are manipulation of rational polynomials and the factorization of expressions. Many other new functions and commands are also added; some of them are very general, while others are designed for building specific high level packages, such as one for Grobner bases. New is also the checkpoint facility, that allows for periodic backups during long calculations. Finally, Form 4.0 has become available as open source under the GNU General Public License version 3. Program summary Program title: FORM. Catalogue identifier: AEOT_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEOT_v1_0.html Program obtainable from: CPC Program Library, Queen\u2019s University, Belfast, N. Ireland Licensing provisions: GNU General Public License, version 3 No. of lines in distributed program, including test data, etc.: 151599 No. of bytes in distributed program, including test data, etc.: 1\u00a0078\u00a0748 Distribution format: tar.gz Programming language: The FORM language. FORM itself is programmed in a mixture of C and C++. Computer: All. Operating system: UNIX, LINUX, Mac OS, Windows. Classification: 5. Nature of problem: FORM defines a symbolic manipulation language in which the emphasis lies on fast processing of very large formulas. It has been used successfully for many calculations in Quantum Field Theory and mathematics. In speed and size of formulas that can be handled it outperforms other systems typically by an order of magnitude. Special in this version: The version 4.0 contains many new features. Most important are factorization and rational arithmetic. The program has also become open source under the GPL. The code in CPC is for reference. You are encouraged to upload the most recent sources from www.nikhef.nl/form/formcvs.php because of frequent bug fixes. Solution method: See \u201cNature of Problem\u201d, above. Additional comments: NOTE: The code in CPC is for reference. You are encouraged to upload the most recent sources from www.nikhef.nl/form/formcvs.php because of frequent bug fixes.", "venue": "Comput. Phys. Commun.", "authors": ["Jan  Kuipers", "Takahiro  Ueda", "J. A. M. Vermaseren", "J.  Vollinga"], "year": 2013, "n_citations": 300}
{"id": 1115931, "s2_id": "8b729dd290e029b4a4d26511e8892d084da62a6b", "title": "Craig Interpolation for Quantifier-Free Presburger Arithmetic", "abstract": "Craig interpolation has become a versatile algorithmic tool for improving software verification. Interpolants can, for instance, accelerate the convergence of fixpoint computations for infinite-state systems. They also help improve the refinement of iteratively computed lazy abstractions. Efficient interpolation procedures have been presented only for a few theories. In this paper, we introduce a complete interpolation method for the full range of quantifier-free Presburger arithmetic formulas. We propose a novel convex variable projection for integer inequalities and a technique to combine them with equalities. The derivation of the interpolant has complexity low-degree polynomial in the size of the refutation proof and is typically fast in practice.", "venue": "ArXiv", "authors": ["Angelo  Brillout", "Daniel  Kroening", "Thomas  Wahl"], "year": 2008, "n_citations": 3}
{"id": 1118933, "s2_id": "98bd44bdb7203ffbb0fc982ea29450ddf4aade98", "title": "Implementation and Evaluation of a Multivariate Abstraction-Based, Interval-Based Dynamic Time-Warping Method as a Similarity Measure for Longitudinal Medical Records", "abstract": "OBJECTIVES\nA common prerequisite for tasks such as classification, prediction, clustering and retrieval of longitudinal medical records is a clinically meaningful similarity measure that considers both [multiple] variable (concept) values and their time. Currently, most similarity measures focus on raw, time-stamped data as these are stored in a medical record. However, clinicians think in terms of clinically meaningful temporal abstractions, such as \"decreasing renal functions\", enabling them to ignore minor time and value variations and focus on similarities among the clinical trajectories of different patients. Our objective was to define an abstraction- and interval-based methodology for matching longitudinal, multivariate medical records, and rigorously assess its value, versus the option of using just the raw, time-stamped data.\n\n\nMETHODS\nWe have developed a new methodology for determination of the relative distance between a pair of longitudinal records, by extending the known dynamic time warping (DTW) method into an interval-based dynamic time warping (iDTW) methodology. The iDTW methodology includes (A): A three-steps interval-based representation (iRep) method: [1] abstracting the raw, time-stamped data of the longitudinal records into clinically meaningful interval-based abstractions, using a domain-specific knowledge base, [2] scoping the period of comparison of the records, [3] creating from the intervals a symbolic time series, by partitioning them into a predetermined temporal granularity; (B) An interval-based matching (iMatch) method to match each relevant pair of multivariate longitudinal records, each represented as multiple series of short symbolic intervals in the determined temporal granularity, using a modified DTW version.\n\n\nEVALUATION\nThree classification or prediction tasks were defined: (1) classifying 161 records of oncology patients as having had autologous versus allogenic bone-marrow transplantation; (2) classifying the longitudinal records of 125 hepatitis patients as having B or C hepatitis; and (3) predicting micro- or macro-albuminuria in the second year, for 151 diabetes patients who were followed for five years. The raw, time-stamped, multivariate data within each medical record, for one, two, or three concepts out of four or five concepts judged as relevant in each medical domain, were abstracted into clinically meaningful intervals using the Knowledge-Based Temporal-Abstraction method, using previously acquired knowledge. We focused on two temporal-abstraction types: (1) State abstractions, which discretize a concept's raw value into a predetermined range (e.g., LOW or HIGH Hemoglobin); and (2) Gradient abstractions, which indicate the trend of the concept's value (e.g., INCREASING, DECREASING Hemoglobin value). We created all of the combinations of either uni-dimensional (State or Gradient) or multi-dimensional (State and Gradient) abstractions, of all of the concepts used. Classification of a record was determined by using a majority of the k-Nearest-Neighbors (KNN) of the given record, k ranging over the odd numbers (to break ties) from 1 to N, N being the size of the training set. We have experimented with all possible configurations of the parameters that our method uses. Overall, a total of 75,936 experiments were performed: 33,600 in the Oncology domain, 28,800 in the Hepatitis domain, and 13,536 in the Diabetes domain. Each experiment involved the performance of a 10-fold Cross Validation to compute the mean performance of a particular iDTW method-configuration set of settings, for a specific subset of one, two, or three concepts out of all of the domain-specific concepts relevant to the classification or prediction task on which the experiment focuses. We measured for each such experimental combination the Area Under the Curve (AUC) and the optimal Specificity/Sensitivity ratio using Youden's Index. We then aggregated the experiments by the types of unidimensional or multidimensional abstractions used in them (including the use of only raw concepts as a special case); for example, two state abstractions of different concepts, and one gradient abstraction of a third concept. We compared the mean AUC when using each such feature representation, or combination of abstractions, across all possible method-setting configurations, to the mean AUC when using as a feature representation, for the same task, only raw concepts, also across all possible method-setting configurations. Finally, we applied a paired t-test, to determine whether the mean difference between the accuracy of each temporal-abstraction representation, across all concept and configuration combinations, and the respective raw-concept combinations, across all concept subset and configuration combinations, is significant (P<0.05).\n\n\nRESULTS\nThe mean performance of the classification and prediction tasks when using, as a feature representation, the various temporal-abstraction combinations, was significantly higher than that performance when using only raw data. Furthermore, in each domain and task, there existed at least one representation using interval-based abstractions whose use led, on average (over all concept subset combinations and method configurations) to a significantly better performance than the use of only subsets of the raw time-stamped data. In seven of nine combinations of domain type (out of three) and number of concepts used (one, two, or three), the variance of the AUCs (for all representations and configurations) was considerably higher across all raw-concept subsets, compared to all abstract combinations. Increasing the number of features used by the matching task enhanced performance. Using multi-dimensional abstractions of the same concept further enhanced the performance. When using only raw data, increasing the number of neighbors monotonically increased the mean performance (over all concept combinations and method configurations) until reaching an optimal saddle-point aroundN; when using abstractions, however, optimal mean performance was often reached after matching only five nearest neighbors.\n\n\nCONCLUSIONS\nUsing multivariate and multidimensional interval-based, abstraction-based similarity measures is feasible, and consistently and significantly improved the mean classification and prediction performance in time-oriented domains, using DTW-inspired methods, compared to the use of only raw, time-stamped data. It also made the KNN classification more effective. Nevertheless, although the mean performance for the abstract representations was higher than the mean performance when using only raw-data concepts, the actual optimal classification performance in each domain and task depends on the choice of the specific raw or abstract concepts used as features.", "venue": "J. Biomed. Informatics", "authors": ["Yuval  Shahar", "Matan  Lion"], "year": 2021, "n_citations": 0}
{"id": 1119823, "s2_id": "02d0cd00dbc4477e0f24cddf9994f26659b3bae6", "title": "The Complexity of Computing the Hilbert Polynomial of Smooth Equidimensional Complex Projective Varieties", "abstract": "We continue the study of counting complexity begun in [13], [14], [15] by proving upper and lower bounds on the complexity of computing the Hilbert polynomial of a homogeneous ideal. We show that the problem of computing the Hilbert polynomial of a smooth equidimensional complex projective variety can be reduced in polynomial time to the problem of counting the number of complex common zeros of a finite set of multivariate polynomials. The reduction is based on a new formula for the coefficients of the Hilbert polynomial of a smooth variety. Moreover, we prove that the more general problem of computing the Hilbert polynomial of a homogeneous ideal is polynomial space hard. This implies polynomial space lower bounds for both the problems of computing the rank and the Euler characteristic of cohomology groups of coherent sheaves on projective space, improving the #P-lower bound in Bach [1].", "venue": "Found. Comput. Math.", "authors": ["Peter  B\u00fcrgisser", "Martin  Lotz"], "year": 2007, "n_citations": 17}
{"id": 1120764, "s2_id": "322195c4b62b213f1cfd2a6314c1afc1f5acb12b", "title": "Faster Algorithms for Multivariate Interpolation With Multiplicities and Simultaneous Polynomial Approximations", "abstract": "The interpolation step in the Guruswami-Sudan algorithm is a bivariate interpolation problem with multiplicities commonly solved in the literature using either structured linear algebra or basis reduction of polynomial lattices. This problem has been extended to three or more variables; for this generalization, all fast algorithms proposed so far rely on the lattice approach. In this paper, we reduce this multivariate interpolation problem to a problem of simultaneous polynomial approximations, which we solve using fast structured linear algebra. This improves the best known complexity bounds for the interpolation step of the list-decoding of Reed-Solomon codes, Parvaresh-Vardy codes, and folded Reed-Solomon codes. In particular, for Reed-Solomon list-decoding with re-encoding, our approach has complexity O~(\u2113\u03c9-1m2(n - k)), where \u2113, m, n, and k are the list size, the multiplicity, the number of sample points, and the dimension of the code, and \u03c9 is the exponent of linear algebra; this accelerates the previously fastest known algorithm by a factor of \u2113/m.", "venue": "IEEE Transactions on Information Theory", "authors": ["Muhammad F. I. Chowdhury", "Claude-Pierre  Jeannerod", "Vincent  Neiger", "\u00c9ric  Schost", "Gilles  Villard"], "year": 2015, "n_citations": 28}
{"id": 1121952, "s2_id": "69640dedbaaa23bcb6f01d421cd185c67927b11c", "title": "Fast Decoding of Codes in the Rank, Subspace, and Sum-Rank Metric", "abstract": "We speed up existing decoding algorithms for three code classes in different metrics: interleaved Gabidulin codes in the rank metric, lifted interleaved Gabidulin codes in the subspace metric, and linearized Reed\u2013Solomon codes in the sum-rank metric. The speed-ups are achieved by new algorithms that reduce the cores of the underlying computational problems of the decoders to one common tool: computing left and right approximant bases of matrices over skew polynomial rings. To accomplish this, we describe a skew-analogue of the existing PM-Basis algorithm for matrices over ordinary polynomials. This captures the bulk of the work in multiplication of skew polynomials, and the complexity benefit comes from existing algorithms performing this faster than in classical quadratic complexity. The new algorithms for the various decoding-related computational problems are interesting in their own and have further applications, in particular parts of decoders of several other codes and foundational problems related to the remainder-evaluation of skew polynomials.", "venue": "IEEE Transactions on Information Theory", "authors": ["Hannes  Bartz", "Thomas  Jerkovits", "Sven  Puchinger", "Johan  Rosenkilde"], "year": 2021, "n_citations": 6}
{"id": 1124671, "s2_id": "fc91d67b5df1116ace433871b2548f05553e56f1", "title": "Factorization of linear partial differential operators and Darboux integrability of nonlinear PDEs", "abstract": "Using a new definition of generalized divisors we prove that the lattice of such divisors for a given linear partial differential operator is modular and obtain analogues of the well-known theorems of the Loewy-Ore theory of factorization of linear ordinary differential operators. Possible applications to factorized Gr&ouml;bner bases computations in the commutative and non-commutative cases are discussed, an application to finding criterions of Darboux integrability of nonlinear PDEs is given.", "venue": "SIGS", "authors": ["Serguei P. Tsarev"], "year": 1998, "n_citations": 23}
{"id": 1132913, "s2_id": "b64896c1a020079a6fe33b60dba1ed626f001f6d", "title": "Efficient q-integer linear decomposition of multivariate polynomials", "abstract": "Abstract We present two new algorithms for the computation of the q-integer linear decomposition of a multivariate polynomial. Such a decomposition is essential for the treatment of q-hypergeometric symbolic summation via creative telescoping and for describing the q-counterpart of Ore-Sato theory. Both of our algorithms require only basic integer and polynomial arithmetic and work for any unique factorization domain containing the ring of integers. Complete complexity analyses are conducted for both our algorithms and two previous algorithms in the case of multivariate integer polynomials, showing that our algorithms have better theoretical performances. A Maple implementation is also included which suggests that our algorithms are also much faster in practice than previous algorithms.", "venue": "J. Symb. Comput.", "authors": ["Mark  Giesbrecht", "Hui  Huang", "George  Labahn", "Eugene V. Zima"], "year": 2021, "n_citations": 1}
{"id": 1135906, "s2_id": "4f579d3cf9f5eeface90570a1ea913c1ac12a71f", "title": "Towards a noncommutative Picard-Vessiot theory", "abstract": "A Chen generating series, along a path and with respect to $m$ differential forms, is a noncommutative series on $m$ letters and with coefficients which are holomorphic functions over a simply connected manifold in other words a series with variable (holomorphic) coefficients. Such a series satisfies a first order noncommutative differential equation which is considered, by some authors, as the universal differential equation, i.e., universality can be seen by replacing each letter by constant matrices (resp. analytic vector fields) and then solving a system of linear (resp. nonlinear) differential equations. Via rational series, on noncommutative indeterminates and with coefficients in rings, and their non-trivial combinatorial Hopf algebras, we give the first step of a noncommutative Picard-Vessiot theory and we illustrate it with the case of linear differential equations with singular regular singularities thanks to the universal equation previously mentioned.", "venue": "ArXiv", "authors": ["G.  Duchamp", "Viincel Hoang Ngoc Minh", "Vu Nguyen Dinh"], "year": 2020, "n_citations": 0}
{"id": 1138941, "s2_id": "dcb309be34da244f2f94f7ab7453e727507757a3", "title": "Computations with one and two real algebraic numbers", "abstract": "We present algorithmic and complexity results concerning computations with one and two real algebraic numbers, as well as real solving of univariate polynomials and bivariate polynomial systems with integer coefficients using Sturm-Habicht sequences. \nOur main results, in the univariate case, concern the problems of real root isolation (Th. 19) and simultaneous inequalities (Cor.26) and in the bivariate, the problems of system real solving (Th.42), sign evaluation (Th. 37) and simultaneous inequalities (Cor. 43).", "venue": "ArXiv", "authors": ["Ioannis Z. Emiris", "Elias P. Tsigaridas"], "year": 2005, "n_citations": 2}
{"id": 1147776, "s2_id": "fc2267731df13776726567fae0bff6c4ea2b6347", "title": "Computing minimal interpolation bases", "abstract": "We consider the problem of computing univariate polynomial matrices over a field that represent minimal solution bases for a general interpolation problem, some forms of which are the vector M-Pad\\'e approximation problem in [Van Barel and Bultheel, Numerical Algorithms 3, 1992] and the rational interpolation problem in [Beckermann and Labahn, SIAM J. Matrix Anal. Appl. 22, 2000]. Particular instances of this problem include the bivariate interpolation steps of Guruswami-Sudan hard-decision and K\\\"otter-Vardy soft-decision decodings of Reed-Solomon codes, the multivariate interpolation step of list-decoding of folded Reed-Solomon codes, and Hermite-Pad\\'e approximation. \nIn the mentioned references, the problem is solved using iterative algorithms based on recurrence relations. Here, we discuss a fast, divide-and-conquer version of this recurrence, taking advantage of fast matrix computations over the scalars and over the polynomials. This new algorithm is deterministic, and for computing shifted minimal bases of relations between $m$ vectors of size $\\sigma$ it uses $O~( m^{\\omega-1} (\\sigma + |s|) )$ field operations, where $\\omega$ is the exponent of matrix multiplication, and $|s|$ is the sum of the entries of the input shift $s$, with $\\min(s) = 0$. This complexity bound improves in particular on earlier algorithms in the case of bivariate interpolation for soft decoding, while matching fastest existing algorithms for simultaneous Hermite-Pad\\'e approximation.", "venue": "J. Symb. Comput.", "authors": ["Claude-Pierre  Jeannerod", "Vincent  Neiger", "\u00c9ric  Schost", "Gilles  Villard"], "year": 2017, "n_citations": 23}
{"id": 1148755, "s2_id": "48a01433913f42e44f7c53bbd6e9757aef8a84c9", "title": "A new algorithm for proving global asymptotic stability of rational difference equations", "abstract": "Global asymptotic stability (GAS) of rational difference equations is an area of research that has been well studied. In contrast to the many current methods for proving GAS, we propose an algorithmic approach. The algorithm we summarize here employs the idea of contractions. Given a particular rational difference equation, defined by a function , we attempt to find a K value for which shrinks distances to the difference equation's equilibrium point. We state some general results that our algorithm has been able to prove, and also mention the implementation of our algorithm using Maple.", "venue": "ArXiv", "authors": ["Emilie  Hogan", "Doron  Zeilberger"], "year": 2011, "n_citations": 2}
{"id": 1148766, "s2_id": "92c3b1fbc5d5479b03d179e9a059f703bb99c964", "title": "On the computation of the straight lines contained in a rational surface", "abstract": "In this paper we present an algorithm to compute the (real and complex) straight lines contained in a rational surface, defined by a rational parameterization. The algorithm relies on the well-known theorem of Differential Geometry that characterizes real straight lines contained in a surface as curves that are simultaneously asymptotic lines, and geodesics. We also report on an implementation carried out in Maple 18, and we compare the behavior of our algorithm with two brute-force approaches.", "venue": "ArXiv", "authors": ["Juan Gerardo Alc\u00e1zar", "Jorge  Caravantes"], "year": 2016, "n_citations": 2}
{"id": 1149045, "s2_id": "305bbe1a9a61f134fe433d82d5661c1e6b302cbd", "title": "Effective radical parametrization of trigonal curves", "abstract": "Let C be a non-hyperelliptic algebraic curve. It is known that its canonical image is the intersection of the quadrics that contain it, except when C is trigonal (that is, it has a linear system of degree 3 and dimension 1) or isomorphic to a plane quintic (genus 6). In this context, we present a method to decide whether a given algebraic curve is trigonal, and in the affirmative case to compute a map from C to the projective line whose fibers cut out the linear system. This can be taken further: the roots of univariate polynomials of degree \u2264 4 can be written in terms of radicals. Therefore, curves which can be expressed as f(x,y) = 0 where one of the variables occurs with degree \u2264 4 can also be parametrized by radicals. The minimum degree which can be obtained by is called the gonality of the curve; hyperelliptic curves are precisely those of gonality two. It is thus interesting to characterize the curves of gonality three (or trigonal) and four, and further to produce algorithms that detect this situation and can even compute a radical parametrization. The description of such an algorithm for trigonal curves is the purpose of this article. In this article, the coefficient field always has characteristic zero, and it will generally be assumed to be algebraically closed although we will point out the necessary modifications for the non-algebraically-closed case when they arise. Our algorithm is based on the Lie algebra method introduced in (dGHPS06) (see also (dGPS09)). We use Lie algebra computations (which mostly amount to linear algebra) to decide if a certain algebraic variety associated to the input curve is", "venue": "ArXiv", "authors": ["Josef  Schicho", "David  Sevilla"], "year": 2011, "n_citations": 7}
{"id": 1149171, "s2_id": "2dabdcf994577ba49ddb7e74be21c53c6484088a", "title": "Faster Modular Composition", "abstract": "A new Las Vegas algorithm is presented for the composition of two polynomials modulo a third one, over an arbitrary field. When the degrees of these polynomials are bounded by $n$, the algorithm uses $O(n^{1.43})$ field operations, breaking through the $3/2$ barrier in the exponent for the first time. The previous fastest algebraic algorithms, due to Brent and Kung in 1978, require $O(n^{1.63})$ field operations in general, and ${n^{3/2+o(1)}}$ field operations in the particular case of power series over a field of large enough characteristic. If using cubic-time matrix multiplication, the new algorithm runs in ${n^{5/3+o(1)}}$ operations, while previous ones run in $O(n^2)$ operations. Our approach relies on the computation of a matrix of algebraic relations that is typically of small size. Randomization is used to reduce arbitrary input to this favorable situation.", "venue": "ArXiv", "authors": ["Vincent  Neiger", "Bruno  Salvy", "\u00c9ric  Schost", "Gilles  Villard"], "year": 2021, "n_citations": 1}
{"id": 1152595, "s2_id": "3fd0526188bda49bfbb5380ac13f43644b7796ec", "title": "Normal and Triangular Determinantal Representations of Multivariate Polynomials", "abstract": "In this paper we give a new and simple algorithm to put any multivariate polynomial into a normal determinant form in which each entry has the form , and in each column the same variable appears. We also apply the algorithm to obtain a triangular determinant representation, a reduced determinant representation, and a uniform determinant representation of any multivariable polynomial. The algorithm could be useful for obtaining representations of dimensions smaller than those available up to now to solve numerical problems.", "venue": "JP Journal of Algebra, Number Theory and Applications", "authors": ["Massimo  Salvi"], "year": 2018, "n_citations": 0}
{"id": 1159555, "s2_id": "f70e07b11c07576cb245894ff632ff63dabd473a", "title": "On the Complexity of Quadratization for Polynomial Differential Equations", "abstract": "Chemical reaction networks (CRNs) are a standard formalism used in chemistry and biology to reason about the dynamics of molecular interaction networks. In their interpretation by ordinary differential equations, CRNs provide a Turing-complete model of analog computattion, in the sense that any computable function over the reals can be computed by a finite number of molecular species with a continuous CRN which approximates the result of that function in one of its components in arbitrary precision. The proof of that result is based on a previous result of Bournez et al. on the Turing-completeness of polyno-mial ordinary differential equations with polynomial initial conditions (PIVP). It uses an encoding of real variables by two non-negative variables for concentrations, and a transformation to an equivalent quadratic PIVP (i.e. with degrees at most 2) for restricting ourselves to at most bimolecular reactions. In this paper, we study the theoretical and practical complexities of the quadratic transformation. We show that both problems of minimizing either the number of variables (i.e., molecular species) or the number of monomials (i.e. elementary reactions) in a quadratic transformation of a PIVP are NP-hard. We present an encoding of those problems in MAX-SAT and show the practical complexity of this algorithm on a benchmark of quadratization problems inspired from CRN design problems.", "venue": "CMSB", "authors": ["Mathieu  Hemery", "Franccois  Fages", "Sylvain  Soliman"], "year": 2020, "n_citations": 3}
{"id": 1159606, "s2_id": "81fce4df24ab39ce7209058b65e0d1959bb1ae37", "title": "From Tensor Equations to Numerical Code - Computer Algebra Tools for Numerical Relativity", "abstract": "In this paper we present our recent work in developing a computer-algebra tool for systems of partial differential equations (PDEs), termed \"Kranc\". Our work is motivated by the problem of finding solutions of the Einstein equations through numerical simulations. Kranc consists of Mathematica based computer-algebra packages, that facilitate the task of dealing with symbolic tensorial calculations and realize the conversion of systems of partial differential evolution equations into parallelized C or Fortran code.", "venue": "ArXiv", "authors": ["Christiane  Lechner", "Dana  Alic", "Sascha  Husa"], "year": 2004, "n_citations": 11}
{"id": 1161032, "s2_id": "6fd13a624a6462e3c20b42dbaa67cd3d78103afa", "title": "Computing symmetric determinantal representations", "abstract": "We introduce the DeterminantalRepresentations package for Macaulay2, which computes definite symmetric determinantal representations of real polynomials. We focus on quadrics and plane curves of low degree (i.e. cubics and quartics). Our algorithms are geared towards speed and robustness, employing linear algebra and numerical algebraic geometry, without genericity assumptions on the polynomials.", "venue": "ArXiv", "authors": ["Justin  Chen", "Papri  Dey"], "year": 2019, "n_citations": 3}
{"id": 1161798, "s2_id": "8ea8ff42e9d6d5524929835507492155ee25373a", "title": "Checking the quality of clinical guidelines using automated reasoning tools", "abstract": "Abstract Requirements about the quality of clinical guidelines can be represented by schemata borrowed from the theory of abductive diagnosis, using temporal logic to model the time-oriented aspects expressed in a guideline. Previously, we have shown that these requirements can be verified using interactive theorem proving techniques. In this paper, we investigate how this approach can be mapped to the facilities of a resolution-based theorem prover, otter and a complementary program that searches for finite models of first-order statements, mace-2. It is shown that the reasoning required for checking the quality of a guideline can be mapped to such a fully automated theorem-proving facilities. The medical quality of an actual guideline concerning diabetes mellitus 2 is investigated in this way.", "venue": "Theory and Practice of Logic Programming", "authors": ["Arjen  Hommersom", "Peter J. F. Lucas", "Patrick van Bommel"], "year": 2008, "n_citations": 21}
{"id": 1162540, "s2_id": "3fd07e9f497cbe9051dec3b40f2ce62fa35b1482", "title": "On the annihilator ideal of an inverse form", "abstract": "Let $$\\mathbbm {k}$$k be a field. We simplify and extend work of Althaler and D\u00fcr on finite sequences over $$\\mathbbm {k}$$k by regarding $$\\mathbbm {k}[x^{-1},z^{-1}]$$k[x-1,z-1] as a $$\\mathbbm {k}[x,z]$$k[x,z] module and studying forms in $$\\mathbbm {k}[x^{-1},z^{-1}]$$k[x-1,z-1] from first principles. Then we apply our results to finite sequences. First we define the annihilator ideal $$\\mathcal {I}_F$$IF of a form $$F\\in \\mathbbm {k}[x^{-1},z^{-1}]$$F\u2208k[x-1,z-1] of total degree $$m\\le 0$$m\u22640. This is a homogeneous ideal. We inductively construct an ordered pair ($$f_1$$f1,\u00a0$$f_2$$f2) of forms in $$\\mathbbm {k}[x,z]$$k[x,z] which generate $$\\mathcal {I}_F$$IF\u00a0; our generators are special in that z does not divide the leading grlex monomial of $$f_1$$f1 but z divides $$f_2$$f2, and the sum of their total degrees is always $$2-m$$2-m. The corresponding algorithm is $$\\sim m^2/2$$\u223cm2/2. We prove that the row vector obtained by accumulating intermediate forms of the construction gives a minimal grlex Gr\u00f6bner basis for $$\\mathcal {I}_F$$IF for no extra computational cost other than storage (this is based on a closed-form description of a \u2019form vector\u2019 for F, an associated vector of total degrees and a syzygy triple derived from the construction. These imply that the remainder of the S polynomial of $$f_1,f_2$$f1,f2 is zero. Then we inductively apply Buchberger\u2019s Criterion to show that the form vector yields a minimal Gb for $$\\mathcal {I}_F$$IF). We apply this to determining $$\\dim _\\mathbbm {k}(\\mathbbm {k}[x,z] /\\mathcal {I}_F)$$dimk(k[x,z]/IF). We show that either the form vector is reduced or a monomial of $$f_1$$f1 can be reduced by $$f_2$$f2. This enables us to efficiently construct the unique reduced Gr\u00f6bner basis for $$\\mathcal {I}_F$$IF from the vector extension of our algorithm. Then we specialise to the inverse form of a finite sequence, obtaining generator forms for its annihilator ideal and a corresponding algorithm. We compute the intersection of two annihilator ideals using syzygies in $$\\mathbbm {k}[x,z]^5$$k[x,z]5. This improves a result of Althaler and D\u00fcr. Finally we show that dehomogenisation induces a one-to-one correspondence ($$f_1$$f1,$$f_2$$f2) $$\\mapsto $$\u21a6 (minimal polynomial, auxiliary polynomial), the output of the author\u2019s variant of the Berlekamp\u2013Massey algorithm. So we can also solve the LFSR synthesis problem via the corresponding algorithm for sequences.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Graham H. Norton"], "year": 2016, "n_citations": 2}
{"id": 1166624, "s2_id": "169e8329fafb67ac01b9ca491b19883946802cc3", "title": "On the symmetry classes of the first covariant derivatives of tensor fields", "abstract": "We show that the symmetry classes of torsion-free covariant deriva- tives rT of r-times covariant tensor fields T can be characterized by Littlewood- Richardson products (1) where is a representation of the symmetric group Sr which is connected with the symmetry class of T. If ( ) is irreducible then (1) has a multiplicity free reduction ( )(1) P \u00b5 (\u00b5) and all primitive idem- potents belonging to that sum can be calculated from a generating idempotent e of the symmetry class of T by means of the irreducible characters or of a dis- crete Fourier transform of Sr+1. We apply these facts to derivatives rS, rA of symmetric or alternating tensor fields. The symmetry classes of the dierences rS sym(rS) and rA alt(rA) = rA dA are characterized by Young frames (r,1) ' r + 1 and (2,1 r 1 ) ' r + 1, respectively. However, while the symmetry class of rA alt(rA) can be generated by Young symmetrizers of (2,1 r 1 ), no Young symmetrizer of (r,1) generates the symmetry class of rS sym(rS). Furthermore we show in the case r = 2 that rS sym(rS) and rA alt(rA) can be applied in generator formulas of algebraic covariant derivative curvature tensors. For certain symbolic calculations we used the Mathematica packages Ricci and PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2003, "n_citations": 5}
{"id": 1167581, "s2_id": "98fd1770c5084531005aaaa577752e693e823c1b", "title": "A Generalized Framework for Virtual Substitution", "abstract": "We generalize the framework of virtual substitution for real quantifier elimination to arbitrary but bounded degrees. We make explicit the representation of test points in elimination sets using roots of parametric univariate polynomials described by Thom codes. Our approach follows an early suggestion by Weispfenning, which has never been carried out explicitly. Inspired by virtual substitution for linear formulas, we show how to systematically construct elimination sets containing only test points representing lower bounds.", "venue": "ArXiv", "authors": ["Marek  Kosta", "Thomas  Sturm"], "year": 2015, "n_citations": 5}
{"id": 1169506, "s2_id": "f2ede4e5c06802f886ae7b804c2896a33cd2c05c", "title": "Fast arithmetics in Artin-Schreier towers over finite fields", "abstract": "An Artin-Schreier tower over the finite field F\"p is a tower of field extensions generated by polynomials of the form X^p-X-@a. Following Cantor and Couveignes, we give algorithms with quasi-linear time complexity for arithmetic operations in such towers. As an application, we present an implementation of Couveignes' algorithm for computing isogenies between elliptic curves using the p-torsion.", "venue": "J. Symb. Comput.", "authors": ["Luca De Feo", "\u00c9ric  Schost"], "year": 2012, "n_citations": 11}
{"id": 1180199, "s2_id": "e9c15dc9be43a65b1f59ff06b27e5bdd365e9023", "title": "Symbolic-Numeric Tools for Analytic Combinatorics in Several Variables", "abstract": "Analytic combinatorics studies the asymptotic behavior of sequences through the analytic properties of their generating functions. This article provides effective algorithms required for the study of analytic combinatorics in several variables, together with their complexity analyses. Given a multivariate rational function we show how to compute its smooth isolated critical points, with respect to a polynomial map encoding asymptotic behaviour, in complexity singly exponential in the degree of its denominator. We introduce a numerical Kronecker representation for solutions of polynomial systems with rational coefficients and show that it can be used to decide several properties (0 coordinate, equal coordinates, sign conditions for real solutions, and vanishing of a polynomial) in good bit complexity. Among the critical points, those that are minimal---a property governed by inequalities on the moduli of the coordinates---typically determine the dominant asymptotics of the diagonal coefficient sequence. When the Taylor expansion at the origin has all non-negative coefficients (known as the 'combinatorial case') and under regularity conditions, we utilize this Kronecker representation to determine probabilistically the minimal critical points in complexity singly exponential in the degree of the denominator, with good control over the exponent in the bit complexity estimate. Generically in the combinatorial case, this allows one to automatically and rigorously determine asymptotics for the diagonal coefficient sequence. Examples obtained with a preliminary implementation show the wide applicability of this approach.", "venue": "ISSAC", "authors": ["Stephen  Melczer", "Bruno  Salvy"], "year": 2016, "n_citations": 14}
{"id": 1180802, "s2_id": "af8359dbe8b73572411ad692bbca994c554857b8", "title": "Fast and Reliable Formal Verification of Smart Contracts with the Move Prover", "abstract": "The Move Prover (MVP) is a formal verifier for smart contracts written in the Move programming language. MVP has an expressive specification language, and is fast and reliable enough that it can be run routinely by developers and in integration testing. Besides the simplicity of smart contracts and the Move language, three implementation approaches are responsible for the practicality of MVP: (1) an alias-free memory model, (2) fine-grained invariant checking, and (3) monomorphization. The entirety of the Move code for the Diem blockchain has been extensively specified and can be completely verified by MVP in a few minutes. Changes in the Diem framework must be successfully verified before being integrated into the open source repository on GitHub.", "venue": "ArXiv", "authors": ["David L. Dill", "Wolfgang  Grieskamp", "Junkil  Park", "Shaz  Qadeer", "Meng  Xu", "Jingyi Emma Zhong"], "year": 2021, "n_citations": 0}
{"id": 1181143, "s2_id": "d160576057d1767a55c6ceef7977c582a0dca4dd", "title": "Computation of the expected Euler characteristic for the largest eigenvalue of a real non-central Wishart matrix", "abstract": "We give an approximate formula for the distribution of the largest eigenvalue of real Wishart matrices by the expected Euler characteristic method for the general dimension. The formula is expressed in terms of a definite integral with parameters. We derive a differential equation satisfied by the integral for the $2 \\times 2$ matrix case and perform a numerical analysis of it.", "venue": "J. Multivar. Anal.", "authors": ["Nobuki  Takayama", "Lin  Jiu", "Satoshi  Kuriki", "Yi  Zhang"], "year": 2020, "n_citations": 2}
{"id": 1181888, "s2_id": "0a9285d44ebd49912096f119a1290628bf82e201", "title": "Complexity Analysis of Root Clustering for a Complex Polynomial", "abstract": "Let F(z) be an arbitrary complex polynomial. We introduce the {local root clustering problem}, to compute a set of natural epsilon-clusters of roots of F(z) in some box region B0 in the complex plane. This may be viewed as an extension of the classical root isolation problem. Our contribution is two-fold: we provide an efficient certified subdivision algorithm for this problem, and we provide a bit-complexity analysis based on the local geometry of the root clusters. Our computational model assumes that arbitrarily good approximations of the coefficients of F(z) are provided by means of an oracle at the cost of reading the coefficients. Our algorithmic techniques come from a companion paper [3] and are based on the Pellet test, Graeffe and Newton iterations, and are independent of Schonhage's splitting circle method. Our algorithm is relatively simple and promises to be efficient in practice.", "venue": "ISSAC", "authors": ["Ruben  Becker", "Michael  Sagraloff", "Vikram  Sharma", "Juan  Xu", "Chee-Keng  Yap"], "year": 2016, "n_citations": 36}
{"id": 1191488, "s2_id": "b948e394a871d23242f807fee17eeed8ef8f8e18", "title": "Exact p-adic computation in Magma", "abstract": "Abstract We describe a new arithmetic system for the Magma computer algebra system for working with p-adic numbers exactly, in the sense that numbers are represented lazily to infinite p-adic precision. This is the first highly featured such implementation. This has the benefits of increasing user-friendliness and speeding up some computations, as well as forcibly producing provable results. We give theoretical and practical justification for its design and describe some use cases. The intention is that this article will be of benefit to anyone wanting to implement similar functionality in other languages.", "venue": "J. Symb. Comput.", "authors": ["Christopher  Doris"], "year": 2021, "n_citations": 1}
{"id": 1198257, "s2_id": "924562785a69f1d09629a194123e4c38f2216d8e", "title": "Efficient parallel verification of Galois field multipliers", "abstract": "Galois field (GF) arithmetic is used to implement critical arithmetic components in communication and security-related hardware, and verification of such components is of prime importance. Current techniques for formally verifying such components are based on computer algebra methods that proved successful in verification of integer arithmetic circuits. However, these methods are sequential in nature and do not offer any parallelism. This paper presents an algebraic functional verification technique of gate-level GF(2m) multipliers, in which verification is performed in bit-parallel fashion. The method is based on extracting a unique polynomial in Galois field of each output bit independently. We demonstrate that this method is able to verify an n-bit GF multiplier in n threads. Experiments performed on pre- and post-synthesized Mastrovito and Montgomery multipliers show high efficiency up to 571 bits.", "venue": "2017 22nd Asia and South Pacific Design Automation Conference (ASP-DAC)", "authors": ["Cunxi  Yu", "Maciej J. Ciesielski"], "year": 2017, "n_citations": 17}
{"id": 1203543, "s2_id": "6b23907507980d1093c9084fad5c6497ea093ff0", "title": "Polyhedral Omega: a New Algorithm for Solving Linear Diophantine Systems", "abstract": "Polyhedral Omega is a new algorithm for solving linear Diophantine systems (LDS), i.e., for computing a multivariate rational function representation of the set of all non-negative integer solutions to a system of linear equations and inequalities. Polyhedral Omegacombines methods from partition analysis with methods from polyhedral geometry. In particular, we combine MacMahon\u2019s iterative approach based on the Omega operator and explicit formulas for its evaluation with geometric tools such as Brion decompositions and Barvinok\u2019s short rational function representations. In this way, we connect two recent branches of research that have so far remained separate, unified by the concept of symbolic cones which we introduce. The resulting LDS solver Polyhedral Omegais significantly faster than previous solvers based on partition analysis and it is competitive with state-of-the-art LDS solvers based on geometric methods. Most importantly, this synthesis of ideas makes Polyhedral Omegathe simplest algorithm for solving linear Diophantine systems available to date. Moreover, we provide an illustrated geometric interpretation of partition analysis, with the aim of making ideas from both areas accessible to readers from a wide range of backgrounds.", "venue": "ArXiv", "authors": ["Felix  Breuer", "Zafeirakis  Zafeirakopoulos"], "year": 2015, "n_citations": 8}
{"id": 1203646, "s2_id": "4982147befcd429803e20e6e5756f5a9757ce292", "title": "An Algebraic Approach for Computing Equilibria of a Subclass of Finite Normal Form Games", "abstract": "A Nash equilibrium has become important solution concept for analyzing the decision making in Game theory. In this paper, we consider the problem of computing Nash equilibria of a subclass of generic finite normal form games. We define \"rational payoff irrational equilibria games\" to be the games with all rational payoffs and all irrational equilibria. We present a purely algebraic method for computing all Nash equilibria of these games that uses knowledge of Galois groups. Some results, showing properties of the class of games, and an example to show working of the method concludes the paper.", "venue": "ArXiv", "authors": ["Samaresh  Chatterji", "Ratnik  Gandhi"], "year": 2010, "n_citations": 2}
{"id": 1206198, "s2_id": "100bcd0751a5ad54c74cc0c0fee70e9f9212c1b8", "title": "Solving large linear algebraic systems in the context of integrable non-abelian Laurent ODEs", "abstract": "The paper reports on a computer algebra program LSSS (Linear Selective Systems Solver) for solving linear algebraic systems with rational coefficients. The program is especially efficient for very large sparse systems that have a solution in which many variables take the value zero. The program is applied to the symmetry investigation of a non-abelian Laurent ODE introduced recently by M. Kontsevich. The computed symmetries confirmed that a Lax pair found for this system earlier generates all first integrals of degree at least up to 14.", "venue": "Programming and Computer Software", "authors": ["Thomas  Wolf", "Eberhard  Schr\u00fcfer", "Kenneth  Webster"], "year": 2012, "n_citations": 4}
{"id": 1208890, "s2_id": "0bb6a35150dcdda047d21b6da776d5e5c833fd9d", "title": "Splitting full matrix algebras over algebraic number fields", "abstract": "Let K be an algebraic number field of degree d and discriminant D over Q. Let A be an associative algebra over K given by structure constants such that A is isomorphic to the algebra M_n(K) of n by n matrices over K for some positive integer n. Suppose that d, n and D are bounded. Then an isomorphism of A with M_n(K) can be constructed by a polynomial time ff-algorithm. (An ff-algorithm is a deterministic procedure which is allowed to call oracles for factoring integers and factoring univariate polynomials over finite fields.) \nAs a consequence, we obtain a polynomial time ff-algorithm to compute isomorphisms of central simple algebras of bounded degree over K.", "venue": "ArXiv", "authors": ["G\u00e1bor  Ivanyos", "Lajos  R\u00f3nyai", "Joseph  Schicho"], "year": 2011, "n_citations": 29}
{"id": 1213600, "s2_id": "6e33804dd9492d46d0dbe5d00e4c482ac6f44d4c", "title": "Temporal viability regulation for control affine systems with applications to mobile vehicle coordination under time-varying motion constraints", "abstract": "Controlled invariant set and viability regulation of dynamical control systems have played important roles in many control and coordination applications. In this paper we develop a temporal viability regulation theory for general dynamical control systems, and in particular for control affine systems. The time-varying viable set is parameterized by time-varying constraint functions, with the aim to regulate a dynamical control system to be invariant in the time-varying viable set so that temporal state-dependent constraints are enforced. We consider both time-varying equality and inequality constraints in defining a temporal viable set. We also present sufficient conditions for the existence of feasible control input for the control affine systems. The developed temporal viability regulation theory is applied to mobile vehicle coordination.", "venue": "2019 18th European Control Conference (ECC)", "authors": ["Marcus  Greiff", "Zhiyong  Sun", "Anders  Robertsson", "Rolf  Johansson"], "year": 2019, "n_citations": 2}
{"id": 1223860, "s2_id": "474fed213b1957ce8327c98c8331e603dbdcab15", "title": "Hopf Algebras in General and in Combinatorial Physics: a practical introduction", "abstract": "This tutorial is intended to give an accessible introduction to Hopf algebras. The mathematical context is that of representation theory, and we also illustrate the structures with examples taken from combinatorics and quantum physics, showing that in this latter case the axioms of Hopf algebra arise naturally. The text contains many exercises, some taken from physics, aimed at expanding and exemplifying the concepts introduced.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Pawel  Blasiak", "Andrzej  Horzela", "Karol A. Penson", "Allan I. Solomon"], "year": 2008, "n_citations": 8}
{"id": 1225036, "s2_id": "7f62eaf8cb431463bed5940b2b84f6d4573facf3", "title": "An Abstraction-guided Approach to Scalable and Rigorous Floating-Point Error Analysis", "abstract": "Automated techniques for rigorous floating-point round-off error analysis are important in areas including formal verification of correctness and precision tuning. Existing tools and techniques, while providing tight bounds, fail to analyze expressions with more than a few hundred operators, thus unable to cover important practical problems. In this work, we present Satire, a new tool that sheds light on how scalability and bound-tightness can be attained through a combination of incremental analysis, abstraction, and judicious use of concrete and symbolic evaluation. Satire has handled problems exceeding 200K operators. We present Satire's underlying error analysis approach, information-theoretic abstraction heuristics, and a wide range of case studies, with evaluation covering FFT, Lorenz system of equations, and various PDE stencil types. Our results demonstrate the tightness of Satire's bounds, its acceptable runtime, and valuable insights provided.", "venue": "ArXiv", "authors": ["Arnab  Das", "Ian  Briggs", "Ganesh  Gopalakrishnan", "Sriram  Krishnamoorthy"], "year": 2020, "n_citations": 0}
{"id": 1228095, "s2_id": "97acb0b34c6eb0eb072c14d2bb97d06ef6b5ec84", "title": "Advanced Computer Algebra Algorithms for the Expansion of Feynman Integrals", "abstract": "Two-point Feynman parameter integrals, with at most one mass and containing local operator insertions in $4+\\ep$-dimensional Minkowski space, can be transformed to multi-integrals or multi-sums over hyperexponential and/or hypergeometric functions depending on a discrete parameter $n$. Given such a specific representation, we utilize an enhanced version of the multivariate Almkvist--Zeilberger algorithm (for multi-integrals) and a common summation framework of the holonomic and difference field approach (for multi-sums) to calculate recurrence relations in $n$. Finally, solving the recurrence we can decide efficiently if the first coefficients of the Laurent series expansion of a given Feynman integral can be expressed in terms of indefinite nested sums and products; if yes, the all $n$ solution is returned in compact representations, i.e., no algebraic relations exist among the occurring sums and products.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein", "Mark  Round", "Carsten  Schneider"], "year": 2012, "n_citations": 19}
{"id": 1230510, "s2_id": "5bd4701d241202c807db57646a3e70a61d7d3b78", "title": "Why Charles Can Pen-test: an Evolutionary Approach to Vulnerability Testing", "abstract": "Discovering vulnerabilities in applications of real-world complexity is a daunting task: a vulnerability may affect a single line of code, and yet it compromises the security of the entire application. Even worse, vulnerabilities may manifest only in exceptional circumstances that do not occur in the normal operation of the application. It is widely recognized that state-of-the-art penetration testing tools play a crucial role, and are routinely used, to dig up vulnerabilities. Yet penetration testing is still primarily a human-driven activity, and its effectiveness still depends on the skills and ingenuity of the security analyst driving the tool. In this paper, we propose a technique for the automatic discovery of vulnerabilities in event-based systems, such as web and mobile applications. Our approach is based on a collaborative, co-evolutionary and contract-driven search strategy that iteratively (i) executes a pool of test cases, (ii) identifies the most promising ones, and (iii) generates new test cases from them. The approach makes a synergistic combination of evolutionary algorithms where several \"species\" contribute to solving the problem: one species, the test species, evolves to find the target test case, i.e., the set of instruction whose execution lead to the vulnerable statement, whereas the other species, called contract species, evolve to select the parameters for the procedure calls needed to trigger the vulnerability. To assess the effectiveness of our approach, we implemented a working prototype and ran it against both a case study and a benchmark web application. The experimental results confirm that our tool automatically discovers and executes a number of injection flaw attacks that are out of reach for state-of-the-art web scanners.", "venue": "ArXiv", "authors": ["Gabriele  Costa", "Andrea  Valenza"], "year": 2020, "n_citations": 0}
{"id": 1232935, "s2_id": "a14d5a83be31839c43c06c16c592443bce7bafb2", "title": "Problem Formulation for Truth-Table Invariant Cylindrical Algebraic Decomposition by Incremental Triangular Decomposition", "abstract": "Cylindrical algebraic decompositions (CADs) are a key tool for solving problems in real algebraic geometry and beyond. We recently presented a new CAD algorithm combining two advances: truth-table invariance, making the CAD invariant with respect to the truth of logical formulae rather than the signs of polynomials; and CAD construction by regular chains technology, where first a complex decomposition is constructed by refining a tree incrementally by constraint. We here consider how best to formulate problems for input to this algorithm. We focus on a choice (not relevant for other CAD algorithms) about the order in which constraints are presented. We develop new heuristics to help make this choice and thus allow the best use of the algorithm in practice. We also consider other choices of problem formulation for CAD, as discussed in CICM 2013, revisiting these in the context of the new algorithm.", "venue": "CICM", "authors": ["Matthew  England", "Russell J. Bradford", "Changbo  Chen", "James H. Davenport", "Marc Moreno Maza", "David J. Wilson"], "year": 2014, "n_citations": 24}
{"id": 1235668, "s2_id": "30e4c656442b92faad2d955fdc220ac1da9f42bf", "title": "Ranking Catamorphisms and Unranking Anamorphisms on Hereditarily Finite Datatypes", "abstract": "Using specializations of unfold and fold on a generic tree data type we derive unranking and ranking functions providing natural number encodings for various Hereditarily Finite datatypes. \nIn this context, we interpret unranking operations as instances of a generic anamorphism and ranking operations as instances of the corresponding catamorphism. \nStarting with Ackerman's Encoding from Hereditarily Finite Sets to Natural Numbers we define pairings and tuple encodings that provide building blocks for a theory of Hereditarily Finite Functions. \nThe more difficult problem of ranking and unranking Hereditarily Finite Permutations is then tackled using Lehmer codes and factoradics. \nThe self-contained source code of the paper, as generated from a literate Haskell program, is available at \\url{this http URL}. \nKeywords: ranking/unranking, pairing/tupling functions, Ackermann encoding, hereditarily finite sets, hereditarily finite functions, permutations and factoradics, computational mathematics, Haskell data representations", "venue": "ArXiv", "authors": ["Paul  Tarau"], "year": 2008, "n_citations": 0}
{"id": 1237221, "s2_id": "2839a17cf9e0913488bc549374ccfae57fd7b93a", "title": "Proceedings of the 9th International Symposium on Symbolic Computation in Software Science", "abstract": "This volume contains papers presented at the Ninth International Symposium on Symbolic Computation in Software Science, SCSS 2021. Symbolic Computation is the science of computing with symbolic objects (terms, formulae, programs, representations of algebraic objects, etc.). Powerful algorithms have been developed during the past decades for the major subareas of symbolic computation: computer algebra and computational logic. These algorithms and methods are successfully applied in various fields, including software science, which covers a broad range of topics about software construction and analysis. Meanwhile, artificial intelligence methods and machine learning algorithms are widely used nowadays in various domains and, in particular, combined with symbolic computation. Several approaches mix artificial intelligence and symbolic methods and tools deployed over large corpora to create what is known as cognitive systems. Cognitive computing focuses on building systems that interact with humans naturally by reasoning, aiming at learning at scale. The purpose of SCSS is to promote research on theoretical and practical aspects of symbolic computation in software science, combined with modern artificial intelligence techniques. These proceedings contain the keynote paper by Bruno Buchberger and ten contributed papers. Besides, the conference program included three invited talks, nine short and work-in-progress papers, and a special session on computer algebra and computational logic. Due to the COVID-19 pandemic, the symposium was held completely online. It was organized by the Research Institute for Symbolic Computation (RISC) of the Johannes Kepler University Linz on September 8--10, 2021.", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Temur  Kutsia"], "year": 2021, "n_citations": 0}
{"id": 1238158, "s2_id": "2322160d77b7bf6672ee0f762f5e53a738015477", "title": "Finding linear dependencies in integration-by-parts equations: A Monte Carlo approach", "abstract": "The reduction of a large number of scalar integrals to a small set of master integrals via Laporta\u2019s algorithm is common practice in multi-loop calculations. It is also a major bottleneck in terms of running time and memory consumption. It involves solving a large set of linear equations where many of the equations are linearly dependent. We propose a simple algorithm that eliminates all linearly dependent equations from a given system, reducing the time and space requirements of a subsequent run of Laporta\u2019s algorithm.", "venue": "Comput. Phys. Commun.", "authors": ["Philipp  Kant"], "year": 2014, "n_citations": 20}
{"id": 1242386, "s2_id": "47694aaa412c46a4e73808563a07bb8977d58eeb", "title": "On the Complexity of the Tiden-Arnborg Algorithm for Unification modulo One-Sided Distributivity", "abstract": "We prove that the Tiden and Arnborg algorithm for equational unification modulo one-sided distributivity is not polynomial time bounded as previously thought. A set of counterexamples is developed that demonstrates that the algorithm goes through exponentially many steps.", "venue": "UNIF", "authors": ["Paliath  Narendran", "Andrew M. Marshall", "Bibhu  Mahapatra"], "year": 2010, "n_citations": 6}
{"id": 1247870, "s2_id": "0cf7624eadca2d9565d64d84df243caa029e0cd8", "title": "Counting points on genus-3 hyperelliptic curves with explicit real multiplication", "abstract": "We propose a Las Vegas probabilistic algorithm to compute the zeta function of a genus-3 hyperelliptic curve defined over a finite field $Fq$, with explicit real multiplication by an order $Z[\u03b7]$ in a totally real cubic field. Our main result states that this algorithm requires an expected number of $O((log q) 6)$ bit-operations, where the constant in the $O()$ depends on the ring $Z[\u03b7]$ and on the degrees of polynomials representing the endomorphism $\u03b7$. As a proof-of-concept, we compute the zeta function of a curve defined over a 64-bit prime field, with explicit real multiplication by $Z[2 cos(2\u03c0/7)$].", "venue": "The Open Book Series", "authors": ["Simon  Abelard", "Pierrick  Gaudry", "Pierre-Jean  Spaenlehauer"], "year": 2019, "n_citations": 6}
{"id": 1252835, "s2_id": "2f56ecb98e189f36ce511dff2b7284b4e10ab85a", "title": "The DMM bound: multivariate (aggregate) separation bounds", "abstract": "In this paper we derive aggregate separation bounds, named after Davenport-Mahler-Mignotte (DMM), on the isolated roots of polynomial systems, specifically on the minimum distance between any two such roots. The bounds exploit the structure of the system and the height of the sparse (or toric) resultant by means of mixed volume, as well as recent advances on aggregate root bounds for univariate polynomials, and are applicable to arbitrary positive dimensional systems. We improve upon Canny's gap theorem [7] by a factor of O(dn-1), where d bounds the degree of the polynomials, and n is the number of variables. One application is to the bitsize of the eigenvalues and eigenvectors of an integer matrix, which also yields a new proof that the problem is polynomial. We also compare against recent lower bounds on the absolute value of the root coordinates by Brownawell and Yap [5], obtained under the hypothesis there is a 0-dimensional projection. Our bounds are in general comparable, but exploit sparseness; they are also tighter when bounding the value of a positive polynomial over the simplex. For this problem, we also improve upon the bounds in [2, 16]. Our analysis provides a precise asymptotic upper bound on the number of steps that subdivision-based algorithms perform in order to isolate all real roots of a polynomial system. This leads to the first complexity bound of Milne's algorithm [22] in 2D.", "venue": "ISSAC", "authors": ["Ioannis Z. Emiris", "Bernard  Mourrain", "Elias P. Tsigaridas"], "year": 2010, "n_citations": 54}
{"id": 1253027, "s2_id": "4a7c6161f687dbb985c24a2442bb981379f4eeee", "title": "A Fast Algorithm for Computing the P-curvature", "abstract": "We design an algorithm for computing the p-curvature of a differential system in positive characteristic p. For a system of dimension r with coefficients of degree at most d, its complexity is O~ (p d r\u03c9) operations in the ground field (where \u03c9 denotes the exponent of matrix multiplication), whereas the size of the output is about p d r2. Our algorithm is then quasi-optimal assuming that matrix multiplication is (i.e. \u03c9 = 2). The main theoretical input we are using is the existence of a well-suited ring of series with divided powers for which an analogue of the Cauchy--Lipschitz Theorem holds.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Xavier  Caruso", "\u00c9ric  Schost"], "year": 2015, "n_citations": 7}
{"id": 1253572, "s2_id": "eb4750f26370d1a8270e8fe65611a2c488874d15", "title": "Holonomic Gradient Descent and its Application to Fisher-Bingham Integral", "abstract": "We give a new algorithm to find local maximum and minimum of a holonomic function and apply it for the Fisher-Bingham integral on the sphere $S^n$, which is used in the directional statistics. The method utilizes the theory and algorithms of holonomic systems.", "venue": "Adv. Appl. Math.", "authors": ["Tomonari  Sei", "Nobuki  Takayama", "Akimichi  Takemura", "Hiromasa  Nakayama", "Kenta  Nishiyama", "Masayuki  Noro", "Katsuyoshi  Ohara"], "year": 2011, "n_citations": 61}
{"id": 1254501, "s2_id": "44858ccc6e33a19cd2a979324bf797eeab320d95", "title": "Improved Linear Parallel Interference Cancellers", "abstract": "In this paper, taking the view that a linear parallel interference canceller (LPIC) can be seen as a linear matrix filter, we propose new linear matrix filters that can result in improved bit error performance compared to other LPICs in the literature. The motivation for the proposed filters arises from the possibility of avoiding the generation of certain interference and noise terms in a given stage that would have been present in a conventional LPIC (CLPIC). In the proposed filters, we achieve such avoidance of the generation of interference and noise terms in a given stage by simply making the diagonal elements of a certain matrix in that stage equal to zero. Hence, the proposed filters do not require additional complexity compared to the CLPIC, and they can allow achieving a certain error performance using fewer LPIC stages.", "venue": "2007 IEEE International Conference on Communications", "authors": ["Thati  Srikanth", "K. Vishnu Vardhan", "Ananthanarayanan  Chockalingam", "Laurence B. Milstein"], "year": 2007, "n_citations": 3}
{"id": 1254841, "s2_id": "a9f5cf6cc520ef35a377190492fbd0a42970b10e", "title": "Computing the homology of groups: The geometric way", "abstract": "In this paper, we present several algorithms related with the computation of the homology of groups, from a geometric perspective (that is to say, carrying out the calculations by means of simplicial sets and using techniques of Algebraic Topology). More concretely, we have developed some algorithms which, making use of the effective homology method, construct the homology groups of Eilenberg-MacLane spaces K(G,1) for different groups G, allowing one in particular to determine the homology groups of G. Our algorithms have been programmed as new modules for the Kenzo system, enhancing it with the following new functionalities: *construction of the effective homology of K(G,1) from a given finite type free resolution of the group G; *construction of the effective homology of K(A,1) for every finitely generated Abelian group A (as a consequence, the effective homology of K(A,n) is also available in Kenzo, for all [email\u00a0protected]?N); *computation of homology groups of some 2-types; *construction of the effective homology for central extensions. In addition, an inverse problem is also approached in this work: given a group G such that K(G,1) has effective homology, can a finite type free resolution of the group G be obtained? We provide some algorithms to solve this problem, based on a notion of norm of a group, allowing us to control the convergence of the process when building such a resolution.", "venue": "J. Symb. Comput.", "authors": ["Ana  Romero", "Julio  Rubio"], "year": 2012, "n_citations": 5}
{"id": 1255874, "s2_id": "5d3a297fa52b31442bdc9e1c0545b4e04f82a82d", "title": "Accurate solution of near-colliding Prony systems via decimation and homotopy continuation", "abstract": "We consider polynomial systems of Prony type, appearing in many areas of mathematics. Their robust numerical solution is considered to be difficult, especially in \"near-colliding\" situations. We consider a case when the structure of the system is a-priori fixed. We transform the nonlinear part of the Prony system into a Hankel-type polynomial system. Combining this representation with a recently discovered \"decimation\" technique, we present an algorithm which applies homotopy continuation to an appropriately chosen Hankel-type system as above. In this way, we are able to solve for the nonlinear variables of the original system with high accuracy when the data is perturbed.", "venue": "Theor. Comput. Sci.", "authors": ["Dmitry  Batenkov"], "year": 2017, "n_citations": 17}
{"id": 1258716, "s2_id": "c0805c9fc87b117ed1a6fafe894509d2790bc97d", "title": "Learning Theorem Proving Components", "abstract": "Saturation-style automated theorem provers (ATPs) based on the given clause procedure are today the strongest general reasoners for classical first-order logic. The clause selection heuristics in such systems are, however, often evaluating clauses in isolation, ignoring other clauses. This has changed recently by equipping the E/ENIGMA system with a graph neural network (GNN) that chooses the next given clause based on its evaluation in the context of previously selected clauses. In this work, we describe several algorithms and experiments with ENIGMA, advancing the idea of contextual evaluation based on learning important components of the graph of clauses.", "venue": "TABLEAUX", "authors": ["Karel  Chvalovsk\u00fd", "Jan  Jakubuv", "Miroslav  Ols\u00e1k", "Josef  Urban"], "year": 2021, "n_citations": 0}
{"id": 1262112, "s2_id": "e93a9e1f9271d9573377185d9f5fa796b6066157", "title": "Rank-profile revealing Gaussian elimination and the CUP matrix decomposition", "abstract": "Transforming a matrix over a field to echelon form, or decomposing the matrix as a product of structured matrices that reveal the rank profile, is a fundamental building block of computational exact linear algebra. This paper surveys the well known variations of such decompositions and transformations that have been proposed in the literature. We present an algorithm to compute the CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra, Moran and Hui (1982), and show reductions from the other most common Gaussian elimination based matrix transformations and decompositions to the CUP decomposition. We discuss the advantages of the CUP algorithm over other existing algorithms by studying time and space complexities: the asymptotic time complexity is rank sensitive, and comparing the constants of the leading terms, the algorithms for computing matrix invariants based on the CUP decomposition are always at least as good except in one case. We also show that the CUP algorithm, as well as the computation of other invariants such as transformation to reduced column echelon form using the CUP algorithm, all work in place, allowing for example to compute the inverse of a matrix on the same storage as the input matrix.", "venue": "J. Symb. Comput.", "authors": ["Claude-Pierre  Jeannerod", "Cl\u00e9ment  Pernet", "Arne  Storjohann"], "year": 2013, "n_citations": 36}
{"id": 1262578, "s2_id": "b5329adfadce878db92fc033e50aadccdbe56a2a", "title": "Can Computer Algebra be Liberated from its Algebraic Yoke ?", "abstract": "So far, the scope of computer algebra has been needlessly restricted to exact algebraic methods. Its possible extension to approximate analytical methods is discussed. The entangled roles of functional analysis and symbolic programming, especially the functional and transformational paradigms, are put forward. In the future, algebraic algorithms could constitute the core of extended symbolic manipulation systems including primitives for symbolic approximations.", "venue": "ArXiv", "authors": ["R.  Barrere"], "year": 2005, "n_citations": 4}
{"id": 1265703, "s2_id": "62a5d4e1f5854ff82d587812cccdeeb4a1274330", "title": "A unified formal description of arithmetic and set theoretical data types", "abstract": "We provide a \"shared axiomatization\" of natural numbers and hereditarily finite sets built around a polymorphic abstraction of bijective base-2 arithmetics.\n The \"axiomatization\" is described as a progressive refinement of Haskell type classes with examples of instances converging to an efficient implementation in terms of arbitrary length integers and bit operations. As an instance, we derive algorithms to perform arithmetic operations efficiently directly with hereditarily finite sets.\n The self-contained source code of the paper is available at http:// logic.cse.unt.edu/tarau/research/2010/unified.hs", "venue": "AISC'10/MKM'10/Calculemus'10", "authors": ["Paul  Tarau"], "year": 2010, "n_citations": 5}
{"id": 1275350, "s2_id": "f30f5e9d633908cbadb79e82cf9eafb46713b727", "title": "Logic, Probability and Action: A Situation Calculus Perspective", "abstract": "The unification of logic and probability is a long-standing concern in AI, and more generally, in the philosophy of science. In essence, logic provides an easy way to specify properties that must hold in every possible world, and probability allows us to further quantify the weight and ratio of the worlds that must satisfy a property. To that end, numerous developments have been undertaken, culminating in proposals such as probabilistic relational models. While this progress has been notable, a general-purpose first-order knowledge representation language to reason about probabilities and dynamics, including in continuous settings, is still to emerge. In this paper, we survey recent results pertaining to the integration of logic, probability and actions in the situation calculus, which is arguably one of the oldest and most well-known formalisms. We then explore reduction theorems and programming interfaces for the language. These results are motivated in the context of cognitive robotics (as envisioned by Reiter and his colleagues) for the sake of concreteness. Overall, the advantage of proving results for such a general language is that it becomes possible to adapt them to any special-purpose fragment, including but not limited to popular probabilistic relational models.", "venue": "SUM", "authors": ["Vaishak  Belle"], "year": 2020, "n_citations": 1}
{"id": 1275567, "s2_id": "e2a3b06a7db9636bd4e6c4d4d83fc29f1c91aeb5", "title": "On Bergman's Diamond Lemma for Ring Theory", "abstract": "This expository paper deals with the Diamond Lemma for ring theory, which is proved in the first section of G.M. Bergman, The Diamond Lemma for Ring Theory, Advances in Mathematics, 29 (1978), pp. 178--218. No originality of the present note is claimed on the part of the author, except for some suggestions and figures. Throughout this paper, I shall mostly use Bergman's expressions in his paper.", "venue": "ArXiv", "authors": ["Takao  Inou'e"], "year": 2020, "n_citations": 0}
{"id": 1275599, "s2_id": "4da2918a9721541b24e1e60acfd6bc1717455364", "title": "Improved cross-validation for classifiers that make algorithmic choices to minimise runtime without compromising output correctness", "abstract": "Our topic is the use of machine learning to improve software by making choices which do not compromise the correctness of the output, but do affect the time taken to produce such output. We are particularly concerned with computer algebra systems (CASs), and in particular, our experiments are for selecting the variable ordering to use when performing a cylindrical algebraic decomposition of $n$-dimensional real space with respect to the signs of a set of polynomials. \nIn our prior work we explored the different ML models that could be used, and how to identify suitable features of the input polynomials. In the present paper we both repeat our prior experiments on problems which have more variables (and thus exponentially more possible orderings), and examine the metric which our ML classifiers targets. The natural metric is computational runtime, with classifiers trained to pick the ordering which minimises this. However, this leads to the situation were models do not distinguish between any of the non-optimal orderings, whose runtimes may still vary dramatically. In this paper we investigate a modification to the cross-validation algorithms of the classifiers so that they do distinguish these cases, leading to improved results.", "venue": "MACIS", "authors": ["Dorian  Florescu", "Matthew  England"], "year": 2019, "n_citations": 5}
{"id": 1276798, "s2_id": "fb0ddecffbd9fe033546af73cc43988fbbf33948", "title": "Genetic Algorithms and the Andrews-Curtis Conjecture", "abstract": "The Andrews\u2013Curtis conjecture claims that every balanced presentation of the trivial group can be transformed into the trivial presentation by a finite sequence of \"elementary transformations\" which are Nielsen transformations together with an arbitrary conjugation of a relator. It is believed that the Andrews\u2013Curtis conjecture is false; however, not so many possible counterexamples are known. It is not a trivial matter to verify whether the conjecture holds for a given balanced presentation or not. The purpose of this paper is to describe some nondeterministic methods, called Genetic Algorithms, designed to test the validity of the Andrews\u2013Curtis conjecture. Using such algorithm we have been able to prove that all known (to us) balanced presentations of the trivial group where the total length of the relators is at most 12 satisfy the conjecture. In particular, the Andrews\u2013Curtis conjecture holds for the presentation which was one of the well known potential counterexamples.", "venue": "Int. J. Algebra Comput.", "authors": ["Alexei D. Miasnikov"], "year": 1999, "n_citations": 29}
{"id": 1278986, "s2_id": "f4319959bf88f7fc0afd29a5be447e338e5f94db", "title": "Towards an exact adaptive algorithm for the determinant of a rational matrix", "abstract": "In this paper we propose several strategies for the exact computation of the determinant of a rational matrix. First, we use the Chinese Remaindering Theorem and the rational reconstruction to recover the rational determinant from its modular images. Then we show a preconditioning for the determinant which allows us to skip the rational reconstruction process and reconstruct an integer result. We compare those approaches with matrix preconditioning which allow us to treat integer instead of rational matrices. This allows us to introduce integer determinant algorithms to the rational determinant problem. In particular, we discuss the applicability of the adaptive determinant algorithm of [9] and compare it with the integer Chinese Remaindering scheme. We present an analysis of the complexity of the strategies and evaluate their experimental performance on numerous examples. This experience allows us to develop an adaptive strategy which would choose the best solution at the run time, depending on matrix properties. All strategies have been implemented in LinBox linear algebra library.", "venue": "ArXiv", "authors": ["Anna  Urbanska"], "year": 2007, "n_citations": 0}
{"id": 1281445, "s2_id": "73bb5e252d88da6bffda85b51bdcea6bf1340811", "title": "Algorithmic approach to strong consistency analysis of finite difference approximations to PDE systems", "abstract": "For a wide class of polynomially nonlinear systems of partial differential equations we suggest an algorithmic approach to the s(trong)-consistency analysis of their finite difference approximations on Cartesian grids. First we apply the differential Thomas decomposition to the input system, resulting in a partition of the solution set. We consider the output simple subsystem that contains a solution of interest. Then, for this subsystem, we suggest an algorithm for verification of s-consistency for its finite difference approximation. For this purpose we develop a difference analogue of the differential Thomas decomposition, both of which jointly allow to verify the s-consistency of the approximation. As an application of our approach, we show how to produce s-consistent difference approximations to the incompressible Navier-Stokes equations including the pressure Poisson equation.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt", "Daniel  Robertz"], "year": 2019, "n_citations": 5}
{"id": 1281604, "s2_id": "d2d5d59f1204a772eed6adda19601fe31692510b", "title": "Generalized Bruhat Decomposition in Commutative Domains", "abstract": "Deterministic recursive algorithms for the computation of generalized Bruhat decomposition of the matrix in commutative domain are presented. This method has the same complexity as the algorithm of matrix multiplication.", "venue": "CASC", "authors": ["Gennadi I. Malaschonok"], "year": 2013, "n_citations": 9}
{"id": 1288500, "s2_id": "52bdd32dd75fdbe81529cfbd6984a4e65587e10c", "title": "A Machine Learning Based Software Pipeline to Pick the Variable Ordering for Algorithms with Polynomial Inputs", "abstract": "We are interested in the application of Machine Learning (ML) technology to improve mathematical software. It may seem that the probabilistic nature of ML tools would invalidate the exact results prized by such software, however, the algorithms which underpin the software often come with a range of choices which are good candidates for ML application. We refer to choices which have no effect on the mathematical correctness of the software, but do impact its performance. In the past we experimented with one such choice: the variable ordering to use when building a Cylindrical Algebraic Decomposition (CAD). We used the Python library Scikit-Learn (sklearn) to experiment with different ML models, and developed new techniques for feature generation and hyper-parameter selection. These techniques could easily be adapted for making decisions other than our immediate application of CAD variable ordering. Hence in this paper we present a software pipeline to use sklearn to pick the variable ordering for an algorithm that acts on a polynomial system. The code described is freely available online.", "venue": "ICMS", "authors": ["Dorian  Florescu", "Matthew  England"], "year": 2020, "n_citations": 1}
{"id": 1293724, "s2_id": "0896f3ba4d78cedfc75d99b628754d9b11c18d88", "title": "Faster exponentials of power series", "abstract": "We describe a new algorithm for computing exp(f) where f is a power series in C[[x]]. If M(n) denotes the cost of multiplying polynomials of degree n, the new algorithm costs (2.1666... + o(1)) M(n) to compute exp(f) to order n. This improves on the previous best result, namely (2.333... + o(1)) M(n).", "venue": "ArXiv", "authors": ["David  Harvey"], "year": 2009, "n_citations": 2}
{"id": 1294368, "s2_id": "eecd715b12e87d39f755ddad92a202337f4bd94d", "title": "Unbounded Software Model Checking with Incremental SAT-Solving", "abstract": "This paper describes a novel unbounded software model checking approach to find errors in programs written in the C language based on incremental SAT-solving. Instead of using the traditional assumption based API to incremental SAT solvers we use the DimSpec format that is used in SAT based automated planning. A DimSpec formula consists of four CNF formulas representing the initial, goal and intermediate states and the relations between each pair of neighboring states of a transition system. We present a new tool called LLUMC which encodes the presence of certain errors in a C program into a DimSpec formula, which can be solved by either an incremental SAT-based DimSpec solver or the IC3 algorithm for invariant checking. We evaluate the approach in the context of SAT-based model checking for both the incremental SAT-solving and the IC3 algorithm. We show that our encoding expands the functionality of bounded model checkers by also covering large and infinite loops, while still maintaining a feasible time performance. Furthermore, we demonstrate that our approach offers the opportunity to generate runtime-optimizations by utilizing parallel SAT-solving.", "venue": "ArXiv", "authors": ["Marko Kleine B\u00fcning", "Tom\u00e1s  Balyo", "Carsten  Sinz"], "year": 2018, "n_citations": 0}
{"id": 1295033, "s2_id": "bb9b8e4042ec5550d29d24865d15fa4355020818", "title": "CLUE: Exact maximal reduction of kinetic models by constrained lumping of differential equations", "abstract": "MOTIVATION\nDetailed mechanistic models of biological processes can pose significant challenges for analysis and parameter estimations due to the large number of equations used to track the dynamics of all distinct configurations in which each involved biochemical species can be found. Model reduction can help tame such complexity by providing a lower-dimensional model in which each macro-variable can be directly related to the original variables.\n\n\nRESULTS\nWe present CLUE, an algorithm for exact model reduction of systems of polynomial differential equations by constrained linear lumping. It computes the smallest dimensional reduction as a linear mapping of the state space such that the reduced model preserves the dynamics of user-specified linear combinations of the original variables. Even though CLUE works with nonlinear differential equations, it is based on linear algebra tools, which makes it applicable to high-dimensional models. Using case studies from the literature, we show how CLUE can substantially lower model dimensionality and help extract biologically intelligible insights from the reduction.\n\n\nAVAILABILITY\nAn implementation of the algorithm and relevant resources to replicate the experiments herein reported are freely available for download at https://github.com/pogudingleb/CLUE.\n\n\nSUPPLEMENTARY INFORMATION\nSupplementary data are available at Bioinformatics online.", "venue": "Bioinform.", "authors": ["Alexey  Ovchinnikov", "Isabel Christina P\u00e9rez-Verona", "Gleb  Pogudin", "Mirco  Tribastone"], "year": 2021, "n_citations": 3}
{"id": 1295992, "s2_id": "965bfcdc2f5c99fa086166b530c99e87d23abaa2", "title": "Fast computation of approximant bases in canonical form", "abstract": "In this article, we design fast algorithms for the computation of approximant bases in shifted Popov normal form. We first recall the algorithm known as PM-Basis, which will be our second fundamental engine after polynomial matrix multiplication: most other fast approximant basis algorithms basically aim at efficiently reducing the input instance to instances for which PM-Basis is fast. Such reductions usually involve partial linearization techniques due to Storjohann, which have the effect of balancing the degrees and dimensions in the manipulated matrices. \nFollowing these ideas, Zhou and Labahn gave two algorithms which are faster than PM-Basis for important cases including Hermite-Pade approximation, yet only for shifts whose values are concentrated around the minimum or the maximum value. The three mentioned algorithms were designed for balanced orders and compute approximant bases that are generally not normalized. Here, we show how they can be modified to return the shifted Popov basis without impact on their cost bound; besides, we extend Zhou and Labahn's algorithms to arbitrary orders. \nFurthermore, we give an algorithm which handles arbitrary shifts with one extra logarithmic factor in the cost bound compared to the above algorithms. To the best of our knowledge, this improves upon previously known algorithms for arbitrary shifts, including for particular cases such as Hermite-Pade approximation. This algorithm is based on a recent divide and conquer approach which reduces the general case to the case where information on the output degree is available. As outlined above, we solve the latter case via partial linearizations and PM-Basis.", "venue": "J. Symb. Comput.", "authors": ["Claude-Pierre  Jeannerod", "Vincent  Neiger", "Gilles  Villard"], "year": 2020, "n_citations": 9}
{"id": 1297762, "s2_id": "1e5346b582489a4b843a73f5966d86eb06010da9", "title": "Generic bivariate multi-point evaluation, interpolation and modular composition with precomputation", "abstract": "Suppose K is a large enough field and P \u2282 K2 is a fixed, generic set of points which is available for precomputation. We introduce a technique called reshaping which allows us to design quasi-linear algorithms for both: computing the evaluations of an input polynomial f \u2208 K [x, y] at all points of P and computing an interpolant f \u2208 K[x, y] which takes prescribed values on P and satisfies an input y-degree bound. Our genericity assumption is explicit and we prove that it holds for most point sets over a large enough field. If P violates the assumption, our algorithms still work and the performance degrades smoothly according to a distance from being generic. To show that the reshaping technique may have an impact on other related problems, we apply it to modular composition: suppose generic polynomials M \u2208 K[x] and A \u2208 K[x] are available for precomputation, then given an input f \u2208 K[x, y] we show how to compute f (x, A(x)) rem M(x) in quasi-linear time.", "venue": "ISSAC", "authors": ["Vincent  Neiger", "Johan  Rosenkilde", "Grigory  Solomatov"], "year": 2020, "n_citations": 3}
{"id": 1303432, "s2_id": "d85941cf2d87a5307eed4d2a7828e2d06d4cc554", "title": "Decoupled molecules with binding polynomials of bidegree (n, 2)", "abstract": "We present a result on the number of decoupled molecules for systems binding two different types of ligands. In the case of n and 2 binding sites respectively, we show that there are $$2(n!)^{2}$$2(n!)2 decoupled molecules to a generic binding polynomial. For molecules with more binding sites for the second ligand, we provide computational results.", "venue": "Journal of mathematical biology", "authors": ["Yue  Ren", "Johannes W. R. Martini", "Jacinta  Torres"], "year": 2019, "n_citations": 2}
{"id": 1304413, "s2_id": "c5df3dd4cd537f22d39a476004dd9dab18179203", "title": "New Symbolic Algorithms For Solving A General Bordered Tridiagonal Linear System", "abstract": "In this paper, the author present reliable symbolic algorithms for solving a general bordered tridiagonal linear system. The first algorithm is based on the LU decomposition of the coefficient matrix and the computational cost of it is O(n). The second is based on The Sherman-Morrison-Woodbury formula. The algorithms are implementable to the Computer Algebra System (CAS) such as MAPLE, MATLAB and MATHEMATICA. Three examples are presented for the sake of illustration.", "venue": "ArXiv", "authors": ["A. A. Karawia"], "year": 2013, "n_citations": 2}
{"id": 1306611, "s2_id": "bd998f076cb0f45fc176c2bcff5055fcad90fa86", "title": "Effective Localization Using Double Ideal Quotient and Its Implementation", "abstract": "In this paper, we propose a new method for localization of polynomial ideal, which we call \u201cLocal Primary Algorithm\u201d. For an ideal I and a prime ideal P, our method computes a P-primary component of I after checking if P is associated with I by using double ideal quotient (I : (I : P)) and its variants which give us a lot of information about localization of I.", "venue": "CASC", "authors": ["Yuki  Ishihara", "Kazuhiro  Yokoyama"], "year": 2018, "n_citations": 2}
{"id": 1310654, "s2_id": "1dad7e23942d379c2bcb5877adf84043bf249df5", "title": "Root isolation of zero-dimensional polynomial systems with linear univariate representation", "abstract": "In this paper, a linear univariate representation for the roots of a zero-dimensional polynomial equation system is presented, where the complex roots of the polynomial system are represented as linear combinations of the roots of several univariate polynomial equations. An algorithm is proposed to compute such a representation for a given zero-dimensional polynomial equation system based on Grobner basis computation. The main advantage of this representation is that the precision of the roots of the system can be easily controlled. In fact, based on the linear univariate representation, we can give the exact precisions needed for isolating the roots of the univariate equations in order to obtain roots of the polynomial system with a given precision. As a consequence, a root isolating algorithm for a zero-dimensional polynomial equation system can be easily derived from its linear univariate representation.", "venue": "J. Symb. Comput.", "authors": ["Jin-San  Cheng", "Xiao-Shan  Gao", "Leilei  Guo"], "year": 2012, "n_citations": 15}
{"id": 1310969, "s2_id": "4965d2b208aa8a00a6ca0f2ffb879f9c5649a351", "title": "A Deep Genetic Programming based Methodology for Art Media Classification Robust to Adversarial Perturbations", "abstract": "Art Media Classification problem is a current research area that has attracted attention due to the complex extraction and analysis of features of high-value art pieces. The perception of the attributes can not be subjective, as humans sometimes follow a biased interpretation of artworks while ensuring automated observation's trustworthiness. Machine Learning has outperformed many areas through its learning process of artificial feature extraction from images instead of designing handcrafted feature detectors. However, a major concern related to its reliability has brought attention because, with small perturbations made intentionally in the input image (adversarial attack), its prediction can be completely changed. In this manner, we foresee two ways of approaching the situation: (1) solve the problem of adversarial attacks in current neural networks methodologies, or (2) propose a different approach that can challenge deep learning without the effects of adversarial attacks. The first one has not been solved yet, and adversarial attacks have become even more complex to defend. Therefore, this work presents a Deep Genetic Programming method, called Brain Programming, that competes with deep learning and studies the transferability of adversarial attacks using two artworks databases made by art experts. The results show that the Brain Programming method preserves its performance in comparison with AlexNet, making it robust to these perturbations and competing to the performance of Deep Learning.", "venue": "ISVC", "authors": ["Gustavo  Olague", "Gerardo  Ibarra-Vazquez", "Mariana  Chan-Ley", "Cesar  Puente", "Carlos  Soubervielle-Montalvo", "Axel  Martinez"], "year": 2020, "n_citations": 3}
{"id": 1312989, "s2_id": "7f6258a6dd0e20c9dcf83ef65c84d64a89afdef2", "title": "Towards Efficient Normalizers of Primitive Groups", "abstract": "We present the ideas behind an algorithm to compute normalizers of primitive groups with non-regular socle in polynomial time. We highlight a concept we developed called permutation morphisms and present timings for a partial implementation of our algorithm. This article is a collection of results from the author\u2019s PhD thesis.", "venue": "ICMS", "authors": ["Sergio  Siccha"], "year": 2020, "n_citations": 0}
{"id": 1314606, "s2_id": "c438fb15f35c341d376773580fe12b64982fe459", "title": "Exact algorithms for semidefinite programs with degenerate feasible set", "abstract": "Abstract Given symmetric matrices A 0 , A 1 , \u2026 , A n of size m with rational entries, the set of real vectors x = ( x 1 , \u2026 , x n ) such that the matrix A 0 + x 1 A 1 + \u22ef + x n A n has non-negative eigenvalues is called a spectrahedron. Minimization of linear functions over spectrahedra is called semidefinite programming. Such problems appear frequently in control theory and real algebra, especially in the context of nonnegativity certificates for multivariate polynomials based on sums of squares. Numerical software for semidefinite programming are mostly based on interior point methods, assuming non-degeneracy properties such as the existence of an interior point in the spectrahedron. In this paper, we design an exact algorithm based on symbolic homotopy for solving semidefinite programs without assumptions on the feasible set, and we analyze its complexity. Because of the exactness of the output, it cannot compete with numerical routines in practice. However, we prove that solving such problems can be done in polynomial time if either n or m is fixed.", "venue": "J. Symb. Comput.", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2021, "n_citations": 0}
{"id": 1315650, "s2_id": "54b9191ad1a2633793d9714075cd343c0e0fac94", "title": "Rigorous uniform approximation of D-finite functions using Chebyshev expansions", "abstract": "A wide range of numerical methods exists for computing polynomial approximations of solutions of ordinary differential equations based on Chebyshev series expansions or Chebyshev interpolation polynomials. We consider the application of such methods in the context of rigorous computing (where we need guarantees on the accuracy of the result), and from the complexity point of view. It is well-known that the order-n truncation of the Chebyshev expansion of a function over a given interval is a near-best uniform polynomial approximation of the function on that interval. In the case of solutions of linear differential equations with polynomial coefficients, the coefficients of the expansions obey linear recurrence relations with polynomial coefficients. Unfortunately, these recurrences do not lend themselves to a direct recursive computation of the coefficients, owing among other things to a lack of initial conditions. We show how they can nevertheless be used, as part of a validated process, to compute good uniform approximations of D-finite functions together with rigorous error bounds, and we study the complexity of the resulting algorithms. Our approach is based on a new view of a classical numerical method going back to Clenshaw, combined with a functional enclosure method.", "venue": "Math. Comput.", "authors": ["Alexandre  Benoit", "Mioara  Joldes", "Marc  Mezzarobba"], "year": 2017, "n_citations": 11}
{"id": 1320025, "s2_id": "c4bbad3c9a8bc1dbf446692d44c231997ceb96c4", "title": "Parameterized Telescoping Proves Algebraic Independence of Sums", "abstract": "Usually creative telescoping is used to derive recurrences for sums. In this article we show that the non-existence of a creative telescoping solution, and more generally, of a parameterized telescoping solution, proves algebraic independence of certain types of sums. Combining this fact with summation-theory shows transcendence of whole classes of sums. Moreover, this result throws new light on the question why, for example, Zeilberger\u2019s algorithm fails to find a recurrence with minimal order.", "venue": "ArXiv", "authors": ["Carsten  Schneider"], "year": 2008, "n_citations": 90}
{"id": 1322276, "s2_id": "83bf3358d6eec9c86f1da70238a164f4b699a789", "title": "Positional Games and QBF: The Corrective Encoding", "abstract": "Positional games are a mathematical class of two-player games comprising Tic-tac-toe and its generalizations. We propose a novel encoding of these games into Quantified Boolean Formulas (QBFs) such that a game instance admits a winning strategy for first player if and only if the corresponding formula is true. Our approach improves over previous QBF encodings of games in multiple ways. First, it is generic and lets us encode other positional games, such as Hex. Second, structural properties of positional games together with a careful treatment of illegal moves let us generate more compact instances that can be solved faster by state-of-the-art QBF solvers. We establish the latter fact through extensive experiments. Finally, the compactness of our new encoding makes it feasible to translate realistic game problems. We identify a few such problems of historical significance and put them forward to the QBF community as milestones of increasing difficulty.", "venue": "SAT", "authors": ["Valentin  Mayer-Eichberger", "Abdallah  Saffidine"], "year": 2020, "n_citations": 2}
{"id": 1326618, "s2_id": "7caabceac686c5d14812384509845b9add08983a", "title": "Fast Computation of the N-th Term of a q-Holonomic Sequence and Applications", "abstract": "In 1977, Strassen invented a famous baby-step/giant-step algorithm that computes the factorial $N!$ in arithmetic complexity quasi-linear in $\\sqrt{N}$. In 1988, the Chudnovsky brothers generalized Strassen's algorithm to the computation of the $N$-th term of any holonomic sequence in essentially the same arithmetic complexity. We design $q$-analogues of these algorithms. We first extend Strassen's algorithm to the computation of the $q$-factorial of $N$, then Chudnovskys' algorithm to the computation of the $N$-th term of any $q$-holonomic sequence. Both algorithms work in arithmetic complexity quasi-linear in $\\sqrt{N}$; surprisingly, they are simpler than their analogues in the holonomic case. We provide a detailed cost analysis, in both arithmetic and bit complexity models. Moreover, we describe various algorithmic consequences, including the acceleration of polynomial and rational solving of linear $q$-differential equations, and the fast evaluation of large classes of polynomials, including a family recently considered by Nogneng and Schost.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Sergey  Yurkevich"], "year": 2020, "n_citations": 0}
{"id": 1327108, "s2_id": "8812b22f8c0719f3128fb3b56b9dbcd3435b4660", "title": "Realcertify: a maple package for certifying non-negativity", "abstract": "Let Q (resp. R) be the field of rational (resp. real) numbers and <i>X</i> = (<i>X</i><sub>1</sub>, ... , <i>X<sub>n</sub></i>) be variables. Deciding the non-negativity of polynomials in Q[<i>X</i>] over R<sup><i>n</i></sup> or over semi-algebraic domains defined by polynomial constraints in Q[<i>X</i>] is a classical algorithmic problem for symbolic computation.\n The Maple package R<scp>eal</scp>C<scp>ertify</scp> tackles this decision problem by computing sum of squares certificates of non-negativity for inputs where such certificates hold over the rational numbers. It can be applied to numerous problems coming from engineering sciences, program verification and cyber-physical systems. It is based on hybrid symbolic-numeric algorithms based on semi-definite programming.", "venue": "ACCA", "authors": ["Victor  Magron", "Mohab Safey El Din"], "year": 2018, "n_citations": 12}
{"id": 1327763, "s2_id": "e2c709b9c9ac7095c31760a511dc48d35171a11d", "title": "On the complexity of computing with planar algebraic curves", "abstract": "In this paper, we give improved bounds for the computational complexity of computing with planar algebraic curves. More specifically, for arbitrary coprime polynomials $f$, $g \\in \\mathbb{Z}[x,y]$ and an arbitrary polynomial $h \\in \\mathbb{Z}[x,y]$, each of total degree less than $n$ and with integer coefficients of absolute value less than $2^\\tau$, we show that each of the following problems can be solved in a deterministic way with a number of bit operations bounded by $\\tilde{O}(n^6+n^5\\tau)$, where we ignore polylogarithmic factors in $n$ and $\\tau$: \n(1) The computation of isolating regions in $\\mathbb{C}^2$ for all complex solutions of the system $f = g = 0$, \n(2) the computation of a separating form for the solutions of $f = g = 0$, \n(3) the computation of the sign of $h$ at all real valued solutions of $f = g = 0$, and \n(4) the computation of the topology of the planar algebraic curve $\\mathcal{C}$ defined as the real valued vanishing set of the polynomial $f$. \nOur bound improves upon the best currently known bounds for the first three problems by a factor of $n^2$ or more and closes the gap to the state-of-the-art randomized complexity for the last problem.", "venue": "J. Complex.", "authors": ["Alexander  Kobel", "Michael  Sagraloff"], "year": 2015, "n_citations": 28}
{"id": 1329050, "s2_id": "f25b3b0f46533d06f68c3a6af671f67c8ad28b88", "title": "An implementation of CAD in Maple utilising problem formulation, equational constraints and truth-table invariance", "abstract": "Cylindrical algebraic decomposition (CAD) is an important tool for the investigation of semi-algebraic sets, with applications within algebraic geometry and beyond. We recently reported on a new implementation of CAD in Maple which implemented the original algorithm of Collins and the subsequent improvement to projection by McCallum. Our implementation was in contrast to Maple\u2019s in-built CAD command, based on a quite separate theory. Although initially developed as an investigative tool to compare the algorithms, we found and reported that our code offered functionality not currently available in any other existing implementations. One particularly important piece of functionality is the ability to produce order-invariant CADs. This has allowed us to extend the implementation to produce CADs invariant with respect to either equational constraints (ECCADs) or the truth-tables of sequences of formulae (TTICADs). This new functionality is contained in the second release of our code, along with commands to consider problem formulation which can be a major factor in the tractability of a CAD. In the report we describe the new functionality and some theoretical discoveries it prompted. We describe how the CADs produced using equational constraints are able to take advantage of not just improved projection but also improvements in the lifting phase. We also present an extension to the original TTICAD algorithm which increases both the applicability of TTICAD and its relative benefit over other algorithms. The code and an introductory Maple worksheet / pdf demonstrating the full functionality of the package should accompany this report.", "venue": "ArXiv", "authors": ["Matthew  England"], "year": 2013, "n_citations": 12}
{"id": 1331665, "s2_id": "149044bc6069030e9bd90c1915b0c41b707cdfac", "title": "SANM: A Symbolic Asymptotic Numerical Solver with Applications in Mesh Deformation", "abstract": "(a) Inverse gravity equilibrium with incompressible neo-Hookean material. This figure shows a rest shape that will deform to the original Armadillo under gravity. (b) Gravity equilibrium with compressible neo-Hookean material. This figure shows the final shape to which an Armadillo will deform under gravity. (c) Controlled deformation of the Bob model with incompressible neo-Hookean material by fixing the head and moving the tail. Top: rest shape. Bottom: deformed shape. Model created by Keenan Crane. (d) Controlled deformation via twisting and bending a horozontal bar with the As-Rigid-AsPossible (ARAP) energy.", "venue": "ACM Trans. Graph.", "authors": ["Kai  Jia"], "year": 2021, "n_citations": 0}
{"id": 1341781, "s2_id": "c393ea169f3703658e8c1764748bb01e69cb2927", "title": "Exceptional points and domains of unitarity for a class of strongly non-Hermitian real-matrix Hamiltonians", "abstract": "A family of non-Hermitian real and tridiagonal-matrix candidates H(\u03bb) = H (N) 0 + \u03bbW (\u03bb) for a hiddenly Hermitian (a.k.a. quasi-Hermitian) quantum Hamiltonian is proposed and studied. Fairly weak assumptions are imposed upon the unperturbed matrix (the square-well-simulating spectrum of H (N) 0 is not assumed equidistant) as well as upon its maximally non-Hermitian N\u2212parametric antisymmetric-matrix perturbations (matrix W (\u03bb) is not even required to be PT \u2212symmetric). In spite of that, the \u201cphysical\u201d parametric domain D[N ] is (constructively!) shown to exist, guaranteeing that in its interior the spectrum remains real and non-degenerate, rendering the quantum evolution unitary. Among the non-Hermitian degeneracies occurring at the boundary \u2202D[N ] of the domain of stability our main attention is paid to their extreme version corresponding to the Kato\u2019s exceptional point of order N (EPN). The localization of the EPNs and, in their vicinity, of the quantum-phase-transition boundaries \u2202D[N ] is found feasible, at the not too large N , using computer-assisted symbolic manipulations including, in particular, the Gr\u00f6bner basis elimination and the high-precision arithmetics.", "venue": "Journal of Mathematical Physics", "authors": ["Miloslav  Znojil"], "year": 2021, "n_citations": 0}
{"id": 1360685, "s2_id": "b22781e614812af00e6db1693bbd74691ee284b8", "title": "Exact algorithms for linear matrix inequalities", "abstract": "Let $A(x)=A\\_0+x\\_1A\\_1+...+x\\_nA\\_n$ be a linear matrix, or pencil, generated by given symmetric matrices $A\\_0,A\\_1,...,A\\_n$ of size $m$ with rational entries. The set of real vectors x such that the pencil is positive semidefinite is a convex semi-algebraic set called spectrahedron, described by a linear matrix inequality (LMI). We design an exact algorithm that, up to genericity assumptions on the input matrices, computes an exact algebraic representation of at least one point in the spectrahedron, or decides that it is empty. The algorithm does not assume the existence of an interior point, and the computed point minimizes the rank of the pencil on the spectrahedron. The degree $d$ of the algebraic representation of the point coincides experimentally with the algebraic degree of a generic semidefinite program associated to the pencil. We provide explicit bounds for the complexity of our algorithm, proving that the maximum number of arithmetic operations that are performed is essentially quadratic in a multilinear B\\'ezout bound of $d$. When $m$ (resp. $n$) is fixed, such a bound, and hence the complexity, is polynomial in $n$ (resp. $m$). We conclude by providing results of experiments showing practical improvements with respect to state-of-the-art computer algebra algorithms.", "venue": "SIAM J. Optim.", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2016, "n_citations": 39}
{"id": 1361379, "s2_id": "d755b3074b224c231c0db69829880b00ecf1013f", "title": "From Big-Step to Small-Step Semantics and Back with Interpreter Specialisation", "abstract": "We investigate representations of imperative programs as constrained Horn clauses. Starting from operational semantics transition rules, we proceed by writing interpreters as constrained Horn clause programs directly encoding the rules. We then specialise an interpreter with respect to a given source program to achieve a compilation of the source language to Horn clauses (an instance of the first Futamura projection). The process is described in detail for an interpreter for a subset of C, directly encoding the rules of big-step operational semantics for C. A similar translation based on small-step semantics could be carried out, but we show an approach to obtaining a small-step representation using a linear interpreter for big-step Horn clauses. This interpreter is again specialised to achieve the translation from big-step to small-step style. The linear small-step program can be transformed back to a big-step non-linear program using a third interpreter. A regular path expression is computed for the linear program using Tarjan's algorithm, and this regular expression then guides an interpreter to compute a program path. The transformation is realised by specialisation of the path interpreter. In all of the transformation phases, we use an established partial evaluator and exploit standard logic program transformation to remove redundant data structures and arguments in predicates and rename predicates to make clear their link to statements in the original source program.", "venue": "VPT/HCVS@ETAPS", "authors": ["John P. Gallagher", "Manuel V. Hermenegildo", "Bishoksan  Kafle", "Maximiliano  Klemen", "Pedro  L\u00f3pez-Garc\u00eda", "Jos\u00e9  Morales"], "year": 2020, "n_citations": 7}
{"id": 1361498, "s2_id": "e1905e943f29ecf4cdbdbcf393d1608694866366", "title": "Resultants and subresultants of p-adic polynomials", "abstract": "We address the problem of the stability of the computations of resultants and subresultants of polynomials defined over complete discrete valuation rings (e.g. Zp or k[[t]] where k is a field). We prove that Euclide-like algorithms are highly unstable on average and we explain, in many cases, how one can stabilize them without sacrifying the complexity. On the way, we completely determine the distribution of the valuation of the principal subresultants of two random monic p-adic polynomials having the same degree.", "venue": "ArXiv", "authors": ["Xavier  Caruso"], "year": 2015, "n_citations": 3}
{"id": 1366330, "s2_id": "c77394020885f33a2d0501287f9402334608bc4d", "title": "A sufficient condition for local nonnegativity", "abstract": "A real polynomial $f$ is called local nonnegative at a point $p$, if it is nonnegative in a neighbourhood of $p$. In this paper, a sufficient condition for determining this property is constructed. Newton's principal part of $f$ (denoted as $f_N$) plays a key role in this process. We proved that if every $F$-face, $(f_N)_F$, of $f_N$ is strictly positive over $(\\mathbb{R}\\setminus 0)^n$, then $f$ is local nonnegative at the origin $O$.", "venue": "ArXiv", "authors": ["Jia  Xu", "Yong  Yao"], "year": 2019, "n_citations": 0}
{"id": 1373631, "s2_id": "94d7fcf94b166636c1ebca72b8d9adf83a30384d", "title": "A comparison of four approaches to the calculation of conservation laws", "abstract": "The paper compares computational aspects of four approaches to compute conservation laws of single Differential Equations (DEs) or systems of them, ODEs and PDEs. The only restriction, required by two of the four corresponding computer algebra programs, is that each DE has to be solvable for a leading derivative. Extra constraints for the conservation laws can be specified. Examples include new conservation laws that are non-polynomial in the functions, that have an explicit variable dependence and families of conservation laws involving arbitrary functions. The following equations are investigated in examples: Ito, Liouville, Burgers, Kadomtsev\u2013Petviashvili, Karney\u2013Sen\u2013Chu\u2013Verheest, Boussinesq, Tzetzeica, Benney.", "venue": "European Journal of Applied Mathematics", "authors": ["Thomas  Wolf"], "year": 2002, "n_citations": 150}
{"id": 1374582, "s2_id": "80c3580ae15f418150adf2da54a26f05e6193df4", "title": "Hypergeometric Structures in Feynman Integrals", "abstract": "Hypergeometric structures in single and multiscale Feynman integrals emerge in a wide class of topologies. Using integration-by-parts relations, associated master or scalar integrals have to be calculated. For this purpose it appears useful to devise an automated method which recognizes the respective (partial) differential equations related to the corresponding higher transcendental functions. We solve these equations through associated recursions of the expansion coefficient of the multivalued formal Taylor series. The expansion coefficients can be determined using either the package Sigma in the case of linear difference equations or by applying heuristic methods in the case of partial linear difference equations. In the present context a new type of sums occurs, the Hurwitz harmonic sums, and generalized versions of them. The code HypSeries transforming classes of differential equations into analytic series expansions is described. Also partial difference equations having rational solutions and rational function solutions of Pochhammer symbols are considered, for which the code solvePartialLDE is designed. Generalized hypergeometric functions, Appell-, Kamp\u00e9 de F\u00e9riet-, Horn-, Lauricella-Saran-, Srivasta-, and Exton\u2013type functions are considered. We illustrate the algorithms by examples.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "M.  Saragnese", "Carsten  Schneider"], "year": 2021, "n_citations": 0}
{"id": 1384223, "s2_id": "dda87a27be2d2874cd773d5470a18f0c8ebfc1d9", "title": "A Tropical F5 Algorithm", "abstract": "Let K be a field equipped with a valuation. Tropical varieties over K can be defined with a theory of Gr\u00f6bner bases taking into account the valuation of K. While generalizing the classical theory of Gr\u00f6bner bases, it is not clear how modern algorithms for computing Gr\u00f6bner bases can be adapted to the tropical case. Among them, one of the most efficient is the celebrated F5 Algorithm of Faug\u00e8re. In this article, we prove that, for homogeneous ideals, it can be adapted to the tropical case. We prove termination and correctness. Because of the use of the valuation, the theory of tropical Gr\u00f6bner bases is promising for stable computations over polynomial rings over a p-adic field. We provide numerical examples to illustrate time-complexity and p-adic stability of this tropical F5 algorithm.", "venue": "ISSAC", "authors": ["Tristan  Vaccon", "Kazuhiro  Yokoyama"], "year": 2017, "n_citations": 10}
{"id": 1386152, "s2_id": "6a6bf43dece04031eefadba2237179e7234d2522", "title": "Linear Time Interactive Certificates for the Minimal Polynomial and the Determinant of a Sparse Matrix", "abstract": "Computational problem certificates are additional data structures for each output, which can be used by a---possibly randomized---verification algorithm that proves the correctness of each output. In this paper, we give an algorithm that computes a certificate for the minimal polynomial of sparse or structured matrices over an abstract field, of sufficiently large cardinality, whose Monte Carlo verification complexity requires a single matrix-vector multiplication and a linear number of extra field operations. We also propose a novel preconditioner that ensures irreducibility of the characteristic polynomial of the generically preconditioned matrix. This preconditioner takes linear time to be applied and uses only two random entries. We then combine these two techniques to give algorithms that compute certificates for the determinant, and thus for the characteristic polynomial, whose Monte Carlo verification complexity is therefore also linear.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "Erich  Kaltofen", "Emmanuel  Thom\u00e9", "Gilles  Villard"], "year": 2016, "n_citations": 14}
{"id": 1391262, "s2_id": "75ff8230802de7c5bfce770ecaae9869499e5c25", "title": "Some results on counting roots of polynomials and the Sylvester resultant", "abstract": "We present two results, the first on the distribution of the roots of a polynomial over the ring of integers modulo $n$ and the second on the distribution of the roots of the Sylvester resultant of two multivariate polynomials. The second result has application to polynomial GCD computation and solving polynomial diophantine equations.", "venue": "ArXiv", "authors": ["Michael B. Monagan", "Baris  Tuncer"], "year": 2016, "n_citations": 4}
{"id": 1391964, "s2_id": "caae11fb20c4c7dfda1a634072ac4a6a17d0d3e1", "title": "Yet another eigenvalue algorithm for solving polynomial systems", "abstract": "In latest years, several advancements have been made in symbolic-numerical eigenvalue techniques for solving polynomial systems. In this article, we add to this list by reducing the task to an eigenvalue problem in a considerably faster and simpler way than in previous methods. This results in an algorithm which solves systems with isolated solutions reliably and efficiently, outperforming homotopy methods in overdetermined cases. We provide an implementation in the proof-ofconcept Julia package EigenvalueSolver.jl.", "venue": "ArXiv", "authors": ["Mat'ias R. Bender", "Simon  Telen"], "year": 2021, "n_citations": 2}
{"id": 1393881, "s2_id": "4f2d58eb9573f2ded949b84945b9f0c5c9b57f4f", "title": "Minimal Polynomial Algorithms for Finite Sequences", "abstract": "In this paper, we show that a straightforward rewrite of a known minimal polynomial algorithm yields a simpler version of an algorithm in a recent paper of A. Salagean.", "venue": "IEEE Transactions on Information Theory", "authors": ["Graham H. Norton"], "year": 2010, "n_citations": 5}
{"id": 1395238, "s2_id": "8cc44cb722704bc185b26583b932205f04bc8ce3", "title": "Verifying Quantized Neural Networks using SMT-Based Model Checking", "abstract": "Artificial Neural Networks (ANNs) are being deployed on an increasing number of safety-critical applications, including autonomous cars and medical diagnosis. However, concerns about their reliability have been raised due to their black-box nature and apparent fragility to adversarial attacks. Here, we develop and evaluate a symbolic verification framework using incremental model checking (IMC) and satisfiability modulo theories (SMT) to check for vulnerabilities in ANNs. More specifically, we propose several ANN-related optimizations for IMC, including invariant inference via interval analysis and the discretization of non-linear activation functions. With this, we can provide guarantees on the safe behavior of ANNs implemented both in floatingpoint and fixed-point (quantized) arithmetic. In this regard, our verification approach was able to verify and produce adversarial examples for 52 test cases spanning image classification and general machine learning applications. For smallto medium-sized ANN, our approach completes most of its verification runs in minutes. Moreover, in contrast to most state-of-the-art methods, our approach is not restricted to specific choices of activation functions or non-quantized representations.", "venue": "ArXiv", "authors": ["Luiz  Sena", "Xidan  Song", "Erickson  Alves", "Iury  Bessa", "Edoardo  Manino", "Lucas  Cordeiro"], "year": 2021, "n_citations": 1}
{"id": 1395808, "s2_id": "0b13691fd9b1cc9ee660282de1a6402e4daebb91", "title": "Chapter 10: Algebraic Algorithms", "abstract": "Our Chapter in the upcoming Volume I: Computer Science and Software Engineering of Computing Handbook (Third edition), Allen Tucker, Teo Gonzales and Jorge L. Diaz-Herrera, editors, covers Algebraic Algorithms, both symbolic and numerical, for matrix computations and root-finding for polynomials and systems of polynomials equations. We cover part of these large subjects and include basic bibliography for further study. To meet space limitation we cite books, surveys, and comprehensive articles with pointers to further references, rather than including all the original technical papers.", "venue": "ArXiv", "authors": ["Ioannis Z. Emiris", "Victor Y. Pan", "Elias P. Tsigaridas"], "year": 2013, "n_citations": 1}
{"id": 1395819, "s2_id": "2d6f1531b35811161f9a83d84d9a82293e5f3fde", "title": "Sparse Polynomial Systems with many Positive Solutions from Bipartite Simplicial Complexes", "abstract": "Consider a regular triangulation of the convex-hull $P$ of a set $\\mathcal A$ of $n$ points in $\\mathbb R^d$, and a real matrix $C$ of size $d \\times n$. A version of Viro's method allows to construct from these data an unmixed polynomial system with support $\\mathcal A$ and coefficient matrix $C$ whose number of positive solutions is bounded from below by the number of $d$-simplices which are positively decorated by $C$. We show that all the $d$-simplices of a triangulation can be positively decorated if and only if the triangulation is balanced, which in turn is equivalent to the fact that its dual graph is bipartite. This allows us to identify, among classical families, monomial supports which admit maximally positive systems, i.e. systems all toric complex solutions of which are real and positive. These families give some evidence in favor of a conjecture due to Bihan. We also use this technique in order to construct fewnomial systems with many positive solutions. This is done by considering a simplicial complex with bipartite dual graph included in a regular triangulation of the cyclic polytope.", "venue": "ArXiv", "authors": ["Fr\u00e9d\u00e9ric  Bihan", "Pierre-Jean  Spaenlehauer"], "year": 2015, "n_citations": 2}
{"id": 1396030, "s2_id": "9dbfcc1a3ce481092ebfe672f779975957c6076f", "title": "An interface between physics and number theory", "abstract": "We extend the Hopf algebra description of a simple quantum system given previously, to a more elaborate Hopf algebra, which is rich enough to encompass that related to a description of perturbative quantum field theory (pQFT). This provides a mathematical route from an algebraic description of non-relativistic, non-field theoretic quantum statistical mechanics to one of relativistic quantum field theory. Such a description necessarily involves treating the algebra of polyzeta functions, extensions of the Riemann Zeta function, since these occur naturally in pQFT. This provides a link between physics, algebra and number theory. As a by-product of this approach, we are led to indicate inter alia a basis for concluding that the Euler gamma constant \u03b3 may be rational.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Vincel Hoang Ngoc Minh", "Allan I. Solomon", "Silvia  Goodenough"], "year": 2010, "n_citations": 5}
{"id": 1396882, "s2_id": "60cd57e71ac8f105f004cc1d23c907515ea99b0c", "title": "Sparse univariate polynomials with many roots over finite fields", "abstract": "Suppose $q$ is a prime power and $f\\in\\mathbb{F}_q[x]$ is a univariate polynomial with exactly $t$ monomial terms and degree $<q-1$. To establish a finite field analogue of Descartes' Rule, Bi, Cheng, and Rojas (2013) proved an upper bound of $2(q-1)^{\\frac{t-2}{t-1}}$ on the number of cosets in $\\mathbb{F}^*_q$ needed to cover the roots of $f$ in $\\mathbb{F}^*_q$. Here, we give explicit $f$ with root structure approaching this bound: For $q$ a $(t-1)$-st power of a prime we give an explicit $t$-nomial vanishing on $q^{\\frac{t-2}{t-1}}$ distinct cosets of $\\mathbb{F}^*_q$. Over prime fields $\\mathbb{F}_p$, computational data we provide suggests that it is harder to construct explicit sparse polynomials with many roots. Nevertheless, assuming the Generalized Riemann Hypothesis, we find explicit trinomials having $\\Omega\\left(\\frac{\\log p}{\\log \\log p}\\right)$ distinct roots in $\\mathbb{F}_p$.", "venue": "Finite Fields Their Appl.", "authors": ["Qi  Cheng", "Shuhong  Gao", "J. Maurice Rojas", "Daqing  Wan"], "year": 2017, "n_citations": 17}
{"id": 1402029, "s2_id": "cae664b5c70da3bbde3e557f9df05afc0ec09799", "title": "Harmonic Sums, Polylogarithms, Special Numbers, and their Generalizations", "abstract": "In these introductory lectures we discuss classes of presently known nested sums, associated iterated integrals, and special constants which hierarchically appear in the evaluation of massless and massive Feynman diagrams at higher loops. These quantities are elements of stuffle and shuffle algebras implying algebraic relations being widely independent of the special quantities considered. They are supplemented by structural relations. The generalizations are given in terms of generalized harmonic sums, (generalized) cyclotomic sums, and sums containing in addition binomial and inverse-binomial weights. To all these quantities iterated integrals and special numbers are associated. We also discuss the analytic continuation of nested sums of different kind to complex values of the external summation bound N.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein"], "year": 2013, "n_citations": 37}
{"id": 1410622, "s2_id": "471f58c1459ab4087ef42b07c947775cd88d3bfa", "title": "Truncated normal forms for solving polynomial systems: Generalized and efficient algorithms", "abstract": "We consider the problem of finding the isolated common roots of a set of polynomial functions defining a zero-dimensional ideal I in a ring R of polynomials over C. Normal form algorithms provide an algebraic approach to solve this problem. The framework presented in Telen et al. (2018) uses truncated normal forms (TNFs) to compute the algebra structure of R/I and the solutions of I. This framework allows for the use of much more general bases than the standard monomials for R/I. This is exploited in this paper to introduce the use of two special (nonmonomial) types of basis functions with nice properties. This allows, for instance, to adapt the basis functions to the expected location of the roots of I. We also propose algorithms for efficient computation of TNFs and a generalization of the construction of TNFs in the case of non-generic zero-dimensional systems. The potential of the TNF method and usefulness of the new results are exposed by many experiments.", "venue": "J. Symb. Comput.", "authors": ["Bernard  Mourrain", "Simon  Telen", "Marc Van Barel"], "year": 2021, "n_citations": 5}
{"id": 1411410, "s2_id": "0b924c1ab3d37b5f6af8d5f7ae2ccbcc89d0a31d", "title": "Covering rational ruled surfaces", "abstract": "We present an algorithm that covers any given rational ruled surface with two rational parametrizations. In addition, we present an algorithm that transforms any rational surface parametrization into a new rational surface parametrization without affine base points and such that the degree of the corresponding maps is preserved.", "venue": "Math. Comput.", "authors": ["J. Rafael Sendra", "David  Sevilla", "Carlos  Villarino"], "year": 2017, "n_citations": 13}
{"id": 1415194, "s2_id": "9c86efbc0163ecc280c3388920787c5ca4451ab5", "title": "Bounded-degree factors of lacunary multivariate polynomials", "abstract": "In this paper, we present a new method for computing bounded-degree factors of lacunary multivariate polynomials. In particular for polynomials over number fields, we give a new algorithm that takes as input a multivariate polynomial f in lacunary representation and a degree bound d and computes the irreducible factors of degree at most d of f in time polynomial in the lacunary size of f and in d. Our algorithm, which is valid for any field of zero characteristic, is based on a new gap theorem that enables reducing the problem to several instances of (a) the univariate case and (b) low-degree multivariate factorization.The reduction algorithms we propose are elementary in that they only manipulate the exponent vectors of the input polynomial. The proof of correctness and the complexity bounds rely on the Newton polytope of the polynomial, where the underlying valued field consists of Puiseux series in a single variable.", "venue": "J. Symb. Comput.", "authors": ["Bruno  Grenet"], "year": 2016, "n_citations": 12}
{"id": 1428146, "s2_id": "cd61cf150ecaf9a0270baedb1d8cab3cbc54b2ee", "title": "Modernizing PHCpack through phcpy", "abstract": "PHCpack is a large software package for solving systems of polynomial equations. The executable phc is menu driven and file oriented. This paper describes the development of phcpy, a Python interface to PHCpack. Instead of navigating through menus, users of phcpy solve systems in the Python shell or via scripts. Persistent objects replace intermediate files.", "venue": "ArXiv", "authors": ["Jan  Verschelde"], "year": 2013, "n_citations": 16}
{"id": 1428801, "s2_id": "83d091d3cfdd88c613b9803f529176ffcdb49a4e", "title": "Fast Minimal Presentations of Bi-graded Persistence Modules", "abstract": "Multi-parameter persistent homology is a recent branch of topological data analysis. In this area, data sets are investigated through the lens of homology with respect to two or more scale parameters. The high computational cost of many algorithms calls for a preprocessing step to reduce the input size. In general, a minimal presentation is the smallest possible representation of a persistence module. Lesnick and Wright proposed recently an algorithm (the LW-algorithm) for computing minimal presentations based on matrix reduction. In this work, we propose, implement and benchmark several improvements over the LW-algorithm. Most notably, we propose the use of priority queues to avoid extensive scanning of the matrix columns, which constitutes the computational bottleneck in the LW-algorithm, and we combine their algorithm with ideas from the multi-parameter chunk algorithm by Fugacci and Kerber. Our extensive experiments show that our algorithm outperforms the LW-algorithm and computes the minimal presentation for data sets with millions of simplices within a few seconds. Our software is publicly available.", "venue": "ALENEX", "authors": ["Michael  Kerber", "Alexander  Rolle"], "year": 2021, "n_citations": 11}
{"id": 1430330, "s2_id": "185f3386ec6a8d2aff3091a390b1d7051b729ff3", "title": "Determinantal Sets, Singularities and Application to Optimal Control in Medical Imagery", "abstract": "Control theory has recently been involved in the field of nuclear magnetic resonance imagery. The goal is to control the magnetic field optimally in order to improve the contrast between two biological matters on the pictures. Geometric optimal control leads us here to analyze meromorphic vector fields depending upon physical parameters, and having their singularities defined by a determinantal variety. The involved matrix has polynomial entries with respect to both the state variables and the parameters. Taking into account the physical constraints of the problem, one needs to classify, with respect to the parameters, the number of real singularities lying in some prescribed semi-algebraic set. We develop a dedicated algorithm for real root classification of the singularities of the rank defects of a polynomial matrix, cut with a given semi-algebraic set. The algorithm works under some genericity assumptions which are easy to check. These assumptions are not so restrictive and are satisfied in the aforementioned application. As more general strategies for real root classification do, our algorithm needs to compute the critical loci of some maps, intersections with the boundary of the semi-algebraic domain, etc. In order to compute these objects, the determinantal structure is exploited through a stratification by the rank of the polynomial matrix. This speeds up the computations by a factor 100. Furthermore, our implementation is able to solve the application in medical imagery, which was out of reach of more general algorithms for real root classification. For instance, computational results show that the contrast problem where one of the matters is water is partitioned into three distinct classes.", "venue": "ISSAC", "authors": ["Bernard  Bonnard", "Jean-Charles  Faug\u00e8re", "Alain  Jacquemard", "Mohab Safey El Din", "Thibaut  Verron"], "year": 2016, "n_citations": 7}
{"id": 1438935, "s2_id": "8c565daf590cfd99883c66acf8e309063dde43af", "title": "Generalized Homogeneous Polynomials for Efficient Template-Based Nonlinear Invariant Synthesis", "abstract": "The template-based method is one of the most successful approaches to algebraic invariant synthesis. In this method, an algorithm designates a template polynomial \\(p\\) over program variables, generates constraints for \\(p=0\\) to be an invariant, and solves the generated constraints. However, this approach often suffers from an increasing template size if the degree of a template polynomial is too high.", "venue": "SAS", "authors": ["Kensuke  Kojima", "Minoru  Kinoshita", "Kohei  Suenaga"], "year": 2016, "n_citations": 2}
{"id": 1444035, "s2_id": "f1f743a25a20f95b0c54938f2a6871d3032be52f", "title": "Simplifying Multiple Sums in Difference Fields", "abstract": "In this survey article we present difference field algorithms for symbolic summation. Special emphasize is put on new aspects in how the summation problems are rephrased in terms of difference fields, how the problems are solved there, and how the derived results in the given difference field can be reinterpreted as solutions of the input problem. The algorithms are illustrated with the Mathematica package Sigma by discovering and proving new harmonic number identities extending those from Paule and Schneider, 2003. In addition, the newly developed package EvaluateMultiSums is introduced that combines the presented tools. In this way, large scale summation problems for the evaluation of Feynman diagrams in QCD (Quantum ChromoDynamics) can be solved completely automatically.", "venue": "ArXiv", "authors": ["Carsten  Schneider"], "year": 2013, "n_citations": 102}
{"id": 1444764, "s2_id": "38d8a868da6381cdc09728adc8fb8b535ecde10d", "title": "A Symbolic Approach to Boundary Problems for Linear Partial Differential Equations - Applications to the Completely Reducible Case of the Cauchy Problem with Constant Coefficients", "abstract": "We introduce a general algebraic setting for describing linear boundary problems in a symbolic computation context, with emphasis on the case of partial differential equations. The general setting is then applied to the Cauchy problem for completely reducible partial differential equations with constant coefficients. While we concentrate on the theoretical features in this paper, the underlying operator ring is implemented and provides a sufficient basis for all methods presented here.", "venue": "CASC", "authors": ["Markus  Rosenkranz", "Nalina  Phisanbut"], "year": 2013, "n_citations": 6}
{"id": 1445419, "s2_id": "f163c985c9faf354d1ccec2d47f6744dabef66e1", "title": "Zeilberger's holonomic ansatz for Pfaffians", "abstract": "A variation of Zeilberger's holonomic ansatz for symbolic determinant evaluations is proposed which is tailored to deal with Pfaffians. The method is also applicable to determinants of skew-symmetric matrices, for which the original approach does not work. As Zeilberger's approach is based on the Laplace expansion (cofactor expansion) of the determinant, we derive our approach from the cofactor expansion of the Pfaffian. To demonstrate the power of our method, we prove, using computer algebra algorithms, some conjectures proposed in the paper \"Pfaffian decomposition and a Pfaffian analogue of q-Catalan Hankel determinants\" by Ishikawa, Tagawa, and Zeng. A minor summation formula related to partitions and Motzkin paths follows as a corollary.", "venue": "ISSAC", "authors": ["Masao  Ishikawa", "Christoph  Koutschan"], "year": 2012, "n_citations": 7}
{"id": 1449257, "s2_id": "daccf0057ec212399f53894be6ff5f33376cf541", "title": "Robust Computer Algebra, Theorem Proving, and Oracle AI", "abstract": "In the context of superintelligent AI systems, the term \u201coracle\u201d has two meanings. One refers to modular systems queried for domain-specific tasks. Another usage, referring to a class of systems which may be useful for addressing the value alignment and AI control problems, is a superintelligent AI system that only answers questions. The aim of this manuscript is to survey contemporary research problems related to oracles which align with long-term research goals of AI safety. We examine existing question answering systems and argue that their high degree of architectural heterogeneity makes them poor candidates for rigorous analysis as oracles. On the other hand, we identify computer algebra systems (CASs) as being primitive examples of domain-specific oracles for mathematics and argue that efforts to integrate computer algebra systems with theorem provers, systems which have largely been developed independent of one another, provide a concrete set of problems related to the notion of provable safety that has emerged in the AI safety community. We review approaches to interfacing CASs with theorem provers, describe well-defined architectural deficiencies that have been identified with CASs, and suggest possible lines of research and practical software projects for scientists interested in AI safety.", "venue": "Informatica", "authors": ["Gopal P. Sarma", "Nick J. Hay"], "year": 2017, "n_citations": 2}
{"id": 1449846, "s2_id": "4a2011598f372ba72b07d7a9c71d57d6e15f0b93", "title": "Finding hyperexponential solutions of linear ODEs by numerical evaluation", "abstract": "We present a new algorithm for computing hyperexponential solutions of linear ordinary differential equations with polynomial coefficients. The algorithm relies on interpreting formal series solutions at the singular points as analytic functions and evaluating them numerically at some common ordinary point. The numerical data is used to determine a small number of combinations of the formal series that may give rise to hyperexponential solutions.", "venue": "ISSAC '13", "authors": ["Fredrik  Johansson", "Manuel  Kauers", "Marc  Mezzarobba"], "year": 2013, "n_citations": 2}
{"id": 1452275, "s2_id": "ae7c2aa948bf0a3e2e8ccf677d6e1774ad0db649", "title": "Computing the rank and a small nullspace basis of a polynomial matrix", "abstract": "We reduce the problem of computing the rank and a null-space basis of a univariate polynomial matrix to polynomial matrix multiplication. For an input n x n matrix of degree, d over a field K we give a rank and nullspace algorithm using about the same number of operations as for multiplying two matrices of dimension, n and degree, d. If the latter multiplication is done in MM(n,d)= O~(n\u03c9d operations, with \u03c9 the exponent of matrix multiplication over K, then the algorithm uses O~MM(n,d) operations in, K. For m x n matrices of rank r and degree d, the cost expression is O(nmr \u03c9-2d). The soft-O notation O~ indicates some missing logarithmic factors. The method is randomized with Las Vegas certification. We achieve our results in part through a combination of matrix Hensel high-order lifting and matrix minimal fraction reconstruction, and through the computation of minimal or small degree vectors in the nullspace seen as a K[x]-module.", "venue": "ISSAC", "authors": ["Arne  Storjohann", "Gilles  Villard"], "year": 2005, "n_citations": 41}
{"id": 1453874, "s2_id": "b6e235ad206cb1f9d2015fd5ef7f3b7f2166cb3b", "title": "Binomial Determinants for Tiling Problems Yield to the Holonomic Ansatz", "abstract": "We present and prove closed form expressions for some families of binomial determinants with signed Kronecker deltas that are located along an arbitrary diagonal in the corresponding matrix. They count cyclically symmetric rhombus tilings of hexagonal regions with triangular holes. We extend a previous systematic study of these families, where the locations of the Kronecker deltas depended on an additional parameter, to families with negative Kronecker deltas. By adapting Zeilberger\u2019s holonomic ansatz to make it work for our problems, we can take full advantage of computer algebra tools for symbolic summation. This, together with the combinatorial interpretation, allows us to realize some new determinantal relationships. From there, we are able to resolve all remaining open conjectures related to these determinants, including one from 2005 due to Lascoux and Krattenthaler.", "venue": "Eur. J. Comb.", "authors": ["Hao  Du", "Christoph  Koutschan", "Thotsaporn  Thanatipanonda", "Elaine  Wong"], "year": 2022, "n_citations": 0}
{"id": 1455891, "s2_id": "8c885fc1edf75a0227e73b10de57ddda3f21d1d1", "title": "Symbolic computation of hypergeometric type and non-holonomic power series", "abstract": "A term an is m-fold hypergeometric, for a given positive integer m, if the ratio an+m/an is a rational function over a field K of characteristic zero. We establish the structure of holonomic recurrence equation, i.e. linear and homogeneous recurrence equations having polynomial coefficients, that have m-fold hypergeometric term solutions over K, for any positive integer m. Consequently, we describe an algorithm, say mfoldHyper, that extends van Hoeij\u2019s algorithm (1998) which computes a basis of the subspace of hypergeometric (m = 1) term solutions of holonomic recurrence equations to the more general case of m-fold hypergeometric terms. A Laurent-Puiseux series \u221e \u2211 n=n0 an(z \u2212 z0) (an \u2208 K, k \u2208 N, n0 \u2208 Z), (1) where k denotes the corresponding Puiseux number, is mainly characterized by the coefficient an. We generalize the concept of hypergeometric type power series introduced by Koepf (1992), by considering linear combinations of Laurent-Puiseux series whose coefficients are m-fold hypergeometric terms. Such power series could not be computed before due to the lack of an algorithm to find m-fold hypergeometric term solutions of holonomic recurrence equation which constitute a key step in Koepf\u2019s procedure. Thanks to mfoldHyper, we deduce a complete procedure to compute these power series; indeed, it turns out that every linear combination of power series with m-fold hypergeometric term coefficients, for finitely many values of m, is detected. On the other hand, we investigate an algorithm to represent power series of non-holonomic functions like tan(z), (1 \u2212 tan(z))/(1 + tan(z)), z/(exp(z) \u2212 1), log(1 + sin(z)), etc. The algorithm follows the same steps of Koepf\u2019s algorithm, but instead of seeking holonomic differential equations, quadratic differential equations are computed and the Cauchy product rule is used to deduce recurrence equations for the power series coefficients. This algorithm defines a normal function that yields together with enough initial values normal forms for many power series of non-holonomic functions. Therefore, non-trivial identities like", "venue": "ArXiv", "authors": ["Bertrand Teguia Tabuguia", "Wolfram  Koepf"], "year": 2021, "n_citations": 1}
{"id": 1456740, "s2_id": "3eae180177cdcb4abbf34217a90e72dcaf6467c0", "title": "Tracking p-adic precision", "abstract": "We present a new method to propagate $p$-adic precision in computations, which also applies to other ultrametric fields. We illustrate it with many examples and give a toy application to the stable computation of the SOMOS 4 sequence.", "venue": "ArXiv", "authors": ["Xavier  Caruso", "David  Roe", "Tristan  Vaccon"], "year": 2014, "n_citations": 24}
{"id": 1461930, "s2_id": "e1a1caf216f287d2c0ab345514a0ff2bbebc67e1", "title": "Symbolic-Manipulation Constructions of Hilbert-Space Metrics in Quantum Mechanics", "abstract": "The recently formulated quantum-mechanics problem of the determination of the Hilbert-space metric \u0398 which renders a given Hamiltonian H self-adjoint is addressed. Via an exactly solvable example of the so called Gegenbauerian quantum-lattice oscillator it is demonstrated that the construction (basically, the solution of the so called Dieudonne's operator equation) and analysis of suitable \u0398 = \u0398(H) (i.e., the determination of their domain's \"exceptional-point\" boundary) may enormously be facilitated via symbolic algebraic manipulations and via the MAPLE-supported numerics and graphics.", "venue": "CASC", "authors": ["Miloslav  Znojil"], "year": 2011, "n_citations": 2}
{"id": 1462999, "s2_id": "a52daa433f6fd5626c9b5439a0055dd1a3e1cc74", "title": "Modular absolute decomposition of equidimensional polynomial ideals", "abstract": "In this paper, we present a modular strategy which describes key properties of the absolute primary decomposition of an equidimensional polynomial ideal defined by polynomials with rational coefficients. The algorithm we design is based on the classical technique of elimination of variables and colon ideals and uses a tricky choice of prime integers to work with. Thanks to this technique, we can obtain the number of absolute irreducible components, their degree, multiplicity and also the affine Hilbert function of the reduced components (namely, their initial ideal w.r.t. a degree-compatible term ordering) .", "venue": "ArXiv", "authors": ["Cristina  Bertone"], "year": 2010, "n_citations": 1}
{"id": 1468296, "s2_id": "cf9ca2865b47916c4a5889fef58a1ef86697a092", "title": "Automated Induction for Complex Data Structures", "abstract": "We propose a procedure for automated implicit inductive theorem proving for equational specifications made of rewrite rules with conditions and constraints. The constraints are interpreted over constructor terms (representing data values), and may express syntactic equality, disequality, ordering and also membership in a fixed tree language. Constrained equational axioms between constructor terms are supported and can be used in order to specify complex data structures like sets, sorted lists, trees, powerlists... \nOur procedure is based on tree grammars with constraints, a formalism which can describe exactly the initial model of the given specification (when it is sufficiently complete and terminating). They are used in the inductive proofs first as an induction scheme for the generation of subgoals at induction steps, second for checking validity and redundancy criteria by reduction to an emptiness problem, and third for defining and solving membership constraints. \nWe show that the procedure is sound and refutationally complete. It generalizes former test set induction techniques and yields natural proofs for several non-trivial examples presented in the paper, these examples are difficult to specify and carry on automatically with related induction procedures.", "venue": "ArXiv", "authors": ["Adel  Bouhoula", "Florent  Jacquemard"], "year": 2008, "n_citations": 15}
{"id": 1469975, "s2_id": "5a9881b646d8812702e74de846b0c7c2c940620a", "title": "A Simple Method for Computing Some Pseudo-Elliptic Integrals in Terms of Elementary Functions", "abstract": "We introduce a method for computing some pseudo-elliptic integrals in terms of elementary functions. The method is simple and fast in comparison to the algebraic case of the Risch-Trager-Bronstein algorithm. This method can quickly solve many pseudo-elliptic integrals which other well-known computer algebra systems (CAS) either fail, return an answer in terms of special functions, or require more than 20 seconds of computing time. Unlike the symbolic integration algorithms of Risch, Davenport, Trager, Bronstein and Miller; our method is not a decision process. The implementation of this method is less than 200 lines of Mathematica code and can be easily ported to other CAS that can solve systems of linear equations.", "venue": "ArXiv", "authors": ["Sam  Blake"], "year": 2020, "n_citations": 0}
{"id": 1472046, "s2_id": "2504973bb0ecee54c1df8fb10faa4a92f3ed46ba", "title": "Schur polynomials do not have small formulas if the determinant doesn't", "abstract": "Schur Polynomials are families of symmetric polynomials that have been classically studied in Combinatorics and Algebra alike. They play a central role in the study of Symmetric functions, in Representation theory [39], in Schubert calculus [26] as well as in Enumerative combinatorics [14, 38, 39]. In recent years, they have also shown up in various incarnations in Computer Science, e.g, Quantum computation [17, 31] and Geometric complexity theory [21]. However, unlike some other families of symmetric polynomials like the Elementary Symmetric polynomials, the Power Symmetric polynomials and the Complete Homogeneous Symmetric polynomials, the computational complexity of syntactically computing Schur polynomials has not been studied much. In particular, it is not known whether Schur polynomials can be computed efficiently by algebraic formulas. In this work, we address this question, and show that unless every polynomial with a small algebraic branching program (ABP) has a small algebraic formula, there are Schur polynomials that cannot be computed by algebraic formula of polynomial size. In other words, unless the algebraic complexity class VBP is equal to the complexity class VF, there exist Schur polynomials which do not have polynomial size algebraic formulas. As a consequence of our proof, we also show that computing the determinant of certain generalized Vandermonde matrices is essentially as hard as computing the general symbolic determinant. To the best of our knowledge, these are one of the first hardness results of this kind for families of polynomials which are not multilinear. A key ingredient of our proof is the study of composition of well behaved algebraically independent polynomials with a homogeneous polynomial, and might be of independent interest.", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Prasad  Chaugule", "Mrinal  Kumar", "Nutan  Limaye", "Chandra Kanta Mohapatra", "Adrian  She", "Srikanth  Srinivasan"], "year": 2019, "n_citations": 1}
{"id": 1474814, "s2_id": "f796bc670183b4e33911f71b39da98bee52df994", "title": "On the Complexity of Solving Generic Over-determined Bilinear Systems", "abstract": "<p style='text-indent:20px;'>In this paper, we study the complexity of solving overdetermined generic systems of bilinear polynomials over a finite field <inline-formula><tex-math id=\"M1\">\\begin{document}$ \\mathbb{F} $\\end{document}</tex-math></inline-formula>. Given a generic bilinear sequence <inline-formula><tex-math id=\"M2\">\\begin{document}$ B\\in \\mathbb{F}[ \\textbf{x}, \\textbf{y}] $\\end{document}</tex-math></inline-formula>, with respect to a partition of variables <inline-formula><tex-math id=\"M3\">\\begin{document}$ \\textbf{x} $\\end{document}</tex-math></inline-formula>, <inline-formula><tex-math id=\"M4\">\\begin{document}$ \\textbf{y} $\\end{document}</tex-math></inline-formula>, we show that, the solutions of the system <inline-formula><tex-math id=\"M5\">\\begin{document}$ B = \\textbf{0} $\\end{document}</tex-math></inline-formula> can be efficiently found on the <inline-formula><tex-math id=\"M6\">\\begin{document}$ \\mathbb{F}[ \\textbf{y}] $\\end{document}</tex-math></inline-formula>-module generated by <inline-formula><tex-math id=\"M7\">\\begin{document}$ B $\\end{document}</tex-math></inline-formula>. Following this observation, we define notions of regularity for overdetermined bilinear systems, and we conjecture that they are generic properties. Also, we propose three variations of Gr\u00f6bner basis algorithms, that only involve multiplication by monomials in the <inline-formula><tex-math id=\"M8\">\\begin{document}$ \\textbf{y} $\\end{document}</tex-math></inline-formula>-variables, namely, <inline-formula><tex-math id=\"M9\">\\begin{document}$ \\textbf{y} $\\end{document}</tex-math></inline-formula>-XL, based on the XL algorithm, <inline-formula><tex-math id=\"M10\">\\begin{document}$ \\textbf{y} $\\end{document}</tex-math></inline-formula>-MXL, based on the mutant XL algorithm, and <inline-formula><tex-math id=\"M11\">\\begin{document}$ \\textbf{y} $\\end{document}</tex-math></inline-formula>-HXL, based on a hybrid approach. We develop the necessary theoretical tools to estimate the complexity of the algorithms for such sequences. We present experimental evidence for testing our conjecture, verifying our results, and comparing the complexity of the various methods. Based on the experimental data, we can conclude that <inline-formula><tex-math id=\"M12\">\\begin{document}$ \\textbf{y} $\\end{document}</tex-math></inline-formula>-MXL outperforms F4 on bilinear systems.</p>", "venue": "Advances in Mathematics of Communications", "authors": ["John B. Baena", "Daniel  Cabarcas", "Javier  Verbel"], "year": 2021, "n_citations": 0}
{"id": 1479073, "s2_id": "2765228f09e3abd223651ca1cb85a69e266e523d", "title": "Groebner basis in Boolean rings is not polynomial-space", "abstract": "AbstractWegiveanexamplewherethenumberofelementsofaGrobnerbasisinaBooleanringisnotpolynomiallyboundedintermsofthebitsizeanddegreesoftheinput. 1 Boolean Rings Let R n = F 2 [x 1 ,...,x n ,y 1 ,...,y n ,z 1 ,...,z n ] where F 2 = Z/(2). If S \u2286 R n then (S) denotes the ideal in R n generated by S, and Sol(S) \u2286 K 3n denotes thesolution set of S, where K is the algebraic closure of F 2 . LetS n := {c 2 \u2212c| c\u2208 {x 1 ,...,x n ,y 1 ,...,y n ,z 1 ,...,z n }}.R bn := R n /(S n ) is a Booleanring , which means r 2 = rfor all rin R bn . If I is anideal in R n , then S n \u2286 I if and only if I is radical and Sol(I) \u2286 F 3n2 .Ideals in R n that contain S n are in 1-1 correspondence with ideals in R bn .Thus, Gr\u00a8obner basis in R bn is equivalent to: Gr\u00a8obner basis in R restrictedto ideals that contain S n . We will show with an example that this is notpolynomial-space. 2 Example LetL n = {x i y i +x i +y i \u2212z i | i= 1,...,n}T n = {x i z i \u2212x i | i= 1,...,n}[{y i z i \u2212y i | i= 1,...,n}P n = {Y ni=1 c i | c", "venue": "ArXiv", "authors": ["Mark van Hoeij"], "year": 2015, "n_citations": 0}
{"id": 1480783, "s2_id": "47f38ebd6fcece3e6c7cc4f32a5c936306cd9500", "title": "Computing generalized inverses using LU factorization of matrix product", "abstract": "An algorithm for computing {2, 3}, {2, 4}, {1, 2, 3}, {1, 2, 4} -inverses and the Moore\u2013Penrose inverse of a given rational matrix A is established. Classes A{2, 3} s and A{2, 4} s are characterized in terms of matrix products (R*A)\u2020 R* and T*(AT*)\u2020, where R and T are rational matrices with appropriate dimensions and corresponding rank. The proposed algorithm is based on these general representations and the Cholesky factorization of symmetric positive matrices. The algorithm is implemented in programming languages MATHEMATICA and DELPHI, and illustrated via examples. Numerical results of the algorithm, corres-ponding to the Moore\u2013Penrose inverse, are compared with corresponding results obtained by several known methods for computing the Moore\u2013Penrose inverse.", "venue": "Int. J. Comput. Math.", "authors": ["Predrag S.  Stanimirovi\u0107", "Milan B.  Tasi\u0107"], "year": 2008, "n_citations": 28}
{"id": 1481185, "s2_id": "1132c8bcea842740dda833024a40d1a9470b32f8", "title": "A \"Piano Movers\" Problem Reformulated", "abstract": "It has long been known that cylindrical algebraic decompositions (CADs) can in theory be used for robot motion planning. However, in practice even the simplest examples can be too complicated to tackle. We consider in detail a ``Piano Mover's Problem'' which considers moving an infinitesimally thin piano (or ladder) through a right-angled corridor. Producing a CAD for the original formulation of this problem is still infeasible after 25 years of improvements in both CAD theory and computer hardware. We review some alternative formulations in the literature which use differing levels of geometric analysis before input to a CAD algorithm. Simpler formulations allow CAD to easily address the question of the existence of a path. We provide a new formulation for which both a CAD can be constructed and from which an actual path could be determined if one exists, and analyse the CADs produced using this approach for variations of the problem. This emphasises the importance of the precise formulation of such problems for CAD. We analyse the formulations and their CADs considering a variety of heuristics and general criteria, leading to conclusions about tackling other problems of this form.", "venue": "2013 15th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing", "authors": ["David J. Wilson", "James H. Davenport", "Matthew  England", "Russell J. Bradford"], "year": 2013, "n_citations": 24}
{"id": 1483634, "s2_id": "f8da563ba32d2f77591228997e51d2497dbc4717", "title": "Triangular decomposition of semi-algebraic systems", "abstract": "Regular chains and triangular decompositions are fundamental and well-developed tools for describing the complex solutions of polynomial systems. This paper proposes adaptations of these tools focusing on solutions of the real analogue: semi-algebraic systems. We show that any such system can be decomposed into finitely many regular semi-algebraic systems. We propose two specifications (full and lazy) of such a decomposition and present corresponding algorithms. Under some simplifying assumptions, the lazy decomposition can be computed in singly exponential time w.r.t. the number of variables. We have implemented our algorithms and present experimental results illustrating their effectiveness.", "venue": "J. Symb. Comput.", "authors": ["Changbo  Chen", "James H. Davenport", "John P. May", "Marc Moreno Maza", "Bican  Xia", "Rong  Xiao"], "year": 2013, "n_citations": 67}
{"id": 1487562, "s2_id": "81aff87c9a49b6b2bc2a039eeb605447f7d0973b", "title": "Multiple binomial sums", "abstract": "Multiple binomial sums form a large class of multi-indexed sequences, closed under partial summation, which contains most of the sequences obtained by multiple summation of products of binomial coefficients and also all the sequences with algebraic generating function. We study the representation of the generating functions of binomial sums by integrals of rational functions. The outcome is twofold. Firstly, we show that a univariate sequence is a multiple binomial sum if and only if its generating function is the diagonal of a rational function. Secondly, we propose algorithms that decide the equality of multiple binomial sums and that compute recurrence relations for them. In conjunction with geometric simplifications of the integral representations, this approach behaves well in practice. The process avoids the computation of certificates and the problem of the appearance of spurious singularities that afflicts discrete creative telescoping, both in theory and in practice.", "venue": "J. Symb. Comput.", "authors": ["Alin  Bostan", "Pierre  Lairez", "Bruno  Salvy"], "year": 2017, "n_citations": 29}
{"id": 1488089, "s2_id": "1aea00b615ba3ca6c0a9c94022b467908aac7399", "title": "Automatic Deduction in Dynamic Geometry using Sage", "abstract": "We present a symbolic tool that provides robust algebraic methods to handle automatic deduction tasks for a dynamic geometry construction. The main prototype has been developed as two different worksheets for the open source computer algebra system Sage, corresponding to two different ways of coding a geometric construction. In one worksheet, diagrams constructed with the open source dynamic geometry system GeoGebra are accepted. In this worksheet, Groebner bases are used to either compute the equation of a geometric locus in the case of a locus construction or to determine the truth of a general geometric statement included in the GeoGebra construction as a boolean variable. In the second worksheet, locus constructions coded using the common file format for dynamic geometry developed by the Intergeo project are accepted for computation. The prototype and several examples are provided for testing. Moreover, a third Sage worksheet is presented in which a novel algorithm to eliminate extraneous parts in symbolically computed loci has been implemented. The algorithm, based on a recent work on the Groebner cover of parametric systems, identifies degenerate components and extraneous adherence points in loci, both natural byproducts of general polynomial algebraic methods. Detailed examples are discussed.", "venue": "ThEdu", "authors": ["Francisco  Botana", "Miguel A. Ab\u00e1nades"], "year": 2011, "n_citations": 5}
{"id": 1490064, "s2_id": "4b752365a63384d6099e684ea5bae60f2cbf85a8", "title": "Tritangents and Their Space Sextics", "abstract": "Two classical results in algebraic geometry are that the branch curve of a del Pezzo surface of degree 1 can be embedded as a space sextic curve and that every space sextic curve has exactly 120 tritangents corresponding to its odd theta characteristics. In this paper we revisit both results from the computational perspective. Specifically, we give an algorithm to construct space sextic curves that arise from blowing up projective plane at eight points and provide algorithms to compute the 120 tritangents and their Steiner system of any space sextic. Furthermore, we develop efficient inverses to the aforementioned methods. We present an algorithm to either reconstruct the original eight points in the projective plane from a space sextic or certify that this is not possible. Moreover, we extend a construction of Lehavi which recovers a space sextic from its tritangents and Steiner system. All algorithms in this paper have been implemented in magma.", "venue": "Journal of Algebra", "authors": ["Turku Ozlum Celik", "Avinash  Kulkarni", "Yue  Ren", "Mahsa Sayyary Namin"], "year": 2019, "n_citations": 1}
{"id": 1492705, "s2_id": "f94d93e5c06dd263e41abacb5a6ecee78cfafc14", "title": "Introduction to the Galois Theory of Linear Differential Equations", "abstract": "This is an expanded version of the 10 lectures given as the 2006 London Mathematical Society Invited Lecture Series at the Heriot-Watt University 31 July - 4 August 2006.", "venue": "ArXiv", "authors": ["Michael F. Singer"], "year": 2007, "n_citations": 27}
{"id": 1493034, "s2_id": "e503e9e6bb258bf31e159b0e5c1fa81e1601e343", "title": "Deciding trigonality of algebraic curves", "abstract": "Let C be a non-hyperelliptic algebraic curve of genus at least 3. Enriques and Babbage proved that its canonical image is the intersection of the quadrics that contain it, except when C is trigonal (that is, it has a linear system of degree 3 and dimension 1) or C is isomorphic to a plane quintic (genus 6). We present a method to decide whether a given algebraic curve is trigonal, and in the affirmative case to compute a map from C to the projective line whose fibers cut out the linear system. It is based on the Lie algebra method presented in Schicho (2006). Our algorithm is part of a larger effort to determine whether a given algebraic curve admits a radical parametrization.", "venue": "ArXiv", "authors": ["Josef  Schicho", "David  Sevilla"], "year": 2011, "n_citations": 1}
{"id": 1495194, "s2_id": "49216c13ac0db26df04e247d422a665742a246ce", "title": "Equivariant Hilbert series for hierarchical models", "abstract": "Toric ideals to hierarchical models are invariant under the action of a product of symmetric groups. Taking the number of factors, say m, into account, we introduce and study invariant filtrations and their equivariant Hilbert series. We present a condition that guarantees that the equivariant Hilbert series is a rational function in m+1 variables with rational coefficients. Furthermore we give explicit formulas for the rational functions with coefficients in a number field and an algorithm for determining the rational functions with rational coefficients. A key is to construct finite automata that recognize languages corresponding to invariant filtrations.", "venue": "Algebraic Statistics", "authors": ["Aida  Maraj", "Uwe  Nagel"], "year": 2019, "n_citations": 3}
{"id": 1509894, "s2_id": "6925a83206e4b4aab289f397ca88b987e0cb9258", "title": "Short formulas for algebraic covariant derivative curvature tensors via Algebraic Combinatorics", "abstract": "We consider generators of algebraic covariant derivative curvature tensors Rwhich can be constructed by a Young symmetrization of product ten- sors W \u2297 U or U \u2297 W, where W and U are covariant tensors of order 2 and 3. W is a symmetric or alternating tensor whereas U belongs to a class of the infinite set S of irreducible symmetry classes characterized by the partition (21). Using Computer Algebra we search for such generators whose coordinate repre- sentations are polynomials with a minimal number of summands. For a generic choice of the symmetry class of U we obtain lengths of 16 or 20 summands if W is symmetric or skew-symmetric, respectively. In special cases these numbers can be reduced to the minima 12 or 10. If these minima occur then U admits an index commutation symmetry. Furthermore minimal lengths are possible if U is formed from torsion-free covariant derivatives of symmetric or alternating 2-tensor fields. Foundation of our investigations is a theorem of S. A. Fulling, R. C. King, B. G. Wybourne and C. J. Cummins about a Young symmetrizer that gen- erates the symmetry class of algebraic covariant derivative curvature tensors. Furthermore we apply ideals and idempotents in group rings C(Sr) and discrete Fourier transforms for symmetric groups Sr. For symbolic calculations we used the Mathematica packages Ricci and PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2003, "n_citations": 4}
{"id": 1518238, "s2_id": "67a85d83b25bbed63706ab02c07c7f55f4fa2f5b", "title": "Encoding and Decoding Algorithms for Arbitrary Dimensional Hilbert Order", "abstract": "Hilbert order is widely applied in many areas. However, most of the algorithms are confined to low dimensional cases. In this paper, algorithms for encoding and decoding arbitrary dimensional Hilbert order are presented. Eight algorithms are proposed. Four algorithms are based on arithmetic operations and the other four algorithms are based on bit operations. For the algorithms complexities, four of them are linear and the other four are constant for given inputs. In the end of the paper, algorithms for two dimensional Hilbert order are presented to demonstrate the usage of the algorithms introduced.", "venue": "ArXiv", "authors": ["Hui  Liu", "Tao  Cui", "Wei  Leng", "Linbo  Zhang"], "year": 2016, "n_citations": 1}
{"id": 1520351, "s2_id": "0a411d00d1467b68625da755c3c54aa10cf4ceee", "title": "Applying machine learning to the problem of choosing a heuristic to select the variable ordering for cylindrical algebraic decomposition", "abstract": "Cylindrical algebraic decomposition(CAD) is a key tool in computational algebraic geometry, particularly for quantifier elimination over real-closed fields. When using CAD, there is often a choice for the ordering placed on the variables. This can be important, with some problems infeasible with one variable ordering but easy with another. Machine learning is the process of fitting a computer model to a complex function based on properties learned from measured data. In this paper we use machine learning (specifically a support vector machine) to select between heuristics for choosing a variable ordering, outperforming each of the separate heuristics.", "venue": "CICM", "authors": ["Zongyan  Huang", "Matthew  England", "David J. Wilson", "James H. Davenport", "Lawrence C. Paulson", "James P. Bridge"], "year": 2014, "n_citations": 48}
{"id": 1521600, "s2_id": "94d8641fd6eeb61817116fbf90abf73e2c0cd15a", "title": "A non-holonomic systems approach to special function identities", "abstract": "We extend Zeilberger's approach to special function identities to cases that are not holonomic. The method of creative telescoping is thus applied to definite sums or integrals involving Stirling or Bernoulli numbers, incomplete Gamma function or polylogarithms, which are not covered by the holonomic framework. The basic idea is to take into account the dimension of appropriate ideals in Ore algebras. This unifies several earlier extensions and provides algorithms for summation and integration in classes that had not been accessible to computer algebra before.", "venue": "ISSAC '09", "authors": ["Fr\u00e9d\u00e9ric  Chyzak", "Manuel  Kauers", "Bruno  Salvy"], "year": 2009, "n_citations": 39}
{"id": 1522847, "s2_id": "0d7d821f2db32b06c1b2aadbfd07bc8a41f0a6cd", "title": "Fast Hermite interpolation and evaluation over finite fields of characteristic two", "abstract": "This paper presents new fast algorithms for Hermite interpolation and evaluation over finite fields of characteristic two. The algorithms reduce the Hermite problems to instances of the standard multipoint interpolation and evaluation problems, which are then solved by existing fast algorithms. The reductions are simple to implement and free of multiplications, allowing low overall multiplicative complexities to be obtained. The algorithms are suitable for use in encoding and decoding algorithms for multiplicity codes.", "venue": "J. Symb. Comput.", "authors": ["Nicholas  Coxon"], "year": 2020, "n_citations": 2}
{"id": 1522966, "s2_id": "23d5c13442d2ddf960d172b19a708a78aeab208a", "title": "Gradual Sub-lattice Reduction and a New Complexity for\u00a0Factoring Polynomials", "abstract": "We present a lattice algorithm specifically designed for some classical applications of lattice reduction. The applications are for lattice bases with a generalized knapsack-type structure, where the target vectors have bounded depth. For such applications, the complexity of the algorithm improves traditional lattice reduction by replacing some dependence on the bit-length of the input vectors by some dependence on the bound for the output vectors. If the bit-length of the target vectors is unrelated to the bit-length of the input, then our algorithm is only linear in the bit-length of the input entries, which is an improvement over the quadratic complexity floating-point LLL algorithms. To illustrate the usefulness of this algorithm we show that a direct application to factoring univariate polynomials over the integers leads to the first complexity bound improvement since 1984. A second application is algebraic number reconstruction, where a new complexity bound is obtained as well.", "venue": "Algorithmica", "authors": ["Mark van Hoeij", "Andrew  Novocin"], "year": 2011, "n_citations": 39}
{"id": 1529207, "s2_id": "d1cd4b2a8c4f0a2d0502656671395f70f6a50309", "title": "Irreducibility of q-difference operators and the knot 7_4", "abstract": "Our goal is to compute the minimal-order recurrence of the colored Jones poly- nomial of the 74 knot, as well as for the first four double twist knots. As a corollary, we verify the AJ Conjecture for the simplest knot 74 with reducible non-abelian SL(2, ) char- acter variety. To achieve our goal, we use symbolic summation techniques of Zeilberger's holonomic systems approach and an irreducibility criterion for q-difference operators. For the latter we use an improved version of the qHyper algorithm of Abramov-Paule-Petkovysek to show that a given q-difference operator has no linear right factors. En route, we in- troduce exterior power Adams operations on the ring of bivariate polynomials and on the corresponding affine curves.", "venue": "ArXiv", "authors": ["Stavros  Garoufalidis", "Christoph  Koutschan"], "year": 2012, "n_citations": 16}
{"id": 1539015, "s2_id": "b5f8dce6dd718ebfbaf53bab4548cb7bdc9b833c", "title": "Accelerated Polynomial Evaluation and Differentiation at Power Series in Multiple Double Precision", "abstract": "The problem is to evaluate a polynomial in several variables and its gradient at a power series truncated to some finite degree with multiple double precision arithmetic. To compensate for the cost overhead of multiple double precision and power series arithmetic, data parallel algorithms for general purpose graphics processing units are presented. The reverse mode of algorithmic differentiation is organized into a massively parallel computation of many convolutions and additions of truncated power series. Experimental results demonstrate that teraflop performance is obtained in deca double precision with power series truncated at degree 152. The algorithms scale well for increasing precision and increasing degrees.", "venue": "2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)", "authors": ["Jan  Verschelde"], "year": 2021, "n_citations": 1}
{"id": 1550736, "s2_id": "af730467c43598c027b7420991de8c6457410f32", "title": "Counting basic-irreducible factors mod pk in deterministic poly-time and p-adic applications", "abstract": "Finding an irreducible factor, of a polynomial f(x) modulo a prime p, is not known to be in deterministic polynomial time. Though there is such a classical algorithm that counts the number of irreducible factors of f mod p. We can ask the same question modulo prime-powers pk. The irreducible factors of f mod pk blow up exponentially in number; making it hard to describe them. Can we count those irreducible factors mod pk that remain irreducible mod p? These are called basic-irreducible. A simple example is in f = x2 + px mod p2; it has p many basic-irreducible factors. Also note that, x2 + p mod p2 is irreducible but not basic-irreducible! We give an algorithm to count the number of basic-irreducible factors of f mod pk in deterministic poly(deg(f), k log p)-time. This solves the open questions posed in (Cheng et al, ANTS'18 & Kopp et al, Math.Comp.'19). In particular, we are counting roots mod pk; which gives the first deterministic poly-time algorithm to compute Igusa zeta function of f. Also, our algorithm efficiently partitions the set of all basic-irreducible factors (possibly exponential) into merely deg(f)-many disjoint sets, using a compact tree data structure and split ideals.", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Ashish  Dwivedi", "Rajat  Mittal", "Nitin  Saxena"], "year": 2019, "n_citations": 12}
{"id": 1558630, "s2_id": "72f8e2b6fcc147ab557a8829e7ddca0426a62313", "title": "Size Reduction and Partial Decoupling of Systems of Equations", "abstract": "A method is presented that reduces the number of terms of systems of linear equations (algebraic, ordinary and partial differential equations). As a byproduct these systems have a tendency to become partially decoupled and are more likely to be factorizable or integrable. A variation of this method is applicable to nonlinear systems. Modifications to improve efficiency are given and examples are shown. This procedure can be used in connection with the computation of the radical of a differential ideal (differential Grobner basis).", "venue": "J. Symb. Comput.", "authors": ["Thomas  Wolf"], "year": 2002, "n_citations": 5}
{"id": 1559293, "s2_id": "2de286ca43b595a7dcfce5d9a495330691dcdf06", "title": "Lopsided Approximation of Amoebas", "abstract": "The amoeba of a Laurent polynomial is the image of the corresponding hypersurface under the coordinatewise log absolute value map. In this article, we demonstrate that a theoretical amoeba approximation method due to Purbhoo can be used efficiently in practice. To do this, we resolve the main bottleneck in Purbhoo's method by exploiting relations between cyclic resultants. We use the same approach to give an approximation of the Log preimage of the amoeba of a Laurent polynomial using semi-algebraic sets. We also provide a SINGULAR/SAGE implementation of these algorithms, which shows a significant speedup when our specialized cyclic resultant computation is used, versus a general purpose resultant algorithm.", "venue": "Math. Comput.", "authors": ["Jens  Forsg\u00e5rd", "Laura Felicia Matusevich", "Nathan  Mehlhop", "Timo de Wolff"], "year": 2019, "n_citations": 7}
{"id": 1568667, "s2_id": "c275dfa9af61214c46ea17348027c85a8efc3942", "title": "Algorithmic Reduction of Biological Networks With Multiple Time Scales", "abstract": "We present a symbolic algorithmic approach that allows to compute invariant manifolds and corresponding reduced systems for differential equations modeling biological networks which comprise chemical reaction networks for cellular biochemistry, and compartmental models for pharmacology, epidemiology and ecology. Multiple time scales of a given network are obtained by scaling, based on tropical geometry. Our reduction is mathematically justified within a singular perturbation setting. The existence of invariant manifolds is subject to hyperbolicity conditions, for which we propose an algorithmic test based on Hurwitz criteria. We finally obtain a sequence of nested invariant manifolds and respective reduced systems on those manifolds. Our theoretical results are generally accompanied by rigorous algorithmic descriptions suitable for direct implementation based on existing off-the-shelf software systems, specifically symbolic computation libraries and Satisfiability Modulo Theories solvers. We present computational examples taken from the well-known BioModels database using our own prototypical implementations.", "venue": "Math. Comput. Sci.", "authors": ["Niclas  Kruff", "Christoph  L\u00fcders", "Ovidiu  Radulescu", "Thomas  Sturm", "Sebastian  Walcher"], "year": 2021, "n_citations": 1}
{"id": 1573249, "s2_id": "6fe6e4218037654b9a2a23916f2503444fc70072", "title": "Lectures on Reduce and Maple at UAM I - Mexico", "abstract": "These lectures give a brief introduction to the Computer Algebra systems Reduce and Maple. The aim is to provide a systematic survey of most important commands and concepts. In particular, this includes a discussion of simplification schemes and the handling of simplification and substitution rules (e.g., a Lie Algebra is implemented in Reduce by means of simplification rules). \nAnother emphasis is on the different implementations of tensor calculi and the exterior calculus by Reduce and Maple and their application in Gravitation theory and Differential Geometry. \nI held the lectures at the Universidad Autonoma Metropolitana-Iztapalapa, Departamento de Fisica, Mexico, in November 1999.", "venue": "ArXiv", "authors": ["Marc  Toussaint"], "year": 2001, "n_citations": 2}
{"id": 1573421, "s2_id": "5c76a036c671e3cea60768057a461507763b78ab", "title": "On the Ring of Local Unitary Invariants for Mixed X-States of Two Qubits", "abstract": "Entangling properties of a mixed two-qubit system can be described by local homogeneous unitary invariant polynomials in the elements of the density matrix. The structure of the corresponding ring of invariant polynomials for a special subclass of states, the so-called mixed X-states, is established. It is shown that for the X-states there is an injective ring homomorphism of the quotient ring of SU(2)\u00d7SU(2)-invariant polynomials modulo its syzygy ideal to the SO(2) \u00d7 SO(2)-invariant ring freely generated by five homogeneous polynomials of degrees 1, 1, 1, 2, 2.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt", "Arsen  Khvedelidze", "Yu. G. Palii"], "year": 2016, "n_citations": 3}
{"id": 1575516, "s2_id": "9719a1acdb8f217595fe320570f19d6549157055", "title": "TeXmacs-maxima interface", "abstract": "This tutorial presents features of the new and improved TeXmacs-maxima interface. It is designed for running maxima-5.9.2 from TeXmacs-1.0.5 (or later).", "venue": "ArXiv", "authors": ["A. G. Grozin"], "year": 2005, "n_citations": 2}
{"id": 1576130, "s2_id": "53e9bbacba4edc80ebf9bb8a81b39478b2788dfd", "title": "Determining surfaces of revolution from their implicit equations", "abstract": "Results of number of geometric operations are in many cases surfaces described implicitly. Then it is a challenging task to recognize the type of the obtained surface, find its characteristics and for the rational surfaces compute also their parameterizations. In?this contribution we will focus on surfaces of revolution. These objects, widely used in geometric modelling, are generated by rotating a generatrix around a given axis. If the generatrix is an algebraic curve then so is also the resulting surface, described uniquely by a polynomial which can be found by some well-established implicitation technique. However, starting from a polynomial it is not known how to decide if the corresponding algebraic surface is rotational or not. Motivated by this, our goal is to formulate a simple and efficient algorithm whose input is a?polynomial with the coefficients from some subfield of R and the output is the answer whether the shape is a surface of revolution. In the affirmative case we also find the equations of its axis and generatrix. Furthermore, we investigate the problem of rationality and unirationality of surfaces of revolution and show that this question can be efficiently answered discussing the rationality of a certain associated planar curve.", "venue": "J. Comput. Appl. Math.", "authors": ["Jan  Vrsek", "Miroslav  L\u00e1vicka"], "year": 2015, "n_citations": 17}
{"id": 1576872, "s2_id": "d31c78ffd35396681327cf785dc8a4bd75cef1d1", "title": "Proving Properties of Sorting Programs: A Case Study in Horn Clause Verification", "abstract": "The proof of a program property can be reduced to the proof of satisfiability of a set of constrained Horn clauses (CHCs) which can be automatically generated from the program and the property. In this paper we have conducted a case study in Horn clause verification by considering several sorting programs with the aim of exploring the effectiveness of a transformation technique which allows us to eliminate inductive data structures such as lists or trees. If this technique is successful, we derive a set of CHCs with constraints over the integers and booleans only, and the satisfiability check can often be performed in an effective way by using state-of-the-art CHC solvers, such as Eldarica or Z3. In this case study we have also illustrated the usefulness of a companion technique based on the introduction of the so-called difference predicates, whose definitions correspond to lemmata required during the verification. We have considered functional programs which implement the following kinds of sorting algorithms acting on lists of integers: (i) linearly recursive sorting algorithms, such as insertion sort and selection sort, and (ii) non-linearly recursive sorting algorithms, such as quicksort and mergesort, and we have considered the following properties: (i) the partial correctness properties, that is, the orderedness of the output lists, and the equality of the input and output lists when viewed as multisets, and (ii) some arithmetic properties, such as the equality of the sum of the elements before and after sorting.", "venue": "CILC", "authors": ["Emanuele De Angelis", "Fabio  Fioravanti", "Alberto  Pettorossi", "Maurizio  Proietti"], "year": 2019, "n_citations": 3}
{"id": 1578871, "s2_id": "f5a43985f2a3ba4ef0220bcc5bb4a3ddb2f2284d", "title": "Computing the Newton-step faster than Hessian accumulation", "abstract": "Computing the Newton-step of a generic function with N decision variables takes O(N) flops. In this paper, we show that given the computational graph of the function, this bound can be reduced to O(m\u03c4), where \u03c4,m are the width & size of a tree-decomposition of the graph. The proposed algorithm generalizes nonlinear optimal-control methods based on LQR to general optimization problems and provides nontrivial gains in iteration-complexity even in cases where the Hessian is dense.", "venue": "ArXiv", "authors": ["Akshay  Srinivasan", "Emanuel  Todorov"], "year": 2021, "n_citations": 0}
{"id": 1582563, "s2_id": "7939cd428dde9a52c9333bec79c2837e48d871f4", "title": "The D-plus Discriminant and Complexity of Root Clustering", "abstract": "Let $p(x)$ be an integer polynomial with $m\\ge 2$ distinct roots $\\rho_1,\\ldots,\\rho_m$ whose multiplicities are $\\boldsymbol{\\mu}=(\\mu_1,\\ldots,\\mu_m)$. We define the D-plus discriminant of $p(x)$ to be $D^+(p):= \\prod_{1\\le i<j\\le m}(\\rho_i-\\rho_j)^{\\mu_i+\\mu_j}$. We first prove a conjecture that $D^+(p)$ is a $\\boldsymbol{\\mu}$-symmetric function of its roots $\\rho_1,\\ldots,\\rho_m$. Our main result gives an explicit formula for $D^+(p)$, as a rational function of its coefficients. Our proof is ideal-theoretic, based on re-casting the classic Poisson resultant as the\"symbolic Poisson formula\". The D-plus discriminant first arose in the complexity analysis of a root clustering algorithm from Becker et al. (ISSAC 2016). The bit-complexity of this algorithm is proportional to a quantity $\\log(|D^+(p)|^{-1})$. As an application of our main result, we give an explicit upper bound on this quantity in terms of the degree of $p$ and its leading coefficient.", "venue": "ArXiv", "authors": ["Jing  Yang", "Chee K. Yap"], "year": 2021, "n_citations": 2}
{"id": 1585512, "s2_id": "5f23f97b908159687f1d0236996b097a9615e071", "title": "The Secant-Newton Map is Optimal Among Contracting $n^{th}$ Degree Maps for $n^{th}$ Root Computation", "abstract": "Consider the problem: given a real number $x$ and an error bound $\\epsilon$, find an interval such that it contains the $\\sqrt[n]{x}$ and its width is less than $\\epsilon$. One way to solve the problem is to start with an initial interval and to repeatedly update it by applying an interval refinement map on it until it becomes narrow enough. In this paper, we prove that the well known Secant-Newton map is optimal among a certain family of natural generalizations.", "venue": "ArXiv", "authors": ["Kayla  Bishop", "Hoon  Hong"], "year": 2014, "n_citations": 0}
{"id": 1586513, "s2_id": "7b44d5c034f958df6bbe3b23bca870effd488696", "title": "First steps towards radical parametrization of algebraic surfaces", "abstract": "We introduce the notion of radical parametrization of a surface, and we provide algorithms to compute such type of parametrizations for families of surfaces, like: Fermat surfaces, surfaces with a high multiplicity (at least the degree minus 4) singularity, all irreducible surfaces of degree at most 5, all irreducible singular surfaces of degree 6, and surfaces containing a pencil of low-genus curves. In addition, we prove that radical parametrizations are preserved under certain type of geometric constructions that include offset and conchoids.", "venue": "Comput. Aided Geom. Des.", "authors": ["J. Rafael Sendra", "David  Sevilla"], "year": 2013, "n_citations": 22}
{"id": 1588572, "s2_id": "a99fd224373502953d4c040705a9ab8960d17487", "title": "Open Graphs and Computational Reasoning", "abstract": "We present a form of algebraic reasoning for computational objects which are expressed as graphs. Edges describe the flow of data between primitive operations which are represented by vertices. These graphs have an interface made of half-edges (edges which are drawn with an unconnected end) and enjoy rich compositional principles by connecting graphs along these half-edges. In particular, this allows equations and rewrite rules to be specified between graphs. Particular computational models can then be encoded as an axiomatic set of such rules. Further rules can be derived graphically and rewriting can be used to simulate the dynamics of a computational system, e.g. evaluating a program on an input. Examples of models which can be formalised in this way include traditional electronic circuits as well as recent categorical accounts of quantum information.", "venue": "DCM", "authors": ["Lucas  Dixon", "Ross  Duncan", "Aleks  Kissinger"], "year": 2010, "n_citations": 18}
{"id": 1589124, "s2_id": "9a7ea29372e4b8d330368479c48dab141af2a920", "title": "Computation of Pommaret Bases Using Syzygies", "abstract": "We investigate the application of syzygies for efficiently computing (finite) Pommaret bases. For this purpose, we first describe a non-trivial variant of Gerdt\u2019s algorithm [10] to construct an involutive basis for the input ideal as well as an involutive basis for the syzygy module of the output basis. Then we apply this new algorithm in the context of Seiler\u2019s method to transform a given ideal into quasi stable position to ensure the existence of a finite Pommaret basis [19]. This new approach allows us to avoid superfluous reductions in the iterative computation of Janet bases required by this method. We conclude the paper by proposing an involutive variant of the signature based algorithm of Gao et al. [8] to compute simultaneously a Grobner basis for a given ideal and for the syzygy module of the input basis. All the presented algorithms have been implemented in Maple and their performance is evaluated via a set of benchmark ideals.", "venue": "CASC", "authors": ["Bentolhoda  Binaei", "Amir  Hashemi", "Werner M. Seiler"], "year": 2018, "n_citations": 1}
{"id": 1600174, "s2_id": "9d911185fae8677b877783f36e799119d2a83682", "title": "Approximate GCD in a Bernstein Basis", "abstract": "We adapt Victor Y. Pan\u2019s root-based algorithm for finding approximate GCD to the case where the polynomials are expressed in Bernstein bases. We use the numerically stable companion pencil of Gu\u00f0bjorn Jonsson to compute the roots, and the Hopcroft-Karp bipartite matching method to find the degree of the approximate GCD. We offer some refinements to improve the process.", "venue": "MC", "authors": ["Robert M. Corless", "Leili Rafiee Sevyeri"], "year": 2019, "n_citations": 2}
{"id": 1601067, "s2_id": "00617ac110e3a4b1056458c4a740d89372fbc76d", "title": "Using two types of computer algebra systems to solve maxwell optics problems", "abstract": "To synthesize Maxwell optics systems, the mathematical apparatus of tensor and vector analysis is generally employed. This mathematical apparatus implies executing a great number of simple stereotyped operations, which are adequately supported by computer algebra systems. In this paper, we distinguish between two stages of working with a mathematical model: model development and model usage. Each of these stages implies its own computer algebra system. As a model problem, we consider the problem of geometrization of Maxwell\u2019s equations. Two computer algebra systems\u2014Cadabra and FORM\u2014are selected for use at different stages of investigation.", "venue": "Programming and Computer Software", "authors": ["Dmitry S. Kulyabov"], "year": 2016, "n_citations": 2}
{"id": 1601218, "s2_id": "fc417b3bd41337c5ff08d9c2fb3cc30aae5ef4a3", "title": "OpenSBLI: A framework for the automated derivation and parallel execution of finite difference solvers on a range of computer architectures", "abstract": "Exascale computing will feature novel and potentially disruptive hardware architectures. Exploiting these to their full potential is non-trivial. Numerical modelling frameworks involving finite difference methods are currently limited by the 'static' nature of the hand-coded discretisation schemes and repeatedly may have to be re-written to run efficiently on new hardware. In contrast, OpenSBLI uses code generation to derive the model's code from a high-level specification. Users focus on the equations to solve, whilst not concerning themselves with the detailed implementation. Source-to-source translation is used to tailor the code and enable its execution on a variety of hardware.", "venue": "J. Comput. Sci.", "authors": ["Christian T. Jacobs", "Satya P. Jammy", "Neil D. Sandham"], "year": 2017, "n_citations": 40}
{"id": 1611648, "s2_id": "2d90e356470f94710e7539baf839bed3569930eb", "title": "Identifying the Parametric Occurrence of Multiple Steady States for some Biological Networks", "abstract": "Abstract We consider a problem from biological network analysis of determining regions in a parameter space over which there are multiple steady states for positive real values of variables and parameters. We describe multiple approaches to address the problem using tools from Symbolic Computation. We describe how progress was made to achieve semi-algebraic descriptions of the multistationarity regions of parameter space, and compare symbolic and numerical methods. The biological networks studied are models of the mitogen-activated protein kinases (MAPK) network which has already consumed considerable effort using special insights into its structure of corresponding models. Our main example is a model with 11 equations in 11 variables and 19 parameters, 3 of which are of interest for symbolic treatment. The model also imposes positivity conditions on all variables and parameters. We apply combinations of symbolic computation methods designed for mixed equality / inequality systems, specifically virtual substitution, lazy real triangularization and cylindrical algebraic decomposition, as well as a simplification technique adapted from Gaussian elimination and graph theory. We are able to determine semi-algebraic conditions for multistationarity of our main example over a 2-dimensional parameter space. We also study a second MAPK model and a symbolic grid sampling technique which can locate such regions in 3-dimensional parameter space.", "venue": "J. Symb. Comput.", "authors": ["Russell J. Bradford", "James H. Davenport", "Matthew  England", "Hassan  Errami", "Vladimir P. Gerdt", "Dima  Grigoriev", "Charles Tapley Hoyt", "Marek  Kosta", "Ovidiu  Radulescu", "Thomas  Sturm", "Andreas  Weber"], "year": 2020, "n_citations": 15}
{"id": 1611787, "s2_id": "5a15331dd02772b2728defedd4861ae1cf0ec608", "title": "Interpolation by decomposable univariate polynomials", "abstract": "The usual univariate interpolation problem of finding a monic polynomial f of degree n that interpolates n given values is well understood. This paper studies a variant where f is required to be composite, say, a composition of two polynomials of degrees d and e, respectively, with de = n, and therefore d+e\u22121 given values. Some special cases are easy to solve, and for the general case, we construct a homotopy between it and a special case. We compute a geometric solution of the algebraic curve presenting this homotopy, and this also provides an answer to the interpolation task. The computing time is polynomial in the geometric data, like the degree, of this curve. A consequence is that for almost all inputs, a decomposable interpolation polynomial exists.", "venue": "ArXiv", "authors": ["Joachim von zur Gathen", "Guillermo  Matera"], "year": 2021, "n_citations": 0}
{"id": 1612548, "s2_id": "a88e9273c2a17295fe28551616c2cfdbdd8ea0fd", "title": "Constructing fewer open cells by GCD computation in CAD projection", "abstract": "A new projection operator based on cylindrical algebraic decomposition (CAD) is proposed. The new operator computes the intersection of projection factor sets produced by different CAD projection orders. In other words, it computes the gcd of projection polynomials in the same variables produced by different CAD projection orders. We prove that the new operator still guarantees obtaining at least one sample point from every connected component of the highest dimension, and therefore, can be used for testing semi-definiteness of polynomials. Although the complexity of the new method is still doubly exponential, in many cases, the new operator does produce smaller projection factor sets and fewer open cells. Some examples of testing semi-definiteness of polynomials, which are difficult to be solved by existing tools, have been worked out efficiently by our program based on the new method.", "venue": "ISSAC", "authors": ["Jingjun  Han", "Liyun  Dai", "Bican  Xia"], "year": 2014, "n_citations": 22}
{"id": 1616697, "s2_id": "8ebb3547edb901f52a2ebd1ffdd1286e4ed19d67", "title": "A direct algorithm to compute the topological Euler characteristic and Chern-Schwartz-MacPherson class of projective complete intersection varieties", "abstract": "Abstract Let V be a possibly singular scheme-theoretic complete intersection subscheme of P n over an algebraically closed field of characteristic zero. Using a recent result of Fullwood (\u201cOn Milnor classes via invariants of singular subschemes\u201d, Journal of Singularities) we develop an algorithm to compute the Chern\u2013Schwartz\u2013MacPherson class and Euler characteristic of V. This algorithm complements existing algorithms by providing performance improvements in the computation of the Chern\u2013Schwartz\u2013MacPherson class and Euler characteristic for certain types of complete intersection subschemes of P n .", "venue": "Theor. Comput. Sci.", "authors": ["Martin  Helmer"], "year": 2017, "n_citations": 9}
{"id": 1619548, "s2_id": "53fdd00ed894359555644ea140320b4a00ff7b85", "title": "Cylindrical Algebraic Sub-Decompositions", "abstract": "Cylindrical algebraic decompositions (CADs) are a key tool in real algebraic geometry, used primarily for eliminating quantifiers over the reals and studying semi-algebraic sets. In this paper we introduce cylindrical algebraic sub-decompositions (sub-CADs), which are subsets of CADs containing all the information needed to specify a solution for a given problem. We define two new types of sub-CAD: variety sub-CADs which are those cells in a CAD lying on a designated variety; and layered sub-CADs which have only those cells of dimension higher than a specified value. We present algorithms to produce these and describe how the two approaches may be combined with each other and the recent theory of truth-table invariant CAD. We give a complexity analysis showing that these techniques can offer substantial theoretical savings, which is supported by experimentation using an implementation in Maple.", "venue": "Math. Comput. Sci.", "authors": ["David J. Wilson", "Russell J. Bradford", "James H. Davenport", "Matthew  England"], "year": 2014, "n_citations": 21}
{"id": 1626239, "s2_id": "46455fc82f40f3044d713fe7595920bbb91ffaa2", "title": "Computing in quotients of rings of integers", "abstract": "We develop algorithms to turn quotients of rings of rings of integers into effective Euclidean rings by giving polynomial algorithms for all fundamental ring operations. In addition, we study normal forms for modules over such rings and their behavior under certain quotients. We illustrate the power of our ideas in a new modular normal form algorithm for modules over rings of integers, vastly outperforming classical algorithms.", "venue": "ArXiv", "authors": ["Tommy  Hofmann", "Claus  Fieker"], "year": 2016, "n_citations": 6}
{"id": 1639731, "s2_id": "f1f639c0ca5acbc0d755319c9f7243d5387bd39b", "title": "Solving Polynomial Systems in the Cloud with Polynomial Homotopy Continuation", "abstract": "Polynomial systems occur in many fields of science and engineering. Polynomial homotopy continuation methods apply symbolic-numeric algorithms to solve polynomial systems. We describe the design and implementation of our web interface and reflect on the application of polynomial homotopy continuation methods to solve polynomial systems in the cloud. Via the graph isomorphism problem we organize and classify the polynomial systems we solved. The classification with the canonical form of a graph identifies newly submitted systems with systems that have already been solved.", "venue": "CASC", "authors": ["Nathan  Bliss", "Jeff  Sommars", "Jan  Verschelde", "Xiangcheng  Yu"], "year": 2015, "n_citations": 8}
{"id": 1644280, "s2_id": "8e6f77946759a3f837cdeb3a3c1283b1f28851b4", "title": "New Bounds for Hypergeometric Creative Telescoping", "abstract": "Based on a modified version of Abramov-Petkovsek reduction, a new algorithm to compute minimal telescopers for bivariate hypergeometric terms was developed last year. We investigate further in this paper and present a new argument for the termination of this algorithm, which provides an independent proof of the existence of telescopers and even enables us to derive lower as well as upper bounds for the order of telescopers for hypergeometric terms. Compared to the known bounds in the literature, our bounds are sometimes better, and never worse than the known ones.", "venue": "ISSAC", "authors": ["Hui  Huang"], "year": 2016, "n_citations": 14}
{"id": 1650896, "s2_id": "8f3950f8870bb8489f43252b464997469736b37e", "title": "Decreasing Diagrams and Relative Termination", "abstract": "In this article we use the decreasing diagrams technique to show that a left-linear and locally confluent term rewrite system $\\mathcal{R}$ is confluent if the critical pair steps are relatively terminating with respect to $\\mathcal{R}$. We further show how to encode the rule-labeling heuristic for decreasing diagrams as a satisfiability problem. Experimental data for both methods are presented.", "venue": "Journal of Automated Reasoning", "authors": ["Nao  Hirokawa", "Aart  Middeldorp"], "year": 2011, "n_citations": 31}
{"id": 1654807, "s2_id": "b80545f17569527038f6958ad3e7b4eefe570e46", "title": "Beyond Polyhedral Homotopies", "abstract": "We present a new algorithmic framework which utilizes tropical geometry and homotopy continuation for solving systems of polynomial equations where some of the polynomials are generic elements in linear subspaces of the polynomial ring. This approach generalizes the polyhedral homotopies by Huber and Sturmfels.", "venue": "J. Symb. Comput.", "authors": ["Anton  Leykin", "Josephine  Yu"], "year": 2019, "n_citations": 2}
{"id": 1655302, "s2_id": "d499f8b62a89b4764978a778509c6515e084ba94", "title": "Algorithms for the Computing Determinants in Commutative Rings", "abstract": "Two known computation methods and one new computation method for matrix determinant over an integral domain are discussed. For each of the methods we evaluate the computation times for different rings and show that the new method is the best.", "venue": "ArXiv", "authors": ["Gennadi I. Malaschonok"], "year": 2017, "n_citations": 4}
{"id": 1656832, "s2_id": "d4c80910ce2c2fca4666cc6d222607377912ecc6", "title": "An Extension to an Algebraic Method for Linear Time-Invariant System and Network Theory: The full AC-Calculus", "abstract": "Being inspired by phasor analysis in linear circuit theory, and its algebraic counterpart - the AC-(operational)-calculus for sinusoids developed by W. Marten and W. Mathis - we define a complex structure on several spaces of real-valued elementary functions. This is used to algebraize inhomogeneous linear ordinary differential equations with inhomogenities stemming from these spaces. Thus we deduce an effective method to calculate particular solutions of these ODEs in a purely algebraic way.", "venue": "ArXiv", "authors": ["Eberhard H.-A. Gerbracht"], "year": 2007, "n_citations": 0}
{"id": 1657354, "s2_id": "af714722f2dd35e9be7a5f89696b1969f90df762", "title": "Factorization of Z-homogeneous polynomials in the First (q)-Weyl Algebra", "abstract": "Factorization of elements of noncommutative rings is an important problem both in theory and applications. For the class of domains admitting nontrivial grading, we have recently proposed an approach, which utilizes the grading in order to factor general elements. This is heavily based on the factorization of graded elements. In this paper, we present algorithms to factorize weighted homogeneous (graded) elements in the polynomial first q-Weyl and Weyl algebras, which are both viewed as \\({ \\mathbb {Z}}\\)-graded rings. We show that graded polynomials have finite number of factorizations. Moreover, the factorization of such can be almost completely reduced to commutative univariate factorization over the same base field with some additional uncomplicated combinatorial steps. This allows to deduce the complexity of our algorithms in detail, which we prove to be polynomial-time. Furthermore, we show, that for a graded polynomial p, irreducibility of p in the polynomial first Weyl algebra implies its irreducibility in the localized (rational) Weyl algebra, which is not true for general polynomials. We report on our implementation in the computer algebra system Singular. For graded polynomials, it outperforms currently available implementations for factoring in the first Weyl algebra\u2014in speed as well as in elegancy of the results.", "venue": "ArXiv", "authors": ["Albert  Heinle", "Viktor  Levandovskyy"], "year": 2013, "n_citations": 11}
{"id": 1663522, "s2_id": "46cd627e2d8f41659acad76fe259221a1e19cbce", "title": "Unirational fields of transcendence degree one and functional decomposition", "abstract": "In this paper we present an algorithm to compute all unirational fields of transcendence degree one, containing a given finite set of multivariate rational functions. In particular, we provide an algorithm to decompose a multivariate rational function <i>f</i> of the form <i>f</i> = <i>g</i>(<i>h</i>), where <i>g</i> is univariate rational function and <i>h</i> a multivariate one.", "venue": "ISSAC '01", "authors": ["Jaime  Gutierrez", "Rosario  Rubio", "David  Sevilla"], "year": 2001, "n_citations": 20}
{"id": 1664741, "s2_id": "533f18cf7225f67e415adddfbfa0ffddb471ea1d", "title": "Polynomial-time computing over quadratic maps i: sampling in real algebraic sets", "abstract": "Abstract.Given a quadratic map\n$$Q:\\mathbb{K}^n \\to \\mathbb{K}^k $$ defined over a computable subring D of a real closed field\n$$\\mathbb{K},$$ and p \u2208D[Y1,...,Yk] of degree d, we consider the zero set\n$$Z = Z(p(Q(X)), \\mathbb{K}^n) \\subseteq \\mathbb{K}^n$$ of p(Q(X1,...,Xn)) \u2208D[X1,...,Xn]. We present a procedure that computes, in (dn)O(k) arithmetic operations in D, a set\n$$\\mathcal{S}$$ of (real univariate representations of) sampling points in\n$$\\mathbb{K}^n$$ that intersects nontrivially each connected component of Z. As soon as k=o(n), this is faster than the known methods that all have exponential dependence on n in the complexity. In particular, our procedure is polynomial-time for constant k. In contrast, the best previously known procedure is only capable of deciding in\n$$n^{O(k^2 )} $$ operations the nonemptiness (rather than constructing sampling points) of the set Z in the case of p(Y)=\u2211iYi2 and homogeneous Q.A by-product of our procedure is a bound (dn)O(k) on the number of connected components of Z.The procedure consists of exact symbolic computations in D and outputs vectors of algebraic numbers. It involves extending\n$$\\mathbb{K}$$ by infinitesimals and subsequent limit computation by a novel procedure that utilizes knowledge of an explicit isomorphism between real algebraic sets.", "venue": "computational complexity", "authors": ["Dima  Grigoriev", "Dmitrii V. Pasechnik"], "year": 2005, "n_citations": 58}
{"id": 1666069, "s2_id": "8ff6f9790779f9345ffa9bb02679b40e8d1d83aa", "title": "The New Rewriting Engine of Dedukti", "abstract": "Fr\u00e9d\u00e9ric Blanqui Universit\u00e9 Paris-Saclay, ENS Paris-Saclay, CNRS, Inria, Laboratoire Sp\u00e9cification et V\u00e9rification, Gif-sur-Yvette, France http://rewriting.gforge.inria.fr/ Abstract Dedukti is a type-checker for the \u03bb\u03a0-calculus modulo rewriting, an extension of Edinburgh\u2019s logical framework LF where functions and type symbols can be defined by rewrite rules. It therefore contains an engine for rewriting LF terms and types according to the rewrite rules given by the user. A key component of this engine is the matching algorithm to find which rules can be fired. In this paper, we describe the class of rewrite rules supported by Dedukti and the new implementation of the matching algorithm. Dedukti supports non-linear rewrite rules on terms with binders using higher-order pattern-matching as in Combinatory Reduction Systems (CRS). The new matching algorithm extends the technique of decision trees introduced by Luc Maranget in the OCaml compiler to this more general context.", "venue": "ArXiv", "authors": ["Gabriel  Hondet", "Fr\u00e9d\u00e9ric  Blanqui"], "year": 2020, "n_citations": 1}
{"id": 1669386, "s2_id": "14b3ff0c06d33cfcf1d086d7a85af61b2c3a8342", "title": "A polynomial approach to the Collatz conjecture", "abstract": "The Collatz conjecture is explored using polynomials based on a binary numeral system. It is shown that the degree of the polynomials, on average, decreases after a finite number of steps of the Collatz operation, which provides a weak proof of the conjecture by using induction with respect to the degree of the polynomials.", "venue": "ArXiv", "authors": ["Feng  Pan", "Jerry P. Draayer"], "year": 2019, "n_citations": 1}
{"id": 1671702, "s2_id": "dfe918b311fe6004fc3a500e10cc4665a3c5164e", "title": "Formal solutions of completely integrable Pfaffian systems with normal crossings", "abstract": "In this paper, we present an algorithm for computing a fundamental matrix of formal solutions of completely integrable Pfaffi an systems with normal crossings in several variables. This algorithm is a generalization of a method developed for the bivariate case based on a combination of several reduction techniques and is implemented in the computer algebra system Maple.", "venue": "ACCA", "authors": ["Suzy S. Maddah"], "year": 2015, "n_citations": 0}
{"id": 1672784, "s2_id": "0840b24c912d1ec27b858ef232c185ac2601af9e", "title": "Evaluation of Logic Programs with Built-Ins and Aggregation: A Calculus for Bag Relations", "abstract": "We present a scheme for translating logic programs, which may use aggregation and arithmetic, into algebraic expressions that denote bag relations over ground terms of the Herbrand universe. To evaluate queries against these relations, we develop an operational semantics based on term rewriting of the algebraic expressions. This approach can exploit arithmetic identities and recovers a range of useful strategies, including lazy strategies that defer work until it becomes possible or necessary.", "venue": "ArXiv", "authors": ["Matthew  Francis-Landau", "Tim  Vieira", "Jason  Eisner"], "year": 2020, "n_citations": 0}
{"id": 1679085, "s2_id": "fd43f90d3937f4b71394289f7dce83384cfaa936", "title": "Automatic Generation of Bounds for Polynomial Systems with Application to the Lorenz System", "abstract": "Abstract This study covers an analytical approach to calculate positive invariant sets of dynamical systems. Using Lyapunov techniques and quantifier elimination methods, an automatic procedure for determining bounds in the state space as an enclosure of attractors is proposed. The available software tools permit an algorithmizable process, which normally requires a good insight into the systems dynamics and experience. As a result we get an estimation of the attractor, whose conservatism only results from the initial choice of the Lyapunov candidate function. The proposed approach is illustrated on the well-known Lorenz system.", "venue": "ArXiv", "authors": ["Klaus  R\u00f6benack", "Rick  Vo\u00dfwinkel", "Hendrik  Richter"], "year": 2017, "n_citations": 10}
{"id": 1679291, "s2_id": "164ebefd525372d2b57f180514f3277a18569036", "title": "Univariate Contraction and Multivariate Desingularization of Ore Ideals", "abstract": "Ore operators with polynomial coefficients form a common algebraic abstraction for representing D-finite functions. They form the Ore ring $K(x)[D_x]$, where $K$ is the constant field. Suppose $K$ is the quotient field of some principal ideal domain $R$. The ring $R[x][D_x]$ consists of elements in $K(x)[D_x]$ without \"denominator\". \nGiven $L \\in K(x)[D_x]$, it generates a left ideal $I$ in $K(x)[D_x]$. We call $I \\cap R[x][D_x]$ the univariate contraction of $I$. \nWhen $L$ is a linear ordinary differential or difference operator, we design a contraction algorithm for $L$ by using desingularized operators as proposed by Chen, Jaroschek, Kauers and Singer. When $L$ is an ordinary differential operator and $R = K$, our algorithm is more elementary than known algorithms. In other cases, our results are new. \nWe propose the notion of completely desingularized operators, study their properties, and design an algorithm for computing them. Completely desingularized operators have interesting applications such as certifying integer sequences and checking special cases of a conjecture of Krattenthaler. \nA D-finite system is a finite set of linear homogeneous partial differential equations in several variables, whose solution space is of finite dimension. For such systems, we give the notion of a singularity in terms of the polynomials appearing in them. We show that a point is a singularity of the system unless it admits a basis of power series solutions in which the starting monomials are as small as possible with respect to some term order. Then a singularity is apparent if the system admits a full basis of power series solutions, the starting terms of which are not as small as possible. We prove that apparent singularities in the multivariate case can be removed like in the univariate case by adding suitable additional solutions to the original system.", "venue": "ArXiv", "authors": ["Yi  Zhang"], "year": 2017, "n_citations": 3}
{"id": 1682963, "s2_id": "d46db257d9b6cd48210f69324ab7191662cbf3e6", "title": "Formal verification of trading in financial markets", "abstract": "We introduce a formal framework for analyzing trades in financial markets. An exchange is where multiple buyers and sellers participate to trade. These days, all big exchanges use computer algorithms that implement double sided auctions to match buy and sell requests and these algorithms must abide by certain regulatory guidelines. For example, market regulators enforce that a matching produced by exchanges should be \\emph{fair}, \\emph{uniform} and \\emph{individual rational}. To verify these properties of trades, we first formally define these notions in a theorem prover and then give formal proofs of relevant results on matchings. Finally, we use this framework to verify properties of two important classes of double sided auctions. All the definitions and results presented in this paper are completely formalised in the Coq proof assistant without adding any additional axioms to it.", "venue": "ArXiv", "authors": ["Suneel  Sarswat", "Abhishek Kr Singh"], "year": 2019, "n_citations": 0}
{"id": 1683888, "s2_id": "837cfad6c0bda582287cd1e707f7ef94d6804d3d", "title": "A Baby Step\u2013Giant Step Roadmap Algorithm for General Algebraic Sets", "abstract": "Let $$\\mathrm {R}$$R be a real closed field and $$\\mathrm{D}\\subset \\mathrm {R}$$D\u2282R an ordered domain. We present an algorithm that takes as input a polynomial $$Q \\in \\mathrm{D}[X_{1},\\ldots ,X_{k}]$$Q\u2208D[X1,\u2026,Xk] and computes a description of a roadmap of the set of zeros, $$\\mathrm{Zer}(Q,\\,\\mathrm {R}^{k}),$$Zer(Q,Rk), of Q in $$\\mathrm {R}^{k}.$$Rk. The complexity of the algorithm, measured by the number of arithmetic operations in the ordered domain $$\\mathrm{D},$$D, is bounded by $$d^{O(k \\sqrt{k})},$$dO(kk), where $$d = \\deg (Q)\\ge 2.$$d=deg(Q)\u22652. As a consequence, there exist algorithms for computing the number of semialgebraically connected components of a real algebraic set, $$\\mathrm{Zer}(Q,\\,\\mathrm {R}^{k}),$$Zer(Q,Rk), whose complexity is also bounded by $$d^{O(k \\sqrt{k})},$$dO(kk), where $$d = \\deg (Q)\\ge 2.$$d=deg(Q)\u22652. The best previously known algorithm for constructing a roadmap of a real algebraic subset of $$\\mathrm {R}^{k}$$Rk defined by a polynomial of degree d has complexity $$d^{O(k^{2})}.$$dO(k2).", "venue": "Found. Comput. Math.", "authors": ["Saugata  Basu", "Marie-Fran\u00e7oise  Roy", "Mohab Safey El Din", "\u00c9ric  Schost"], "year": 2014, "n_citations": 28}
{"id": 1684391, "s2_id": "9adf2eba8ec240b9ae2a56c7cffa9fac7129f9bd", "title": "Zero-nonzero and real-nonreal sign determination", "abstract": "We consider first the zero-nonzero determination problem, which consists in determining the list of zero-nonzero conditions realized by a finite list of polynomials on a finite set Z included in C^k with C an algebraic closed field. We describe an algorithm to solve the zero-nonzero determination problem and we perform its bit complexity analysis. This algorithm, which is in many ways an adaptation of the methods used to solve the more classical sign determination problem, presents also new ideas which can be used to improve sign determination. Then, we consider the real-nonreal sign determination problem, which deals with both the sign determination and the zero-nonzero determination problem. We describe an algorithm to solve the real-nonreal sign determination problem, we perform its bit complexity analysis and we discuss this problem in a parametric context.", "venue": "ArXiv", "authors": ["Daniel  Perrucci", "Marie-Fran\u00e7oise  Roy"], "year": 2013, "n_citations": 1}
{"id": 1688931, "s2_id": "075db1ff01f507c9038c6487c7267906dd7bbd00", "title": "An Efficient Method for Computing Liouvillian First Integrals of Planar Polynomial Vector Fields", "abstract": "Here we present an efficient method to compute Darboux polynomials for polynomial vector fields in the plane. This approach is restricetd to polynomial vector fields presenting a Liouvillian first integral (or, equivalently, to rational first order differential equations (rational 1ODEs) presenting a Liouvillian general solution). The key to obtaining this method was to separate the procedure of solving the (nonlinear) algebraic systems resulting from the equation that translates the condition of existence of a Darboux polynomial into feasible steos (procedures that requires less memory consumption). We also present a brief performance analysis of the algorithms developed.", "venue": "ArXiv", "authors": ["L.G.S.  Duarte", "L.A.C.P. da Mota"], "year": 2020, "n_citations": 0}
{"id": 1690320, "s2_id": "a19227eb90643b679342d74fd79918a24d1577b3", "title": "Using the Distribution of Cells by Dimension in a Cylindrical Algebraic Decomposition", "abstract": "We investigate the distribution of cells by dimension in cylindrical algebraic decompositions (CADs). We find that they follow a standard distribution which seems largely independent of the underlying problem or CAD algorithm used. Rather, the distribution is inherent to the cylindrical structure and determined mostly by the number of variables. This insight is then combined with an algorithm that produces only full-dimensional cells to give an accurate method of predicting the number of cells in a complete CAD. Since constructing only full-dimensional cells is relatively inexpensive (involving no costly algebraic number calculations) this leads to heuristics for helping with various questions of problem formulation for CAD, such as choosing an optimal variable ordering. Our experiments demonstrate that this approach can be highly effective.", "venue": "2014 16th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing", "authors": ["David J. Wilson", "Matthew  England", "Russell J. Bradford", "James H. Davenport"], "year": 2014, "n_citations": 12}
{"id": 1693234, "s2_id": "bf3f3cf9ce7b70f73b35ec1b04a6db1ca774a843", "title": "Aligator.jl - A Julia Package for Loop Invariant Generation", "abstract": "We describe the Aligator.jl software package for automatically generating all polynomial invariants of the rich class of extended P-solvable loops with nested conditionals. Aligator.jl is written in the programming language Julia and is open-source. Aligator.jl transforms program loops into a system of algebraic recurrences and implements techniques from symbolic computation to solve recurrences, derive closed form solutions of loop variables and infer the ideal of polynomial invariants by variable elimination based on Grobner basis computation.", "venue": "CICM", "authors": ["Andreas  Humenberger", "Maximilian  Jaroschek", "Laura  Kov\u00e1cs"], "year": 2018, "n_citations": 3}
{"id": 1693810, "s2_id": "9dfcb33ac58c3ef0a2837a4a2f763854ccec9ecf", "title": "Calcium: Computing in Exact Real and Complex Fields", "abstract": "Calcium is a C library for real and complex numbers in a form suitable for exact algebraic and symbolic computation. Numbers are represented as elements of fields Q(a1,...,an) where the extension numbers ak may be algebraic or transcendental. The system combines efficient field operations with automatic discovery and certification of algebraic relations, resulting in a practical computational model of R and C in which equality is rigorously decidable for a large class of numbers.", "venue": "ISSAC", "authors": ["Fredrik  Johansson"], "year": 2021, "n_citations": 0}
{"id": 1694915, "s2_id": "8105ab7337737c1d2f3244ce9fd49a8819677e9c", "title": "Planar linkages following a prescribed motion", "abstract": "Designing mechanical devices, called linkages, that draw a given plane curve has been a topic that interested engineers and mathematicians for hundreds of years, and recently also computer scientists. Already in 1876, Kempe proposed a procedure for solving the problem in full generality, but his constructions tend to be extremely complicated. We provide a novel algorithm that produces much simpler linkages, but works only for parametric curves. Our approach is to transform the problem into a factorization task over some noncommutative algebra. We show how to compute such a factorization, and how to use it to construct a linkage tracing a given curve.", "venue": "Math. Comput.", "authors": ["Matteo  Gallet", "Christoph  Koutschan", "Zijia  Li", "Georg  Regensburger", "Josef  Schicho", "Nelly  Villamizar"], "year": 2017, "n_citations": 23}
{"id": 1699028, "s2_id": "3103f75dc7998e9ecce1d947ba3ac9583852312e", "title": "Symmetries and similarities of planar algebraic curves using harmonic polynomials", "abstract": "We present novel, deterministic, efficient algorithms to compute the symmetries of a planar algebraic curve, implicitly defined, and to check whether or not two given implicit planar algebraic curves are similar, i.e. equal up to a similarity transformation. Both algorithms are based on the fact, well-known in Harmonic Analysis, that the Laplacian operator commutes with orthogonal transformations, and on efficient algorithms to find the symmetriessimilarities of a harmonic algebraic curvetwo given harmonic algebraic curves. In fact, we show that in general the problem can be reduced to the harmonic case, except for some special cases, easy to treat.", "venue": "J. Comput. Appl. Math.", "authors": ["Juan Gerardo Alc\u00e1zar", "Miroslav  L\u00e1vicka", "Jan  Vrsek"], "year": 2019, "n_citations": 8}
{"id": 1705573, "s2_id": "1ee639bcc0c67091c65cd4b3484e102b7cd05925", "title": "Supernodal Analysis Revisited", "abstract": "In this paper we show how to extend the known algorithm of nodal analysis in such a way that, in the case of circuits without nullors and controlled sources (but allowing for both, independent current and voltage sources), the system of nodal equations describing the circuit is partitioned into one part, where the nodal variables are explicitly given as linear combinations of the voltage sources and the voltages of certain reference nodes, and another, which contains the node variables of these reference nodes only and which moreover can be read off directly from the given circuit. Neither do we need preparational graph transformations, nor do we need to introduce additional current variables (as in MNA). Thus this algorithm is more accessible to students, and consequently more suitable for classroom presentations.", "venue": "ArXiv", "authors": ["Eberhard H.-A. Gerbracht"], "year": 2009, "n_citations": 1}
{"id": 1706120, "s2_id": "d4898014dbbab7df6344dda5a60533affb40d220", "title": "Proving inequalities and solving global optimization problems via simplified CAD projection", "abstract": "Let x n = ( x 1 , ? , x n ) and f ? R x n , k . The problem of finding all k 0 such that f ( x n , k 0 ) ? 0 on R n is considered in this paper, which obviously takes as a special case the problem of computing the global infimum or proving the semi-definiteness of a polynomial. For solving the problems, we propose a simplified Brown-McCallum's CAD projection operator, Nproj, of which the projection scale is always no larger than that of Brown-McCallum's. For many problems, the projection scale is much smaller than that of Brown-McCallum's. As a result, the lifting phase is also simplified. Some new algorithms based on Nproj for solving those problems are designed and proved to be correct. Comparison to some existing tools on some examples is reported to illustrate the effectiveness of our new algorithms.", "venue": "J. Symb. Comput.", "authors": ["Jingjun  Han", "Zhi  Jin", "Bican  Xia"], "year": 2016, "n_citations": 12}
{"id": 1709294, "s2_id": "34bd6a8276cd87adb3f3681793f22a5c02681e27", "title": "The Symbolic Interior Point Method", "abstract": "A recent trend in probabilistic inference emphasizes the codification of models in a formal syntax, with suitable high-level features such as individuals, relations, and connectives, enabling descriptive clarity, succinctness and circumventing the need for the modeler to engineer a custom solver. Unfortunately, bringing these linguistic and pragmatic benefits to numerical optimization has proven surprisingly challenging. In this paper, we turn to these challenges: we introduce a rich modeling language, for which an interior-point method computes approximate solutions in a generic way. While logical features easily complicates the underlying model, often yielding intricate dependencies, we exploit and cache local structure using algebraic decision diagrams (ADDs). Indeed, standard matrix-vector algebra is efficiently realizable in ADDs, but we argue and show that well-known optimization methods are not ideal for ADDs. Our engine, therefore, invokes a sophisticated matrix-free approach. We demonstrate the flexibility of the resulting symbolic-numeric optimizer on decision making and compressed sensing tasks with millions of non-zero entries.", "venue": "AAAI", "authors": ["Martin  Mladenov", "Vaishak  Belle", "Kristian  Kersting"], "year": 2017, "n_citations": 5}
{"id": 1713360, "s2_id": "0965e0503ae5fb09bc2563e63c2b3012e79f7aa3", "title": "Computing necessary integrability conditions for planar parametrized homogeneous potentials", "abstract": "Let <i>V</i> \u2208 Q(<i>i</i>)(<b>a</b><sub>1</sub>,..., <b>a</b><sub><i>n</i></sub>)(<b>q</b><sub>1</sub>, <b>q</b><sub>2</sub>) be a rationally parametrized planar homogeneous potential of homogeneity degree <i>k</i> \u2260 \u22122, 0, 2. We design an algorithm that computes polynomial <i>necessary</i> conditions on the parameters (<b>a</b><sub>1</sub>,..., <b>a</b><sub><i>n</i></sub>) such that the dynamical system associated to the potential <i>V</i> is integrable. These conditions originate from those of the Morales-Ramis-Sim\u00f3 integrability criterion near all Darboux points. The implementation of the algorithm allows to treat applications that were out of reach before, for instance concerning the non-integrability of polynomial potentials up to degree 9. Another striking application is the first complete proof of the non-integrability of the <i>collinear three body problem</i>.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Thierry  Combot", "Mohab Safey El Din"], "year": 2014, "n_citations": 3}
{"id": 1722120, "s2_id": "7cd6a4bb03104162a5c8cb74f16c69fad8232399", "title": "Computing border bases without using a term ordering", "abstract": "Border bases, a generalization of Gr\u00f6bner bases, have actively been researched during recent years due to their applicability to industrial problems. Kehrein and Kreuzer (J Pure Appl Alg 205:279\u2013295, 2006) formulated the so called Border Basis Algorithm, an algorithm which allows the computation of border bases that relate to a degree compatible term ordering. In this paper we extend the original Border Basis Algorithm in such a way that also border bases that do not relate to any term ordering can be computed by it.", "venue": "ArXiv", "authors": ["Stefan  Kaspar"], "year": 2011, "n_citations": 9}
{"id": 1723143, "s2_id": "355048aefa8e6b9cb1612ab1b0a0de4751e7582d", "title": "Compile-Time Symbolic Differentiation Using C++ Expression Templates", "abstract": "Template metaprogramming is a popular technique for implementing compile time mechanisms for numerical computing. We demonstrate how expression templates can be used for compile time symbolic differentiation of algebraic expressions in C++ computer programs. Given a positive integer $N$ and an algebraic function of multiple variables, the compiler generates executable code for the $N$th partial derivatives of the function. Compile-time simplification of the derivative expressions is achieved using recursive templates. A detailed analysis indicates that current C++ compiler technology is already sufficient for practical use of our results, and highlights a number of issues where further improvements may be desirable.", "venue": "ArXiv", "authors": ["Drosos  Kourounis", "Leonidas  Gergidis", "Michael  Saunders", "Andrea  Walther", "Olaf  Schenk"], "year": 2017, "n_citations": 2}
{"id": 1725280, "s2_id": "59273dd9167c4c700ac2d05664b1ac9be8909763", "title": "Determination of the basis of the space of all root functionals of a system of polynomial equations and of the basis of its ideal by the operation of the extension of bounded root functionals", "abstract": "It is proposed the algorithm that find a basis of the ideal and a basis of the space of all root functionals by using the extension operation for bounded root functionals, when the number of polynomials is equal to the number of variables, if it is known that the ideal of polynomials is 0-dimensional. The asyptotic complexity of this algorithm is d^{O(n)} operations, where n is the number of polynomials and the number of variables, d is the maximal degree of polynomials. The extension operation has connection with the multivariate Bezoutian construction.", "venue": "ArXiv", "authors": ["Timur R. Seifullin"], "year": 2008, "n_citations": 1}
{"id": 1732382, "s2_id": "aa4772d100cb429a3527d3592d002badd83b5139", "title": "Fast Integer Multiplication Using Modular Arithmetic", "abstract": "We give an $N\\cdot \\log N\\cdot 2^{O(\\log^*N)}$ time algorithm to multiply two $N$-bit integers that uses modular arithmetic for intermediate computations instead of arithmetic over complex numbers as in Furer's algorithm, which also has the same and so far the best known complexity. The previous best algorithm using modular arithmetic (by Schonhage and Strassen) has complexity $O(N \\cdot \\log N \\cdot \\log\\log N)$. The advantage of using modular arithmetic as opposed to complex number arithmetic is that we can completely evade the task of bounding the truncation error due to finite approximations of complex numbers, which makes the analysis relatively simple. Our algorithm is based upon Furer's algorithm, but uses fast Fourier transform over multivariate polynomials along with an estimate of the least prime in an arithmetic progression to achieve this improvement in the modular setting. It can also be viewed as a $p$-adic version of Furer's algorithm.", "venue": "SIAM J. Comput.", "authors": ["Anindya  De", "Piyush P. Kurur", "Chandan  Saha", "Ramprasad  Saptharishi"], "year": 2013, "n_citations": 32}
{"id": 1735517, "s2_id": "34e9113e3764b6bbac0b04f547ce9ab238848c03", "title": "Symbolic Computation of Recursion Operators for Nonlinear Differential-Difference equations", "abstract": "An algorithm for the symbolic computation of recursion operators for systems of nonlinear differential-difference equations (DDEs) is presented. Recursion operators allow one to generate an infinite sequence of generalized symmetries. The existence of a recursion operator therefore guarantees the complete integrability of the DDE. The algo-rithm is based in part on the concept of dilation invariance and uses our earlier algorithms for the symbolic computation of conservation laws and generalized symmetries. \nThe algorithm has been applied to a number of well-known DDEs, including the Kac-van Moerbeke (Volterra), Toda, and Ablowitz-Ladik lattices, for which recursion opera-tors are shown. The algorithm has been implemented in Mathematica, a leading com-puter algebra system. The package DDERecursionOperator.m is briefly discussed.", "venue": "ArXiv", "authors": ["\u00dcnal  G\u00f6ktas", "Willy  Hereman"], "year": 2011, "n_citations": 0}
{"id": 1741992, "s2_id": "6ac576a527c9bfb08fb070e04bde77ec469a6a97", "title": "New ways to multiply 3 x 3-matrices", "abstract": "It is known since the 1970s that no more than 23 multiplications are required for computing the product of two 3 x 3-matrices. It is not known whether this can also be done with fewer multiplications. However, there are several mutually inequivalent ways of doing the job with 23 multiplications. In this article, we extend this list considerably by providing more than 13 000 new and mutually inequivalent schemes for multiplying 3 x 3-matrices using 23 multiplications. Moreover, we show that the set of all these schemes is a manifold of dimension at least 17.", "venue": "J. Symb. Comput.", "authors": ["Marijn J.H. Heule", "Manuel  Kauers", "Martina  Seidl"], "year": 2021, "n_citations": 13}
{"id": 1746726, "s2_id": "be69c103118086d21ecc2bad8cdd33957aa6f28c", "title": "Complex Golay Pairs up to Length 28: A Search via Computer Algebra and Programmatic SAT", "abstract": "Abstract We use techniques from the fields of computer algebra and satisfiability checking to develop a new algorithm to search for complex Golay pairs. We implement this algorithm and use it to perform a complete search for complex Golay pairs of lengths up to 28. In doing so, we find that complex Golay pairs exist in the lengths 24 and 26 but do not exist in the lengths 23, 25, 27, and 28. This independently verifies work done by F. Fiedler in 2013 and confirms the 2002 conjecture of Craigen, Holzmann, and Kharaghani that complex Golay pairs of length 23 don't exist. Our algorithm is based on the recently proposed SAT+CAS paradigm of combining SAT solvers with computer algebra systems to efficiently search large spaces specified by both algebraic and logical constraints. The algorithm has two stages: first, a fine-tuned computer program uses functionality from computer algebra systems and numerical libraries to construct a list containing every sequence that could appear as the first sequence in a complex Golay pair up to equivalence. Second, a programmatic SAT solver constructs every sequence (if any) that pair off with the sequences constructed in the first stage to form a complex Golay pair. This extends work originally presented at the International Symposium on Symbolic and Algebraic Computation (ISSAC) in 2018; we discuss and implement several improvements to our algorithm that enabled us to improve the efficiency of the search and increase the maximum length we search from length 25 to 28.", "venue": "J. Symb. Comput.", "authors": ["Curtis  Bright", "Ilias  Kotsireas", "Albert  Heinle", "Vijay  Ganesh"], "year": 2021, "n_citations": 5}
{"id": 1751727, "s2_id": "8086eb947e10e5a7e2db6b3c9c165152b05bb9b6", "title": "Discovering and Proving Infinite Pochhammer Sum Identities", "abstract": "We consider nested sums involving the Pochhammer symbol at infinity and rewrite them in terms of a small set of constants, such as powers of $\\pi,$ $\\log(2)$ or zeta values. In order to perform these simplifications, we view the series as specializations of generating series. For these generating series, we derive integral representations in terms of root-valued iterated integrals or directly in terms of cyclotomic harmonic polylogarithms. Using substitutions, we express the root-valued iterated integrals as cyclotomic harmonic polylogarithms. Finally, by applying known relations among the cyclotomic harmonic polylogarithms, we derive expressions in terms of several constants. The methods are implemented in the computer algebra package HarmonicSums.", "venue": "Experimental Mathematics", "authors": ["Jakob  Ablinger"], "year": 2019, "n_citations": 15}
{"id": 1756150, "s2_id": "e41e08a8d124ef949c8968b88f1270a730b7ca94", "title": "OTTER 3.3 Reference Manual", "abstract": "OTTER is a resolution-style theorem-proving program for first-order logic with equality. OTTER includes the inference rules binary resolution, hyperresolution, UR-resolution, and binary paramodulation. Some of its other abilities and features are conversion from first-order formulas to clauses, forward and back subsumption, factoring, weighting, answer literals, term ordering, forward and back demodulation, evaluable functions and predicates, Knuth-Bendix completion, and the hints strategy. OTTER is coded in ANSI C, is free, and is portable to many different kinds of computer.", "venue": "ArXiv", "authors": ["William  McCune"], "year": 2003, "n_citations": 164}
{"id": 1756357, "s2_id": "7ddd0590007f7a24f723e27bbfa0b1c0ba7a9a1d", "title": "Obtaining exact interpolation multivariate polynomial by approximation", "abstract": "In some fields such as Mathematics Mechanization, automated reasoning and Trustworthy Computing, etc., exact results are needed. Symbolic computations are used to obtain the exact results. Symbolic computations are of high complexity. In order to improve the situation, exact interpolating methods are often proposed for the exact results and approximate interpolating methods for the approximate ones. In this paper, the authors study how to obtain exact interpolation polynomial with rational coefficients by approximate interpolating methods.", "venue": "J. Syst. Sci. Complex.", "authors": ["Yong  Feng", "Xiaolin  Qin", "Jingzhong  Zhang", "Xun  Yuan"], "year": 2011, "n_citations": 4}
{"id": 1756500, "s2_id": "ce060bd4473ae7137e5b63fb933dbe3a4b29d7f7", "title": "Linear solving for sign determination", "abstract": "We give a specific method to solve with quadratic complexity the linear systems arising in known algorithms to deal with the sign determination problem, both in the univariate and multivariate setting. In particular, this enables us to improve the complexity bound for sign determination in the univariate case to O(sd^2log^3d), where s is the number of polynomials involved and d is a bound for their degree. Previously known complexity results involve a factor of d^2^.^3^7^6.", "venue": "Theor. Comput. Sci.", "authors": ["Daniel  Perrucci"], "year": 2011, "n_citations": 6}
{"id": 1759137, "s2_id": "4558aa72c1e9738b0c690dd57010043f23f90b77", "title": "Compositions and collisions at degree p2", "abstract": "A univariate polynomial f over a field is decomposable if [email\u00a0protected]?h=g(h) for nonlinear polynomials g and h. In order to count the decomposables, one wants to know, under a suitable normalization, the number of equal-degree collisions of the form [email\u00a0protected]?h=g^@[email\u00a0protected]?h^@? with (g,h) (g^@?,h^@?) and degg=degg^@?. Such collisions only occur in the wild case, where the field characteristic p divides degf. Reasonable bounds on the number of decomposables over a finite field are known, but they are less sharp in the wild case, in particular for degree p^2. We provide a classification of all polynomials of degree p^2 with a collision. It yields the exact number of decomposable polynomials of degree p^2 over a finite field of characteristic p. We also present an efficient algorithm that determines whether a given polynomial of degree p^2 has a collision or not.", "venue": "J. Symb. Comput.", "authors": ["Raoul  Blankertz", "Joachim von zur Gathen", "Konstantin  Ziegler"], "year": 2013, "n_citations": 7}
{"id": 1763357, "s2_id": "5e13f141bfef6aa842dd10f0cfedaff74f559b3b", "title": "Computing the First Betti Numberand Describing the Connected Components of Semi-algebraic Sets", "abstract": "In this paper we describe a singly exponential algorithm for computing the first Betti number of a given semi-algebraic set. Singly exponential algorithms for computing the zero-th Betti number, and the Euler-Poincar\\'e characteristic, were known before. No singly exponential algorithm was known for computing any of the individual Betti numbers other than the zero-th one. We also give algorithms for obtaining semi-algebraic descriptions of the semi-algebraically connected components of any given real algebraic or semi-algebraic set in single-exponential time improving on previous results.", "venue": "ArXiv", "authors": ["Saugata  Basu", "Richard  Pollack", "Marie-Fran\u00e7oise  Roy"], "year": 2006, "n_citations": 7}
{"id": 1766713, "s2_id": "9bce792bcbd6966de0fa8e93f4c98154f905e0d9", "title": "Transitive factorizations of free partially commutative monoids and Lie algebras", "abstract": "Soit M(A, \u03b8) un monoide partiellement commutatif libre. Nous donnons une condition necessaire et suffisante sur un sous alphabet B \u222a A pour que le facteur droit d'une bisection de la forme M(A, \u03b8)= M(B, \u03b8B).T soit partiellement commutatif libre. Ceci nous permet d'etendre strictement et de facon optimale la theorie (classique) de l'elimination avec commutations partielles et de construire de nouvelles factorisations de M(A, \u03b8) ainsi que les bases de LK(A, \u03b8) associees.", "venue": "Discret. Math.", "authors": ["G\u00e9rard  Duchamp", "Jean-Gabriel  Luque"], "year": 2002, "n_citations": 4}
{"id": 1774572, "s2_id": "c09f0a3c0cf9cd4b400b85dc4afd398cd241d7a5", "title": "A novel approach to symbolic algebra", "abstract": "A prototype for an extensible interactive graphical term manipulation system is presented that combines pattern matching and nondeterministic evaluation to provide a convenient framework for doing tedious algebraic manipulations that so far had to be done manually in a semi-automatic fashion.", "venue": "ArXiv", "authors": ["Thomas  Fischbacher"], "year": 2004, "n_citations": 0}
{"id": 1777025, "s2_id": "1f9f01e9676ee5d457b69fe026e63d4cc4f148e3", "title": "Sparse Differential Resultant for Laurent Differential Polynomials", "abstract": "In this paper, we first introduce the concept of Laurent differentially essential systems and give a criterion for a Laurent differential polynomial system to be Laurent differentially essential in terms of its support matrix. Then, the sparse differential resultant for a Laurent differentially essential system is defined, and its basic properties are proved. In particular, order and degree bounds for the sparse differential resultant are given. Based on these bounds, an algorithm to compute the sparse differential resultant is proposed, which is single exponential in terms of the Jacobi number and the size of the system.", "venue": "Found. Comput. Math.", "authors": ["Wei  Li", "Chun-Ming  Yuan", "Xiao-Shan  Gao"], "year": 2015, "n_citations": 9}
{"id": 1790481, "s2_id": "5277bdb04ad9952c6359a5af8384ff6622106c90", "title": "Characterization of Rational Ruled Surfaces", "abstract": "The algebraic ruled surface is a typical modeling surface in computer aided geometric design. In this paper, we present algorithms to determine whether a given implicit or parametric algebraic surface is a rational ruled surface, and in the affirmative case, to compute a standard parametric representation for the surface.", "venue": "J. Symb. Comput.", "authors": ["Sonia  P\u00e9rez-D\u00edaz", "Li-Yong  Shen"], "year": 2014, "n_citations": 18}
{"id": 1794405, "s2_id": "676e8ac131371120e8377623afcec4f00af5655a", "title": "Solving parametric systems of polynomial equations over the reals through Hermite matrices", "abstract": "We design a new algorithm for solving parametric systems of equations having finitely many complex solutions for generic values of the \nparameters. More precisely, let $\\mathbf{f} = (f_1, \\ldots, f_m)\\subset \\mathbb{Q}[\\mathbf{y}][\\mathbf{x}]$ with $\\mathbf{y} = (y_1, \\ldots, y_{t})$ and $\\mathbf{x} = (x_1, \\ldots, x_{n})$, $\\mathcal{V}\\subset \\mathbb{C}^t \\times \\mathbb{C}^n$ be the algebraic set defined by the simultaneous vanishing of the $f_i$'s and $\\pi$ be the projection $(\\mathbf{y}, \\mathbf{x}) \\to \\mathbf{y}$. Under the assumptions that $\\mathbf{f}$ admits finitely many complex solutions when specializing $\\mathbf{y}$ to generic values and that the ideal generated by $\\mathbf{f}$ is radical, we solve the following algorithmic problem. On input $\\mathbf{f}$, we compute {\\em semi-algebraic formulas} defining open semi-algebraic sets \n$\\mathcal{S}_1, \\ldots, \\mathcal{S}_{\\ell}$ in the parameters' space $\\mathbb{R}^t$ such that $\\cup_{i=1}^{\\ell} \\mathcal{S}_i$ is dense in \n$\\mathbb{R}^t$ and, for $1\\leq i \\leq \\ell$, the number of real points in $\\mathcal{V}\\cap \\pi^{-1}(\\eta)$ is invariant when $\\eta$ ranges \nover $\\mathcal{S}_i$. \n \nThis algorithm exploits special properties of some well chosen monomial bases in the quotient algebra $\\mathbb{Q}(\\mathbf{y})[\\mathbf{x}] / I$ where $I\\subset \\mathbb{Q}(\\mathbf{y})[\\mathbf{x}]$ is the ideal generated by $\\mathbf{f}$ in $\\mathbb{Q}(\\mathbf{y})[\\mathbf{x}]$ as well as the \nspecialization property of the so-called Hermite matrices which represent Hermite's quadratic forms. This allows us to obtain \n``compact'' representations of the semi-algebraic sets $\\mathcal{S}_i$ by means of semi-algebraic formulas encoding the signature of a given \nsymmetric matrix. \n \nWhen $\\mathbf{f}$ satisfies extra genericity assumptions (such as regularity), we use the theory of Gr\\\"obner bases to derive complexity \nbounds both on the number of arithmetic operations in $\\mathbb{Q}$ and the degree of the output polynomials. More precisely, letting $d$ be \nthe maximal degrees of the $f_i$'s and $\\mathfrak{D} = n(d-1)d^n$, we prove that, on a generic input $\\mathbf{f}=(f_1,\\ldots,f_n)$, one can \ncompute those semi-algebraic formulas with $O\\ {\\widetilde{~}}\\left (\\binom{t+\\mathfrak{D}}{t}\\ 2^{3t}\\ n^{2t+1} d^{3nt+2(n+t)+1} \\right )$ \narithmetic operations in $\\mathbb{Q}$ and that the polynomials involved in these formulas have degree bounded by $\\mathfrak{D}$. \n \nWe report on practical experiments which illustrate the efficiency of this algorithm, both on generic parametric systems and parametric \nsystems coming from applications since it allows us to solve systems which are out of reach on the current state-of-the-art.", "venue": "Journal of Symbolic Computation", "authors": ["Huu Phuoc Le", "Mohab Safey El Din"], "year": 2021, "n_citations": 3}
{"id": 1797111, "s2_id": "bcc424a1628a841f4e6cf222f07f06d3e906250c", "title": "Representation of hypergeometric products of higher nesting depths in difference rings", "abstract": "A non-trivial symbolic machinery is presented that can rephrase algorithmically a finite set of nested hypergeometric products in appropriately designed difference rings. As a consequence, one obtains an alternative representation in terms of one single product defined over a root of unity and nested hypergeometric products which are algebraically independent among each other. In particular, one can solve the zero-recognition problem: the input expression of nested hypergeometric products evaluates to zero if and only if the output expression is the zero expression. Combined with available symbolic summation algorithms in the setting of difference rings, one obtains a general machinery that can represent (and simplify) nested sums defined over nested products.", "venue": "ArXiv", "authors": ["Evans Doe Ocansey", "Carsten  Schneider"], "year": 2020, "n_citations": 1}
{"id": 1798260, "s2_id": "caf10cb433de123b13cfa5d13d6c7bbbbbcfc428", "title": "Multivariate Power Series in Maple", "abstract": "We present MultivariatePowerSeries, a Maple library introduced in Maple 2021, providing a variety of methods to study formal multivariate power series and univariate polynomials over such series. This library offers a simple and easy-to-use user interface. Its implementation relies on lazy evaluation techniques and takes advantage of Maple\u2019s features for object-oriented programming. The exposed methods include Weierstrass Preparation Theorem and factorization via Hensel\u2019s lemma. The computational performance is demonstrated by means of an experimental comparison with software counterparts.", "venue": "MC", "authors": ["Mohammadali  Asadi", "Alexander  Brandt", "Mahsa  Kazemi", "Marc Moreno Maza", "Erik  Postma"], "year": 2020, "n_citations": 1}
{"id": 1800318, "s2_id": "fb2524a8c57ea608f61035146844fa8f17e01402", "title": "Solving determinantal systems using homotopy techniques", "abstract": "Let $\\K$ be a field of characteristic zero and $\\Kbar$ be an algebraic closure of $\\K$. Consider a sequence of polynomials$G=(g\\_1,\\dots,g\\_s)$ in $\\K[X\\_1,\\dots,X\\_n]$, a polynomial matrix $\\F=[f\\_{i,j}] \\in \\K[X\\_1,\\dots,X\\_n]^{p \\times q}$, with $p \\leq q$,and the algebraic set $V\\_p(F, G)$ of points in $\\KKbar$ at which all polynomials in $\\G$ and all $p$-minors of $\\F$vanish. Such polynomial systems appear naturally in e.g. polynomial optimization, computational geometry.We provide bounds on the number of isolated points in $V\\_p(F, G)$ depending on the maxima of the degrees in rows (resp. columns) of $\\F$. Next, we design homotopy algorithms for computing those points. These algorithms take advantage of the determinantal structure of the system defining $V\\_p(F, G)$. In particular, the algorithms run in time that is polynomial in the bound on the number of isolated points.", "venue": "J. Symb. Comput.", "authors": ["Jonathan D. Hauenstein", "Mohab Safey El Din", "\u00c9ric  Schost", "Thi Xuan Vu"], "year": 2021, "n_citations": 4}
{"id": 1802822, "s2_id": "93435ec541f09f299a4659686734770438a80d33", "title": "An Algorithm to Decompose Permutation Representations of Finite Groups: Polynomial Algebra Approach", "abstract": "We describe an algorithm for splitting a permutation representation of a finite group into irreducible components. The algorithm is based on the fact that the components of the invariant inner product in invariant subspaces are operators of projection into these subspaces. An important element of the algorithm is the calculation of Gr\\\"obner bases of polynomial ideals. A preliminary implementation of the algorithm splits representations up to dimensions of several thousand. Some examples of computations are given in appendix.", "venue": "ArXiv", "authors": ["Vladimir V. Kornyak"], "year": 2018, "n_citations": 1}
{"id": 1805159, "s2_id": "0111aa066f01466113aa95ced62cd2cf937c2469", "title": "Domain-of-Attraction Estimation for Uncertain Non-polynomial Systems", "abstract": "Abstract In this paper, we consider the problem of computing estimates of the domain-of-attraction for non-polynomial systems. A polynomial approximation technique, based on multivariate polynomial interpolation and error analysis for remaining functions, is applied to compute an uncertain polynomial system, whose set of trajectories contains that of the original non-polynomial system. The efficiency of the presented method is illustrated by some numerical examples.", "venue": "Commun. Nonlinear Sci. Numer. Simul.", "authors": ["Min  Wu", "Zhengfeng  Yang", "Wang  Lin"], "year": 2014, "n_citations": 7}
{"id": 1822216, "s2_id": "478d17838065291763666365c806840099c4de0b", "title": "The Absent-Minded Passengers Problem: A Motivating Challenge Solved by Computer Algebra", "abstract": "In Ekhad and Zeilberger (Personal J Shalosh B Ekhad and Doron Zeilberger, 2020) an exciting case study has been initiated in which experimental mathematics and symbolic computation are utilized to discover new properties concerning the so-called Absent-Minded Passengers Problem. Based on these results, Doron Zeilberger raised some challenging tasks to gain further probabilistic insight. In this note we report on this enterprise. In particular, we demonstrate how the computer algebra packages of RISC can be used to carry out the underlying heavy calculations.\n", "venue": "Math. Comput. Sci.", "authors": ["Carsten  Schneider"], "year": 2021, "n_citations": 1}
{"id": 1824177, "s2_id": "125876c8d43bc102da86be20ffcee0dc22324c9f", "title": "A baby steps/giant steps Monte Carlo algorithm for computing roadmaps in smooth compact real hypersurfaces", "abstract": "We consider the problem of constructing roadmaps of real algebraic sets. The problem was introduced by Canny to answer connectivity questions and solve motion planning problems. Given $s$ polynomial equations with rational coefficients, of degree $D$ in $n$ variables, Canny's algorithm has a Monte Carlo cost of $s^n\\log(s) D^{O(n^2)}$ operations in $\\mathbb{Q}$; a deterministic version runs in time $s^n \\log(s) D^{O(n^4)}$. The next improvement was due to Basu, Pollack and Roy, with an algorithm of deterministic cost $s^{d+1} D^{O(n^2)}$ for the more general problem of computing roadmaps of semi-algebraic sets ($d \\le n$ is the dimension of an associated object). We give a Monte Carlo algorithm of complexity $(nD)^{O(n^{1.5})}$ for the problem of computing a roadmap of a compact hypersurface $V$ of degree $D$ in $n$ variables; we also have to assume that $V$ has a finite number of singular points. Even under these extra assumptions, no previous algorithm featured a cost better than $D^{O(n^2)}$.", "venue": "ArXiv", "authors": ["Mohab Safey El Din", "\u00c9ric  Schost"], "year": 2009, "n_citations": 3}
{"id": 1833560, "s2_id": "95a12ee6d6f7734f7cf8a8d27a6125d71cbea81a", "title": "Dense Linear Algebra over Finite Fields: the FFLAS and FFPACK packages", "abstract": "In the last past two decades, several efforts have been made to reduce exact lin ear algebra problems to matrix multiplication in order to provide algorithms with optimal asymptotic complexity. To provide efficient implementations of such algorithms one need to be careful w ith the underlying arithmetic. It is well know that modular technique such as Chinese remainder algorithm or p -adic lifting allow in practice to achieve better performances especially when word size arithmetic are used. Therefore, finite field arithmetics becomes an important core for efficient exac t linear algebra libraries. In this paper we study different implementations of finite field in order to ach ieve efficiency for basic linear algebra routines such as dot product or matrix multiplication; our goal being to provide an exact alterna te to numerical BLAS library. Following matrix multiplication reductions, our kernel has many symbolic linear algebra applications: symbolic triangularization, system solving, exact determin ant computation and matrix inversion are then studied and we demonstrate the efficie ncy of these reductions in practice.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Thierry  Gautier", "Pascal  Giorgi", "Cl\u00e9ment  Pernet"], "year": 2006, "n_citations": 14}
{"id": 1835479, "s2_id": "696d81f0915520c9ae7c794797065e5f79e23bd3", "title": "Private Multi-party Matrix Multiplication and Trust Computations", "abstract": "This paper deals with distributed matrix multiplication. Each player owns only one row of both matrices and \n \nwishes to learn about one distinct row of the product matrix, without revealing its input to the other players. \n \nWe first improve on a weighted average protocol, in order to securely compute a dot-product with a \n \nquadratic volume of communications and linear number of rounds. We also propose a protocol with five communication \n \nrounds, using a Paillier-like underlying homomorphic public key cryptosystem, which is secure in \n \nthe semi-honest model or secure with high probability in the malicious adversary model. Using ProVerif, a \n \ncryptographic protocol verification tool, we are able to check the security of the protocol and provide a countermeasure \n \nfor each attack found by the tool. We also give a randomization method to avoid collusion attacks. \n \nAs an application, we show that this protocol enables a distributed and secure evaluation of trust relationships \n \nin a network, for a large class of trust evaluation schemes.", "venue": "SECRYPT", "authors": ["Jean-Guillaume  Dumas", "Pascal  Lafourcade", "Jean-Baptiste  Orfila", "Maxime  Puys"], "year": 2016, "n_citations": 9}
{"id": 1836243, "s2_id": "1be3f9d4ec8ebc5e0a59977bf5a21ab42cf112fc", "title": "Towards a new ode solver based on cartan's equivalence method", "abstract": "The aim of the present paper is to propose an algorithm for a new ODE-solver which should improve the abilities of current solvers to handle second order differential equations. The paper provides also a theoretical result revealing the relationship between the change of coordinates, that maps the generic equation to a given target equation, and the symmetry D-groupoid of this target.", "venue": "ISSAC '07", "authors": ["Raouf  Dridi", "Michel  Petitot"], "year": 2007, "n_citations": 3}
{"id": 1836975, "s2_id": "a04142067bb26511a6e67be5821289f00f28c93f", "title": "On the Complexity of Real Root Isolation", "abstract": "We introduce a new approach to isolate the real roots of a square-free polynomial $F=\\sum_{i=0}^n A_i x^i$ with real coefficients. It is assumed that each coefficient of $F$ can be approximated to any specified error bound. The presented method is exact, complete and deterministic. Due to its similarities to the Descartes method, we also consider it practical and easy to implement. Compared to previous approaches, our new method achieves a significantly better bit complexity. It is further shown that the hardness of isolating the real roots of $F$ is exclusively determined by the geometry of the roots and not by the complexity or the size of the coefficients. For the special case where $F$ has integer coefficients of maximal bitsize $\\tau$, our bound on the bit complexity writes as $\\tilde{O}(n^3\\tau^2)$ which improves the best bounds known for existing practical algorithms by a factor of $n=deg F$. The crucial idea underlying the new approach is to run an approximate version of the Descartes method, where, in each subdivision step, we only consider approximations of the intermediate results to a certain precision. We give an upper bound on the maximal precision that is needed for isolating the roots of $F$. For integer polynomials, this bound is by a factor $n$ lower than that of the precision needed when using exact arithmetic explaining the improved bound on the bit complexity.", "venue": "ArXiv", "authors": ["Michael  Sagraloff"], "year": 2010, "n_citations": 21}
{"id": 1838856, "s2_id": "4834ca0b6ea414a5652cb6d30f0ec4f7935fc87f", "title": "Schemes for deterministic polynomial factoring", "abstract": "In this work we relate the deterministic complexity of factoring polynomials (over finite fields) to certain combinatorial objects, we call m-schemes, that are generalizations of permutation groups. We design a new generalization of the known conditional deterministic subexponential time polynomial factoring algorithm to get an underlying m-scheme. We then demonstrate how progress in understanding m-schemes relate to improvements in the deterministic complexity of factoring polynomials, assuming the Generalized Riemann Hypothesis (GRH).\n In particular, we give the first deterministic polynomial time algorithm (assuming GRH) to find a nontrivial factor of a polynomial of prime degree n where (n-1) is a constant-smooth number. We use a structural theorem about association schemes on a prime number of points, which Hanaki and Uno (2006) proved by representation theory methods.", "venue": "ISSAC '09", "authors": ["G\u00e1bor  Ivanyos", "Marek  Karpinski", "Nitin  Saxena"], "year": 2009, "n_citations": 16}
{"id": 1843134, "s2_id": "8afe7cc3ae6750cdecd010b4707a3bf4f626412c", "title": "Heuristic Reasoning on Graph and Game Complexity of Sudoku", "abstract": "The Sudoku puzzle has achieved worldwide popularity recently, and attracted great attention of the computational intelligence community. Sudoku is always considered as Satisfiability Problem or Constraint Satisfaction Problem. In this paper, we propose to focus on the essential graph structure underlying the Sudoku puzzle. First, we formalize Sudoku as a graph. Then a solving algorithm based on heuristic reasoning on the graph is proposed. The related r-Reduction theorem, inference theorem and their properties are proved, providing the formal basis for developments of Sudoku solving systems. In order to evaluate the difficulty levels of puzzles, a quantitative measurement of the complexity level of Sudoku puzzles based on the graph structure and information theory is proposed. Experimental results show that all the puzzles can be solved fast using the proposed heuristic reasoning, and that the proposed game complexity metrics can discriminate difficulty levels of puzzles perfectly.", "venue": "ArXiv", "authors": ["Zhe  Chen"], "year": 2009, "n_citations": 9}
{"id": 1843337, "s2_id": "c0bb8d12330a85d5c24f8681585b6b2a8fe0ec27", "title": "The fundamental theorem of tropical partial differential algebraic geometry", "abstract": "Tropical Differential Algebraic Geometry considers difficult or even intractable problems in Differential Equations and tries to extract information on their solutions from a restricted structure of the input. The Fundamental Theorem of Tropical Differential Algebraic Geometry states that the support of solutions of systems of ordinary differential equations with formal power series coefficients over an uncountable algebraically closed field of characteristic zero can be obtained by solving a so-called tropicalized differential system. Tropicalized differential equations work on a completely different algebraic structure which may help in theoretical and computational questions. We show that the Fundamental Theorem can be extended to the case of systems of partial differential equations by introducing vertex sets of Newton polytopes.", "venue": "ISSAC", "authors": ["Sebastian  Falkensteiner", "Cristhian  Garay-L'opez", "Mercedes  Haiech", "Marc Paul Noordman", "Zeinab  Toghani", "Franccois  Boulier"], "year": 2020, "n_citations": 3}
{"id": 1847663, "s2_id": "a47b446874f525fa510782e1fbe04dab233fa071", "title": "CPS Engineering: Gap Analysis and Perspectives", "abstract": "Virtualization of computing and networking, IT-OT convergence, cybersecurity and AI-based enhancement of autonomy are significantly increasing the complexity of CPS and CPSoS. New challenges have emerged to demonstrate that these systems are safe and secure. We emphasize the role of control and emerging fields therein, like symbolic control or set-based fault-tolerant and decentralized control, to address safety. We have chosen three open verification problems we deem central in cost-effective development and certification of safety critical CPSoS. We review some promising threads of research that could lead in the long term to a scalable and powerful verification strategy. Its main components are set-based and invariant-based design, contracts, adversarial testing, algorithmic geometry of dynamics, and probabilistic estimation derived from compositional massive testing. To explore these orientations in collaborative projects, and to promote them in certification arenas, we propose to continue and upgrade an open innovation drone-based use case that originated from a collaborative research project in aeronautic certification reformation", "venue": "ArXiv", "authors": ["Emmanuel  Ledinot"], "year": 2021, "n_citations": 0}
{"id": 1850561, "s2_id": "79f9f4dc3f5ae63dee00abc3efc8c803dd6c0200", "title": "Topological rewriting systems applied to standard bases and syntactic algebras", "abstract": "We propose a functional description of rewriting systems on topological vector spaces. We introduce the topological confluence property as an approximation of the confluence property. Using a representation of linear topological rewriting systems with continuous reduction operators, we show that the topological confluence is characterised by lattice operations. We relate these operations to standard bases and show that the latter induce topologically confluent rewriting systems on formal power series. Finally, we investigate duality for reduction operators that we relate to series representations and syntactic algebras. In particular, we use duality for proving that an algebra is syntactic or not.", "venue": "Journal of Algebra", "authors": ["Cyrille  Chenavier"], "year": 2020, "n_citations": 1}
{"id": 1851594, "s2_id": "636957c820059bdae72fe0d70679526fc799d532", "title": "Performance Comparison of Function Evaluation Methods", "abstract": "We perform a comparison of the performance and efficiency of four different function evaluation methods: black-box functions, binary trees, $n$-ary trees and string parsing. The test consists in evaluating 8 different functions of two variables $x,y$ over 5000 floating point values of the pair $(x,y)$. The outcome of the test indicates that the $n$-ary tree representation of algebraic expressions is the fastest method, closely followed by black-box function method, then by binary trees and lastly by string parsing.", "venue": "ArXiv", "authors": ["Leo  Liberti"], "year": 2002, "n_citations": 3}
{"id": 1851619, "s2_id": "98c192fe59f97353e55a6a5b303e88b67b87bae4", "title": "Stability Analysis of Linear Uncertain Systems via Checking Positivity of Forms on Simplices", "abstract": "In this paper, we mainly study the robust stability of linear continuous systems with parameter uncertainties, a more general kind of uncertainties for system matrices is considered, i.e., entries of system matrices are rational functions of uncertain parameters which are varying in intervals. we present a method which can check the robust Hurwitz stability of such uncertain systems in finite steps. Examples show the efficiency of our approach.", "venue": "ArXiv", "authors": ["Xiaorong  Hou", "Junwei  Shao"], "year": 2010, "n_citations": 0}
{"id": 1854226, "s2_id": "78d71c8d2040693b76461a6a91313f666e8f9711", "title": "Effective Matrix Methods in Commutative Domains", "abstract": "Effective matrix methods for solving standard linear algebra problems in a commutative domains are discussed. Two of them are new. There are a methods for computing adjoined matrices and solving system of linear equations in a commutative domains.", "venue": "ArXiv", "authors": ["Gennadi I. Malaschonok"], "year": 2017, "n_citations": 7}
{"id": 1856836, "s2_id": "15a43ca7f3e2cdb08e9e02d0bc75eb60c2894143", "title": "Fast Jacobian group operations for C_{3,4} curves over a large finite field", "abstract": "Let C be an arbitrary smooth algebraic curve of genus g over a large finite field K. We revisit fast addition algorithms in the Jacobian of C due to Khuri-Makdisi (math.NT/0409209, to appear in Math. Comp.). The algorithms, which reduce to linear algebra in vector spaces of dimension O(g) once |K| >> g, and which asymptotically require O(g^{2.376}) field operations using fast linear algebra, are shown to perform efficiently even for certain low genus curves. Specifically, we provide explicit formulae for performing the group law on Jacobians of C_{3,4} curves of genus 3. We show that, typically, the addition of two distinct elements in the Jacobian of a C_{3,4} curve requires 117 multiplications and 2 inversions in K, and an element can be doubled using 129 multiplications and 2 inversions in K. This represents an improvement of approximately 20% over previous methods.", "venue": "ArXiv", "authors": ["Fatima Abu Salem", "Kamal  Khuri-Makdisi"], "year": 2006, "n_citations": 16}
{"id": 1860164, "s2_id": "c3fbc2b66e2ea91e2c8c44f7086780a9d11bcc7b", "title": "Unification and combination of a class of traversal strategies made with pattern matching and fixed-points", "abstract": "Motivated by an ongoing project on computer aided derivation of asymptotic models governed by partial differential equations, we introduce a class of term transformations that consists of traversal strategies and insertion of contexts. We define unification and combination operations on this class which amount to merging transformations in order to obtain more complex ones. We show that the unification and combination operations enjoy nice algebraic properties like associativity, congruence and the existence of neutral elements. The main part of this paper is devoted to proving that the unification and combination operations are correct.", "venue": "Journal of Logical and Algebraic Methods in Programming", "authors": ["Walid  Belkhir", "Nicolas  Ratier", "Duy Duc Nguyen", "Michel  Lenczner"], "year": 2021, "n_citations": 0}
{"id": 1862261, "s2_id": "67db583cca09d8ec9feb76822929c57d30084816", "title": "Fast Algorithm for Calculating the Minimal Annihilating Polynomials of Matrices via Pseudo Annihilating Polynomials", "abstract": "We propose a efficient method to calculate \"the minimal annihilating polynomials\" for all the unit vectors, of square matrix over the integers or the rational numbers. The minimal annihilating polynomials are useful for improvement of efficiency in wide variety of algorithms in exact linear algebra. We propose an efficient algorithm for calculating the minimal annihilating polynomials for all the unit vectors via pseudo annihilating polynomials with the key idea of binary splitting technique. Efficiency of the proposed algorithm is shown by arithmetic time complexity analysis.", "venue": "ArXiv", "authors": ["Shinichi  Tajima", "Katsuyoshi  Ohara", "Akira  Terui"], "year": 2018, "n_citations": 1}
{"id": 1863267, "s2_id": "098d527b7423c405deea3eb6bd5b447a070a2d25", "title": "Sparse Polynomial Interpolation Based on Derivative", "abstract": "In this paper, we propose two new interpolation algorithms for sparse multivariate polynomials represented by a straight-line program(SLP). Both of our algorithms work over any finite fields $F_q$ with large characteristic. The first one is a Monte Carlo randomized algorithm. Its arithmetic complexity is linear in the number $T$ of non-zero terms of $f$, in the number $n$ of variables. If $q$ is $O((nTD)^{(1)})$, where $D$ is the partial degree bound, then our algorithm has better complexity than other existing algorithms. The second one is a deterministic algorithm. It has better complexity than existing deterministic algorithms over a field with large characteristic. Its arithmetic complexity is quadratic in $n,T,\\log D$, i.e., quadratic in the size of the sparse representation. And we also show that the complexity of our deterministic algorithm is the same as the one of deterministic zero-testing of Blaser et al. for the polynomial given by an SLP over finite field (for large characteristic).", "venue": "ArXiv", "authors": ["Qiao-Long  Huang"], "year": 2020, "n_citations": 1}
{"id": 1863552, "s2_id": "aa07667e4705f4652e9b0fa530c74e7856c2ae62", "title": "Efficiently Computing Real Roots of Sparse Polynomials", "abstract": "We propose an efficient algorithm to compute the real roots of a sparse polynomial f\u2208R[x] having k non-zero real-valued coefficients. It is assumed that arbitrarily good approximations of the non-zero coefficients are given by means of a coefficient oracle. For a given positive integer L, our algorithm returns disjoint disks \u03941,...,\u0394s\u2282C, with s<2k, centered at the real axis and of radius less than 2-L together with positive integers \u03bc1,...,\u03bcs such that each disk \u0394i contains exactly \u03bci roots of f counted with multiplicity. In addition, it is ensured that each real root of f is contained in one of the disks. If f has only simple real roots, our algorithm can also be used to isolate all real roots. The bit complexity of our algorithm is polynomial in k and log n, and near-linear in L and \u03c4, where 2-\u03c4 and 2\u03c4 constitute lower and upper bounds on the absolute values of the non-zero coefficients of f, and n is the degree of f. For root isolation, the bit complexity is polynomial in k and log n, and near-linear in \u03c4 and log\u03c3-1, where \u03c3 denotes the separation of the real roots.", "venue": "ISSAC", "authors": ["Gorav  Jindal", "Michael  Sagraloff"], "year": 2017, "n_citations": 5}
{"id": 1866491, "s2_id": "5b228a56739a41e7048de7d6f6d9ed5e0ef0a652", "title": "Drinfeld Modules with Complex Multiplication, Hasse Invariants and Factoring Polynomials over Finite Fields", "abstract": "We present a novel randomized algorithm to factor polynomials over a finite field $\\F_q$ of odd characteristic using rank $2$ Drinfeld modules with complex multiplication. The main idea is to compute a lift of the Hasse invariant (modulo the polynomial $f \\in \\F_q[x]$ to be factored) with respect to a random Drinfeld module $\\phi$ with complex multiplication. Factors of $f$ supported on prime ideals with supersingular reduction at $\\phi$ have vanishing Hasse invariant and can be separated from the rest. Incorporating a Drinfeld module analogue of Deligne's congruence, we devise an algorithm to compute the Hasse invariant lift, which turns out to be the crux of our algorithm. The resulting expected runtime of $n^{3/2+\\varepsilon} (\\log q)^{1+o(1)}+n^{1+\\varepsilon} (\\log q)^{2+o(1)}$ to factor polynomials of degree $n$ over $\\F_q$ matches the fastest previously known algorithm, the Kedlaya-Umans implementation of the Kaltofen-Shoup algorithm.", "venue": "J. Symb. Comput.", "authors": ["Javad  Doliskani", "Anand Kumar Narayanan", "\u00c9ric  Schost"], "year": 2021, "n_citations": 4}
{"id": 1867596, "s2_id": "16c9b9d0acbcb8756184ccbf18258f0f45911972", "title": "Algorithms to solve coupled systems of differential equations in terms of power series", "abstract": "Using integration by parts relations, Feynman integrals can be represented in terms of coupled systems of differential equations. In the following we suppose that the unknown Feynman integrals can be given in power series representations, and that sufficiently many initial values of the integrals are given. Then there exist algorithms that decide constructively if the coefficients of their power series representations can be given within the class of nested sums over hypergeometric products. In this article we will work out the calculation steps that solve this problem. First, we will present a successful tactic that has been applied recently to challenging problems coming from massive 3-loop Feynman integrals. Here our main tool is to solve scalar linear recurrences within the class of nested sums over hypergeometric products. Second, we will present a new variation of this tactic which relies on more involved summation technologies but succeeds in reducing the problem to solve scalar recurrences with lower recurrence orders. The article will work out the different challenges of this new tactic and demonstrates how they can be treated efficiently with our existing summation technologies.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Arnd  Behring", "Johannes  Bl\u00fcmlein", "Abilio De Freitas", "Carsten  Schneider"], "year": 2016, "n_citations": 6}
{"id": 1871720, "s2_id": "9fac4372f0d2f54b518c63fb53b8d9443eab6439", "title": "On the structure of compatible rational functions", "abstract": "A finite number of rational functions are compatible if they satisfy the compatibility conditions of a first-order linear functional system involving differential, shift and q-shift operators. We present a theorem that describes the structure of compatible rational functions. The theorem enables us to decompose a solution of such a system as a product of a rational function, several symbolic powers, a hyperexponential function, a hypergeometric term, and a q-hypergeometric term. We outline an algorithm for computing this product, and present an application.", "venue": "ISSAC '11", "authors": ["Shaoshi  Chen", "Ruyong  Feng", "Guofeng  Fu", "Ziming  Li"], "year": 2011, "n_citations": 12}
{"id": 1881151, "s2_id": "b860a5cf788cdc5830dcec83e31c2bdde1b39b4a", "title": "Toric difference variety", "abstract": "In this paper, the concept of toric difference varieties is defined and four equivalent descriptions for toric difference varieties are presented in terms of difference rational parametrization, difference coordinate rings, toric difference ideals, and group actions by difference tori. Connections between toric difference varieties and affine \u2115[x]-semimodules are established by proving the one-to-one correspondence between irreducible invariant difference subvarieties and faces of \u2115[x]-semimodules and the orbit-face correspondence. Finally, an algorithm is given to decide whether a binomial difference ideal represented by a \u2124[x]-lattice defines a toric difference variety.", "venue": "J. Syst. Sci. Complex.", "authors": ["Xiao-Shan  Gao", "Zhang  Huang", "Jie  Wang", "Chun-Ming  Yuan"], "year": 2017, "n_citations": 7}
{"id": 1881155, "s2_id": "375668da1264696d08ba1e50e08d08d5c15dd386", "title": "A Fast Randomized Geometric Algorithm for Computing Riemann-Roch Spaces", "abstract": "We propose a probabilistic variant of Brill-Noether's algorithm for computing a basis of \nthe \nRiemann-Roch space $L(D)$ associated to a divisor $D$ on a projective nodal plane curve \n$\\mathcal C$ over a sufficiently large perfect field $k$. Our main result shows that this \nalgorithm requires at most $O(\\max(\\deg(\\mathcal C)^{2\\omega}, \\deg(D_+)^\\omega))$ \narithmetic operations in $k$, \nwhere $\\omega$ is a feasible exponent for matrix multiplication and $D_+$ is the \nsmallest effective divisor such that $D_+\\geq D$. This improves the \nbest known upper bounds on the complexity of computing Riemann-Roch spaces. \nOur algorithm may fail, but we show that provided that a few mild assumptions \nare satisfied, the failure probability is bounded by $O(\\max(\\deg(\\mathcal C)^4, \n\\deg(D_+)^2)/\\lvert \\mathcal E\\rvert)$, where $\\mathcal E$ \nis a finite subset of $k$ in which we pick elements uniformly at random. \nWe provide a freely available C++/NTL implementation of the proposed algorithm \nand we present experimental data. In particular, our \nimplementation enjoys a speedup larger than 6 on many examples (and larger than 200 on some \ninstances over large finite \nfields) \ncompared to the reference implementation in the Magma computer algebra system. \nAs a by-product, our algorithm also yields a method for computing the group \nlaw on the Jacobian of a smooth plane curve of genus $g$ within $O(g^\\omega)$ \noperations in $k$, which equals the best known complexity for this problem.", "venue": "Math. Comput.", "authors": ["Aude Le Gluher", "Pierre-Jean  Spaenlehauer"], "year": 2020, "n_citations": 7}
{"id": 1885120, "s2_id": "6b1fd29dac34a8006a4157cbe2bf329587b9154b", "title": "Classification of Higher Mobility Linkages", "abstract": "We provide a complete classification of paradoxical n\u2212linkages, n \u2265 6 whose mobility is n\u22124 or higher containing R, P or H joints. We also explicitly write down strong necessary conditions for nR-linkages of mobility n\u2212 5.", "venue": "ArXiv", "authors": ["Tiago  Guerreiro", "Zijia  Li", "Josef  Schicho"], "year": 2021, "n_citations": 0}
{"id": 1897437, "s2_id": "418f69a1f3684b01a9be58da3f0b94619d0e3431", "title": "Resultant of an equivariant polynomial system with respect to the symmetric group", "abstract": "Given a system of n ? 2 homogeneous polynomials in n variables which is equivariant with respect to the symmetric group of n symbols, it is proved that its resultant can be decomposed into a product of several resultants that are given in terms of some divided differences. As an application, we obtain a decomposition formula for the discriminant of a multivariate homogeneous symmetric polynomial.", "venue": "J. Symb. Comput.", "authors": ["Laurent  Bus\u00e9", "Anna  Karasoulou"], "year": 2016, "n_citations": 4}
{"id": 1897577, "s2_id": "5b0762cf723de11455f3e10b5a0c49e66ee7c641", "title": "Compatible rewriting of noncommutative polynomials for proving operator identities", "abstract": "The goal of this paper is to prove operator identities using equalities between noncommutative polynomials. In general, a polynomial expression is not valid in terms of operators, since it may not be compatible with domains and codomains of the corresponding operators. Recently, some of the authors introduced a framework based on labelled quivers to rigorously translate polynomial identities to operator identities. In the present paper, we extend and adapt the framework to the context of rewriting and polynomial reduction. We give a sufficient condition on the polynomials used for rewriting to ensure that standard polynomial reduction automatically respects domains and codomains of operators. Finally, we adapt the noncommutative Buchberger procedure to compute additional compatible polynomials for rewriting. In the package OperatorGB, we also provide an implementation of the concepts developed.", "venue": "ISSAC", "authors": ["Cyrille  Chenavier", "Clemens  Hofstadler", "Clemens G. Raab", "Georg  Regensburger"], "year": 2020, "n_citations": 5}
{"id": 1911655, "s2_id": "f8289f615b47e1d2d5b8fc903c9b989f59c5bd03", "title": "Desingularization of Ore operators", "abstract": "We show that Ore operators can be desingularized by calculating a least common left multiple with a random operator of appropriate order, thereby turning a heuristic used for many years in several computer algebra systems into an algorithm. Our result can be viewed as a generalization of a classical result about apparent singularities of linear differential equations.", "venue": "J. Symb. Comput.", "authors": ["Shaoshi  Chen", "Manuel  Kauers", "Michael F. Singer"], "year": 2016, "n_citations": 19}
{"id": 1913060, "s2_id": "b40466bd46d537f61a25bd58ca8eff6f38da9503", "title": "Sparse difference resultant", "abstract": "In this paper, the concept of sparse difference resultant for a Laurent transformally essential system of Laurent difference polynomials is introduced and its properties are proved. In particular, order and degree bounds for the sparse difference resultant are given. Based on these bounds, an algorithm to compute the sparse difference resultant is proposed, which is single exponential in terms of the number of variables, the Jacobi number, and the size of the system. Also, the precise order, degree, a determinant representation, and a Poissontype product formula for the difference resultant are given.", "venue": "J. Symb. Comput.", "authors": ["Wei  Li", "Chun-Ming  Yuan", "Xiao-Shan  Gao"], "year": 2015, "n_citations": 6}
{"id": 1916630, "s2_id": "514ce4b943ce72ea03a659c3d88114242438c9f0", "title": "Code optimization in FORM", "abstract": "We describe the implementation of output code optimization in the open source computer algebra system FORM. This implementation is based on recently discovered techniques of Monte Carlo tree search to find efficient multivariate Horner schemes, in combination with other optimization algorithms, such as common subexpression elimination. For systems for which no specific knowledge is provided it performs significantly better than other methods we could compare with. Because the method has a number of free parameters, we also show some methods by which to tune them to different types of problems.", "venue": "Comput. Phys. Commun.", "authors": ["Jan  Kuipers", "Takahiro  Ueda", "J. A. M. Vermaseren"], "year": 2015, "n_citations": 51}
{"id": 1920266, "s2_id": "d9b4242fc719ed94ffe8a0bfe1e96d70716187f6", "title": "A new edge selection heuristic for computing the Tutte polynomial of an undirected graph", "abstract": "We present a new edge selection heuristic and vertex ordering heuristic that together enable one to compute the Tutte polynomial of much larger sparse graphs than was previously doable. As a specific example, we are able to compute the Tutte polynomial of the truncated icosahedron graph using our Maple implementation in under 4 minutes on a single CPU. This compares with a recent result of Haggard, Pearce and Royle whose special purpose C++ software took one week on 150 computers. R\u00b4", "venue": "ArXiv", "authors": ["Michael B. Monagan"], "year": 2012, "n_citations": 1}
{"id": 1920954, "s2_id": "3c2b1ed17451c2a8ee2f13ddf79a67637077c76f", "title": "Detecting tropical defects of polynomial equations", "abstract": "We introduce the notion of tropical defects, certificates that a system of polynomial equations is not a tropical basis, and provide two algorithms for finding them in affine spaces of complementary dimension to the zero set. We use these techniques to solve open problems regarding del Pezzo surfaces of degree\u00a03 and realizability of valuated gaussoids on\u00a04 elements.", "venue": "Journal of Algebraic Combinatorics", "authors": ["Paul  G\u00f6rlach", "Yue  Ren", "Jeff  Sommars"], "year": 2019, "n_citations": 3}
{"id": 1930210, "s2_id": "375f9fb3e9da0c8046fab7274a2b3197d3593e36", "title": "How Can I Do That with ACL2? Recent Enhancements to ACL2", "abstract": "The last several years have seen major enhancements to ACL2 functionality, largely driven by requests from its user community, including utilities now in common use such as 'make-event', 'mbe', and trust tags. In this paper we provide user-level summaries of some ACL2 enhancements introduced after the release of Version 3.5 (in May, 2009, at about the time of the 2009 ACL2 workshop) up through the release of Version 4.3 in July, 2011, roughly a couple of years later. Many of these features are not particularly well known yet, but most ACL2 users could take advantage of at least some of them. Some of the changes could affect existing proof efforts, such as a change that treats pairs of functions such as 'member' and 'member-equal' as the same function.", "venue": "ACL2", "authors": ["Matt  Kaufmann", "J Strother Moore"], "year": 2011, "n_citations": 5}
{"id": 1933666, "s2_id": "d5b087abc32485d02dd0b1e7cdf45ae0d4ac0484", "title": "Effective Coefficient Asymptotics of Multivariate Rational Functions via Semi-Numerical Algorithms for Polynomial Systems", "abstract": "The coefficient sequences of multivariate rational functions appear in many areas of combinatorics. Their diagonal coefficient sequences enjoy nice arithmetic and asymptotic properties, and the field of analytic combinatorics in several variables (ACSV) makes it possible to compute asymptotic expansions. We consider these methods from the point of view of effectivity. In particular, given a rational function, ACSV requires one to determine a (generically) finite collection of points that are called critical and minimal. Criticality is an algebraic condition, meaning it is well treated by classical methods in computer algebra, while minimality is a semi-algebraic condition describing points on the boundary of the domain of convergence of a multivariate power series. We show how to obtain dominant asymptotics for the diagonal coefficient sequence of multivariate rational functions under some genericity assumptions using symbolic-numeric techniques. To our knowledge, this is the first completely automatic treatment and complexity analysis for the asymptotic enumeration of rational functions in an arbitrary number of variables.", "venue": "J. Symb. Comput.", "authors": ["Stephen  Melczer", "Bruno  Salvy"], "year": 2021, "n_citations": 5}
{"id": 1939566, "s2_id": "8bcfaf45a391869f990f85aede34ae47622f2754", "title": "Munchausen Iteration", "abstract": "We present a method for solving polynomial equations over idempotent \u03c9-continuous semirings. The idea is to iterate over the semiring of functions rather than the semiring of interest, and only evaluate when needed. The key operation is substitution. In the initial step, we compute a linear completion of the system of equations that exhaustively inserts the equations into one another. With functions as approximants, the following steps insert the current approximant into itself. Since the iteration improves its precision by substitution rather than computation we named it Munchausen, after the fictional baron that pulled himself out of a swamp by his own hair. The first result shows that an evaluation of the nth Munchausen approximant coincides with the 2nth Newton approximant. Second, we show how to compute linear completions with standard techniques from automata theory. In particular, we are not bound to (but can use) the notion of differentials prominent in Newton iteration.", "venue": "ArXiv", "authors": ["Roland  Meyer", "Sebastian  Muskalla"], "year": 2016, "n_citations": 1}
{"id": 1954417, "s2_id": "b16999b672bdb38d45b05c98f085cf770ac6f425", "title": "A Characterization of Reduced Forms of Linear Differential Systems", "abstract": "A differential system $[A] : \\; Y'=AY$, with $A\\in \\mathrm{Mat}(n, \\bar{k})$ is said to be in reduced form if $A\\in \\mathfrak{g}(\\bar{k})$ where $\\mathfrak{g}$ is the Lie algebra of the differential Galois group $G$ of $[A]$. In this article, we give a constructive criterion for a system to be in reduced form. When $G$ is reductive and unimodular, the system $[A]$ is in reduced form if and only if all of its invariants (rational solutions of appropriate symmetric powers) have constant coefficients (instead of rational functions). When $G$ is non-reductive, we give a similar characterization via the semi-invariants of $G$. In the reductive case, we propose a decision procedure for putting the system into reduced form which, in turn, gives a constructive proof of the classical Kolchin-Kovacic reduction theorem.", "venue": "ArXiv", "authors": ["Ainhoa  Aparicio-Monforte", "Elie  Compoint", "Jacques-Arthur  Weil"], "year": 2012, "n_citations": 15}
{"id": 1956425, "s2_id": "fd5f2d3a411ce9bbd90ac2e55b684bdb5ab6d120", "title": "Unsatisfiability Proofs for Weight 16 Codewords in Lam's Problem", "abstract": "In the 1970s and 1980s, searches performed by L. Carter, C. Lam, L. Thiel, and S. Swiercz showed that projective planes of order ten with weight 16 codewords do not exist. These searches required highly specialized and optimized computer programs and required about 2,000 hours of computing time on mainframe and supermini computers. In 2011, these searches were verified by D. Roy using an optimized C program and 16,000 hours on a cluster of desktop machines. We performed a verification of these searches by reducing the problem to the Boolean satisfiability problem (SAT). Our verification uses the cube-and-conquer SAT solving paradigm, symmetry breaking techniques using the computer algebra system Maple, and a result of Carter that there are ten nonisomorphic cases to check. Our searches completed in about 30 hours on a desktop machine and produced nonexistence proofs of about 1 terabyte in the DRAT (deletion resolution asymmetric tautology) format.", "venue": "IJCAI", "authors": ["Curtis  Bright", "Kevin K. H. Cheung", "Brett  Stevens", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2020, "n_citations": 1}
{"id": 1961765, "s2_id": "3e8be904ccac4325c3f9f18a4787523c6068c8fa", "title": "Lonely Points in Simplices", "abstract": "Given a lattice L in Z^m and a subset A of R^m, we say that a point in A is lonely if it is not equivalent modulo L to another point of A. We are interested in identifying lonely points for specific choices of L when A is a dilated standard simplex, and in conditions on L which ensure that the number of lonely points is unbounded as the simplex dilation goes to infinity.", "venue": "ArXiv", "authors": ["Maximilian  Jaroschek", "Manuel  Kauers", "Laura  Kov\u00e1cs"], "year": 2019, "n_citations": 0}
{"id": 1967237, "s2_id": "28d2adb85a2e61928331473a41298115c55ab00f", "title": "Generalized Hermite Reduction, Creative Telescoping and Definite Integration of D-Finite Functions", "abstract": "Hermite reduction is a classical algorithmic tool in symbolic integration. It is used to decompose a given rational function as a sum of a function with simple poles and the derivative of another rational function. We extend Hermite reduction to arbitrary linear differential operators instead of the pure derivative, and develop efficient algorithms for this reduction. We then apply the generalized Hermite reduction to the computation of linear operators satisfied by single definite integrals of D-finite functions of several continuous or discrete parameters. The resulting algorithm is a generalization of reduction-based methods for creative telescoping.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Pierre  Lairez", "Bruno  Salvy"], "year": 2018, "n_citations": 19}
{"id": 1967978, "s2_id": "c2330a892ee3f2b327f57e92ed41a0427d0248d9", "title": "New effective differential Nullstellensatz", "abstract": "We show new upper and lower bounds for the effective differential Nullstellensatz for differential fields of characteristic zero with several commuting derivations. Seidenberg was the first to address this problem in 1956, without giving a complete solution. The first explicit bounds appeared in 2009 in a paper by Golubitsky, Kondratieva, Szanto, and Ovchinnikov, with the upper bound expressed in terms of the Ackermann function. D'Alfonso, Jeronimo, and Solern\\'o, using novel ideas, obtained in 2014 a new bound if restricted to the case of one derivation and constant coefficients. To obtain the bound in the present paper without this restriction, we extend this approach and use the new methods of Freitag and Le\\'on S\\'anchez and of Pierce from 2014, which represent a model-theoretic approach to differential algebraic geometry.", "venue": "ArXiv", "authors": ["Richard  Gustavson", "Marina V. Kondratieva", "Alexey  Ovchinnikov"], "year": 2014, "n_citations": 25}
{"id": 1974713, "s2_id": "e499c8948218ea1e7cee8dcc4474075a4ceefac3", "title": "Deciding Kleene Algebras in Coq", "abstract": "We present a reflexive tactic for deciding the equational theory of Kleene\nalgebras in the Coq proof assistant. This tactic relies on a careful\nimplementation of efficient finite automata algorithms, so that it solves\ncasual equations instantaneously and properly scales to larger expressions. The\ndecision procedure is proved correct and complete: correctness is established\nw.r.t. any model by formalising Kozen's initiality theorem; a counter-example\nis returned when the given equation does not hold. The correctness proof is\nchallenging: it involves both a precise analysis of the underlying automata\nalgorithms and a lot of algebraic reasoning. In particular, we have to\nformalise the theory of matrices over a Kleene algebra. We build on the recent\naddition of firstorder typeclasses in Coq in order to work efficiently with the\ninvolved algebraic structures.", "venue": "Log. Methods Comput. Sci.", "authors": ["Thomas  Braibant", "Damien  Pous"], "year": 2012, "n_citations": 36}
{"id": 1975036, "s2_id": "f5b3071fb8dec6dfe1d2529f2040c769541367ef", "title": "On Sign Conditions Over Real Multivariate Polynomials", "abstract": "We present a new probabilistic algorithm to find a finite set of points intersecting the closure of each connected component of the realization of every sign condition over a family of real polynomials defining regular hypersurfaces that intersect transversally. This enables us to show a probabilistic procedure to list all feasible sign conditions over the polynomials. In addition, we extend these results to the case of closed sign conditions over an arbitrary family of real multivariate polynomials. The complexity bounds for these procedures improve the known ones.", "venue": "Discret. Comput. Geom.", "authors": ["Gabriela  Jeronimo", "Daniel  Perrucci", "Juan  Sabia"], "year": 2010, "n_citations": 9}
{"id": 1980773, "s2_id": "89cf93ace8ef4a5c8ea38ff5cbf4368d5d63712b", "title": "Formal Verification of Arithmetic RTL: Translating Verilog to C++ to ACL2", "abstract": "We present a methodology for formal verification of arithmetic RTL designs that combines sequential logic equivalence checking with interactive theorem proving. An intermediate model of a Verilog module is hand-coded in Restricted Algorithmic C (RAC), a primitive subset of C augmented by the integer and fixed-point register class templates of Algorithmic C. The model is designed to be as abstract and compact as possible, but sufficiently faithful to the RTL to allow efficient equivalence checking with a commercial tool. It is then automatically translated to the logic of ACL2, enabling a mechanically checked proof of correctness with respect to a formal architectural specification. In this paper, we describe the RAC language, the translation process, and some techniques that facilitate formal analysis of the resulting ACL2 code.", "venue": "ACL2", "authors": ["David M. Russinoff"], "year": 2020, "n_citations": 0}
{"id": 1985536, "s2_id": "c64e0f0fefd15a66f697d267b4f53bced022327d", "title": "Symbolic Script Programming for Java", "abstract": "Computer algebra in Java is a promising field of development. It has not yet reached an industrial strength, in part because of a lack of good user interfaces. Using a general purpose scripting language can bring a natural mathematical notation, akin to the one of specialized interfaces included in most computer algebra systems. We present such an interface for Java computer algebra libraries, using scripts available in the JSR 223 framework. We introduce the concept of `symbolic programming' and show its usefulness by prototypes of symbolic polynomials and polynomial rings.", "venue": "ArXiv", "authors": ["Raphael  Jolly", "Heinz  Kredel"], "year": 2009, "n_citations": 1}
{"id": 1987017, "s2_id": "3f957d8b9a6b30abfd5d14d7f6c79871f2cda1c8", "title": "Congruences and Concurrent Lines in Multi-View Geometry", "abstract": "We present a new framework for multi-view geometry in computer vision. A camera is a mapping between $\\mathbb{P}^3$ and a line congruence. This model, which ignores image planes and measurements, is a natural abstraction of traditional pinhole cameras. It includes two-slit cameras, pushbroom cameras, catadioptric cameras, and many more. We study the concurrent lines variety, which consists of $n$-tuples of lines in $\\mathbb{P}^3$ that intersect at a point. Combining its equations with those of various congruences, we derive constraints for corresponding images in multiple views. We also study photographic cameras which use image measurements and are modeled as rational maps from $\\mathbb{P}^3$ to $\\mathbb{P}^2$ or $\\mathbb{P}^1\\times \\mathbb{P}^1$.", "venue": "Adv. Appl. Math.", "authors": ["Jean  Ponce", "Bernd  Sturmfels", "Matthew  Trager"], "year": 2017, "n_citations": 17}
{"id": 1990668, "s2_id": "5b2f780c3ce63f1795bbfa6e3e7e22d8ae5e268b", "title": "Introduction to the GiNaC Framework for Symbolic Computation within the C++ Programming Language", "abstract": "The traditional split into a low level language and a high level language in the design of computer algebra systems may become obsolete with the advent of more versatile computer languages. We describe GiNaC, a special-purpose system that deliberately denies the need for such a distinction. It is entirely written in C++and the user can interact with it directly in that language. It was designed to provide efficient handling of multivariate polynomials, algebras and special functions that are needed for loop calculations in theoretical quantum field theory. It also bears some potential to become a more general purpose symbolic package.", "venue": "J. Symb. Comput.", "authors": ["Christian  Bauer", "Alexander  Frink", "Richard  Kreckel"], "year": 2002, "n_citations": 375}
{"id": 1993545, "s2_id": "e310f02f47e6c795f0b7e24ede9645653648dc00", "title": "Formal proof for delayed finite field arithmetic using floating point operators", "abstract": "Formal proof checkers such as Coq are capable of validating proofs of correction of algorithms for finite field arithmetics but they require extensive training from potential users. The delayed solution of a triangular system over a finite field mixes operations on integers and operations on floating point numbers. We focus in this report on verifying proof obligations that state that no round off error occurred on any of the floating point operations. We use a tool named Gappa that can be learned in a matter of minutes to generate proofs related to floating point arithmetic and hide technicalities of formal proof checkers. We found that three facilities are missing from existing tools. The first one is the ability to use in Gappa new lemmas that cannot be easily expressed as rewriting rules. We coined the second one ``variable interchange'' as it would be required to validate loop interchanges. The third facility handles massive loop unrolling and argument instantiation by generating traces of execution for a large number of cases. We hope that these facilities may sometime in the future be integrated into mainstream code validation.", "venue": "ArXiv", "authors": ["Marc  Daumas", "Pascal  Giorgi"], "year": 2007, "n_citations": 4}
{"id": 1997722, "s2_id": "cc1cf08cc8b9593de6c768e8ad12080439028bc3", "title": "Computation of Darboux polynomials and rational first integrals with bounded degree in polynomial time", "abstract": "In this paper we study planar polynomial differential systems of this form: dX/dt=A(X, Y), dY/dt= B(X, Y), where A,B belongs to Z[X, Y], degA \\leq d, degB \\leq d, and the height of A and B is smaller than H. A lot of properties of planar polynomial differential systems are related to irreducible Darboux polynomials of the corresponding derivation: D =A(X, Y)dX + B(X, Y)dY . Darboux polynomials are usually computed with the method of undetermined coefficients. With this method we have to solve a polynomial system. We show that this approach can give rise to the computation of an exponential number of reducible Darboux polynomials. Here we show that the Lagutinskii-Pereira's algorithm computes irreducible Darboux polynomials with degree smaller than N, with a polynomial number, relatively to d, log(H) and N, binary operations. We also give a polynomial-time method to compute, if it exists, a rational first integral with bounded degree.", "venue": "J. Complex.", "authors": ["Guillaume  Ch\u00e8ze"], "year": 2011, "n_citations": 19}
{"id": 1999117, "s2_id": "0b8b23ecab891f161dd764e58aebb7802af92ad9", "title": "Computing the topology of a planar or space hyperelliptic curve", "abstract": "We present algorithms to compute the topology of 2D and 3D hyperelliptic curves. The algorithms are based on the fact that 2D and 3D hyperelliptic curves can be seen as the image of a planar curve (the Weierstrass form of the curve), whose topology is easy to compute, under a birational mapping of the plane or the space. We report on a {\\tt Maple} implementation of these algorithms, and present several examples. Complexity and certification issues are also discussed.", "venue": "Comput. Aided Geom. Des.", "authors": ["Juan Gerardo Alc\u00e1zar", "Jorge  Caravantes", "Gema Mar\u00eda D\u00edaz-Toca", "Elias P. Tsigaridas"], "year": 2020, "n_citations": 1}
{"id": 2004140, "s2_id": "cc55d7b632936c5612c6c02b42e1c9ba533f7ea8", "title": "Group Extensions over Infinite Words", "abstract": "We construct an extension $E(A,G)$ of a given group $G$ by infinite non-Archimedean words over an discretely ordered abelian group like $Z^n$. This yields an effective and uniform method to study various groups that \"behave like $G$\". We show that the Word Problem for f.g. subgroups in the extension is decidable if and only if and only if the Cyclic Membership Problem in $G$ is decidable. \nThe present paper embeds the partial monoid of infinite words as defined by Myasnikov, Remeslennikov, and Serbin (Contemp. Math., Amer. Math. Soc., 378:37-77, 2005) into $E(A,G)$. Moreover, we define the extension group $E(A,G)$ for arbitrary groups $G$ and not only for free groups as done in previous work. We show some structural results about the group (existence and type of torsion elements, generation by elements of order 2) and we show that some interesting HNN extensions of $G$ embed naturally in the larger group $E(A,G)$.", "venue": "Int. J. Found. Comput. Sci.", "authors": ["Volker  Diekert", "Alexei G. Myasnikov"], "year": 2012, "n_citations": 1}
{"id": 2006206, "s2_id": "ba189ac8a526b9853a14864f03b4be9c89bb5ca4", "title": "An explicit solution to Post's Problem over the reals", "abstract": "In the BSS model of real number computations we prove a concrete and explicit semi-decidable language to be undecidable yet not reducible from (and thus strictly easier than) the real Halting Language. This solution to Post's Problem over the reals significantly differs from its classical, discrete variant where advanced diagonalization techniques are only known to yield the existence of such intermediate Turing degrees. Then we strengthen the above result and show as well the existence of an uncountable number of incomparable semi-decidable Turing degrees below the real Halting Problem in the BSS model. Again, our proof will give concrete such problems representing these different degrees. Finally we show the corresponding result for the linear BSS model, that is over (R,+,-,<) rather than (R,+,-,x,@?,<).", "venue": "J. Complex.", "authors": ["Klaus  Meer", "Martin  Ziegler"], "year": 2008, "n_citations": 20}
{"id": 2012675, "s2_id": "e2b2e758a201378dc388403399b40bb8f478e756", "title": "A Fast Algorithm for Computing the Truncated Resultant", "abstract": "Let P and Q be two polynomials in K[x,y] with degree at most d, where K is a field. Denoting by R \u2208 K[x] the resultant of P and Q with respect to y, we present an algorithm to compute R mod xk in O~(kd) arithmetic operations in K, where the ~O notation indicates that we omit polylogarithmic factors. This is an improvement over state-of-the-art algorithms that require to compute R in O~(d3) operations before computing its first k coefficients.", "venue": "ISSAC", "authors": ["Guillaume  Moroz", "\u00c9ric  Schost"], "year": 2016, "n_citations": 7}
{"id": 2014286, "s2_id": "4c3464a7f47b33a0b2b6eb7ebcc6e51cb67dfa18", "title": "Summer Research Report: Towards Incremental Lazard Cylindrical Algebraic Decomposition", "abstract": "Cylindrical Algebraic Decomposition (CAD) is an important tool within computational real algebraic geometry, capable of solving many problems to do with polynomial systems over the reals, but known to have worst-case computational complexity doubly exponential in the number of variables. It has long been studied by the Symbolic Computation community and is implemented in a variety of computer algebra systems, however, it has also found recent interest in the Satisfiability Checking community for use with SMT-solvers. The SCSC Project seeks to build bridges between these communities. \nThe present report describes progress made during a Research Internship in Summer 2017 funded by the EU H2020 SCSC CSA. We describe a proof of concept implementation of an Incremental CAD algorithm in Maple, where CADs are built and refined incrementally by polynomial constraint, in contrast to the usual approach of a single computation from a single input. This advance would make CAD of use to SMT-solvers who search for solutions by constantly reformulating logical formula and querying solvers like CAD for whether a logical solution is admissible. We describe experiments for the proof of concept, which clearly display the computational advantages when compared to iterated re-computation. In addition, the project implemented this work under the recently verified Lazard projection scheme (with corresponding Lazard evaluation). That is the minimal complete CAD method in theory, and this is the first documented implementation.", "venue": "ArXiv", "authors": ["Alexander Imani Cowen-Rivers", "Matthew  England"], "year": 2018, "n_citations": 1}
{"id": 2018797, "s2_id": "0da9eea270c207398974d113534b0e3db8a3a353", "title": "A Majorization Order on Monomials and Termination of a Successive Difference Substitution Algorithm", "abstract": "When the ordering of variables is fixed, e.g., x1 \ufffd x2 \ufffd \u00b7\u00b7\u00b7 \ufffd xn, the monomial X \ufffd = x \ufffd 1 1 \u00b7\u00b7\u00b7x \ufffdn n majorizing the monomial X \ufffd = x \ufffd1 1 \u00b7\u00b7\u00b7x \ufffdn n (|\ufffd| = |\ufffd|) means that P k i=1 \ufffdi \ufffd Pk i=1 \ufffdi (k = 1,\u00b7\u00b7\u00b7 ,n 1). In this paper, a necessary condition of positively terminating of a general successive difference substitution algorithm (KSDS) for an input f is obtained by using a majorization order on monomials. That is, every single term with negative coefficients in the form f is majorized at least by a single term with positive coefficients off in an arbitrary ordering of variables.", "venue": "ArXiv", "authors": ["Jia  Xu", "Yong  Yao"], "year": 2011, "n_citations": 0}
{"id": 2029523, "s2_id": "c38e34a3a566f24d2e71f31e6c2117e025133050", "title": "Neurally-Guided Structure Inference", "abstract": "Most structure inference methods either rely on exhaustive search or are purely data-driven. Exhaustive search robustly infers the structure of arbitrarily complex data, but it is slow. Data-driven methods allow efficient inference, but do not generalize when test data have more complex structures than training data. In this paper, we propose a hybrid inference algorithm, the Neurally-Guided Structure Inference (NG-SI), keeping the advantages of both search-based and data-driven methods. The key idea of NG-SI is to use a neural network to guide the hierarchical, layer-wise search over the compositional space of structures. We evaluate our algorithm on two representative structure inference tasks: probabilistic matrix decomposition and symbolic program parsing. It outperforms data-driven and search-based alternatives on both tasks.", "venue": "ICML", "authors": ["Sidi  Lu", "Jiayuan  Mao", "Joshua B. Tenenbaum", "Jiajun  Wu"], "year": 2019, "n_citations": 3}
{"id": 2030601, "s2_id": "7f695897f6a895c5b8fa441de7f9efad255f2cd3", "title": "Maximum Entropy in the framework of Algebraic Statistics: A First Step", "abstract": "Algebraic statistics is a recently evolving field, where one would treat statistical models as algebraic objects and thereby use tools from computational commutative algebra and algebraic geometry in the analysis and computation of statistical models. In this approach, calculation of parameters of statistical models amounts to solving set of polynomial equations in several variables, for which one can use celebrated Grobner basis theory. Owing to the important role of information theory in statistics, this paper as a first step, explores the possibility of describing maximum and minimum entropy (ME) models in the framework of algebraic statistics. We show that ME-models are toric models (a class of algebraic statistical models) when the constraint functions (that provide the information about the underlying random variable) are integer valued functions, and maximum entropy distributions can be calculated by solving set of (Laurent) polynomial equations when expected values of constraint functions are supplied as sample means.", "venue": "ArXiv", "authors": ["Ambedkar  Dukkipati"], "year": 2007, "n_citations": 0}
{"id": 2031312, "s2_id": "bbff0e25693022b479d74e9f47d810abc52a1877", "title": "Decomposition of Polynomials", "abstract": "This diploma thesis is concerned with functional decomposition $f = g \\circ h$ of polynomials. First an algorithm is described which computes decompositions in polynomial time. This algorithm was originally proposed by Zippel (1991). A bound for the number of minimal collisions is derived. Finally a proof of a conjecture in von zur Gathen, Giesbrecht & Ziegler (2010) is given, which states a classification for a special class of decomposable polynomials.", "venue": "ArXiv", "authors": ["Raoul  Blankertz"], "year": 2011, "n_citations": 5}
{"id": 2033602, "s2_id": "8110568d0e2df08e30ed44a57fa51b9641ed90a8", "title": "A Practical Approach to Testing Random Number Generators in Computer Algebra Systems", "abstract": "Abstract This paper has a practical aim. For a long time, implementations of pseudorandom number generators in standard libraries of programming languages had poor quality. The situation started to improve only recently. Up to now, a large number of libraries and weakly supported mathematical packages use outdated algorithms for random number generation. Four modern sets of statistical tests that can be used for verifying random number generators are described. It is proposed to use command line utilities, which makes it possible to avoid low-level programming in such languages as C or C++. Only free open source systems are considered.", "venue": "ArXiv", "authors": ["Migran N. Gevorkyan", "Dmitry S. Kulyabov", "Anastasia V. Demidova", "Anna V. Korolkova"], "year": 2020, "n_citations": 0}
{"id": 2034240, "s2_id": "55e2cbf18401be45187ce3c71c8be43f52804ebb", "title": "Note on the construction of Picard-Vessiot rings for linear differential equations", "abstract": "In this note, we describe a method to construct the Picard-Vessiot ring of a given linear differential equation.", "venue": "ArXiv", "authors": ["Ruyong  Feng"], "year": 2019, "n_citations": 0}
{"id": 2036405, "s2_id": "d49cc9ecb4ba2119efdb75de689766a398d64ecd", "title": "Linear Differential Equations as a Data Structure", "abstract": "A lot of information concerning solutions of linear differential equations can be computed directly from the equation. It is therefore natural to consider these equations as a data structure, from which mathematical properties can be computed. A variety of algorithms has thus been designed in recent years that do not aim at \u201csolving,\u201d but at computing with this representation. Many of these results are surveyed here.", "venue": "Found. Comput. Math.", "authors": ["Bruno  Salvy"], "year": 2019, "n_citations": 9}
{"id": 2043827, "s2_id": "e5312db7f3ef2a70f20ca7c612f0605dc88471ef", "title": "A Lambda-Calculus with letrec, case, constructors and non-determinism", "abstract": "A non-deterministic call-by-need lambda-calculus \\calc with case, constructors, letrec and a (non-deterministic) erratic choice, based on rewriting rules is investigated. A standard reduction is defined as a variant of left-most outermost reduction. The semantics is defined by contextual equivalence of expressions instead of using $\\alpha\\beta(\\eta)$-equivalence. It is shown that several program transformations are correct, for example all (deterministic) rules of the calculus, and in addition the rules for garbage collection, removing indirections and unique copy. \nThis shows that the combination of a context lemma and a meta-rewriting on reductions using complete sets of commuting (forking, resp.) diagrams is a useful and successful method for providing a semantics of a functional programming language and proving correctness of program transformations.", "venue": "ArXiv", "authors": ["Manfred  Schmidt-Schau\u00df", "Michael  Huber"], "year": 2000, "n_citations": 7}
{"id": 2047332, "s2_id": "2dc0708f4e682f8a967bcefbf1afea021a9d8d5e", "title": "Nested (inverse) binomial sums and new iterated integrals for massive Feynman diagrams", "abstract": "Nested sums containing binomial coefficients occur in the computation of massive operator matrix elements. Their associated iterated integrals lead to alphabets including radicals, for which we determined a suitable basis. We discuss algorithms for converting between sum and integral representations, mainly relying on the Mellin transform. To aid the conversion we worked out dedicated rewrite rules, based on which also some general patterns emerging in the process can be obtained.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein", "Clemens G. Raab", "Carsten  Schneider"], "year": 2014, "n_citations": 4}
{"id": 2047458, "s2_id": "84a49b26b86b561e766f5bedf24d25f6959aa0dd", "title": "Elimination for Generic Sparse Polynomial Systems", "abstract": "We present a new probabilistic symbolic algorithm that, given a variety defined in an n-dimensional affine space by a generic sparse system with fixed supports, computes the Zariski closure of its projection to an \u2113-dimensional coordinate affine space with \u2113<n. The complexity of the algorithm depends polynomially on some combinatorial invariants associated to the supports.", "venue": "Discret. Comput. Geom.", "authors": ["Mar\u00eda Isabel Herrero", "Gabriela  Jeronimo", "Juan  Sabia"], "year": 2014, "n_citations": 4}
{"id": 2060025, "s2_id": "49299c4bde88b8311b7534ae2508e3317fe2dfe3", "title": "Kolmogorov Complexity Theory over the Reals", "abstract": "Kolmogorov Complexity constitutes an integral part of computability theory, information theory, and computational complexity theory-in the discrete setting of bits and Turing machines. Over real numbers, on the other hand, the BSS-machine (aka real-RAM) has been established as a major model of computation. This real realm has turned out to exhibit natural counterparts to many notions and results in classical complexity and recursion theory; although usually with considerably different proofs. The present work investigates similarities and differences between discrete and real Kolmogorov Complexity as introduced by Montana and Pardo (1998).", "venue": "Electron. Notes Theor. Comput. Sci.", "authors": ["Martin  Ziegler", "Wouter M. Koolen"], "year": 2008, "n_citations": 4}
{"id": 2067869, "s2_id": "590c910f3eea8b8c540653664f8fceaeef00c10a", "title": "Algorithmic Linearly Constrained Gaussian Processes", "abstract": "We algorithmically construct multi-output Gaussian process priors which satisfy linear differential equations. Our approach attempts to parametrize all solutions of the equations using Grobner bases. If successful, a push forward Gaussian process along the paramerization is the desired prior. We consider several examples from physics, geomathematics and control, among them the full inhomogeneous system of Maxwell's equations. By bringing together stochastic learning and computer algebra in a novel way, we combine noisy observations with precise algebraic computations.", "venue": "NeurIPS", "authors": ["Markus  Lange-Hegermann"], "year": 2018, "n_citations": 12}
{"id": 2074091, "s2_id": "b1a676d70c78ad01edb8e6a338244f500473e870", "title": "Time-and space-efficient evaluation of some hypergeometric constants", "abstract": "The currently best known algorithms for the numerical evaluation of hypergeometric constants such as \u00c7(3) to <i>d</i> decimal digits have time complexity <i>O</i>(<i>M</i>(<i>d</i>) log<sup>2</sup><i>d</i>) and space complexity of <i>O</i>(<i>d</i> log <i>d</i>) or <i>O</i>(<i>d</i>). Following work from Cheng, Gergel, Kim and Zima, we present a new algorithm with the same asymptotic complexity, but more efficient in practice. Our implementation of this algorithm improves over existing programs for the computation of \u03a0, and we announce a new record of 2 billion digits for \u00c7(3).", "venue": "ISSAC '07", "authors": ["Howard  Cheng", "Guillaume  Hanrot", "Emmanuel  Thom\u00e9", "Paul  Zimmermann", "Eugene V. Zima"], "year": 2007, "n_citations": 15}
{"id": 2086256, "s2_id": "73899d1c5626edeb873b07425809006b0ba26e67", "title": "Recent Symbolic Summation Methods to Solve Coupled Systems of Differential and Difference Equations", "abstract": "We outline a new algorithm to solve coupled systems of differential equations in one continuous variable $x$ (resp. coupled difference equations in one discrete variable $N$) depending on a small parameter $\\epsilon$: given such a system and given sufficiently many initial values, we can determine the first coefficients of the Laurent-series solutions in $\\epsilon$ if they are expressible in terms of indefinite nested sums and products. This systematic approach is based on symbolic summation algorithms in the context of difference rings/fields and uncoupling algorithms. The proposed method gives rise to new interesting applications in connection with integration by parts (IBP) methods. As an illustrative example, we will demonstrate how one can calculate the $\\epsilon$-expansion of a ladder graph with 6 massive fermion lines.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "Abilio De Freitas", "Carsten  Schneider"], "year": 2014, "n_citations": 16}
{"id": 2087995, "s2_id": "8bcd16e0e0efa7687ee0a4fdd40b0facdf39d890", "title": "Web-based Structural Identifiability Analyzer", "abstract": "Parameter identifiability describes whether, for a given differential model, one can determine parameter values from model equations. Knowing global or local identifiability properties allows construction of better practical experiments to identify parameters from experimental data. In this work, we present a web-based software tool that allows to answer specific identifiability queries. Concretely, our toolbox can determine identifiability of individual parameters of the model and also provide all functions of parameters that are identifiable (also called identifiable combinations) from single or multiple experiments. The program is freely available at https://maple.cloud/app/6509768948056064.", "venue": "CMSB", "authors": ["Ilia  Ilmer", "Alexey  Ovchinnikov", "Gleb  Pogudin"], "year": 2021, "n_citations": 2}
{"id": 2089862, "s2_id": "f675f9290d3cea21aefca0892ab6b2518751b234", "title": "Reconstruction Algorithms for Sums of Affine Powers", "abstract": "A sum of affine powers is an expression of the form f(x) = s\u2211/i=1 \u03b1i (x - ai)ei. Although quite simple, this model is a generalization of two well-studied models: Waring decomposition and Sparsest Shift. For these three models there are natural extensions to several variables, but this paper is mostly focused on univariate polynomials. We propose algorithms that find the smallest decomposition of f in the first model (sums of affine powers) for an input polynomial f given in dense representation. Our algorithms only work in situations where the smallest decomposition is unique, and we provide conditions that guarantee the uniqueness of the smallest decomposition.", "venue": "ISSAC", "authors": ["Ignacio  Garc\u00eda-Marco", "Pascal  Koiran", "Timoth\u00e9e  Pecatte"], "year": 2017, "n_citations": 7}
{"id": 2094311, "s2_id": "34fde1302cf1c9eab1395cb85051b5fe5e6cb816", "title": "Subtropical Real Root Finding", "abstract": "We describe a new incomplete but terminating heuristic method for real root finding for large multivariate polynomials. We take an abstract view of the polynomial as the set of exponent vectors associated with sign information on the coefficients. Then we employ linear programming to heuristically find roots. There is a specialized variant for roots with exclusively positive coordinates, which is of considerable interest for applications in chemistry and systems biology. An implementation of our method combining the computer algebra system Reduce with the linear programming solver Gurobi has been successfully applied to input data originating from established mathematical models used in these areas. We have solved several hundred problems with up to more than 800,000 monomials in up to 10 variables with degrees up to 12. Our method has failed due to its incompleteness in only 10 percent of the cases.", "venue": "ISSAC", "authors": ["Thomas  Sturm"], "year": 2015, "n_citations": 6}
{"id": 2098202, "s2_id": "77c5e713474c4607d27a2bb371291f4f78d47f80", "title": "Efficiently Factoring Polynomials Modulo p4", "abstract": "Polynomial factoring has famous practical algorithms over fields-- finite, rational and p-adic. However, modulo prime powers, factoring gets harder because there is non-unique factorization and a combinatorial blowup ensues. For example, x^2+p \\bmod p^2 is irreducible, but x^2+px \\bmod p^2 has exponentially many factors! We present the first randomized poly(\\deg f, \u0142og p) time algorithm to factor a given univariate integral f(x) modulo p^k, for a prime p and k \u0142eq 4. Thus, we solve the open question of factoring modulo p^3 posed in (Sircana, ISSAC'17). Our method reduces the general problem of factoring f(x) mod p^k to that of \\em root finding in a related polynomial E(y) \\bmod\u0142angle p^k, \\varphi(x)^\\ell \\rangle for some irreducible \\varphi \\bmod p. We can efficiently solve the latter for k\u0142e4, by incrementally transforming E(y). Moreover, we discover an efficient refinement of Hensel lifting to lift factors of f(x) \\bmod p to those \\bmod\\ p^4 (if possible). This was previously unknown, as the case of repeated factors of f(x) \\bmod p forbids classical Hensel lifting.", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Ashish  Dwivedi", "Rajat  Mittal", "Nitin  Saxena"], "year": 2019, "n_citations": 5}
{"id": 2102470, "s2_id": "6b8d8bb7637fe2ec887620031f75054175ecbada", "title": "Differential Chow Form for Projective Differential Variety", "abstract": "In this paper, a generic intersection theorem in projective differential algebraic geometry is presented. Precisely, the intersection of an irreducible projective differential variety of dimension d>0 and order h with a generic projective differential hyperplane is shown to be an irreducible projective differential variety of dimension d-1 and order h. Based on the generic intersection theorem, the Chow form for an irreducible projective differential variety is defined and most of the properties of the differential Chow form in affine differential case are established for its projective differential counterpart. Finally, we apply the differential Chow form to a result of linear dependence over projective varieties given by Kolchin.", "venue": "ArXiv", "authors": ["Wei  Li", "Xiao-Shan  Gao"], "year": 2011, "n_citations": 7}
{"id": 2104139, "s2_id": "a82ba50a270853445a3ebc3be39527dd9f56de50", "title": "Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning", "abstract": "We study the problem of dynamic visual reasoning on raw videos. This is a challenging problem; currently, state-of-the-art models often require dense supervision on physical object properties and events from simulation, which are impractical to obtain in real life. In this paper, we present the Dynamic Concept Learner (DCL), a unified framework that grounds physical objects and events from dynamic scenes and language. DCL first adopts a trajectory extractor to track each object over time and to represent it as a latent, object-centric feature vector. Building upon this object-centric representation, DCL learns to approximate the dynamic interaction among objects using graph networks. DCL further incorporates a semantic parser to parse question into semantic programs and, finally, a program executor to run the program to answer the question, levering the learned dynamics model. After training, DCL can detect and associate objects across the frames, ground visual properties and physical events, understand the causal relationship between events, make future and counterfactual predictions, and leverage these extracted presentations for answering queries. DCL achieves state-of-the-art performance on CLEVRER, a challenging causal video reasoning dataset, even without using ground-truth attributes and collision labels from simulations for training. We further test DCL on a newly proposed video-retrieval and event localization dataset derived from CLEVRER, showing its strong generalization capacity.", "venue": "ICLR", "authors": ["Zhenfang  Chen", "Jiayuan  Mao", "Jiajun  Wu", "Kwan-Yee Kenneth Wong", "Joshua B. Tenenbaum", "Chuang  Gan"], "year": 2021, "n_citations": 14}
{"id": 2104873, "s2_id": "12ed127ff44493233d3801084cf490e230c7bd4a", "title": "Extraction of cylinders and cones from minimal point sets", "abstract": "We propose new algebraic methods for extracting cylinders and cones from minimal point sets, including oriented points. More precisely, we are interested in computing efficiently cylinders through a set of three points, one of them being oriented, or through a set of five simple points. We are also interested in computing efficiently cones through a set of two oriented points, through a set of four points, one of them being oriented, or through a set of six points. For these different interpolation problems, we give optimal bounds on the number of solutions. Moreover, we describe algebraic methods targeted to solve these problems efficiently.", "venue": "Graph. Model.", "authors": ["Laurent  Bus\u00e9", "Andr\u00e9  Galligo", "Jiajun  Zhang"], "year": 2016, "n_citations": 7}
{"id": 2106526, "s2_id": "7b4da8d94409c82ab4366c301ba27633fba86f4d", "title": "Computing curves on real rational surfaces", "abstract": "We present an algorithm for computing curves and families of curves of prescribed degree and geometric genus on real rational surfaces.", "venue": "ArXiv", "authors": ["Niels  Lubbes"], "year": 2018, "n_citations": 2}
{"id": 2108003, "s2_id": "02e11153b83b235931e65971faaded573926a653", "title": "Algorithmic computation of polynomial amoebas", "abstract": "We present algorithms for computation and visualization of amoebas, their contours, compactified amoebas and sections of three-dimensional amoebas by two-dimensional planes. We also provide method and an algorithm for the computation of~polynomials whose amoebas exhibit the most complicated topology among all polynomials with a fixed Newton polytope. The presented algorithms are implemented in computer algebra systems Matlab 8 and Mathematica 9.", "venue": "CASC", "authors": ["D. V. Bogdanov", "A. A. Kytmanov", "Timur M. Sadykov"], "year": 2016, "n_citations": 5}
{"id": 2111215, "s2_id": "7f247db14c88dd470803af184c75df697872ae87", "title": "Symbolic computations in differential geometry", "abstract": "We introduce the C++ library Wedge, based on GiNaC, for symbolic computations in differential geometry. We show how Wedge makes it possible to use the language C++ to perform such computations, and illustrate some advantages of this approach with explicit examples. In particular, we describe a short program to determine whether a given linear exterior differential system is involutive.", "venue": "ArXiv", "authors": ["Diego  Conti"], "year": 2008, "n_citations": 1}
{"id": 2111809, "s2_id": "1e4257b0f0bd7076e31f531f010ba95b0e12d9b9", "title": "Towards a symbolic summation theory for unspecified sequences", "abstract": "The article addresses the problem whether indefinite double sums involving a generic sequence can be simplified in terms of indefinite single sums. Depending on the structure of the double sum, the proposed summation machinery may provide such a simplification without exceptions. If it fails, it may suggest a more advanced simplification introducing in addition a single nested sum where the summand has to satisfy a particular constraint. More precisely, an explicitly given parameterized telescoping equation must hold. Restricting to the case that the arising unspecified sequences are specialized to the class of indefinite nested sums defined over hypergeometric, multi-basic or mixed hypergeometric products, it can be shown that this constraint is not only sufficient but also necessary.", "venue": "Texts & Monographs in Symbolic Computation", "authors": ["Peter  Paule", "Carsten  Schneider"], "year": 2019, "n_citations": 5}
{"id": 2119054, "s2_id": "b490c514028c0ba66031534a213d75084d6f86e2", "title": "Analytic and Algorithmic Aspects of Generalized Harmonic Sums and Polylogarithms", "abstract": "In recent three-loop calculations of massive Feynman integrals within Quantum Chromodynamics (QCD) and, e.g., in recent combinatorial problems the so-called generalized harmonic sums (in short S-sums) arise. They are characterized by rational (or real) numerator weights also different from \u00b11. In this article we explore the algorithmic and analytic properties of these sums systematically. We work out the Mellin and inverse Mellin transform which connects the sums under consideration with the associated Poincare iterated integrals, also called generalized harmonic polylogarithms. In this regard, we obtain explicit analytic continuations by means of asymptotic expansions of the S-sums which started to occur frequently in current QCD calculations. In addition, we derive algebraic and structural relations, like differentiation with respect to the external summation index and different multi-argument relations, for the compactification of S-sum expressions. Finally, we calculate algebraic relations for infinite S-sums, or equivalently for generalized harmonic polylogarithms evaluated at special values. The corresponding algorithms and relations are encoded in the computer algebra package HarmonicSums.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein", "Carsten  Schneider"], "year": 2013, "n_citations": 171}
{"id": 2119225, "s2_id": "7356dc9ad152730296e15eabb46065be239682af", "title": "Computing Real Roots of Real Polynomials ... and now For Real!", "abstract": "Very recent work introduces an asymptotically fast subdivision algorithm, denoted ANewDsc, for isolating the real roots of a univariate real polynomial. The method combines Descartes? Rule of Signs to test intervals for the existence of roots, Newton iteration to speed up convergence against clusters of roots, and approximate computation to decrease the required precision. It achieves record bounds on the worst-case complexity for the considered problem, matching the complexity of Pan's method for computing all complex roots and improving upon the complexity of other subdivision methods by several magnitudes. In the article at hand, we report on an implementation of ANewDsc on top of the RS root isolator. RS is a highly efficient realization of the classical Descartes method and currently serves as the default real root solver in Maple. We describe crucial design changes within ANewDsc and RS that led to a high-performance implementation without harming the theoretical complexity of the underlying algorithm. With an excerpt of our extensive collection of benchmarks, available online at http://anewdsc.mpi-inf.mpg.de/, we illustrate that the theoretical gain in performance of ANewDsc over other subdivision methods also transfers into practice. These experiments also show that our new implementation outperforms both RS and mature competitors by magnitudes for notoriously hard instances with clustered roots. For all other instances, we avoid almost any overhead by integrating additional optimizations and heuristics.", "venue": "ISSAC", "authors": ["Alexander  Kobel", "Fabrice  Rouillier", "Michael  Sagraloff"], "year": 2016, "n_citations": 41}
{"id": 2120539, "s2_id": "d6c91451eebdaff6730f126d828b24337d914f2a", "title": "Shortest Two-way Linear Recurrences", "abstract": "Let $s$ be a finite sequence over a field of length $n$. It is well-known that if $s$ satisfies a linear recurrence of order $d$ with non-zero constant term, then the reverse of $s$ also satisfies a recurrence of order $d$ (with coefficients in reverse order). A recent article of A. Salagean proposed an algorithm to find such a shortest 'two-way' recurrence -- which may be longer than a linear recurrence for $s$ of shortest length $\\LC_n$. \nWe give a new and simpler algorithm to compute a shortest two-way linear recurrence. First we show that the pairs of polynomials we use to construct a minimal polynomial iteratively are always relatively prime; we also give the extended multipliers. Then we combine degree lower bounds with a straightforward rewrite of a published algorithm due to the author to obtain our simpler algorithm. The increase in shortest length is $\\max\\{n+1-2\\LC_n,0\\}$.", "venue": "ArXiv", "authors": ["Graham H. Norton"], "year": 2009, "n_citations": 0}
{"id": 2121626, "s2_id": "75ba2988150368cd4b4c462a2ee9f3e8e4526b81", "title": "LU Factorization with Errors", "abstract": "We present new algorithms to detect and correct errors in the lower-upper factorization of a matrix, or the triangular linear system solution, over an arbitrary field. Our main algorithms do not require any additional information or encoding other than the original inputs and the erroneous output. Their running time is softly linear in the dimension times the number of errors when there are few errors, smoothly growing to the cost of fast matrix multiplication as the number of errors increases. We also present applications to general linear system solving.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "Joris van der Hoeven", "Cl\u00e9ment  Pernet", "Daniel S. Roche"], "year": 2019, "n_citations": 0}
{"id": 2124094, "s2_id": "b17de4a461e6da87b55d71b6bf79534091f6fccb", "title": "Computing the Distance between Piecewise-Linear Bivariate Functions", "abstract": "We consider the problem of computing the distance between two piecewise-linear bivariate functions <i>f</i> and <i>g</i> defined over a common domain <i>M</i>, induced by the <i>L</i><sub>2</sub> norm\u2014that is, \u2016 <i>f</i> \u2212 <i>g</i>\u20162 = &sqrt;&int<i><sub>M</sub></i>(<i>f</i> \u2212\u2212 <i>g</i>)<sup>2</sup>. If <i>f</i> is defined by linear interpolation over a triangulation of <i>M</i> with <i>n</i> triangles and <i>g</i> is defined over another such triangulation, the obvious naive algorithm requires \u0398(<i>n</i><sup>2</sup>) arithmetic operations to compute this distance. We show that it is possible to compute it in <i>O</i>(<i>n</i>log<sup>4</sup> <i>n</i>log log <i>n</i>) arithmetic operations by reducing the problem to multipoint evaluation of a certain type of polynomials.\n We also present several generalizations and an application to terrain matching.", "venue": "TALG", "authors": ["Guillaume  Moroz", "Boris  Aronov"], "year": 2016, "n_citations": 6}
{"id": 2130171, "s2_id": "c7262e7d5098b18143895fbf61d6dc64fa840f52", "title": "Recursive Polynomial Remainder Sequence and its Subresultants", "abstract": "Abstract We introduce concepts of \u201crecursive polynomial remainder sequence (PRS)\u201d and \u201crecursive subresultant,\u201d along with investigation of their properties. A recursive PRS is defined as, if there exists the GCD (greatest common divisor) of initial polynomials, a sequence of PRSs calculated \u201crecursively\u201d for the GCD and its derivative until a constant is derived, and recursive subresultants are defined by determinants representing the coefficients in recursive PRS as functions of coefficients of initial polynomials. We give three different constructions of subresultant matrices for recursive subresultants; while the first one is built-up just with previously defined matrices thus the size of the matrix increases fast as the recursion deepens, the last one reduces the size of the matrix drastically by the Gaussian elimination on the second one which has a \u201cnested\u201d expression, i.e. a Sylvester matrix whose elements are themselves determinants.", "venue": "ArXiv", "authors": ["Akira  Terui"], "year": 2008, "n_citations": 4}
{"id": 2130528, "s2_id": "0ea3c2a9bb80777828b8ee9d26a31371db35aee1", "title": "Repairing dynamic models: a method to obtain identifiable and observable reparameterizations with mechanistic insights", "abstract": "Mechanistic dynamic models allow for a quantitative and systematic interpretation of data and the generation of testable hypotheses. However, these models are often over-parameterized, leading to non-identifiability and non-observability, i.e. the impossibility of inferring their parameters and state variables. The lack of structural identifiability and observability (SIO) compromises a model's ability to make predictions and provide insight. Here we present a methodology, AutoRepar, that corrects SIO deficiencies automatically, yielding reparameterized models that are structurally identifiable and observable. The reparameterization preserves the mechanistic meaning of selected variables, and has the exact same dynamics and input-output mapping as the original model. We implement AutoRepar as an extension of the STRIKE-GOLDD software toolbox for SIO analysis, applying it to several models from the literature to demonstrate its ability to repair their structural deficiencies. AutoRepar increases the applicability of mechanistic models, enabling them to provide reliable information about their parameters and dynamics.", "venue": "ArXiv", "authors": ["Gemma  Massonis", "Julio R. Banga", "Alejandro F. Villaverde"], "year": 2020, "n_citations": 2}
{"id": 2132786, "s2_id": "5d4167b285db10999b0acd0e07970933ebe5434a", "title": "Fast (Multi-)Evaluation of Linearly Recurrent Sequences: Improvements and Applications", "abstract": "For a linearly recurrent vector sequence P[n+1] = A(n) * P[n], consider the problem of calculating either the n-th term P[n] or L 0 within O((log(1/e)^{1/2} loglog(1/e)) -- as opposed to O(log(1/e)) -- arithmetic steps. * Given m and a polynomial p of degree d over a field of characteristic zero, the coefficient of p^m to term X^n can be computed within O(d^2 M(n^{1/2})) steps where M(n) denotes the cost of multiplying two degree-n polynomials. * The same time bound holds for the joint calculation of any L<=n^{1/2} desired coefficients of p^m to terms X^{n_i}, n_1,...,n_L <= n.", "venue": "ArXiv", "authors": ["Martin  Ziegler"], "year": 2005, "n_citations": 5}
{"id": 2133853, "s2_id": "1d4f6cd994cb53af2de1351a25b4748a8890ba6b", "title": "Binomial difference ideals", "abstract": "In this paper, binomial difference ideals are studied. Three canonical representations for Laurent binomial difference ideals are given in terms of the reduced Groebner basis of Z[x]-lattices, regular and coherent difference ascending chains, and partial characters over Z[x]-lattices, respectively. Criteria for a Laurent binomial difference ideal to be reflexive, prime, well-mixed, and perfect are given in terms of their support lattices. The reflexive, well-mixed, and perfect closures of a Laurent binomial difference ideal are shown to be binomial. Most of the properties of Laurent binomial difference ideals are extended to the case of difference binomial ideals. Finally, algorithms are given to check whether a given Laurent binomial difference ideal I is reflexive, prime, well-mixed, or perfect, and in the negative case, to compute the reflexive, well-mixed, and perfect closures of I. An algorithm is given to decompose a finitely generated perfect binomial difference ideal as the intersection of reflexive prime binomial difference ideals.", "venue": "J. Symb. Comput.", "authors": ["Xiao-Shan  Gao", "Zhang  Huang", "Chun-Ming  Yuan"], "year": 2017, "n_citations": 11}
{"id": 2137661, "s2_id": "714657a7e465e7bd5a32ed6eb7c3e2b99edda5a1", "title": "Bayesian filtering for nonlinear stochastic systems using holonomic gradient method with integral transform", "abstract": "This paper proposes a symbolic-numeric Bayesian filtering method for a class of discrete-time nonlinear stochastic systems to achieve high accuracy with a relatively small online computational cost. The proposed method is based on the holonomic gradient method (HGM), which is a symbolicnumeric method to evaluate integrals efficiently depending on several parameters. By approximating the posterior probability density function (PDF) of the state as a Gaussian PDF, the update process of its mean and variance can be formulated as evaluations of several integrals that exactly take into account the nonlinearity of the system dynamics. An integral transform is used to evaluate these integrals more efficiently using the HGM compared to our previous method. Further, a numerical example is provided to demonstrate the efficiency of the proposed method over other existing methods.", "venue": "ArXiv", "authors": ["Tomoyuki  Iori", "Toshiyuki  Ohtsuka"], "year": 2021, "n_citations": 0}
{"id": 2139863, "s2_id": "07e7efeecd12a01fe901463660f7070b18b35591", "title": "Bosphorus: Bridging ANF and CNF Solvers", "abstract": "Algebraic Normal Form (ANF) and Conjunctive Normal Form (CNF) are commonly used to encode problems in Boolean algebra. ANFs are typically solved via Grobner \u00a8 basis algorithms, often using more memory than is feasible; while CNFs are solved using SAT solvers, which cannot exploit the algebra of polynomials naturally. We propose a paradigm that bridges between ANF and CNF solving techniques: the techniques are applied in an iterative manner to learn facts to augment the original problems. Experiments on over 1,100 benchmarks arising from four different applications domains demonstrate that learnt facts can significantly improve runtime and enable more benchmarks to be solved.", "venue": "2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)", "authors": ["Davin  Choo", "Mate  Soos", "Kian Ming Adam Chai", "Kuldeep S. Meel"], "year": 2019, "n_citations": 7}
{"id": 2139901, "s2_id": "c6a8303886342776107d6102902935fd0a256d70", "title": "Chain Rules for Hessian and Higher Derivatives Made Easy by Tensor Calculus", "abstract": "Computing multivariate derivatives of matrix-like expressions in the compact, coordinate free fashion is very important for both theory and applied computations (e.g. optimization and machine learning). \nThe critical components of such computations are \\emph{chain and product rules} for derivatives. Although they are taught early in simple scenarios, practical applications involve high-dimensional arrays; in this context it is very hard to find easy accessible and compact explanation. \nThis paper discusses how to relatively simply carry such derivations based on the (simplified as adapted in applied computer science) concept of tensors. Numerical examples in modern Python libraries are provided. This discussion simplifies and illustrates an earlier exposition by Manton (2012).", "venue": "ArXiv", "authors": ["Maciej  Skorski"], "year": 2019, "n_citations": 3}
{"id": 2142094, "s2_id": "504464f92dd3ae2d5acb31ab89b111c267e69f26", "title": "Even faster integer multiplication", "abstract": "We give a new proof of Furer's bound for the cost of multiplying n-bit integers in the bit complexity model. Unlike Furer, our method does not require constructing special coefficient rings with ''fast'' roots of unity. Moreover, we establish the improved bound O(n log n K^(log^\u2217 n)) with K=8. We show that an optimised variant of Furer's algorithm achieves only K=16, suggesting that the new algorithm is faster than Furer's by a factor of 2^(log^\u2217 n). Assuming standard conjectures about the distribution of Mersenne primes, we give yet another algorithm that achieves K=4.", "venue": "J. Complex.", "authors": ["David  Harvey", "Joris van der Hoeven", "Gr'egoire  Lecerf"], "year": 2016, "n_citations": 93}
{"id": 2143937, "s2_id": "6b8359c508109b4c05363a065e841ff8837af444", "title": "Certification of the QR factor R and of lattice basis reducedness", "abstract": "Given a lattice basis of n vectors in Zn, we propose an algorithm using 12n3+O(n2) floating point operations for checking whether the basis is LLL-reduced. If the basis is reduced then the algorithm will hopefully answer \"yes\". If the basis is not reduced, or if the precision used is not sufficient with respect to n, and to the numerical properties of the basis, the algorithm will answer \"failed\". Hence a positive answer is a rigorous certificate. For implementing the certificate itself, we propose a oating point algorithm for computing (certified) error bounds for the R factor of the QR factorization. This algorithm takes into account all possible approximation and rounding errors. The certificate may be implemented using matrix library routines only. We report experiments that show that for a reduced basis of adequate dimension and quality the certificate succeeds, and establish the effectiveness of the certificate. This effectiveness is applied for certifying the output of fastest existing floating point heuristics of LLL reduction, without slowing down the whole process.", "venue": "ISSAC '07", "authors": ["Gilles  Villard"], "year": 2007, "n_citations": 17}
{"id": 2144891, "s2_id": "9a51eafe31da99decef2522f35a58358c7ab2f39", "title": "Mixed discriminants", "abstract": "The mixed discriminant of $$n$$ Laurent polynomials in $$n$$ variables is the irreducible polynomial in the coefficients which vanishes whenever two of the roots coincide. The Cayley trick expresses the mixed discriminant as an $$A$$-discriminant. We show that the degree of the mixed discriminant is a piecewise linear function in the Pl\u00fccker coordinates of a mixed Grassmannian. An explicit degree formula is given for the case of plane curves.", "venue": "ArXiv", "authors": ["Eduardo  Cattani", "Mar\u00eda Ang\u00e9lica Cueto", "Alicia  Dickenstein", "Sandra Di Rocco", "Bernd  Sturmfels"], "year": 2011, "n_citations": 24}
{"id": 2146191, "s2_id": "14cbdd75d6814773a7738f0665d3057310bcad71", "title": "Computing representation matrices for the action of Frobenius to cohomology groups", "abstract": "This paper is concerned with the computation of representation matrices for the action of Frobenius to the cohomology groups of algebraic varieties. Specifically we shall give an algorithm to compute the matrices for arbitrary algebraic varieties with defining equations over perfect fields of positive characteristic, and estimate its complexity. Moreover, we propose a specific efficient method, which works for complete intersections.", "venue": "J. Symb. Comput.", "authors": ["Momonari  Kudo"], "year": 2022, "n_citations": 4}
{"id": 2152439, "s2_id": "62a0bd99dd122d6ffd68d412ab2c0d65caba8bd1", "title": "Missing sets in rational parametrizations of surfaces of revolution", "abstract": "Parametric representations do not cover, in general, the whole geometric object that they parametrize. This can be a problem in practical applications. In this paper we analyze the question for surfaces of revolution generated by real rational profile curves, and we describe a simple small superset of the real zone of the surface not covered by the parametrization. This superset consists, in the worst case, of the union of a circle and the mirror curve of the profile curve. We give a simple description of the missing area of ruled surface parametrization.We provide algorithms to compute, in each case, the missing area.We analyze the real and the complex case.", "venue": "Comput. Aided Des.", "authors": ["J. Rafael Sendra", "Carlos  Villarino", "David  Sevilla"], "year": 2015, "n_citations": 9}
{"id": 2154515, "s2_id": "4f5a03e8fc6a07b71b69800deae33c577be247b5", "title": "A Modular Algorithm for Computing Polynomial GCDs over Number Fields presented with Multiple Extensions", "abstract": "We consider the problem of computing the monic gcd of two polynomials over a number field L = Q(alpha_1,...,alpha_n). Langemyr and McCallum have already shown how Brown's modular GCD algorithm for polynomials over Q can be modified to work for Q(alpha) and subsequently, Langemyr extended the algorithm to L[x]. Encarnacion also showed how to use rational number to make the algorithm for Q(alpha) output sensitive, that is, the number of primes used depends on the size of the integers in the gcd and not on bounds based on the input polynomials. \nOur first contribution is an extension of Encarnacion's modular GCD algorithm to the case n>1, which, like Encarnacion's algorithm, is is output sensitive. \nOur second contribution is a proof that it is not necessary to test if p divides the discriminant. This simplifies the algorithm; it is correct without this test. \nOur third contribution is a modification to the algorithm to treat the case of reducible extensions. Such cases arise when solving systems of polynomial equations. \nOur fourth contribution is an implementation of the modular GCD algorithm in Maple and in Magma. Both implementations use a recursive dense polynomial data structure for representing polynomials over number fields with multiple field extensions. \nOur fifth contribution is a primitive fraction-free algorithm. This is the best non-modular approach. We present timing comparisons of the Maple and Magma implementations demonstrating various optimizations and comparing them with the monic Euclidan algorithm and our primitive fraction-free algorithm.", "venue": "ArXiv", "authors": ["Mark van Hoeij", "Michael B. Monagan"], "year": 2016, "n_citations": 2}
{"id": 2159781, "s2_id": "6a1f2358a9fef382981beef41848e6a88c76cc50", "title": "Essentially optimal sparse polynomial multiplication", "abstract": "We present a probabilistic algorithm to compute the product of two univariate sparse polynomials over a field with a number of bit operations that is quasi-linear in the size of the input and the output. Our algorithm works for any field of characteristic zero or larger than the degree. We mainly rely on sparse interpolation and on a new algorithm for verifying a sparse product that has also a quasi-linear time complexity. Using Kronecker substitution techniques we extend our result to the multivariate case.", "venue": "ISSAC", "authors": ["Pascal  Giorgi", "Bruno  Grenet", "Armelle Perret du Cray"], "year": 2020, "n_citations": 5}
{"id": 2165294, "s2_id": "7bb735538ae0e9cf5f8b72c1f96ffbc62361e7f5", "title": "Iteration in ACL2", "abstract": "Iterative algorithms are traditionally expressed in ACL2 using recursion. On the other hand, Common Lisp provides a construct, loop, which -- like most programming languages -- provides direct support for iteration. We describe an ACL2 analogue loop$ of loop that supports efficient ACL2 programming and reasoning with iteration.", "venue": "ACL2", "authors": ["Matt  Kaufmann", "J Strother Moore"], "year": 2020, "n_citations": 1}
{"id": 2165875, "s2_id": "3535980a712fc33e3fb157c8f4c135d028f6fdd8", "title": "On exact Reznick, Hilbert-Artin and Putinar's representations", "abstract": "We consider the problem of computing exact sums of squares (SOS) decompositions for certain classes of non-negative multivariate polynomials, relying on semidefinite programming (SDP) solvers. \nWe provide a hybrid numeric-symbolic algorithm computing exact rational SOS decompositions with rational coefficients for polynomials lying in the interior of the SOS cone. The first step of this algorithm computes an approximate SOS decomposition for a perturbation of the input polynomial with an arbitrary-precision SDP solver. Next, an exact SOS decomposition is obtained thanks to the perturbation terms and a compensation phenomenon. We prove that bit complexity estimates on output size and runtime are both polynomial in the degree of the input polynomial and singly exponential in the number of variables. Next, we apply this algorithm to compute exact Reznick, Hilbert-Artin's representation and Putinar's representations respectively for positive definite forms and positive polynomials over basic compact semi-algebraic sets. We also report on practical experiments done with the implementation of these algorithms and existing alternatives such as the critical point method and cylindrical algebraic decomposition.", "venue": "J. Symb. Comput.", "authors": ["Victor  Magron", "Mohab Safey El Din"], "year": 2021, "n_citations": 6}
{"id": 2166044, "s2_id": "59b65760e0ac88e55f8df67b3cd228b751436a16", "title": "Sparse implicitization by interpolation: Geometric computations using matrix representations", "abstract": "Based on the computation of a superset of the implicit support, implicitization of a parametrically given hyper-surface is reduced to computing the nullspace of a numeric matrix. Our approach exploits the sparseness of the given parametric equations and of the implicit polynomial. In this work, we study how this interpolation matrix can be used to reduce some key geometric predicates on the hyper-surface to simple numerical operations on the matrix, namely membership and sidedness for given query points. We illustrate our results with examples based on our Maple implementation.", "venue": "ArXiv", "authors": ["Ioannis Z. Emiris", "Tatjana  Kalinka", "Christos  Konaxis"], "year": 2014, "n_citations": 0}
{"id": 2169791, "s2_id": "471cc797c04b2c168bba265bdc5f3d657b246c0d", "title": "Nonexistence Certificates for Ovals in a Projective Plane of Order Ten", "abstract": "In 1983, a computer search was performed for ovals in a projective plane of order ten. The search was exhaustive and negative, implying that such ovals do not exist. However, no nonexistence certificates were produced by this search, and to the best of our knowledge the search has never been independently verified. In this paper, we rerun the search for ovals in a projective plane of order ten and produce a collection of nonexistence certificates that, when taken together, imply that such ovals do not exist. Our search program uses the cube-and-conquer paradigm from the field of satisfiability (SAT) checking, coupled with a programmatic SAT solver and the nauty symbolic computation library for removing symmetries from the search.", "venue": "IWOCA", "authors": ["Curtis  Bright", "Kevin K. H. Cheung", "Brett  Stevens", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2020, "n_citations": 0}
{"id": 2173149, "s2_id": "5cbca4b3658c66969819eaf228a9d6edf87f8fc4", "title": "Satisfiability checking and symbolic computation", "abstract": "Symbolic Computation and Satisfiability Checking are viewed as individual research areas, but they share common interests in the development, implementation and application of decision procedures for arithmetic theories. Despite these commonalities, the two communities are currently only weakly connected. We introduce a new project SC2 to build a joint community in this area, supported by a newly accepted EU (H2020-FETOPEN-CSA) project of the same name. We aim to strengthen the connection between these communities by creating common platforms, initiating interaction and exchange, identifying common challenges, and developing a common roadmap. This abstract and accompanying poster describes the motivation and aims for the project, and reports on the first activities.", "venue": "ACCA", "authors": ["Erika  \u00c1brah\u00e1m", "John  Abbott", "Bernd  Becker", "Anna Maria Bigatti", "Martin  Brain", "Bruno  Buchberger", "Alessandro  Cimatti", "James H. Davenport", "Matthew  England", "Pascal  Fontaine", "Stephen  Forrest", "Alberto  Griggio", "Daniel  Kroening", "Werner M. Seiler", "Thomas  Sturm"], "year": 2017, "n_citations": 5}
{"id": 2184194, "s2_id": "1bf8d28caee80d0acd4942130c57bb83ca5b90d5", "title": "Real Root Isolation of Polynomial Equations Based on Hybrid Computation", "abstract": "A new algorithm for real root isolation of zero-dimensional nonsingular square polynomial systems based on hybrid computation is presented in this paper. First, approximate the (complex) roots of the given polynomial equations via homotopy continuation method. Then, for each approximate root, an initial box relying on the Kantorovich theorem is constructed, which contains the corresponding accurate root. Finally, the Krawczyk interval iteration with interval arithmetic is applied to the initial boxes so as to check whether or not the corresponding approximate roots are real and to obtain the real root isolation boxes. Moreover, an empirical construction of initial box is provided for speeding-up the computation in practice. Our experiments on many benchmarks show that the new hybrid method is very efficient. The method can find all real roots of any given zero-dimensional nonsingular square polynomial systems provided that the homotopy continuation method can find all complex roots of the equations.", "venue": "ASCM", "authors": ["Fei  Shen", "Wenyuan  Wu", "Bican  Xia"], "year": 2012, "n_citations": 8}
{"id": 2186216, "s2_id": "9cdc604daf788cadb6d6e37321e0c1e3b5d69a33", "title": "Functional Decomposition Using Principal Subfields", "abstract": "Let f \u2208 K(t) be a univariate rational function. It is well known that any non-trivial decomposition g o h, with g,h \u2208 K(t), corresponds to a non-trivial subfield K(f(t)) \u228a L \u228a K(t) and vice-versa. In this paper we use the idea of principal subfields and fast subfield-intersection techniques to compute the subfield lattice of K(t)/K(f(t)). This yields a Las Vegas type algorithm with improved complexity and better run times for finding all non-equivalent complete decompositions of f.", "venue": "ISSAC", "authors": ["Luiz Emilio Allem", "Juliane G. Capaverde", "Mark van Hoeij", "Jonas  Szutkoski"], "year": 2017, "n_citations": 0}
{"id": 2188375, "s2_id": "e839ea1ce1640b55efe38551de2a3cfd8cfea544", "title": "RationalizeRoots: Software Package for the Rationalization of Square Roots", "abstract": "The computation of Feynman integrals often involves square roots. One way to obtain a solution in terms of multiple polylogarithms is to rationalize these square roots by a suitable variable change. We present a program that can be used to find such transformations. After an introduction to the theoretical background, we explain in detail how to use the program in practice.", "venue": "Comput. Phys. Commun.", "authors": ["Marco  Besier", "Pascal  Wasser", "Stefan  Weinzierl"], "year": 2020, "n_citations": 23}
{"id": 2188732, "s2_id": "368d0542a296a5639092bee062689d7daa30bbaf", "title": "Program Verification in the Presence of Complex Numbers, Functions with Branch Cuts etc", "abstract": "In considering the reliability of numerical programs, it is normal to ``limit our study to the semantics dealing with numerical precision'' (Martel, 2005). On the other hand, there is a great deal of work on the reliability of programs that essentially ignores the numerics. The thesis of this paper is that there is a class of problems that fall between these two, which could be described as ``does the low-level arithmetic implement the high-level mathematics''. Many of these problems arise because mathematics, particularly the mathematics of the complex numbers, is more difficult than expected: for example the complex function log is not continuous, writing down a program to compute an inverse function is more complicated than just solving an equation, and many algebraic simplification rules are not universally valid. The good news is that these problems are theoretically capable of being solved, and are practically close to being solved, but not yet solved, in several real-world examples. However, there is still a long way to go before implementations match the theoretical possibilities.", "venue": "2012 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing", "authors": ["James H. Davenport", "Russell J. Bradford", "Matthew  England", "David J. Wilson"], "year": 2012, "n_citations": 38}
{"id": 2189222, "s2_id": "6853b45c85d83b7ffbc6cb2ca556053d85a4fc18", "title": "Dealing with Rational Second Order Ordinary Differential Equations where both Darboux and Lie Find It Difficult: The $S$-function Method", "abstract": "Abstract Here we present a new approach to search for first order invariants (first integrals) of rational second order ordinary differential equations. This method is an alternative to the Darbouxian and symmetry approaches. Our procedure can succeed in many cases where these two approaches fail. We also present here a Maple implementation of the theoretical results and methods, hereby introduced, in a computational package \u2014\u00a0InSyDE. The package is designed, apart from materializing the algorithms presented, to provide a set of tools to allow the user to analyse the intermediary steps of the process. Computer programs in physics Program Title: InSyDE \u2014\u00a0Invariants and Symmetries of (racional second order ordinary) Differential Equations. Program Files doi: http://dx.doi.org/10.17632/4ytft6zgk7.1 Licensing provisions: GPLv3 Programming language: Maple 17. Nature of problem Search for first integrals of rational 2ODEs. Solution method: The method of solution is based on an algorithm described in this paper. Restrictions: If the rational 2ODE that is being analysed presents a very high degree in ( x , y , z ), then the method may not work well. Unusual features: Our implementation can find first integrals in many cases where the rational 2ODE under study cannot be reduced by other powerful solvers. Besides that, the package presents some useful research commands.", "venue": "Comput. Phys. Commun.", "authors": ["J.  Avellar", "M. S. Cardoso", "L. G. S. Duarte", "L. A. C. P. da Mota"], "year": 2019, "n_citations": 2}
{"id": 2192435, "s2_id": "0af44979c1a3a4bef547e56022885b751581d8f2", "title": "A fast algorithm for reversion of power series", "abstract": "We give an algorithm for reversion of formal power series, based on an efficient way to evaluate the Lagrange inversion formula. Our algorithm requires O(n 1/2 (M(n)+MM(n 1/2 ))) operations where M(n) and MM(n) are the costs of polynomial and matrix multiplication respectively. This matches an algorithm of Brent and Kung, but we achieve a constant factor speedup whose magnitude depends on the polynomial and matrix multiplication algo- rithms used. Benchmarks confirm that the algorithm performs well in practice.", "venue": "Math. Comput.", "authors": ["Fredrik  Johansson"], "year": 2015, "n_citations": 12}
{"id": 2195796, "s2_id": "745bf74aba0aebec8618dc825463bc7b7d1a2606", "title": "Solution of Interpolation Problems via the Hankel Polynomial Construction", "abstract": "We treat the interpolation problem $ \\{f(x_j)=y_j\\}_{j=1}^N $ for polynomial and rational functions. Developing the approach by C.Jacobi, we represent the interpolants by virtue of the Hankel polynomials generated by the sequences $ \\{\\sum_{j=1}^N x_j^ky_j/W^{\\prime}(x_j) \\}_{k\\in \\mathbb N} $ and $ \\{\\sum_{j=1}^N x_j^k/(y_jW^{\\prime}(x_j)) \\}_{k\\in \\mathbb N} $; here $ W(x)=\\prod_{j=1}^N(x-x_j) $. The obtained results are applied for the error correction problem, i.e. the problem of reconstructing the polynomial from a redundant set of its values some of which are probably erroneous. The problem of evaluation of the resultant of polynomials $ p(x) $ and $ q(x) $ from the set of values $ \\{p(x_j)/q(x_j) \\}_{j=1}^N $ is also tackled within the framework of this approach.", "venue": "ArXiv", "authors": ["Alexei Yu. Uteshev", "Ivan  Baravy"], "year": 2016, "n_citations": 2}
{"id": 2199942, "s2_id": "b52309e5cb25a642818834c69287e2151b2b2755", "title": "Parallel degree computation for solution space of binomial systems with an application to the master space of $\\mathcal{N}=1$ gauge theories", "abstract": "The problem of solving a system of polynomial equations is one of the most fundamental problems in applied mathematics. Among them, the problem of solving a system of binomial equations form a important subclass for which specialized techniques exist. For both theoretic and applied purposes, the degree of the solution set of a system of binomial equations often plays an important role in understanding the geometric structure of the solution set. Its computation, however, is computationally intensive. This paper proposes a specialized parallel algorithm for computing the degree on GPUs that takes advantage of the massively parallel nature of GPU devices. The preliminary implementation shows remarkable efficiency and scalability when compared to the closest CPU-based counterpart. Applied to the \"master space problem of $\\mathcal{N}=1$ gauge theories\" the GPU-based implementation achieves nearly 30 fold speedup over its CPU-only counterpart enabling the discovery of previously unknown results. Equally important to note is the far superior scalability: with merely 3 GPU devices on a single workstation, the GPU-based implementation shows better performance, on certain problems, than a small cluster totaling 100 CPU cores.", "venue": "ArXiv", "authors": ["Tianran  Chen", "Dhagash  Mehta"], "year": 2015, "n_citations": 2}
{"id": 2200489, "s2_id": "7c263f6fe1738d13f5d885fc767e724703345701", "title": "The Set of Equations to Evaluate Objects", "abstract": "The notion of an equational shell is studied to involve the objects and their environment. Appropriate methods are studied as valid embeddings of refined objects. The refinement process determines the linkages between the variety of possible representations giving rise to variants of computations. The case study is equipped with the adjusted equational systems that validate the initial applicative framework.", "venue": "ArXiv", "authors": ["Larissa  Ismailova"], "year": 2001, "n_citations": 0}
{"id": 2201910, "s2_id": "2321767d95fbf01310ccf632bb7bad1731e42e11", "title": "Towards a Symbolic-Numeric Method to Compute Puiseux Series: The Modular Part", "abstract": "We have designed a new symbolic-numeric strategy to compute efficiently and accurately floating point Puiseux series defined by a bivariate polynomial over an algebraic number field. In essence, computations modulo a well chosen prime $p$ are used to obtain the exact information required to guide floating point computations. In this paper, we detail the symbolic part of our algorithm: First of all, we study modular reduction of Puiseux series and give a good reduction criterion to ensure that the information required by the numerical part is preserved. To establish our results, we introduce a simple modification of classical Newton polygons, that we call \"generic Newton polygons\", which happen to be very convenient. Then, we estimate the arithmetic complexity of computing Puiseux series over finite fields and improve known bounds. Finally, we give bit-complexity bounds for deterministic and randomized versions of the symbolic part. The details of the numerical part will be described in a forthcoming paper.", "venue": "ArXiv", "authors": ["Adrien  Poteaux", "Marc  Rybowicz"], "year": 2008, "n_citations": 7}
{"id": 2210058, "s2_id": "7d453d9750e3f60f5fe83a9e9d27caa5f70b6651", "title": "The Method of Arbitrarily Large Moments to Calculate Single Scale Processes in Quantum Field Theory", "abstract": "Abstract We devise a new method to calculate a large number of Mellin moments of single scale quantities using the systems of differential and/or difference equations obtained by integration-by-parts identities between the corresponding Feynman integrals of loop corrections to physical quantities. These scalar quantities have a much simpler mathematical structure than the complete quantity. A sufficiently large set of moments may even allow the analytic reconstruction of the whole quantity considered, holding in case of first order factorizing systems. In any case, one may derive highly precise numerical representations in general using this method, which is otherwise completely analytic.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "Carsten  Schneider"], "year": 2017, "n_citations": 24}
{"id": 2210658, "s2_id": "393edbd595b9c6dff785c94fffc0a13493aea554", "title": "Rigorous Multiple-Precision Evaluation of D-Finite Functions in SageMath", "abstract": "We present a new open source implementation in the SageMath computer algebra system of algorithms for the numerical solution of linear ODEs with polynomial coefficients. Our code supports regular singular connection problems and provides rigorous error bounds.", "venue": "ArXiv", "authors": ["Marc  Mezzarobba"], "year": 2016, "n_citations": 24}
{"id": 2211576, "s2_id": "805e516555de7c9067eb6e73e071c53b1bdb6966", "title": "Digital Version of Green's Theorem and its Application to The Coverage Problem in Formal Verification", "abstract": "We present a novel scheme to the coverage problem, introducing a quantitative way to estimate the interaction between a block and its enviroment.This is achieved by setting a discrete version of Green`s theorem, specially adapted for Model Checking based verification of integrated circuits.This method is best suited for the coverage problem since it enables one to quantify the incompleteness or, on the other hand, the redundancy of a set of rules, describing the model under verification.Moreover this can be done continuously throughout the verification process, thus enabling the user to pinpoint the stages at which incompleteness/redundancy occurs. Although the method is presented locally on a small hardware example, we additionally show its possibility to provide precise coverage estimation also for large scale systems. We compare this method to others by checking it on the same test-cases.", "venue": "ArXiv", "authors": ["Eli  Appleboim", "Emil  Saucan"], "year": 2003, "n_citations": 1}
{"id": 2213051, "s2_id": "ff3569301ad4a491c87e134e92758734dcd8de4a", "title": "Asymptotics of multivariate sequences in the presence of a lacuna", "abstract": "We explain a discontinuous drop in the exponential growth rate for certain multivariate generating functions at a critical parameter value, in even dimensions $d \\geq 4$. This result depends on computations in the homology of the algebraic variety where the generating function has a pole. These computations are similar to, and inspired by, a thread of research in applications of complex algebraic geometry to hyperbolic PDEs, going back to Leray, Petrowski, Atiyah, Bott and Garding. As a consequence, we give a topological explanation for certain asymptotic phenomenon appearing in the combinatorics and number theory literature. Furthermore, we show how to combine topological methods with symbolic algebraic computation to determine explicitly the dominant asymptotics for such multivariate generating functions. This in turn enables the rigorous determination of integer coefficients in the Morse-Smale complex, which are difficult to determine using direct geometric methods.", "venue": "ArXiv", "authors": ["Yuliy  Baryshnikov", "Stephen  Melczer", "Robin  Pemantle"], "year": 2019, "n_citations": 8}
{"id": 2219228, "s2_id": "09d14e97d2aeb6474c27cba45fbde20ae2407e2b", "title": "Parallel sparse interpolation using small primes", "abstract": "To interpolate a supersparse polynomial with integer coefficients, two alternative approaches are the Prony-based \"big prime\" technique, which acts over a single large finite field, or the more recently-proposed \"small primes\" technique, which reduces the unknown sparse polynomial to many low-degree dense polynomials. While the latter technique has not yet reached the same theoretical efficiency as Prony-based methods, it has an obvious potential for parallelization. We present a heuristic \"small primes\" interpolation algorithm and report on a low-level C implementation using FLINT and MPI.", "venue": "PASCO", "authors": ["Mohamed  Khochtali", "Daniel S. Roche", "Xisen  Tian"], "year": 2015, "n_citations": 2}
{"id": 2223304, "s2_id": "23cb1615c47bbb9ec8b9182ac7f50c7715542f81", "title": "On reconstructing n-point configurations from the distribution of distances or areas", "abstract": "One way to characterize configurations of points up to congruence is by considering the distribution of all mutual distances between points. This paper deals with the question if point configurations are uniquely determined by this distribution. After giving some counterexamples, we prove that this is the case for the vast majority of configurations. In the second part of the paper, the distribution of areas of sub-triangles is used for characterizing point configurations. Again it turns out that most configurations are reconstructible from the distribution of areas, though there are counterexamples.", "venue": "Adv. Appl. Math.", "authors": ["Mireille  Boutin", "Gregor  Kemper"], "year": 2004, "n_citations": 81}
{"id": 2233257, "s2_id": "99e9c9641c38f1a50b97d8677aa97b5a7f8a26c2", "title": "Computing with Quasiseparable Matrices", "abstract": "The class of quasiseparable matrices is defined by a pair of bounds, called the quasiseparable orders, on the ranks of the sub-matrices entirely located in their strictly lower and upper triangular parts. These arise naturally in applications, as e.g. the inverse of band matrices, and are widely used for they admit structured representations allowing to compute with them in time linear in the dimension. We show, in this paper, the connection between the notion of quasiseparability and the rank profile matrix invariant, presented in [Dumas & al. ISSAC'15]. This allows us to propose an algorithm computing the quasiseparable orders (rL,rU) in time O{n2s\u03c9-2} where s=max(rL,rU) and \u03c9 the exponent of matrix multiplication. We then present two new structured representations, a binary tree of PLUQ decompositions, and the Bruhat, using respectively O{ns log n/s and O{ns} field elements instead of O{ns2} for the classical generator and O{ns log n} for the hierarchically semiseparable representations. We present algorithms computing these representations in time O{n2s\u03c9-2}. These representations allow a matrix-vector product in time linear in the size of their representation. Lastly we show how to multiply two such structured matrices in time O{n2s\u03c9-2}.", "venue": "ISSAC", "authors": ["Cl\u00e9ment  Pernet"], "year": 2016, "n_citations": 4}
{"id": 2235445, "s2_id": "ca55a7a79d861ee3c2d105073a3db1949efa24b0", "title": "Rewriting Calculus: Foundations and Applications", "abstract": "This thesis is devoted to the study of a calculus that describes the application of conditional rewriting rules and the obtained results at the same level of representation. We introduce the rewriting calculus, also called the rho-calculus, which generalizes the first order term rewriting and lambda-calculus, and makes possible the representation of the non-determinism. In our approach the abstraction operator as well as the application operator are objects of calculus. The result of a reduction in the rewriting calculus is either an empty set representing the application failure, or a singleton representing a deterministic result, or a set having several elements representing a not-deterministic choice of results. \nIn this thesis we concentrate on the properties of the rewriting calculus where a syntactic matching is used in order to bind the variables to their current values. We define evaluation strategies ensuring the confluence of the calculus and we show that these strategies become trivial for restrictions of the general rewriting calculus to simpler calculi like the lambda-calculus. The rewriting calculus is not terminating in the untyped case but the strong normalization is obtained for the simply typed calculus. \nIn the rewriting calculus extended with an operator allowing to test the application failure we define terms representing innermost and outermost normalizations with respect to a set of rewriting rules. By using these terms, we obtain a natural and concise description of the conditional rewriting. Finally, starting from the representation of the conditional rewriting rules, we show how the rewriting calculus can be used to give a semantics to ELAN, a language based on the application of rewriting rules controlled by strategies.", "venue": "ArXiv", "authors": ["Horatiu  Cirstea"], "year": 2000, "n_citations": 6}
{"id": 2235603, "s2_id": "7a237e77f652ab7ce64147df4967f9e710d0b29a", "title": "NRPyLaTeX: A LaTeX interface to computer algebra systems for general relativity", "abstract": "While each computer algebra system (CAS) contains its own unique syntax for inputting mathematical expressions, LTEX is perhaps the most widespread language for typesetting mathematics. NRPyLaTeX (NL) enables direct LTEX input of complex tensorial expressions (written in Einstein notation) relevant to general relativity and differential geometry into the SymPy CAS. As SymPy also supports output compatible with the Mathematica and Maple CASs, NL lowers the learning curve for inputting and manipulating tensorial expressions in three widely used CASs. LTEX however is a typesetting language, and as such is not designed to resolve ambiguities in mathematical expressions. To address this, NL implements a convenient configuration interface that, e.g., defines variables/keywords and assigns properties/attributes to them. Configuration commands appear as LTEX comments, so that entire NL workflows can fit seamlessly into the LTEX source code of scientific papers without interfering with the rendered mathematical expressions. Further, NL adopts NRPy+\u2019s rigid syntax for indexed symbols (e.g., tensors), which enables NL output to be directly converted into highly optimized C/C++-code kernels using NRPy+. Finally NL has robust and user-friendly error-handling, which catches common tensor indexing errors and reports unresolved ambiguities, further expediting the input and validation of LTEX expressions into a CAS.", "venue": "ArXiv", "authors": ["Kenneth J. Sible", "Zachariah B. Etienne"], "year": 2021, "n_citations": 0}
{"id": 2244589, "s2_id": "2f4e21bc644587234adee172425a03ec1f2842ff", "title": "Solving sums of squares in global fields", "abstract": "The problem of writing a totally positive element as a sum of squares has a long history in mathematics, going back to Bachet and Lagrange. While for some specific rings (like integers or polynomials over the rationals), there are known methods for decomposing an element into a sum of squares, in general, for many other important rings and fields, the problem is still widely open. In this paper, we present an explicit algorithm for decomposing an element of an arbitrary global field (either a number field or a global function field) into a sum of squares of minimal length.", "venue": "ArXiv", "authors": ["Przemyslaw  Koprowski"], "year": 2021, "n_citations": 0}
{"id": 2246226, "s2_id": "64f7931ddfa010a680b05b9681040fc501b61a75", "title": "Descartes' Rule of Signs for Polynomial Systems supported on Circuits", "abstract": "We give a multivariate version of Descartes' rule of signs to bound the number of positive real roots of a system of polynomial equations in n variables with n+2 monomials, in terms of the sign variation of a sequence associated both to the exponent vectors and the given coefficients. We show that our bound is sharp and is related to the signature of the circuit.", "venue": "ArXiv", "authors": ["Fr\u00e9d\u00e9ric  Bihan", "Alicia  Dickenstein"], "year": 2016, "n_citations": 15}
{"id": 2249576, "s2_id": "cb4de2bb2f1b21401a6fcb98252f1bf0eee18e34", "title": "Polynomial XL: A Variant of the XL Algorithm Using Macaulay Matrices over Polynomial Rings", "abstract": "Solving a system of m multivariate quadratic equations in n variables (the MQ problem) is one of the main challenges of algebraic cryptanalysis. The XL algorithm (XL for short) is a major approach for solving the MQ problem with linearization over a coefficient field. Furthermore, the hybrid approach with XL (h-XL) is a variant of XL guessing some variables beforehand. In this paper, we present a variant of h-XL, which we call the polynomial XL (PXL). In PXL, the whole n variables are divided into k variables to be fixed and the remaining n \u2212 k variables as \u201cmain variables\u201d, and we generate the Macaulay matrix with respect to the n\u2212k main variables over a polynomial ring of the k variables. By eliminating some columns of the Macaulay matrix over the polynomial ring before guessing k variables, the amount of manipulations required for each guessed value can be reduced. Our complexity analysis indicates that PXL is efficient on the system with n \u2248 m. For example, on systems over F28 with n = m = 80, the number of manipulations required by the hybrid approaches with XL and Wiedemann XL and PXL is estimated as 2, 2, and 2, respectively.", "venue": "ArXiv", "authors": ["Hiroki  Furue", "Momonari  Kudo"], "year": 2021, "n_citations": 0}
{"id": 2257923, "s2_id": "0d0816880170e517f06e9b84bc21a66aa1710d06", "title": "Model checking linear logic specifications", "abstract": "The overall goal of this paper is to investigate the theoretical foundations of algorithmic verification techniques for first order linear logic specifications. The fragment of linear logic we consider in this paper is based on the linear logic programming language called LO (Andreoli and Pareschi, 1990) enriched with universally quantified goal formulas. Although LO was originally introduced as a theoretical foundation for extensions of logic programming languages, it can also be viewed as a very general language to specify a wide range of infinite-state concurrent systems (Andreoli, 1992; Cervesato, 1995). Our approach is based on the relation between backward reachability and provability highlighted in our previous work on propositional LO programs (Bozzano et al., 2002). Following this line of research, we define here a general framework for the bottom-up. evaluation of first order linear logic specifications. The evaluation procedure is based on an effective fixpoint operator working on a symbolic representation of infinite collections of first order linear logic formulas. The theory of well quasi-orderings Abdulla et al., 1996; Finkel and Schnoebelen, 2001) can be used to provide sufficient conditions for the termination of the evaluation of non trivial fragments of first order linear logic.", "venue": "Theory and Practice of Logic Programming", "authors": ["Marco  Bozzano", "Giorgio  Delzanno", "Maurizio  Martelli"], "year": 2004, "n_citations": 18}
{"id": 2261202, "s2_id": "1718f715bd09be857fa2ab8f495e48269f4bd664", "title": "Events in Property Patterns", "abstract": "A pattern-based approach to the presentation, codification and reuse of property specifications for finite-state verification was proposed by Dwyer and his colleagues in [4,3]. The patterns enable nonexperts to read and write formal specifications for realistic systems and facilitate easy conversion of specifications between formalisms, such as LTL, CTL, QRE. In this paper we extend the pattern system with events -- changes of values of variables in the context of LTL.", "venue": "SPIN", "authors": ["Marsha  Chechik", "Dimitrie O. Paun"], "year": 1999, "n_citations": 30}
{"id": 2262719, "s2_id": "d9cc1c33eaffa08d23740e5fd5b094c1537e24f3", "title": "Defeating Opaque Predicates Statically through Machine Learning and Binary Analysis", "abstract": "We present a new approach that bridges binary analysis techniques with machine learning classification for the purpose of providing a static and generic evaluation technique for opaque predicates, regardless of their constructions. We use this technique as a static automated deobfuscation tool to remove the opaque predicates introduced by obfuscation mechanisms. According to our experimental results, our models have up to 98% accuracy at detecting and deobfuscating state-of-the-art opaque predicates patterns. By contrast, the leading edge deobfuscation methods based on symbolic execution show less accuracy mostly due to the SMT solvers constraints and the lack of scalability of dynamic symbolic analyses. Our approach underlines the efficiency of hybrid symbolic analysis and machine learning techniques for a static and generic deobfuscation methodology.", "venue": "SPRO@CCS", "authors": ["Ramtine  Tofighi-Shirazi", "Irina  Asavoae", "Philippe  Elbaz-Vincent", "Thanh Ha Le"], "year": 2019, "n_citations": 10}
{"id": 2275767, "s2_id": "1e8b20fbd5d2de28d76a58c3087a82b09f1ead64", "title": "Linear programming using limited-precision oracles", "abstract": "Since the elimination algorithm of Fourier and Motzkin, many different methods have been developed for solving linear programs. When analyzing the time complexity of LP algorithms, it is typically either assumed that calculations are performed exactly and bounds are derived on the number of elementary arithmetic operations necessary, or the cost of all arithmetic operations is considered through a bit-complexity analysis. Yet in practice, implementations typically use limited-precision arithmetic. In this paper we introduce the idea of a limited-precision LP oracle and study how such an oracle could be used within a larger framework to compute exact precision solutions to LPs. Under mild assumptions, it is shown that a polynomial number of calls to such an oracle and a polynomial number of bit operations, is sufficient to compute an exact solution to an LP. This work provides a foundation for understanding and analyzing the behavior of the methods that are currently most effective in practice for solving LPs exactly.", "venue": "Math. Program.", "authors": ["Ambros  Gleixner", "Daniel E. Steffy"], "year": 2020, "n_citations": 1}
{"id": 2277676, "s2_id": "3e5ce5c766a9418167b1ea9230544f62317c7419", "title": "Fast Algorithms for Computing Eigenvectors of Matrices via Pseudo Annihilating Polynomials", "abstract": "An efficient algorithm for computing eigenvectors of a matrix of integers by exact computation is proposed. The components of calculated eigenvectors are expressed as polynomials in the eigenvalue to which the eigenvector is associated, as a variable. The algorithm, in principle, utilizes the minimal annihilating polynomials for eliminating redundant calculations. Furthermore, in the actual computation, the algorithm computes candidates of eigenvectors by utilizing pseudo annihilating polynomials and verifies their correctness. The experimental results show that our algorithms have better performance compared to conventional methods.", "venue": "ArXiv", "authors": ["Shinichi  Tajima", "Katsuyoshi  Ohara", "Akira  Terui"], "year": 2018, "n_citations": 0}
{"id": 2282110, "s2_id": "7a6c247fee770608bd624402250bffe4015342e7", "title": "A Streamlined Difference Ring Theory: Indefinite Nested Sums, the Alternating Sign, and the Parameterized Telescoping Problem", "abstract": "We present an algebraic framework to represent indefinite nested sums over hyper geometric expressions in difference rings. In order to accomplish this task, parts of Karr's difference field theory have been extended to a ring theory in which also the alternating sign can be expressed. The underlying machinery relies on algorithms that compute all solutions of a given parameterized telescoping equation. As a consequence, we can solve the telescoping and creative telescoping problem in such difference rings.", "venue": "2014 16th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing", "authors": ["Carsten  Schneider"], "year": 2014, "n_citations": 19}
{"id": 2289071, "s2_id": "d6e3c71684b2f141bc008c8d6842494d5e7ad522", "title": "Exact Solutions in Structured Low-Rank Approximation", "abstract": "Structured low-rank approximation is the problem of minimizing a weighted Frobenius distance to a given matrix among all matrices of fixed rank in a linear space of matrices. We study exact solutions to this problem by way of computational algebraic geometry. A particular focus lies on Hankel matrices, Sylvester matrices and generic linear spaces.", "venue": "SIAM J. Matrix Anal. Appl.", "authors": ["Giorgio  Ottaviani", "Pierre-Jean  Spaenlehauer", "Bernd  Sturmfels"], "year": 2014, "n_citations": 41}
{"id": 2289596, "s2_id": "c025c40239dc8181944ce07de6049880458793aa", "title": "D-Modules and Holonomic Functions", "abstract": "In algebraic geometry, one studies the solutions to polynomial equations, or, equivalently, to linear partial differential equations with constant coefficients. These lecture notes address the more general case when the coefficients are polynomials. The letter D stands for the Weyl algebra, and a D-module is a left module over D. We focus on left ideals, or D-ideals. We represent holonomic functions in several variables by the linear differential equations they satisfy. This encoding by a D-ideal is useful for many problems, e.g., in geometry, physics and statistics. We explain how to work with holonomic functions. Applications include volume computations and likelihood inference.", "venue": "ArXiv", "authors": ["Anna-Laura  Sattelberger", "Bernd  Sturmfels"], "year": 2019, "n_citations": 7}
{"id": 2294821, "s2_id": "781080faf420d3fef24d169565f8f5f181331370", "title": "A variant of van Hoeij's algorithm to compute hypergeometric term solutions of holonomic recurrence equations", "abstract": "Linear homogeneous recurrence equations with polynomial coefficients are said to be holonomic. Such equations have been introduced in the last century for proving and discovering combinatorial and hypergeometric identities. Given a field K of characteristic zero, a term an is called hypergeometric with respect to K, if the ratio an+1/an is a rational function over K. The solutions space of holonomic recurrence equations gained more interest in the 1990s from the well known Zeilberger\u2019s algorithm. In particular, algorithms computing the subspace of hypergeometric term solutions which covers polynomial, rational, and some algebraic solutions of these equations were investigated by Marko Petkov\u0161ek (1993) and Mark van Hoeij (1999). The algorithm proposed by the latter is characterized by a much better efficiency than that of the other; it computes, in Gamma representations, a basis of the subspace of hypergeometric term solutions of any given holonomic recurrence equation, and is considered as the current state of the art in this area. Mark van Hoeij implemented his algorithm in the Computer Algebra System (CAS) Maple through the command LREtools[hypergeomsols]. We propose a variant of van Hoeij\u2019s algorithm that performs the same efficiency and gives outputs in terms of factorials and shifted factorials, without considering certain recommendations of the original version. We have implementations of our algorithm for the CASs Maxima and Maple. Such an implementation is new for Maxima which is therefore used for general-purpose examples. Our Maxima code is currently available as a thirdparty package for Maxima. A comparison between van Hoeij\u2019s implementation and ours is presented for Maple 2020. It appears that both have the same efficiency, and moreover, for some particular cases, our code finds results where LREtools[hypergeomsols] fails.", "venue": "ArXiv", "authors": ["Bertrand Teguia Tabuguia"], "year": 2020, "n_citations": 1}
{"id": 2306488, "s2_id": "722d7974544f744b1ad4e72860adc6d477dc8c1a", "title": "Toward an optimal quantum algorithm for polynomial factorization over finite fields", "abstract": "We present a randomized quantum algorithm for polynomial factorization over finite fields. For polynomials of degree n over a finite field F_q, the average-case complexity of our algorithm is an expected O(n^{1 + o(1)} \\log^{2 + o(1)}q) bit operations. Only for a negligible subset of polynomials of degree $n$ our algorithm has a higher complexity of O(n^{4/3 + o(1)} \\log^{2 + o(1)}q) bit operations. This breaks the classical 3/2-exponent barrier for polynomial factorization over finite fields \\cite{guo2016alg}.", "venue": "Quantum Inf. Comput.", "authors": ["Javad  Dolizkani"], "year": 2018, "n_citations": 0}
{"id": 2309941, "s2_id": "94102862055932bc2a2a4f88f200640159725e09", "title": "Automatic Differentiation using Constraint Handling Rules in Prolog", "abstract": "Automatic differentiation is a technique which allows a programmer to define a numerical computation via compositions of a broad range of numeric and computational primitives and have the underlying system support the computation of partial derivatives of the result with respect to any of its inputs, without making any finite difference approximations, and without manipulating large symbolic expressions representing the computation. This note describes a novel approach to reverse mode automatic differentiation using constraint logic programmming, specifically, the constraint handling rules (CHR) library of SWI Prolog, resulting in a very small (50 lines of code) implementation. When applied to a differentiation-based implementation of the inside-outside algorithm for parameter learning in probabilistic grammars, the CHR based implementations outperformed two well-known frameworks for optimising differentiable functions, Theano and TensorFlow, by a large margin.", "venue": "ArXiv", "authors": ["Samer  Abdallah"], "year": 2017, "n_citations": 1}
{"id": 2312683, "s2_id": "9baf24d90d48e5bd08516749566c24ea2b42996d", "title": "Sparse Rational Function Interpolation with Finitely Many Values for the Coefficients", "abstract": "In this paper, we give new sparse interpolation algorithms for black box univariate and multivariate rational functions \\(h=f/g\\) whose coefficients are integers with an upper bound. The main idea is as follows: choose a proper integer \\(\\beta \\) and let \\(h(\\beta ) = a/b\\) with \\(\\gcd (a,b)=1\\). Then f and g can be computed by solving the polynomial interpolation problems \\(f(\\beta )=ka\\) and \\(g(\\beta )=ka\\) for some unique integer k. Experimental results show that the univariate interpolation algorithm is almost optimal.", "venue": "MACIS", "authors": ["Qiao-Long  Huang", "Xiao-Shan  Gao"], "year": 2017, "n_citations": 4}
{"id": 2313794, "s2_id": "5c41bd427e285291ee7fefe2e12e44cbeefbd8a6", "title": "Logic Conditionals, Supervenience, and Selection Tasks", "abstract": "Principles of cognitive economy would require that concepts about objects, properties and relations should be introduced only if they simplify the conceptualisation of a domain. Unexpectedly, classic logic conditionals, specifying structures holding within elements of a formal conceptualisation, do not always satisfy this crucial principle. The paper argues that this requirement is captured by supervenience, hereby further identified as a property necessary for compression. The resulting theory suggests an alternative explanation of the empirical experiences observable in Wason's selection tasks, associating human performance with conditionals on the ability of dealing with compression, rather than with logic necessity.", "venue": "DKB/KIK@KI", "authors": ["Giovanni  Sileno"], "year": 2019, "n_citations": 0}
{"id": 2316488, "s2_id": "bfaad2290527afa9a4cd8101ffb0a1cb7c1abd06", "title": "A Complete Method for Checking Hurwitz Stability of a Polytope of Matrices", "abstract": "We present a novel method for checking the Hurwitz stability of a polytope of matrices. First we prove that the polytope matrix is stable if and only if two homogenous polynomials are positive on a simplex, then through a newly proposed method, i.e., the weighted difference substitution method, the latter can be checked in finite steps. Examples show the efficiency of our method.", "venue": "ArXiv", "authors": ["Junwei  Shao", "Xiaorong  Hou"], "year": 2010, "n_citations": 3}
{"id": 2317807, "s2_id": "dd013b3175df17c438b61834a16aba90d0c4602b", "title": "Reducing the complexity for class group computations using small defining polynomials", "abstract": "In this paper, we describe an algorithm that efficiently collect relations in class groups of number fields defined by a small defining polynomial. This conditional improvement consists in testing directly the smoothness of principal ideals generated by small algebraic integers. This strategy leads to an algorithm for computing the class group whose complexity is possibly as low as $L_{|\\Delta_{\\mathbf K}|}\\left(\\frac{1}{3}\\right)$.", "venue": "ArXiv", "authors": ["Alexandre  G\u00e9lin"], "year": 2018, "n_citations": 2}
{"id": 2334414, "s2_id": "10af1e0087fc957e960b8737d2bc14fc2ae91e5f", "title": "Automatic Generation of Moment-Based Invariants for Prob-Solvable Loops", "abstract": "One of the main challenges in the analysis of probabilistic programs is to compute invariant properties that summarise loop behaviours. Automation of invariant generation is still at its infancy and most of the times targets only expected values of the program variables, which is insufficient to recover the full probabilistic program behaviour. We present a method to automatically generate moment-based invariants of a subclass of probabilistic programs, called Prob-Solvable loops, with polynomial assignments over random variables and parametrised distributions. We combine methods from symbolic summation and statistics to derive invariants as valid properties over higher-order moments, such as expected values or variances, of program variables. We successfully evaluated our work on several examples where full automation for computing higher-order moments and invariants over program variables was not yet possible.", "venue": "ATVA", "authors": ["Ezio  Bartocci", "Laura  Kov\u00e1cs", "Miroslav  Stankovic"], "year": 2019, "n_citations": 8}
{"id": 2338194, "s2_id": "be31a288bad4be2ab871726b8944bba545316059", "title": "Finding exact minimal polynomial by approximations", "abstract": "We present a new algorithm for reconstructing an exact algebraic number from its approximate value by using an improved parameterized integer relation construction method. Our result is consistent with the existence of error controlling on obtaining an exact rational number from its approximation. The algorithm is applicable for finding exact minimal polynomial of an algebraic number by its approximate root. This also enables us to provide an efficient method of converting the rational approximation representation to the minimal polynomial representation, and devise a simple algorithm to factor multivariate polynomials with rational coefficients.\n Compared with the subsistent methods, our method combines advantage of high efficiency in numerical computation, and exact, stable results in symbolic computation. The experimental results show that the method is more efficient than identify in Maple for obtaining an exact algebraic number from its approximation. Moreover, the Digits of our algorithm is far less than the LLL-lattice basis reduction technique in theory. In this paper, we completely implement how to obtain exact results by numerical approximate computations.", "venue": "SNC '09", "authors": ["Xiaolin  Qin", "Yong  Feng", "Jingwei  Chen", "Jingzhong  Zhang"], "year": 2009, "n_citations": 6}
{"id": 2340060, "s2_id": "344713557729a61b89c8faa939405f841ec15f0b", "title": "On the probability of generating a primitive matrix", "abstract": "Given a k \u00d7 n integer primitive matrix A (i.e., a matrix can be extended to an n \u00d7 n unimodular matrix over the integers) with size of entries bounded by \u03bb, we study the probability that the m \u00d7 n matrix extended from A by choosing other m \u2212 k vectors uniformly at random from {0, 1, . . . , \u03bb \u2212 1} is still primitive. We present a complete and rigorous proof that the probability is at least a constant for the case of m \u2264 n \u2212 4. Previously, only the limit case for \u03bb \u2192 \u221e with k = 0 was analysed in Maze et al. (2011), known as the natural density. As an application, we prove that there exists a fast Las Vegas algorithm that completes a k \u00d7 n primitive matrix A to an n \u00d7 n unimodular matrix within expected \u00d5(n log \u2016A\u2016) bit operations, where \u00d5 is big-O but without log factors, \u03c9 is the exponent on the arithmetic operations of matrix multiplication and \u2016A\u2016 is the maximal absolute value of entries of A.", "venue": "ArXiv", "authors": ["Jingwei  Chen", "Yong  Feng", "Yang  Liu", "Wenyuan  Wu"], "year": 2021, "n_citations": 0}
{"id": 2353942, "s2_id": "7ea15dc14e9b6b0954aa940ab3824403715510b2", "title": "Real Computational Universality: The Word Problem for a Class of Groups with Infinite Presentation", "abstract": "The word problem for discrete groups is well-known to be undecidable by a Turing Machine; more precisely, it is reducible both to and from and thus equivalent to the discrete Halting Problem. \n \nThe present work introduces and studies a real extension of the word problem for a certain class of groups which are presented as quotient groups of a free group and a normal subgroup. As main difference with discrete groups, these groups may be generated by uncountably many generators with index running over certain sets of real numbers. This includes a variety of groups which are not captured by the finite framework of the classical word problem. \n \nOur contribution extends computational group theory from the discrete to the Blum-Shub-Smale (BSS) model of real number computation. It provides a step towards applying BSS theory, in addition to semialgebraic geometry, also to further areas of mathematics. \n \nThe main result establishes the word problem for such groups to be not only semi-decidable (and thus reducible to) but also reducible from the Halting Problem for such machines. It thus gives the first non-trivial example of a problem complete, that is, computationally universal for this model.", "venue": "MFCS", "authors": ["Klaus  Meer", "Martin  Ziegler"], "year": 2007, "n_citations": 1}
{"id": 2360698, "s2_id": "9b8a3f4ec27c8c33ca4ad6c101aa72a1fff523a3", "title": "PolyAdd: Polynomial Formal Verification of Adder Circuits", "abstract": "Only by formal verification approaches functional correctness can be ensured. While for many circuits fast verification is possible, in other cases the approaches fail. In general no efficient algorithms can be given, since the underlying verification problem is NP-complete. In this paper we prove that for different types of adder circuits polynomial verification can be ensured based on BDDs. While it is known that the output functions for addition are polynomially bounded, we show in the following that the entire construction process can be carried out in polynomial time. This is shown for the simple Ripple Carry Adder, but also for fast adders like the Conditional Sum Adder and the Carry Look Ahead Adder. Properties about the adder function are proven and the core principle of polynomial verification is described that can also be extended to other classes of functions and circuit realizations.", "venue": "2021 24th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)", "authors": ["Rolf  Drechsler"], "year": 2021, "n_citations": 5}
{"id": 2372111, "s2_id": "4614cd16535e6727e421c005d50ccda46e5430fb", "title": "On the complexity of the generalized MinRank problem", "abstract": "We study the complexity of solving the generalized MinRank problem, i.e. computing the set of points where the evaluation of a polynomial matrix has rank at most r. A natural algebraic representation of this problem gives rise to a determinantal ideal: the ideal generated by all minors of size r+1 of the matrix. We give new complexity bounds for solving this problem using Grobner bases algorithms under genericity assumptions on the input matrix. In particular, these complexity bounds allow us to identify families of generalized MinRank problems for which the arithmetic complexity of the solving process is polynomial in the number of solutions. We also provide an algorithm to compute a rational parametrization of the variety of a 0-dimensional and radical system of bi-degree (D,1). We show that its complexity can be bounded by using the complexity bounds for the generalized MinRank problem.", "venue": "J. Symb. Comput.", "authors": ["Jean-Charles  Faug\u00e8re", "Mohab Safey El Din", "Pierre-Jean  Spaenlehauer"], "year": 2013, "n_citations": 41}
{"id": 2376943, "s2_id": "dd43de1c720df8d471c86dc6855fa9798ba64b5d", "title": "Symmetries of Quantified Boolean Formulas", "abstract": "While symmetries are well understood for Boolean formulas and successfully exploited in practical SAT solving, less is known about symmetries in quantified Boolean formulas (QBF). There are some works introducing adaptions of propositional symmetry breaking techniques, with a theory covering only very specific parts of QBF symmetries. We present a general framework that gives a concise characterization of symmetries of QBF. Our framework naturally incorporates the duality of universal and existential symmetries resulting in a general basis for QBF symmetry breaking.", "venue": "SAT", "authors": ["Manuel  Kauers", "Martina  Seidl"], "year": 2018, "n_citations": 5}
{"id": 2377007, "s2_id": "999085a549a25ca37dd88163e5c00c639aaff73f", "title": "Effective Certification of Approximate Solutions to Systems of Equations Involving Analytic Functions", "abstract": "We develop algorithms for certifying an approximation to a nonsingular solution of a square system of equations built from univariate analytic functions. These algorithms are based on the existence of oracles for evaluating basic data about the input analytic functions. One approach for certification is based on \u03b1-theory while the other is based on the Krawczyk generalization of Newton's iteration. We show that the necessary oracles exist for \\Dfinite\\ functions and compare the two algorithmic approaches for this case using our software implementation in \\sage.", "venue": "ISSAC", "authors": ["Michael  Burr", "Kisun  Lee", "Anton  Leykin"], "year": 2019, "n_citations": 5}
{"id": 2378169, "s2_id": "1632ac7419be747303a49464a703109550d16b63", "title": "Explicit Bounds for Linear Forms in the Exponentials of Algebraic Numbers", "abstract": "In this paper, we study linear forms \u03bb = \u03b21e1 + \u00b7 \u00b7 \u00b7 + \u03b2mem , where \u03b1i and \u03b2i are algebraic numbers. An explicit lower bound for |\u03bb | is proved, which is derived from \u201cth\u00e9or\u00e8me de Lindemann\u2013 Weierstrass effectif\u201d via constructive methods in algebraic computation. Besides, an explicit upper bound for the minimal |\u03bb | is established on systematic results of counting algebraic numbers. CCS CONCEPTS \u2022 Computing methodologies \u2192 Number theory algorithms; \u2022 Theory of computation \u2192 Algebraic complexity theory.", "venue": "ArXiv", "authors": ["Cheng-Chao  Huang"], "year": 2021, "n_citations": 0}
{"id": 2379387, "s2_id": "821658c6229c008797a8bb3e618643b5afe71246", "title": "On sequences associated to the invariant theory of rank two simple Lie algebras", "abstract": "We study two families of sequences, listed in the On-Line Encyclopedia of Integer Sequences (OEIS), which are associated to invariant theory of Lie algebras. For the first family, we prove combinatorially that the sequences A059710 and A108307 are related by a binomial transform. Based on this, we present two independent proofs of a recurrence equation for A059710, which was conjectured by Mihailovs. Besides, we also give a direct proof of Mihailovs' conjecture by the method of algebraic residues. As a consequence, closed formulae for the generating function of sequence A059710 are obtained in terms of classical Gaussian hypergeometric functions. Moreover, we show that sequences in the second family are also related by binomial transforms.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Jordan  Tirrell", "Bruce W. Westbury", "Yi  Zhang"], "year": 2019, "n_citations": 2}
{"id": 2383594, "s2_id": "d6a2a599e5f82b457b69c498a10c8700c16fe8d6", "title": "On the Complexity and Parallel Implementation of Hensel's Lemma and Weierstrass Preparation", "abstract": "Hensel\u2019s lemma, combined with repeated applications of Weierstrass preparation theorem, allows for the factorization of polynomials with multivariate power series coefficients. We present a complexity analysis for this method and leverage those results to guide the load-balancing of a parallel implementation to concurrently update all factors. In particular, the factorization creates a pipeline where the terms of degree k of the first factor are computed simultaneously with the terms of degree k \u2212 1 of the second factor, etc. An implementation challenge is the inherent irregularity of computational work between factors, as our complexity analysis reveals. Additional resource utilization and load-balancing is achieved through the parallelization of Weierstrass preparation. Experimental results show the efficacy of this mixed parallel scheme, achieving up to 9\u00d7 parallel speedup on a 12-core ma-", "venue": "CASC", "authors": ["Alexander  Brandt", "Marc Moreno Maza"], "year": 2021, "n_citations": 1}
{"id": 2391181, "s2_id": "855d0f722d75cc56a66a00ede18ace96bafee6bd", "title": "Theano: new features and speed improvements", "abstract": "Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.", "venue": "ArXiv", "authors": ["Fr\u00e9d\u00e9ric  Bastien", "Pascal  Lamblin", "Razvan  Pascanu", "James  Bergstra", "Ian J. Goodfellow", "Arnaud  Bergeron", "Nicolas  Bouchard", "David  Warde-Farley", "Yoshua  Bengio"], "year": 2012, "n_citations": 1363}
{"id": 2401784, "s2_id": "d4359e58e3e0957556e823b2e54c8531546f298c", "title": "Tropical Implicitization and Mixed Fiber Polytopes", "abstract": "The software TrIm offers implementations of tropical implicitization and tropical elimination, as developed by Tevelev and the authors. Given a polynomial map with generic coefficients, TrIm computes the tropical variety of the image. When the image is a hypersurface, the output is the Newton polytope of the defining polynomial. TrIm can thus be used to compute mixed fiber polytopes, including secondary polytopes.", "venue": "ArXiv", "authors": ["Bernd  Sturmfels", "Josephine  Yu"], "year": 2007, "n_citations": 39}
{"id": 2403398, "s2_id": "2e8c84fd61c91e067dddef52ced76b824beb7013", "title": "Learning Reasoning Strategies in End-to-End Differentiable Proving", "abstract": "Attempts to render deep learning models interpretable, data-efficient, and robust have seen some success through hybridisation with rule-based systems, for example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions. However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. We present Conditional Theorem Provers (CTPs), an extension to NTPs that learns an optimal rule selection strategy via gradient-based optimisation. We show that CTPs are scalable and yield state-of-the-art results on the CLUTRR dataset, which tests systematic generalisation of neural models by learning to reason over smaller graphs and evaluating on larger ones. Finally, CTPs show better link prediction results on standard benchmarks in comparison with other neural-symbolic models, while being explainable. All source code and datasets are available online, at this https URL.", "venue": "ICML", "authors": ["Pasquale  Minervini", "Sebastian  Riedel", "Pontus  Stenetorp", "Edward  Grefenstette", "Tim  Rocktaschel"], "year": 2020, "n_citations": 24}
{"id": 2404263, "s2_id": "fecc0e9339bab9d40d7ca62528f050c8d8d39c20", "title": "CREST: Hardware Formal Verification with ANSI-C Reference Specifications", "abstract": "This paper presents CREST, a prototype front-end tool intended as an add-on to commercial EDA formal verifcation environments. CREST is an adaptation of the CBMC bounded model checker for C, an academic tool widely used in industry for software analysis and property verification. It leverages the capabilities of CBMC to process hardware datapath specifications written in arbitrary ANSI-C, without limiting restrictions to a synthesizable subset. We briefly sketch the architecture of our tool and show its use in a range of verification case studies.", "venue": "ArXiv", "authors": ["Andreas  Tiemeyer", "Thomas F. Melham", "Daniel  Kroening", "John  O'Leary"], "year": 2019, "n_citations": 0}
{"id": 2408153, "s2_id": "dc05a30cee8f5f0eb0ea9c9ed0135d260dfc33a9", "title": "Factorization of Dual Quaternion Polynomials Without Study\u2019s Condition", "abstract": "In this paper we investigate factorizations of polynomials over the ring of dual quaternions into linear factors. While earlier results assume that the norm polynomial is real (\u201cmotion polynomials\u201d), we only require the absence of real polynomial factors in the primal part and factorizability of the norm polynomial over the dual numbers into monic quadratic factors. This obviously necessary condition is also sufficient for existence of factorizations. We present an algorithm to compute factorizations of these polynomials and use it for new constructions of mechanisms which cannot be obtained by existing factorization algorithms for motion polynomials. While they produce mechanisms with rotational or translational joints, our approach yields mechanisms consisting of \u201cvertical Darboux joints\u201d. They exhibit mechanical deficiencies so that we explore ways to replace them by cylindrical joints while keeping the overall mechanism sufficiently constrained.", "venue": "Advances in applied Clifford algebras", "authors": ["Johannes  Siegele", "Martin  Pfurner", "Hans-Peter  Schr\u00f6cker"], "year": 2021, "n_citations": 1}
{"id": 2415005, "s2_id": "7f7d3212938671c667034c826bf6d335c5ecb170", "title": "Isotropic vectors over global fields", "abstract": "We present a complete suite of algorithms for finding isotropic vectors of quadratic forms (of any dimension) over an arbitrary global field of characteristic different from 2.", "venue": "ArXiv", "authors": ["Przemyslaw  Koprowski"], "year": 2021, "n_citations": 0}
{"id": 2422600, "s2_id": "c08639bd1ca3c142f570bcb970be577d1f823f11", "title": "MultivariateApart: Generalized Partial Fractions", "abstract": "We present a package to perform partial fraction decompositions of multivariate rational functions. The algorithm allows to systematically avoid spurious denominator factors and is capable of producing unique results also when being applied to terms of a sum separately. The package is designed to work in Mathematica, but also provides interfaces to the Form and Singular computer algebra systems. Email addresses: maheller@students.uni-mainz.de (Matthias Heller), vmante@msu.edu (Andreas von Manteuffel)", "venue": "Computer Physics Communications", "authors": ["Matthias  Heller", "Andreas von Manteuffel"], "year": 2022, "n_citations": 10}
{"id": 2428722, "s2_id": "f6b79ac047bbeb66fd6f78c30048606ca0f5d70b", "title": "Annotary: A Concolic Execution System for Developing Secure Smart Contracts", "abstract": "Ethereum smart contracts are executable programs, deployed on a peer-to-peer network and executed in a consensus-based fashion. Their bytecode is public, immutable and once deployed to the blockchain, cannot be patched anymore. As smart contracts may hold Ether worth of several million dollars, they are attractive targets for attackers and indeed some contracts have successfully been exploited in the recent past, resulting in tremendous financial losses. The correctness of smart contracts is thus of utmost importance. While first approaches on formal verification exist, they demand users to be well-versed in formal methods which are alien to many developers and are only able to analyze individual contracts, without considering their execution environment, i.e., calls to external contracts, sequences of transaction, and values from the actual blockchain storage. In this paper, we present Annotary, a concolic execution framework to analyze smart contracts for vulnerabilities, supported by annotations which developers write directly in the Solidity source code. In contrast to existing work, Annotary supports analysis of inter-transactional, inter-contract control flows and combines symbolic execution of EVM bytecode with a resolution of concrete values from the public Ethereum blockchain. While the analysis of Annotary tends to weight precision higher than soundness, we analyze inter-transactional call chains to eliminate false positives from unreachable states that traditional symbolic execution would not be able to handle. We present the annotation and analysis concepts of Annotary, explain its implementation on top of the Laser symbolic virtual machine, and demonstrate its usage as a plugin for the Sublime Text editor.", "venue": "ESORICS", "authors": ["Konrad  Weiss", "Julian  Sch\u00fctte"], "year": 2019, "n_citations": 5}
{"id": 2431309, "s2_id": "5466454dadd97f7f132e39b04fed60803783843f", "title": "On the representation of non-holonomic power series", "abstract": "Abstract. Holonomic functions play an essential role in Computer Algebra since they allow the application of many symbolic algorithms. Among all algorithmic attempts to find formulas for power series, the holonomic property remains the most important requirement to be satisfied by the function under consideration. The targeted functions mainly summarize that of meromorphic functions. However, expressions like tan(z), z/(exp(z)\u2212 1), sec(z), etc. are not holonomic, therefore their power series are inaccessible by non-pattern matching implementations like the current Maple convert/FormalPowerSeries up to Maple 2021. From the mathematical dictionaries, one can observe that most of the known closed-form formulas of non-holonomic power series involve another sequence whose evaluation depends on some finite summations. In the case of tan(z) and sec(z) the corresponding sequences are the Bernoulli and Euler numbers, respectively. Thus providing a symbolic approach that yields complete representations when linear summations for power series coefficients of non-holonomic functions appear, might be seen as a step forward towards the representation of non-holonomic power series. By adapting the method of ansatz with undetermined coefficients, we build an algorithm that computes leastorder quadratic differential equations with polynomial coefficients for a large class of non-holonomic functions. A differential equation resulting from this procedure is converted into a recurrence equation by applying the Cauchy product formula and rewriting powers into polynomials and derivatives into shifts. Finally, using enough initial values we are able to give normal form representations (Geddes et al. 1992) to characterize several nonholonomic power series. As a consequence of the defined normal relation, it turns out that our algorithm is able to detect identities between non-holonomic functions that were not accessible in the past. We discuss this algorithm and its implementation for Maple 2022. Our Maple and Maxima implementations are available under the FPS software which can be downloaded at http://www.mathematik.uni-kassel.de/~bteguia/FPS_webpage/FPS.htm.", "venue": "ArXiv", "authors": ["Bertrand Teguia Tabuguia", "Wolfram  Koepf"], "year": 2021, "n_citations": 0}
{"id": 2432563, "s2_id": "496601350e88363f94550d16a85e1cc9e518718f", "title": "Compression for 2-Parameter Persistent Homology", "abstract": "Compression aims to reduce the size of an input, while maintaining its relevant properties. For multi-parameter persistent homology, compression is a necessary step in any computational pipeline, since standard constructions lead to large inputs, and computational tasks in this area tend to be expensive. We propose two compression methods for chain complexes of free 2-parameter persistence modules. The first method extends the multi-chunk algorithm for one-parameter persistent homology, returning the smallest chain complex among all the ones quasi-isomorphic to the input. The second method produces minimal presentations of the homology of the input; it is based on an algorithm of Lesnick and Wright, but incorporates several improvements that lead to dramatic performance gains. The two methods are complementary, and can be combined to compute minimal presentations for complexes with millions of generators in a few seconds. The methods have been implemented, and the software is publicly available. We report on experimental evaluations, which demonstrate substantial improvements in performance compared to previously available compression strategies.", "venue": "ArXiv", "authors": ["Ulderico  Fugacci", "Michael  Kerber", "Alexander  Rolle"], "year": 2021, "n_citations": 0}
{"id": 2432809, "s2_id": "be0d9e90002785b8111567fc8548ab7dd10d3063", "title": "Sufficient Set of Integrability Conditions of\u00a0an\u00a0Orthonomic System", "abstract": "Every orthonomic system of partial differential equations is known to possess a finite number of integrability conditions sufficient to ensure the validity of them all. Here we show that a redundancy-free sufficient set of integrability conditions can be constructed in a time proportional to the number of equations cubed.", "venue": "Found. Comput. Math.", "authors": ["Michal  Marvan"], "year": 2009, "n_citations": 30}
{"id": 2440880, "s2_id": "4116e9ae184daa500f444476bf2652cfe2cca1c6", "title": "Deciding Regularity of the Set of Instances of a Set of Terms with Regular Constraints is EXPTIME-Complete", "abstract": "Finite-state tree automata are a well studied formalism for representing term languages. This paper studies the problem of determining the regularity of the set of instances of a finite set of terms with variables, where each variable is restricted to instantiations of a regular set given by a tree automaton. The problem was recently proved decidable, but with an unknown complexity. Here, the exact complexity of the problem is determined by proving EXPTIME-completeness. The main contribution is a new, exponential time algorithm that performs various exponential transformations on the involved terms and tree automata, and decides regularity by analyzing formulas over inequality and height predicates.", "venue": "SIAM J. Comput.", "authors": ["Omer  Gim\u00e9nez", "Guillem  Godoy", "Sebastian  Maneth"], "year": 2011, "n_citations": 5}
{"id": 2441959, "s2_id": "1421649c384aef82091a8c437e896164016fc7e7", "title": "On the Inverse Of General Cyclic Heptadiagonal and Anti-Heptadiagonal Matrices", "abstract": "In the current work, the author present a symbolic algorithm for finding the determinant of any general nonsingular cyclic heptadiagonal matrices and inverse of anti-cyclic heptadiagonal matrices. The algorithms are mainly based on the work presented in [A. A. KARAWIA, A New Algorithm for Inverting General Cyclic Heptadiagonal Matrices Recursively, arXiv:1011.2306v1 [cs.SC]]. The symbolic algorithms are suited for implementation using Computer Algebra Systems (CAS) such as MATLAB, MAPLE and MATHEMATICA. An illustrative example is given.", "venue": "ArXiv", "authors": ["A. A. Karawia"], "year": 2010, "n_citations": 0}
{"id": 2450274, "s2_id": "bec78151f58c0ee4ecbafa87c978861ae9cca7d5", "title": "Comparative study of space filling curves for cache oblivious TU Decomposition", "abstract": "We examine several matrix layouts based on space-filling curves that allow for a cache-oblivious adaptation of parallel TU decomposition for rectangular matrices over finite fields. The TU algorithm of \\cite{Dumas} requires index conversion routines for which the cost to encode and decode the chosen curve is significant. Using a detailed analysis of the number of bit operations required for the encoding and decoding procedures, and filtering the cost of lookup tables that represent the recursive decomposition of the Hilbert curve, we show that the Morton-hybrid order incurs the least cost for index conversion routines that are required throughout the matrix decomposition as compared to the Hilbert, Peano, or Morton orders. The motivation lies in that cache efficient parallel adaptations for which the natural sequential evaluation order demonstrates lower cache miss rate result in overall faster performance on parallel machines with private or shared caches, on GPU's, or even cloud computing platforms. We report on preliminary experiments that demonstrate how the TURBO algorithm in Morton-hybrid layout attains orders of magnitude improvement in performance as the input matrices increase in size. For example, when $N = 2^{13}$, the row major TURBO algorithm concludes within about 38.6 hours, whilst the Morton-hybrid algorithm with truncation size equal to $64$ concludes within 10.6 hours.", "venue": "ArXiv", "authors": ["Fatima K. Abu Salem", "Mira Al Arab"], "year": 2016, "n_citations": 3}
{"id": 2452344, "s2_id": "a5d6ec621f365c01db9c46777a5b1cd931b9b879", "title": "Executable Set Theory and Arithmetic Encodings in Prolog", "abstract": "The paper is organized as a self-contained literate Prolog program that implements elements of an executable finite set theory with focus on combinatorial generation and arithmetic encodings. The complete Prolog code is available at this http URL . First, ranking and unranking functions for some \"mathematically elegant\" data types in the universe of Hereditarily Finite Sets with Urelements are provided, resulting in arithmetic encodings for powersets, hypergraphs, ordinals and choice functions. After implementing a digraph representation of Hereditarily Finite Sets we define {\\em decoration functions} that can recover well-founded sets from encodings of their associated acyclic digraphs. We conclude with an encoding of arbitrary digraphs and discuss a concept of duality induced by the set membership relation. In the process, we uncover the surprising possibility of internally sharing isomorphic objects, independently of their language level types and meanings.", "venue": "ArXiv", "authors": ["Paul  Tarau"], "year": 2008, "n_citations": 0}
{"id": 2455284, "s2_id": "432476da08fb1d103a6e87d52af92ff364ac6e6f", "title": "Polynomial Systems Solving by Fast Linear Algebra", "abstract": "Polynomial system solving is a classical problem in mathematics with a wide range of applications. This makes its complexity a fundamental problem in computer science. Depending on the context, solving has different meanings. In order to stick to the most general case, we consider a representation of the solutions from which one can easily recover the exact solutions or a certified approximation of them. Under generic assumption, such a representation is given by the lexicographical Grobner basis of the system and consists of a set of univariate polynomials. The best known algorithm for computing the lexicographical Grobner basis is in $\\widetilde{O}(d^{3n})$ arithmetic operations where $n$ is the number of variables and $d$ is the maximal degree of the equations in the input system. The notation $\\widetilde{O}$ means that we neglect polynomial factors in $n$. We show that this complexity can be decreased to $\\widetilde{O}(d^{\\omega n})$ where $2 \\leq \\omega < 2.3727$ is the exponent in the complexity of multiplying two dense matrices. Consequently, when the input polynomial system is either generic or reaches the Bezout bound, the complexity of solving a polynomial system is decreased from $\\widetilde{O}(D^3)$ to $\\widetilde{O}(D^\\omega)$ where $D$ is the number of solutions of the system. To achieve this result we propose new algorithms which rely on fast linear algebra. When the degree of the equations are bounded uniformly by a constant we propose a deterministic algorithm. In the unbounded case we present a Las Vegas algorithm.", "venue": "ArXiv", "authors": ["Jean-Charles  Faug\u00e8re", "Pierrick  Gaudry", "Louise  Huot", "Gu\u00e9na\u00ebl  Renault"], "year": 2013, "n_citations": 26}
{"id": 2457749, "s2_id": "fbee950e30ccb13ffc63b84e346875a4e90922f1", "title": "The integration of systems of linear PDEs using conservation laws of syzygies", "abstract": "A new integration technique is presented for systems of linear partial differential equations (PDEs) for which syzygies can be formulated that obey conservation laws. These syzygies come for free as a by-product of the differential Grobner basis computation. Compared with the more obvious way of integrating a single equation and substituting the result in other equations the new technique integrates more than one equation simultaneously and therefore introduces temporarily fewer new functions of integration that in addition depend on fewer variables. Especially for high order PDE systems in many variables the conventional integration technique may lead to an explosion of the number of functions of integration which is avoided with the new method. A further benefit is that redundant free functions in the solution are either prevented or that their number is at least reduced.", "venue": "J. Symb. Comput.", "authors": ["Thomas  Wolf"], "year": 2003, "n_citations": 3}
{"id": 2461236, "s2_id": "0158b7bf773967246cac7a0eaf5c1759c28f9ad6", "title": "Probabilistic analysis of block wiedemann for leading invariant factors", "abstract": "The exact probability, dependent on the matrix structure, is given that the block Wiedemann algorithm correctly computes the leading invariant factors of a matrix. A tight lower bound, structure independent, is derived.", "venue": "ACCA", "authors": ["Gavin  Harrison", "Jeremy R. Johnson", "B. David Saunders"], "year": 2017, "n_citations": 0}
{"id": 2461613, "s2_id": "dd1e920d7515b1365f0909dc9e1fbda98c00bef0", "title": "Sparse Interpolation With Errors in Chebyshev Basis Beyond Redundant-Block Decoding", "abstract": "We present sparse interpolation algorithms for recovering a polynomial with <inline-formula> <tex-math notation=\"LaTeX\">$\\le B$ </tex-math></inline-formula> terms from <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> evaluations at distinct values for the variable when <inline-formula> <tex-math notation=\"LaTeX\">$\\le E$ </tex-math></inline-formula> of the evaluations can be erroneous. Our algorithms perform exact arithmetic in the field of scalars <inline-formula> <tex-math notation=\"LaTeX\">$ \\mathsf {K}$ </tex-math></inline-formula> and the terms can be standard powers of the variable or Chebyshev polynomials, in which case the characteristic of <inline-formula> <tex-math notation=\"LaTeX\">$ \\mathsf {K}$ </tex-math></inline-formula> is <inline-formula> <tex-math notation=\"LaTeX\">$\\ne 2$ </tex-math></inline-formula>. Our algorithms return a list of valid sparse interpolants for the <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> support points and run in polynomial-time. For standard power basis our algorithms sample at <inline-formula> <tex-math notation=\"LaTeX\">$N = \\lfloor \\frac {4}{3} E + 2 \\rfloor B$ </tex-math></inline-formula> points, which are fewer points than <inline-formula> <tex-math notation=\"LaTeX\">$N = 2(E+1)B - 1$ </tex-math></inline-formula> given by Kaltofen and Pernet in 2014. For Chebyshev basis our algorithms sample at <inline-formula> <tex-math notation=\"LaTeX\">$N = \\lfloor \\frac {3}{2} E + 2 \\rfloor B$ </tex-math></inline-formula> points, which are also fewer than the number of points required by the algorithm given by Arnold and Kaltofen in 2015, which has <inline-formula> <tex-math notation=\"LaTeX\">$N = 74 \\lfloor \\frac {E}{13} + 1 \\rfloor $ </tex-math></inline-formula> for <inline-formula> <tex-math notation=\"LaTeX\">$B = 3$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$E \\ge 222$ </tex-math></inline-formula>. Our method shows how to correct 2 errors in a block of <inline-formula> <tex-math notation=\"LaTeX\">$4B$ </tex-math></inline-formula> points for standard basis and how to correct 1 error in a block of <inline-formula> <tex-math notation=\"LaTeX\">$3B$ </tex-math></inline-formula> points for Chebyshev Basis.", "venue": "IEEE Transactions on Information Theory", "authors": ["Erich L. Kaltofen", "Zhi-Hong  Yang"], "year": 2021, "n_citations": 1}
{"id": 2464514, "s2_id": "4cbfe90275adb0a1b70a3c4beb9481637c744a51", "title": "Recovery from Power Sums", "abstract": "We study the problem of recovering a collection of n numbers from the evaluation of m power sums. This yields a system of polynomial equations, which can be underconstrained (m < n), square (m = n), or overconstrained (m > n). Fibers and images of power sum maps are explored in all three regimes, and in settings that range from complex and projective to real and positive. This involves surprising deviations from the B\u00e9zout bound, and the recovery of vectors from length measurements by p-norms.", "venue": "ArXiv", "authors": ["Hana  Mel'anov'a", "Bernd  Sturmfels", "Rosa  Winter"], "year": 2021, "n_citations": 0}
{"id": 2465029, "s2_id": "a05ec495092acb1f6c18cdca5e38c598e481c287", "title": "Learning an arbitrary mixture of two multinomial logits", "abstract": "In this paper, we consider mixtures of multinomial logistic models (MNL), which are known to $\\epsilon$-approximate any random utility model. Despite its long history and broad use, rigorous results are only available for learning a uniform mixture of two MNLs. Continuing this line of research, we study the problem of learning an arbitrary mixture of two MNLs. We show that the identifiability of the mixture models may only fail on an algebraic variety of a negligible measure. This is done by reducing the problem of learning a mixture of two MNLs to the problem of solving a system of univariate quartic equations. We also devise an algorithm to learn any mixture of two MNLs using a polynomial number of samples and a linear number of queries, provided that a mixture of two MNLs over some finite universe is identifiable. Several numerical experiments and conjectures are also presented.", "venue": "ArXiv", "authors": ["Wenpin  Tang"], "year": 2020, "n_citations": 1}
{"id": 2466207, "s2_id": "fad439bdececa0cdcbd2dc206683434c3b5f7c32", "title": "Polynomial relations among principal minors of a 4x4-matrix", "abstract": "The image of the principal minor map for n x n-matrices is shown to be closed. In the 19th century, Nansen and Muir studied the implicitization problem of finding all relations among principal minors when n=4. We complete their partial results by constructing explicit polynomials of degree 12 that scheme-theoretically define this affine variety and also its projective closure in $\\PP^{15}$. The latter is the main component in the singular locus of the 2 x 2 x 2 x 2-hyperdeterminant.", "venue": "ArXiv", "authors": ["Shaowei  Lin", "Bernd  Sturmfels"], "year": 2008, "n_citations": 25}
{"id": 2466897, "s2_id": "575a419c8faa289d97ccaf28b7df74edd4f57949", "title": "Deterministic computation of the characteristic polynomial in the time of matrix multiplication", "abstract": "This paper describes an algorithm which computes the characteristic polynomial of a matrix over a field within the same asymptotic complexity, up to constant factors, as the multiplication of two square matrices. Previously, to our knowledge, this was only achieved by resorting to genericity assumptions or randomization techniques, while the best known complexity bound with a general deterministic algorithm was obtained by Keller-Gehrig in 1985 and involves logarithmic factors. Our algorithm computes more generally the determinant of a univariate polynomial matrix in reduced form, and relies on new subroutines for transforming shifted reduced matrices into shifted weak Popov matrices, and shifted weak Popov matrices into shifted Popov matrices.", "venue": "J. Complex.", "authors": ["Vincent  Neiger", "Cl'ement  Pernet"], "year": 2021, "n_citations": 1}
{"id": 2472255, "s2_id": "202a7f09003add0ddb4ae94cbcf9bf8576136579", "title": "A Symbolic Approach to Detecting Hardware Trojans Triggered by Don't Care Transitions", "abstract": "Due to the globalization of Integrated Circuit (IC) supply chain, hardware trojans and the attacks that can trigger them have become an important security issue. One type of hardware Trojans leverages the don\u2019t care transitions in Finite State Machines (FSMs) of hardware designs. In this paper, we present a symbolic approach to detecting don\u2019t care transitions and the hidden Trojans. Our detection approach works at both RTL and gate-level, does not require a golden design, and works in three stages. In the first stage, it explores the reachable states. In the second stage, it performs an approximate analysis to find the don\u2019t care transitions. In the third stage, it performs a state-space exploration from reachable states that have incoming don\u2019t care transitions to find behavioral discrepancies with respect to what has been observed in the first stage. We also present a pruning technique based on the reachability of FSM states. We present a methodology that leverages both RTL and gate-level for soundness and efficiency. Specifically, we show that don\u2019t care transitions must be detected at the gate-level, i.e., after synthesis has been performed, for soundness. However, under specific conditions, Trojan detection can be performed more efficiently at RTL. Evaluation of our approach on a set of benchmarks from OpenCores and TrustHub and using gate-level representation generated by two synthesis tools, Yosys and Synopsis Design Compiler (SDC), shows that our approach is both efficient (up to 10X speedup w.r.t. no pruning) and precise (0% false positives) in detecting don\u2019t care transitions and the Trojans that leverage them. Additionally, the total analysis time can achieve up to 3.40X (using Yosys) and 2.52X (SDC) speedup when synthesis preserves the FSM structure and the Trojan detection is performed at RTL.", "venue": "ArXiv", "authors": ["Ruochen  Dai", "Tuba  Yavuz"], "year": 2021, "n_citations": 0}
{"id": 2473126, "s2_id": "4ffcfd0b0359894181e3e4a97b86aee7ec4e2054", "title": "Weakly nonlocal Poisson brackets: tools, examples, computations", "abstract": "We implement an algorithm for the computation of Schouten bracket of weakly nonlocal Hamiltonian operators in three different computer algebra systems: Maple, Reduce and Mathematica. This class of Hamiltonian operators encompass almost all the examples coming from the theory of (1+1)-integrable evolutionary PDEs.", "venue": "ArXiv", "authors": ["Matteo  Casati", "Paolo  Lorenzoni", "Daniele  Valeri", "Raffaele  Vitolo"], "year": 2021, "n_citations": 2}
{"id": 2473414, "s2_id": "1d054d31c2cfa3e1cdfd27f8be4e2907efc374eb", "title": "An Optimization-Based Sum-of-Squares Approach to Vizing's Conjecture", "abstract": "Vizing's conjecture (open since 1968) relates the sizes of dominating sets in two graphs to the size of a dominating set in their Cartesian product graph. In this paper, we formulate Vizing's conjecture itself as a Positivstellensatz existence question. In particular, we encode the conjecture as an ideal/polynomial pair such that the polynomial is nonnegative if and only if the conjecture is true. We demonstrate how to use semidefinite optimization techniques to computationally obtain numeric sum-of-squares certificates, and then show how to transform these numeric certificates into symbolic certificates approving nonnegativity of our polynomial. After outlining the theoretical structure of this computer-based proof of Vizing's conjecture, we present computational and theoretical results. In particular, we present exact low-degree sparse sum-of-squares certificates for particular families of graphs.", "venue": "ISSAC", "authors": ["Elisabeth  Gaar", "Daniel  Krenn", "Susan  Margulies", "Angelika  Wiegele"], "year": 2019, "n_citations": 2}
{"id": 2475839, "s2_id": "f26fc6f0c352cfde1d1a65deb0cf3c2613d009c7", "title": "Benchmarking the solar dynamo with Maxima", "abstract": "Recently, Jouve et al(A&A, 2008) published the paper that presents the numerical benchmark for the solar dynamo models. Here, I would like to show a way how to get it with help of computer algebra system Maxima. This way was used in our paper (Pipin & Seehafer, A&A 2008, in print) to test some new ideas in the large-scale stellar dynamos. In the present paper I complement the dynamo benchmark with the standard test that address the problem of the free-decay modes in the sphere which is submerged in vacuum.", "venue": "ArXiv", "authors": ["Valery V. Pipin"], "year": 2008, "n_citations": 0}
{"id": 2487650, "s2_id": "720e26a44baee55b9559a3f037baf604b7e4d1b4", "title": "On the Uniqueness Problem for Quadrature Domains", "abstract": "We study questions of existence and uniqueness of quadrature domains using computational tools from real algebraic geometry. These problems are transformed into questions about the number of solutions to an associated real semi-algebraic system, which is analyzed using the method of real comprehensive triangular decomposition.", "venue": "Computational Methods and Function Theory", "authors": ["Yacin  Ameur", "Martin  Helmer", "Felix  Tellander"], "year": 2021, "n_citations": 0}
{"id": 2487808, "s2_id": "c563f677b2be4da2394dd1971466a3fece01df24", "title": "Smoothed analysis for the condition number of structured real polynomial systems", "abstract": "We consider the sensitivity of real zeros of structured polynomial systems to perturbations of their coefficients. In particular, we provide explicit estimates for condition numbers of structured random real polynomial systems, and extend these estimates to the smoothed analysis setting.", "venue": "Math. Comput.", "authors": ["Alperen Ali Erg\u00fcr", "Grigoris  Paouris", "J. Maurice Rojas"], "year": 2021, "n_citations": 1}
{"id": 2491968, "s2_id": "fdba0bd64404b2b88a01f6a9f6f6b2c13caa5c26", "title": "Bilinear Systems with Two Supports: Koszul Resultant Matrices, Eigenvalues, and Eigenvectors", "abstract": "A fundamental problem in computational algebraic geometry is the computation of the resultant. A central question is when and how to compute it as the determinant of a matrix whose elements are the coefficients of the input polynomials up-to sign. This problem is well understood for unmixed multihomogeneous systems, that is for systems consisting of multihomogeneous polynomials with the same support. However, little is known for mixed systems, that is for systems consisting of polynomials with different supports. We consider the computation of the multihomogeneous resultant of bilinear systems involving two different supports. We present a constructive approach that expresses the resultant as the exact determinant of a Koszul resultant matrix, that is a matrix constructed from maps in the Koszul complex. % We exploit the resultant matrix to propose an algorithm to solve such systems. In the process we extend the classical eigenvalues and eigenvectors criterion to a more general setting. Our extension of the eigenvalues criterion applies to a general class of matrices, including the Sylvester-type and the Koszul-type ones.", "venue": "ISSAC", "authors": ["Mat\u00edas R. Bender", "Jean-Charles  Faug\u00e8re", "Angelos  Mantzaflaris", "Elias P. Tsigaridas"], "year": 2018, "n_citations": 6}
{"id": 2492804, "s2_id": "6103a210be111560bcffccc6372f0dbd87688acb", "title": "New practical advances in polynomial root clustering", "abstract": "We report an ongoing work on clustering algorithms for complex roots of a univariate polynomial $p$ of degree $d$ with real or complex coefficients. As in their previous best subdivision algorithms our root-finders are robust even for multiple roots of a polynomial given by a black box for the approximation of its coefficients, and their complexity decreases at least proportionally to the number of roots in a region of interest (ROI) on the complex plane, such as a disc or a square, but we greatly strengthen the main ingredient of the previous algorithms. Namely our new counting test essentially amounts to the evaluation of a polynomial $p$ and its derivative $p'$, which is a major benefit, e.g., for sparse polynomials $p$. Moreover with evaluation at about $\\log(d)$ points (versus the previous record of order $d$) we output correct number of roots in a disc whose contour has no roots of $p$ nearby. Moreover we greatly soften the latter requirement versus the known subdivision algorithms. Our second and less significant contribution concerns subdivision algorithms for polynomials with real coefficients. Our tests demonstrate the power of the proposed algorithms.", "venue": "MACIS", "authors": ["R'emi  Imbach", "Victor Y. Pan"], "year": 2019, "n_citations": 5}
{"id": 2494510, "s2_id": "bd1d1c295ae070fc7f39cf1fcb6f3a32c58c8326", "title": "Computing Periods of Hypersurfaces", "abstract": "We give an algorithm to compute the periods of smooth projective hypersurfaces of any dimension. This is an improvement over existing algorithms which could only compute the periods of plane curves. Our algorithm reduces the evaluation of period integrals to an initial value problem for ordinary differential equations of Picard-Fuchs type. In this way, the periods can be computed to extreme-precision in order to study their arithmetic properties. The initial conditions are obtained by an exact determination of the cohomology pairing on Fermat hypersurfaces with respect to a natural basis.", "venue": "Math. Comput.", "authors": ["Emre Can Sert\u00f6z"], "year": 2019, "n_citations": 6}
{"id": 2494664, "s2_id": "c3f35793219b4d67ede8b56c76690fed30cd1ced", "title": "Building Executable Secure Design Models for Smart Contracts with Formal Methods", "abstract": "Smart contracts are appealing because they are self-executing business agreements between parties with the predefined and immutable obligations and rights. However, as with all software, smart contracts may contain vulnerabilities because of design flaws, which may be exploited by one of the parties to defraud the others. In this paper, we demonstrate a systematic approach to building secure design models for smart contracts using formal methods. To build the secure models, we first model the behaviors of participating parties as state machines, and then, we model the predefined obligations and rights of contracts, which specify the interactions among state machines for achieving the business goal. After that, we illustrate executable secure model design patterns in TLA+ (Temporal Logic of Actions) to against well-known smart contract vulnerabilities in terms of state machines and obligations and rights at the design level. These vulnerabilities are found in Ethereum contracts, including Call to the unknown, Gasless send, Reentrancy, Lost in the transfer, and Unpredictable state. The resultant TLA+ specifications are called secure models. We illustrate our approach to detect the vulnerabilities using a real-estate contract example at the design level.", "venue": "Financial Cryptography Workshops", "authors": ["Weifeng  Xu", "Glenn A. Fink"], "year": 2019, "n_citations": 3}
{"id": 2501463, "s2_id": "4b5f1d93cb9c8fbe63b5d7d4ccdefe0f0a1f4ad8", "title": "On Two-Generated Non-commutative Algebras Subject to the Affine Relation", "abstract": "We consider algebras over a field K, generated by two variables x and y subject to the single relation yx = qxy + ax + \u03b2y + \u03b3 for q \u2208 K* and \u03b1, \u03b2, \u03b3 \u2208 K. We prove, that among such algebras there are precisely five isomorphism classes. The representatives of these classes, which are ubiquitous operator algebras, are called model algebras. We derive explicit multiplication formulas for ym \u010b xn in terms of standard monomials xiyj for many algebras of the considered type. Such formulas are used in e. g. establishing formulas of binomial type and in an implementation of non-commutative multiplication in a computer algebra system. By using the formulas we also study centers and ring-theoretic properties of the non-commutative model algebras.", "venue": "CASC", "authors": ["Viktor  Levandovskyy", "Christoph  Koutschan", "Oleksandr  Motsak"], "year": 2011, "n_citations": 1}
{"id": 2507399, "s2_id": "b307a4bea644e1535ccbeee42b44cd33be84c3a6", "title": "Modeling Terms by Graphs with Structure Constraints (Two Illustrations)", "abstract": "In the talk at the workshop my aim was to demonstrate the usefulness of graph techniques for tackling problems that have been studied predominantly as problems on the term level: increasing sharing in functional programs, and addressing questions about Milner's process semantics for regular expressions. For both situations an approach that is based on modeling terms by graphs with structure constraints has turned out to be fruitful. In this extended abstract I describe the underlying problems, give references, provide examples, indicate the chosen approaches, and compare the initial situations as well as the results that have been obtained, and some results that are being developed at present.", "venue": "TERMGRAPH@FSCD", "authors": ["Clemens  Grabmayer"], "year": 2018, "n_citations": 3}
{"id": 2508434, "s2_id": "a5800474fa2e68195a790e2dd8454a7824a546ad", "title": "Competition Report: CHC-COMP-20", "abstract": "CHC-COMP-20 is the third competition of solvers for Constrained Horn Clauses. In this year, 9 solvers participated at the competition, and were evaluated in four separate tracks on problems in linear integer arithmetic, linear real arithmetic, and arrays. The competition was run in the first week of May 2020 using the StarExec computing cluster. This report gives an overview of the competition design, explains the organisation of the competition, and presents the competition results.", "venue": "VPT/HCVS@ETAPS", "authors": ["Philipp  R\u00fcmmer"], "year": 2020, "n_citations": 3}
{"id": 2509194, "s2_id": "2073a76ed2105db033697671680942ee0cc86829", "title": "A Polyhedral Method to Compute All Affine Solution Sets of Sparse Polynomial Systems", "abstract": "To compute solutions of sparse polynomial systems efficiently we have to exploit the structure of their Newton polytopes. While the application of polyhedral methods naturally excludes solutions with zero components, an irreducible decomposition of a variety is typically understood in affine space, including also those components with zero coordinates. We present a polyhedral method to compute all affine solution sets of a polynomial system. The method enumerates all factors contributing to a generalized permanent. Toric solution sets are recovered as a special case of this enumeration. For sparse systems as adjacent 2-by-2 minors our methods scale much better than the techniques from numerical algebraic geometry.", "venue": "ArXiv", "authors": ["Danko  Adrovic", "Jan  Verschelde"], "year": 2013, "n_citations": 4}
{"id": 2522794, "s2_id": "d4ca960c3be1c9b71d210ec311712b30f7952614", "title": "Counting Roots of Polynomials Over Prime Power Rings", "abstract": "Suppose $p$ is a prime, $t$ is a positive integer, and $f\\!\\in\\!\\mathbb{Z}[x]$ is a univariate polynomial of degree $d$ with coefficients of absolute value $<\\!p^t$. We show that for any fixed $t$, we can compute the number of roots in $\\mathbb{Z}/(p^t)$ of $f$ in deterministic time $(d+\\log p)^{O(1)}$. This fixed parameter tractability appears to be new for $t\\!\\geq\\!3$. A consequence for arithmetic geometry is that we can efficiently compute Igusa zeta functions $Z$, for univariate polynomials, assuming the degree of $Z$ is fixed.", "venue": "The Open Book Series", "authors": ["Qi  Cheng", "Shuhong  Gao", "J. Maurice Rojas", "Daqing  Wan"], "year": 2019, "n_citations": 6}
{"id": 2528031, "s2_id": "6686c77a2183b78a740adbeef31e8a89bc78f9de", "title": "Semialgebraic Invariant Synthesis for the Kannan-Lipton Orbit Problem", "abstract": "The Orbit Problem consists of determining, given a linear transformation A on d-dimensional rationals Q^d, together with vectors x and y, whether the orbit of x under repeated applications of A can ever reach y. This problem was famously shown to be decidable by Kannan and Lipton in the 1980s. \n \nIn this paper, we are concerned with the problem of synthesising suitable invariants P which are subsets of R^d, i.e., sets that are stable under A and contain x and not y, thereby providing compact and versatile certificates of non-reachability. We show that whether a given instance of the Orbit Problem admits a semialgebraic invariant is decidable, and moreover in positive instances we provide an algorithm to synthesise suitable invariants of polynomial size. \n \nIt is worth noting that the existence of semilinear invariants, on the other hand, is (to the best of our knowledge) not known to be decidable.", "venue": "STACS", "authors": ["Nathana\u00ebl  Fijalkow", "Pierre  Ohlmann", "Jo\u00ebl  Ouaknine", "Amaury  Pouly", "James  Worrell"], "year": 2017, "n_citations": 6}
{"id": 2529044, "s2_id": "b0752bea0ea35870f559f24f96fb9e1482085091", "title": "Nominal Unification from a Higher-Order Perspective", "abstract": "Nominal Logic is an extension of first-order logic with equality, name-binding, name-swapping, and freshness of names. Contrarily to higher-order logic, bound variables are treated as atoms, and only free variables are proper unknowns in nominal unification. This allows \"variable capture\", breaking a fundamental principle of lambda-calculus. Despite this difference, nominal unification can be seen from a higher-order perspective. From this view, we show that nominal unification can be reduced to a particular fragment of higher-order unification problems: higher-order patterns unification. This reduction proves that nominal unification can be decided in quadratic deterministic time.", "venue": "RTA", "authors": ["Jordi  Levy", "Mateu  Villaret"], "year": 2008, "n_citations": 25}
{"id": 2530959, "s2_id": "0f001f4548c246d2f679b9e9f96e82a852f5c1be", "title": "Matrix Methods for Solving Algebraic Systems", "abstract": "The problem of computing all common zeros of a system of polynomials is of fundamental importance in a wide variety of scientific and engineering applications. This article surveys efficient methods based on the sparse resultant for computing all isolated solutions of an arbitrary system of n polynomials in n unknowns. In particular, we construct matrix formulae which yield nontrivial multiples of the resultant thus reducing root-finding to the eigendecomposition of a square matrix.", "venue": "Symbolic Algebraic Methods and Verification Methods", "authors": ["Ioannis Z. Emiris"], "year": 2001, "n_citations": 5}
{"id": 2531924, "s2_id": "1c7194ecf02fad9b3d352982c6c25b2aa2d1b05e", "title": "Polynomial Complexity Recognizing a Tropical Linear Variety", "abstract": "A polynomial complexity algorithm is designed which tests whether a point belongs to a given tropical linear variety.", "venue": "CASC", "authors": ["Dima  Grigoriev"], "year": 2015, "n_citations": 3}
{"id": 2540066, "s2_id": "235bbb1f75582f40f70b7a8298855ebeec5da745", "title": "Computational linear algebra over finite fields", "abstract": "We present here algorithms for efficient computation of linear algebra problems over finite fields.", "venue": "Handbook of Finite Fields", "authors": ["Jean-Guillaume  Dumas", "Cl\u00e9ment  Pernet"], "year": 2013, "n_citations": 10}
{"id": 2541257, "s2_id": "3a092d05dac16af965f610d6da0365a17074505b", "title": "Multiplicity structure of the arc space of a fat point", "abstract": "The equation x = 0 defines a fat point on a line. The algebra of regular functions on the arc space of this scheme is the quotient of k[x, x\u2032, x, . . .] by all differential consequences of x = 0. This infinite-dimensional algebra admits a natural filtration by finite dimensional algebras corresponding to the truncations of arcs. We show that the generating series for their dimensions equals m 1\u2212mt . We also determine the lexicographic initial ideal of the defining ideal of the arc space. These results are motivated by nonreduced version of the geometric motivic Poincar\u00e9 series, multiplicities in differential algebra, and connections between arc spaces and the Rogers-Ramanujan identities. We also prove a recent conjecture put forth by Afsharijoo in the latter context.", "venue": "ArXiv", "authors": ["Rida Ait El Manssour", "Gleb  Pogudin"], "year": 2021, "n_citations": 0}
{"id": 2547848, "s2_id": "4e20db17cd0dab232730b1c0e4c7bbc37b0803d8", "title": "Over-constrained Weierstrass iteration and the nearest consistent system", "abstract": "We propose a generalization of the Weierstrass iteration for over-constrained systems of equations and we prove that the proposed method is the Gauss-Newton iteration to find the nearest system which has at least $k$ common roots and which is obtained via a perturbation of prescribed structure. In the univariate case we show the connection of our method to the optimization problem formulated by Karmarkar and Lakshman for the nearest GCD. In the multivariate case we generalize the expressions of Karmarkar and Lakshman, and give explicitly several iteration functions to compute the optimum. \nThe arithmetic complexity of the iterations is detailed.", "venue": "ArXiv", "authors": ["Olivier  Ruatta", "Mark  Sciabica", "\u00c1gnes  Sz\u00e1nt\u00f3"], "year": 2014, "n_citations": 1}
{"id": 2553247, "s2_id": "10e4135784ccc6949ba78e2243b643f5d087ad87", "title": "Exact Optimization via Sums of Nonnegative Circuits and Sums of AM/GM Exponentials", "abstract": "We provide two hybrid numeric-symbolic optimization algorithms, computing exact sums of nonnegative circuits (SONC) and sums of arithmetic-geometric-exponentials (SAGE) decompositions. Moreover, we provide a hybrid numeric-symbolic decision algorithm for polynomials lying in the interior of the SAGE cone. Each framework, inspired by previous contributions of Parrilo and Peyrl, is a rounding-projection procedure. \nFor a polynomial lying in the interior of the SAGE cone, we prove that the decision algorithm terminates within a number of arithmetic operations, which is polynomial in the degree and number of terms of the input, and singly exponential in the number of variables. We also provide experimental comparisons regarding the implementation of the two optimization algorithms.", "venue": "ArXiv", "authors": ["Victor  Magron", "Henning  Seidler", "Timo de Wolff"], "year": 2019, "n_citations": 0}
{"id": 2555763, "s2_id": "9cee9a2d52846acb1bc79f753daf803135babe7f", "title": "Computer-Assisted Program Reasoning Based on a Relational Semantics of Programs", "abstract": "We present an approach to program reasoning which inserts between a program and its verification conditions an additional layer, the denotation of the program expressed in a declarative form. The program is first translated into its denotation from which subsequently the verification conditions are generated. However, even before (and independently of) any verification attempt, one may investigate the denotation itself to get insight into the \"semantic essence\" of the program, in particular to see whether the denotation indeed gives reason to believe that the program has the expected behavior. Errors in the program and in the meta-information may thus be detected and fixed prior to actually performing the formal verification. More concretely, following the relational approach to program semantics, we model the effect of a program as a binary relation on program states. A formal calculus is devised to derive from a program a logic formula that describes this relation and is subject for inspection and manipulation. We have implemented this idea in a comprehensive form in the RISC ProgramExplorer, a new program reasoning environment for educational purposes which encompasses the previously developed RISC ProofNavigator as an interactive proving assistant.", "venue": "ThEdu", "authors": ["Wolfgang  Schreiner"], "year": 2011, "n_citations": 7}
{"id": 2565274, "s2_id": "09ddd35bb5b25ce7c1d4e070dac8ad950b26cdf9", "title": "An Effective Framework for Constructing Exponent Lattice Basis of Nonzero Algebraic Numbers", "abstract": "Computing a basis for the exponent lattice of algebraic numbers is a basic problem in the field of computational number theory with applications to many other areas. The bottleneck of the computation of a well-known algorithm \\citege1993, kauers2005 solving the problem is the computation of the primitive element of the extended field generated by the given algebraic numbers. When the extended field is of large degree, the problem seems intractable by the tool implementing the algorithm. In this paper, a special kind of exponent lattice basis is introduced. An important feature of that basis is that it can be inductively constructed, which allows us to deal with the given algebraic numbers one by one and to work in smaller fields while computing the basis. Based on this, an effective framework for constructing exponent lattice basis is proposed. Through computing a so-called pre-basis first and then solving some linear Diophantine equations, the basis can be efficiently constructed. A new certificate for multiplicative independence and some techniques for decreasing degrees of algebraic numbers are provided to speed up the computation. The new algorithm has been implemented with Mathematica and its effectiveness is verified by testing various examples.", "venue": "ISSAC", "authors": ["Tao  Zheng", "Bican  Xia"], "year": 2019, "n_citations": 3}
{"id": 2569560, "s2_id": "6d7aa6c9337576b12ceea5cb351affbec7466fd5", "title": "On the Complexity of Computing the Topology of Real Algebraic Space Curves", "abstract": "This paper presents an algorithm to compute the topology of an algebraic space curve. This is a modified version of the previous algorithm. Furthermore, the authors also analyse the bit complexity of the algorithm, which is $$\\widetilde{\\cal O}\\left( {{N^{20}}} \\right)$$ O \u02dc ( N 20 ) , where N = max{ d, \u03c4 }, d and \u03c4 are the degree bound and the bit size bound of the coefficients of the defining polynomials of the algebraic space curve. To our knowledge, this is the best bound among the existing work. It gains the existing results at least N 2 . Meanwhile, the paper contains some contents of the conference papers (CASC 2014 and SNC 2014).", "venue": "J. Syst. Sci. Complex.", "authors": ["Kai  Jin", "Jin-San  Cheng"], "year": 2021, "n_citations": 1}
{"id": 2573970, "s2_id": "d52dae209fcccdd70d80cac2c98e905f3dfc7643", "title": "Definite Sums of Hypergeometric Terms and Limits of P-Recursive Sequences", "abstract": "The ubiquity of the class of D-finite functions and P-recursive sequences in symbolic computation is widely recognized. In this thesis, the presented work consists of two parts related to this class. \nIn the first part, we generalize the reduction-based creative telescoping algorithms to the hypergeometric setting, which allows to deal with definite sums of hypergeometric terms more quickly. We first modify the Abramov-Petkovsek reduction, and then design a new algorithm to compute minimal telescopers for bivariate hypergeometric terms based on the modified reduction. This new algorithm can avoid the costly computation of certificates, and outperforms the classical Zeilberger algorithm no matter whether certificates are computed or not according to the computational experiments. Moreover, we also derive order bounds for minimal telescopers. These bounds are sometimes better, and never worse than the known ones. \nIn the second part of the thesis, we study the class of D-finite numbers. It consists of the limits of convergent P-recursive sequences. Typically, this class contains many well-known mathematical constants in addition to the algebraic numbers. Our definition of the class of D-finite numbers depends on two subrings of the field of complex numbers. We investigate how different choices of these two subrings affect the class. Moreover, we show that D-finite numbers over the Gaussian rational field are essentially the same as the values of D-finite functions at non-singular algebraic number arguments (so-called the regular holonomic constants). This result makes it easier to recognize certain numbers as belonging to this class.", "venue": "ArXiv", "authors": ["Hui  Huang"], "year": 2017, "n_citations": 0}
{"id": 2577365, "s2_id": "ab5510fdaef418dcd65214cafd66f0ba06fe764c", "title": "Optimized Multivariate Polynomial Determinant on GPU", "abstract": "We present an optimized algorithm calculating determinant for multivariate polynomial matrix on GPU. The novel algorithm provides precise determinant for input multivariate polynomial matrix in controllable time. Our approach is based on modular methods and split into Fast Fourier Transformation, Condensation method and Chinese Remainder Theorem where each algorithm is paralleled on GPU. The experiment results show that our parallel method owns substantial speedups compared to Maple, allowing memory overhead and time expedition in steady increment. We are also able to deal with complex matrix which is over the threshold on Maple and constrained on CPU. In addition, calculation during the process could be recovered without losing accuracy at any point regardless of disruptions. Furthermore, we propose a time prediction for calculation of polynomial determinant according to some basic matrix attributes and we solve an open problem relating to harmonic elimination equations on the basis of our GPU implementation.", "venue": "ArXiv", "authors": ["Jianjun  Wei", "Liangyu  Chen"], "year": 2020, "n_citations": 0}
{"id": 2595823, "s2_id": "a17e51b4dcf3dfc9367faaaf1b939fa3bd7623e8", "title": "An Improved Algorithm based on Shannon-Happ Formula for Calculating Transfer Function from Signal Flow Graph and Its Visualization", "abstract": "A new method based on Shannon-Happ formula to calculate transfer function from Signal Flow Graph (SFG) is presented. The algorithm provides an explicit approach to get the transfer function in a format with both numerical and symbolic expressions. The adoption of the symbolic variable in SFG, which could represent the nonlinear item or the independent sub-system, is achieved by variable separation approach. An investigation is given for the solutions of several special conditions of SFG. To improve the efficiency of the algorithm, a new technique combined with Johnson method for generating the combinations of the non-touching loops is developed. It uses the previous combinations in lower order to get the ones in higher order. There is an introduction about the visualization of SFG and the subroutines for system performance analysis in the software, AVANT.", "venue": "ArXiv", "authors": ["Hongyu  Lu", "Chongguang  Wu", "Shanglian  Bao"], "year": 2009, "n_citations": 2}
{"id": 2598022, "s2_id": "b878a54ba3cd9b68c3649aa69145c539a25b1b60", "title": "Index reduction of differential algebraic equations by differential algebraic elimination", "abstract": "High index differential algebraic equations (DAEs) are ordinary differential equations (ODEs) with constraints and arise frequently from many mathematical models of physical phenomenons and engineering fields. In this paper, we generalize the idea of differential elimination with Dixon resultant to polynomially nonlinear DAEs. We propose a new algorithm for index reduction of DAEs and establish the notion of differential algebraic elimination, which can provide the differential algebraic resultant of the enlarged system of original equations. To make use of structure of DAEs, variable pencil technique is given to determine the termination of differentiation. Moreover, we also provide a heuristics method for removing the extraneous factors from differential algebraic resultant. The experimentation shows that the proposed algorithm outperforms existing ones for many examples taken from the literature.", "venue": "ArXiv", "authors": ["Xiaolin  Qin", "Lu  Yang", "Yong  Feng", "Bernhard  Bachmann", "Peter  Fritzson"], "year": 2015, "n_citations": 4}
{"id": 2610323, "s2_id": "caae9f6cf29beaa676a4d5ccad296c3ba0110f97", "title": "Computations modulo regular chains", "abstract": "The computation of triangular decompositions involve two fundamental operations: polynomial GCDs modulo regular chains and regularity test modulo saturated ideals. We propose new algorithms for these core operations based on modular methods and fast polynomial arithmetic. We rely on new results connecting polynomial subresultants and GCDs modulo regular chains. We report on extensive experimentation, comparing our code to pre-existing Maple implementations, as well as more optimized Magma functions. In most cases, our new code outperforms the other packages by several orders of magnitude.", "venue": "ISSAC '09", "authors": ["Xin  Li", "Marc Moreno Maza", "Wei  Pan"], "year": 2009, "n_citations": 42}
{"id": 2612684, "s2_id": "e155d658949d6f6a6570a2839cb45b2b3afd267f", "title": "miniKanren as a Tool for Symbolic Computation in Python", "abstract": "In this article, we give a brief overview of the current state and future potential of symbolic computation within the Python statistical modeling and machine learning community. We detail the use of miniKanren as an underlying framework for term rewriting and symbolic mathematics, as well as its ability to orchestrate the use of existing Python libraries. We also discuss the relevance and potential of relational programming for implementing more robust, portable, domain-specific \"math-level\" optimizations--with a slight focus on Bayesian modeling. Finally, we describe the work going forward and raise some questions regarding potential cross-overs between statistical modeling and programming language theory.", "venue": "ArXiv", "authors": ["Brandon T. Willard"], "year": 2020, "n_citations": 0}
{"id": 2614990, "s2_id": "d72a73fb17a5813610022ed96579413808c65dd8", "title": "Error Correcting Codes, finding polynomials of bounded degree agreeing on a dense fraction of a set of points", "abstract": "Here we present some revised arguments to a randomized algorithm proposed by Sudan to find the polynomials of bounded degree agreeing on a dense fraction of a set of points in $\\mathbb{F}^{2}$ for some field $\\mathbb{F}$.", "venue": "ArXiv", "authors": ["Priyank  Deshpande"], "year": 2020, "n_citations": 0}
{"id": 2615767, "s2_id": "2cabf5b69cd5dd95dc4a1a0c207758450008be1a", "title": "A recombination algorithm for the decomposition of multivariate rational functions", "abstract": "In this paper we show how we can compute in a deterministic way the decomposition of a multivariate rational function with a recombination strategy. The key point of our recombination strategy is the used of Darboux polynomials. We study the complexity of this strategy and we show that this method improves the previous ones. In appendix, we explain how the strategy proposed recently by J. Berthomieu and G. Lecerf for the sparse factorization can be used in the decomposition setting. Then we deduce a decomposition algorithm in the sparse bivariate case and we give its complexity", "venue": "Math. Comput.", "authors": ["Guillaume  Ch\u00e8ze"], "year": 2013, "n_citations": 5}
{"id": 2622409, "s2_id": "529c583dfbafb081699df52fdffd7aae10cee561", "title": "Computing Canonical Bases of Modules of Univariate Relations", "abstract": "We study the computation of canonical bases of sets of univariate relations (p1,...,pm) \u2208 K[x]m such that p1 f1 + \u22ef + pm fm = 0; here, the input elements f1,...,fm are from a quotient K[x]n/M, where M is a K[x]-module of rank n given by a basis M \u2208 K[x]n x n in Hermite form. We exploit the triangular shape of M to generalize a divide-and-conquer approach which originates from fast minimal approximant basis algorithms. Besides recent techniques for this approach, we rely on high-order lifting to perform fast modular products of polynomial matrices of the form P F mod M. Our algorithm uses O~(m\u03c9-1D + n\u03c9 D/m) operations in K, where D = deg(det(M)) is the K-vector space dimension of K[x]n/M, O~(\u00b7) indicates that logarithmic factors are omitted, and \u03c9 is the exponent of matrix multiplication. This had previously only been achieved for a diagonal matrix M. Furthermore, our algorithm can be used to compute the shifted Popov form of a nonsingular matrix within the same cost bound, up to logarithmic factors, as the previously fastest known algorithm, which is randomized.", "venue": "ISSAC", "authors": ["Vincent  Neiger", "Thi Xuan Vu"], "year": 2017, "n_citations": 6}
{"id": 2623886, "s2_id": "e2947a05321c79c3e0e2e97ea5b065afc44814dd", "title": "On the Summability of Bivariate Rational Functions", "abstract": "We present criteria for deciding whether a bivariate rational function in two variables can be written as a sum of two (q-)dierences of bivariate rational functions. Using these criteria, we show how certain double sums can be evaluated, rst, in terms of single sums and, nally, in terms of values of special functions.", "venue": "ArXiv", "authors": ["Shaoshi  Chen", "Michael F. Singer"], "year": 2012, "n_citations": 9}
{"id": 2624467, "s2_id": "066287a7ffe73997e5b068c7e040d2f19fb0dc34", "title": "Intuitionistic Linear Temporal Logics", "abstract": "We consider intuitionistic variants of linear temporal logic with \u201cnext,\u201d \u201cuntil,\u201d and \u201crelease\u201d based on expanding posets: partial orders equipped with an order-preserving transition function. This class of structures gives rise to a logic that we denote ITLe, and by imposing additional constraints, we obtain the logics ITLp of persistent posets and ITLht of here-and-there temporal logic, both of which have been considered in the literature. We prove that ITLe has the effective finite model property and hence is decidable, while ITLp does not have the finite model property. We also introduce notions of bounded bisimulations for these logics and use them to show that the \u201cuntil\u201d and \u201crelease\u201d operators are not definable in terms of each other, even over the class of persistent posets.", "venue": "ACM Trans. Comput. Log.", "authors": ["Philippe  Balbiani", "Joseph  Boudou", "Mart'in  Di'eguez", "David  Fern'andez-Duque"], "year": 2020, "n_citations": 7}
{"id": 2627557, "s2_id": "07db8d9642938b35476e80075326eef7c4ce8118", "title": "Implementation of Motzkin-Burger algorithm in Maple", "abstract": "Subject of this paper is an implementation of a well-known Motzkin-Burger algorithm, which solves the problem of finding the full set of solutions of a system of linear homogeneous inequalities. There exist a number of implementations of this algorithm, but there was no one in Maple, to the best of the author's knowledge.", "venue": "ArXiv", "authors": ["P. A. Burovsky"], "year": 2005, "n_citations": 0}
{"id": 2628427, "s2_id": "6bcbfc188cedaa7472b098ee362424a177dee64d", "title": "Absolute root separation", "abstract": "The absolute separation of a polynomial is the minimum nonzero difference between the absolute values of its roots. In the case of polynomials with integer coefficients, it can be bounded from below in terms of the degree and the height (the maximum absolute value of the coefficients) of the polynomial. We improve the known bounds for this problem and related ones. Then we report on extensive experiments in low degrees, suggesting that the current bounds are still very pessimistic.", "venue": "ArXiv", "authors": ["Yann  Bugeaud", "Andrej  Dujella", "Wenjie  Fang", "Tomislav  Pejkovic", "Bruno  Salvy"], "year": 2019, "n_citations": 1}
{"id": 2630822, "s2_id": "5d5f658acc6865f5f05adf1082a5b5fd41357fa8", "title": "Visualization in teaching and learning mathematics in elementary, secondary and higher education", "abstract": "In this paper we present our experience in using visualization in mathematics education. The experience with our university courses: \"Computer tools in matematics\" and \"Symbolic algebra\" provides the basis for mathematics teacher education program this http URL The program is intended for elementary and high school teachers. The education program deals with modern techniques of visualization by using technologies such as GeoGegebra, JAVA and HTML.", "venue": "ArXiv", "authors": ["Branko  Malesevic", "Ivana  Jovovic", "Bojan  Banjac"], "year": 2015, "n_citations": 1}
{"id": 2632400, "s2_id": "e0402f61323920e0ce3d023df65dadd1a01d0198", "title": "Mathematical Theory Exploration in Theorema: Reduction Rings", "abstract": "In this paper we present the first-ever computer formalization of the theory of Gr\\\"obner bases in reduction rings, which is an important theory in computational commutative algebra, in Theorema. Not only the formalization, but also the formal verification of all results has already been fully completed by now; this, in particular, includes the generic implementation and correctness proof of Buchberger's algorithm in reduction rings. Thanks to the seamless integration of proving and computing in Theorema, this implementation can now be used to compute Gr\\\"obner bases in various different domains directly within the system. Moreover, a substantial part of our formalization is made up solely by \"elementary theories\" such as sets, numbers and tuples that are themselves independent of reduction rings and may therefore be used as the foundations of future theory explorations in Theorema. \nIn addition, we also report on two general-purpose Theorema tools we developed for an efficient and convenient exploration of mathematical theories: an interactive proving strategy and a \"theory analyzer\" that already proved extremely useful when creating large structured knowledge bases.", "venue": "CICM", "authors": ["Alexander  Maletzky"], "year": 2016, "n_citations": 2}
{"id": 2633658, "s2_id": "cde3ef3d08c00a99fb8cc037fdd9b785ffb16ab1", "title": "Computing elements of certain form in ideals to prove properties of operators", "abstract": "Proving statements about linear operators expressed in terms of identities often leads to finding elements of certain form in noncommutative polynomial ideals. We illustrate this by examples coming from actual operator statements and discuss relevant algorithmic methods for finding such polynomials based on noncommutative Gr\u00f6bner bases. In particular, we present algorithms for computing the intersection of a two-sided ideal with a one-sided ideal as well as for computing homogeneous polynomials in two-sided ideals and monomials in one-sided ideals. All methods presented in this work are implemented in the Mathematica package OperatorGB. Mathematics Subject Classification (2010). Primary 16Z10; Secondary 03B35.", "venue": "ArXiv", "authors": ["Clemens  Hofstadler", "Clemens G. Raab", "Georg  Regensburger"], "year": 2021, "n_citations": 0}
{"id": 2648398, "s2_id": "ea7c5f21e4dad5882612e3c68ead8eaff2551f04", "title": "Computing spectral sequences", "abstract": "John McCleary insisted in his interesting textbook entitled \u201cUser\u2019s guide to spectral sequences\u201d on the fact that the tool \u201cspectral sequence\u201d is not in the general situation an algorithm allowing its user to compute the looked-for homology groups. The present article explains how the notion of \u201cObject with Effective Homology\u201d on the contrary allows the user to recursively obtain all the components of the Serre and Eilenberg\u2010Moore spectral sequences, when the data are objects with effective homology. In particular the computability problem of the higher differentials is solved, the extension problem at abutment is also recursively solved. Furthermore, these methods have been concretely implemented as an extension of the Kenzo computer program. Two typical examples of spectral sequence computations are reported. c 2006 Elsevier Ltd. All rights reserved.", "venue": "J. Symb. Comput.", "authors": ["Ana  Romero", "Julio  Rubio", "Francis  Sergeraert"], "year": 2006, "n_citations": 40}
{"id": 2651454, "s2_id": "d3e3762858314e4e9fa9fe98814bfbf57bf9d25f", "title": "Computing Multi-Homogeneous Bezout Numbers is Hard", "abstract": "The multi-homogeneous B\u00e9zout number is a bound for the number of solutions of a system of multi-homogeneous polynomial equations. Estimating the number of isolated solutions of a polynomial system is useful for the design and analysis of homotopy algorithms and certain applications [2, 5]. An application of multi-homogeneous B\u00e9zout bounds outside the realm of algebraic equation solving is discussed in [3], where the number of roots is used to bound geometrical quantities such as volume and curvature. There is an important connection between rootcounting and NP-completeness theory. Indeed, it is easy to reduce an NP-complete or NP-hard problem such as SAT, the Traveling Salesman problem, Integer Programming (and thus all other NP problems as well) to the question whether certain polynomial systems have a common zero.", "venue": "ArXiv", "authors": ["Gregorio  Malajovich", "Klaus  Meer"], "year": 2004, "n_citations": 9}
{"id": 2652528, "s2_id": "597a55a5322fdc22121245563380cc9da9649987", "title": "Contraction of Ore Ideals with Applications", "abstract": "Ore operators form a common algebraic abstraction of linear ordinary differential and recurrence equations. Given an Ore operator L with polynomial coefficients in x, it generates a left ideal I in the Ore algebra over the field k(x) of rational functions. We present an algorithm for computing a basis of the contraction ideal of I in the Ore algebra over the ring R[x] of polynomials, where~$R$ may be either k or a domain with k as its fraction field. This algorithm is based on recent work on desingularization for Ore operators by Chen, Jaroschek, Kauers and Singer. Using a basis of the contraction ideal, we compute a completely desingularized operator for L whose leading coefficient not only has minimal degree in x but also has minimal content. Completely desingularized operators have interesting applications such as certifying integer sequences and checking special cases of a conjecture of Krattenthaler.", "venue": "ISSAC", "authors": ["Yi  Zhang"], "year": 2016, "n_citations": 8}
{"id": 2660963, "s2_id": "cff3e6cfe01005fe447e27b93f0b640fbf844bb2", "title": "Logcf: An Efficient Tool for Real Root Isolation", "abstract": "Computing upper bounds of the positive real roots of some polynomials is a key step of those real root isolation algorithms based on continued fraction expansion and Vincent's theorem. The authors give a new algorithm for computing an upper bound of positive roots in this paper. The complexity of the algorithm is O(n log(u+1)) additions and multiplications where u is the optimal upper bound satisfying Theorem 3.1 of this paper and n is the degree of the polynomial. The method together with some tricks have been implemented as a software package logcf using C language. Experiments on many benchmarks show that logcf is competitive with RootIntervals of Mathematica and the function realroot of Maple averagely and it is much faster than existing open source real root solvers in many test cases.", "venue": "J. Syst. Sci. Complex.", "authors": ["Liyun  Dai", "Bican  Xia"], "year": 2019, "n_citations": 0}
{"id": 2662393, "s2_id": "54d0a54c13da18fbbf3ab82eb4403a88db1372b7", "title": "When Causal Intervention Meets Adversarial Examples and Image Masking for Deep Neural Networks", "abstract": "Discovering and exploiting the causality in deep neural networks (DNNs) are crucial challenges for understanding and reasoning causal effects (CE) on an explainable visual model. \"Intervention\" has been widely used for recognizing a causal relation ontologically. In this paper, we propose a causal inference framework for visual reasoning via docalculus. To study the intervention effects on pixel-level features for causal reasoning, we introduce pixel-wise masking and adversarial perturbation. In our framework, CE is calculated using features in a latent space and perturbed prediction from a DNN-based model. We further provide a first look into the characteristics of discovered CE of adversarially perturbed images generated by gradient-based methods1. Experimental results show that CE is a competitive and robust index for understanding DNNs when compared with conventional methods such as class-activation mappings (CAMs) on the Chest X-Ray-14 dataset for human-interpretable feature(s) (e.g., symptom) reasoning. Moreover, CE holds promises for detecting adversarial examples as it possesses distinct characteristics in the presence of adversarial perturbations.", "venue": "2019 IEEE International Conference on Image Processing (ICIP)", "authors": ["Chao-Han Huck Yang", "Yi-Chieh  Liu", "Pin-Yu  Chen", "Xiaoli  Ma", "Yi-Chang James Tsai"], "year": 2019, "n_citations": 10}
{"id": 2665640, "s2_id": "4e18294a07be646100aa4565b2cbf28c9ac438a1", "title": "Polynomial Time Nondimensionalisation of Ordinary Differential Equations via their Lie Point Symmetries", "abstract": "Lie group theory states that knowledge of a~$m$-parameters solvable group of symmetries of a system of ordinary differential equations allows to reduce by~$m$ the number of equation. We apply this principle by finding dilatations and translations that are Lie point symmetries of considered ordinary differential system. By rewriting original problem in an invariant coordinates set for these symmetries, one can reduce the involved number of parameters. This process is classically call nondimensionalisation in dimensional analysis. We present an algorithm based on this standpoint and show that its arithmetic complexity is polynomial in input's size.", "venue": "ArXiv", "authors": ["Evelyne  Hubert", "Alexandre  Sedoglavic"], "year": 2006, "n_citations": 5}
{"id": 2670712, "s2_id": "edcb577f0a36d48ca709d5c4026419290f5e7ef9", "title": "Standard Lattices of Compatibly Embedded Finite Fields", "abstract": "Lattices of compatibly embedded finite fields are useful in computer algebra systems for managing many extensions of a finite field \\F_p at once. They can also be used to represent the algebraic closure \\bar\\F_p, and to represent all finite fields in a standard manner. The most well known constructions are Conway polynomials, and the Bosma--Cannon--Steel framework used in Magma. In this work, leveraging the theory of the Lenstra-Allombert isomorphism algorithm, we generalize both at the same time. Compared to Conway polynomials, our construction defines a much larger set of field extensions from a small pre-computed table; however it is provably as inefficient as Conway polynomials if one wants to represent all field extensions, and thus yields no asymptotic improvement for representing \\bar\\F_p. Compared to Bosma--Cannon--Steel lattices, it is considerably more efficient both in computation time and storage: all algorithms have at worst quadratic complexity, and storage is linear in the number of represented field extensions and their degrees. Our implementation written in C/Flint/Julia/Nemo shows that our construction in indeed practical.", "venue": "ISSAC", "authors": ["Luca De Feo", "Hugues  Randriam", "\u00c9douard  Rousseau"], "year": 2019, "n_citations": 2}
{"id": 2671666, "s2_id": "6e145dcfa0f55ddb5e211f92725bc553cf610cf4", "title": "Computing rational points in convex semi-algebraic sets and SOS decompositions", "abstract": "Let ${\\cal P}=\\{h_1, ..., h_s\\}\\subset \\Z[Y_1, ..., Y_k]$, $D\\geq \\deg(h_i)$ for $1\\leq i \\leq s$, $\\sigma$ bounding the bit length of the coefficients of the $h_i$'s, and $\\Phi$ be a quantifier-free ${\\cal P}$-formula defining a convex semi-algebraic set. We design an algorithm returning a rational point in ${\\cal S}$ if and only if ${\\cal S}\\cap \\Q\\neq\\emptyset$. It requires $\\sigma^{\\bigO(1)}D^{\\bigO(k^3)}$ bit operations. If a rational point is outputted its coordinates have bit length dominated by $\\sigma D^{\\bigO(k^3)}$. Using this result, we obtain a procedure deciding if a polynomial $f\\in \\Z[X_1, >..., X_n]$ is a sum of squares of polynomials in $\\Q[X_1, ..., X_n]$. Denote by $d$ the degree of $f$, $\\tau$ the maximum bit length of the coefficients in $f$, $D={{n+d}\\choose{n}}$ and $k\\leq D(D+1)-{{n+2d}\\choose{n}}$. This procedure requires $\\tau^{\\bigO(1)}D^{\\bigO(k^3)}$ bit operations and the coefficients of the outputted polynomials have bit length dominated by $\\tau D^{\\bigO(k^3)}$.", "venue": "ArXiv", "authors": ["Mohab Safey El Din", "Lihong  Zhi"], "year": 2009, "n_citations": 5}
{"id": 2678974, "s2_id": "595c1f3e364a9dc12a31b6c355efea52f02c1ec5", "title": "SymbolicGPT: A Generative Transformer Model for Symbolic Regression", "abstract": "Symbolic regression is the task of identifying a mathematical expression that best fits a provided dataset of input and output values. Due to the richness of the space of mathematical expressions, symbolic regression is generally a challenging problem. While conventional approaches based on genetic evolution algorithms have been used for decades, deep learning-based methods are relatively new and an active research area. In this work, we present SymbolicGPT, a novel transformer-based language model for symbolic regression3. This model exploits the advantages of probabilistic language models like GPT, including strength in performance and flexibility. Through comprehensive experiments, we show that our model performs strongly compared to competing models with respect to the accuracy, running time, and data efficiency.", "venue": "ArXiv", "authors": ["Mojtaba  Valipour", "Bowen  You", "Maysum  Panju", "Ali  Ghodsi"], "year": 2021, "n_citations": 1}
{"id": 2681707, "s2_id": "ecb8546ac50d36d656cd8348ede8647986e01edd", "title": "Conormal Spaces and Whitney Stratifications", "abstract": "We describe a new algorithm for computing Whitney stratifications of complex projective varieties. The main ingredients are (a) an algebraic criterion, due to L\u00ea and Teissier, which reformulates Whitney regularity in terms of conormal spaces and maps, and (b) a new interpretation of this conormal criterion via ideal saturations, which can be practically implemented on a computer. We show that this algorithm improves upon the existing state of the art by several orders of magnitude, even for relatively small input varieties. En route, we introduce related algorithms for efficiently stratifying affine varieties, flags on a given variety, and algebraic maps.", "venue": "ArXiv", "authors": ["Martin  Helmer", "Vidit  Nanda"], "year": 2021, "n_citations": 0}
{"id": 2682954, "s2_id": "e22ecee9404011ee333e2fb259121d6bf937f9e1", "title": "Improvement on Extrapolation of Species Abundance Distribution Across Scales from Moments Across Scales", "abstract": "Raw moments are used as a way to estimate species abundance distribution. The almost linear pattern of the log transformation of raw moments across scales allow us to extrapolate species abundance distribution for larger areas. However, results may produce errors. Some of these errors are due to computational complexity, fittings of patterns, binning methods, and so on. We provide some methods to reduce some of the errors. The main result is introducing new techniques for evaluating a more accurate species abundance distributions across scales through moments across scales.", "venue": "ArXiv", "authors": ["Saeid  Alirezazadeh", "Khadijeh  Alibabaei"], "year": 2020, "n_citations": 0}
{"id": 2683088, "s2_id": "bcfcb43d56a1466bbfb4ce1fc380323678404fef", "title": "Creative Telescoping for Holonomic Functions", "abstract": "The aim of this article is twofold: on the one hand it is intended to serve as a gentle introduction to the topic of creative telescoping, from a practical point of view; for this purpose its application to several problems is exemplified. On the other hand, this chapter has the flavour of a survey article: the developments in this area during the last two decades are sketched and a selection of references is compiled in order to highlight the impact of creative telescoping in numerous contexts.", "venue": "ArXiv", "authors": ["Christoph  Koutschan"], "year": 2013, "n_citations": 43}
{"id": 2690206, "s2_id": "d5f38da1cb3c849a95116b2d81e57bd6b201201c", "title": "Computing the multilinear factors of lacunary polynomials without heights", "abstract": "We present a deterministic polynomial-time algorithm which computes the multilinear factors of multivariate lacunary polynomials over number fields. It is based on a new Gap theorem which allows to test whether $P(X)=\\sum_{j=1}^k a_j X^{\\alpha_j}(vX+t)^{\\beta_j}(uX+w)^{\\gamma_j}$ is identically zero in polynomial time. Previous algorithms for this task were based on Gap Theorems expressed in terms of the height of the coefficients. Our Gap Theorem is based on the valuation of the polynomial and is valid for any field of characteristic zero. As a consequence we obtain a faster and more elementary algorithm. Furthermore, we can partially extend the algorithm to other situations, such as absolute and approximate factorizations. \nWe also give a version of our Gap Theorem valid for fields of large characteristic, and deduce a randomized polynomial-time algorithm to compute multilinear factors with at least three monomials of multivariate lacunary polynomials of finite fields of large characteristic. We provide $\\mathsf{NP}$-hardness results to explain our inability to compute binomial factors.", "venue": "J. Symb. Comput.", "authors": ["Arkadev  Chattopadhyay", "Bruno  Grenet", "Pascal  Koiran", "Natacha  Portier", "Yann  Strozecki"], "year": 2021, "n_citations": 1}
{"id": 2696085, "s2_id": "50f17031b5554df317705dc389f52d6aff85a53f", "title": "One-Step Stochastic Processes Simulation Software Package", "abstract": "Background. It is assumed that the introduction of stochastic in mathematical model makes it more adequate. But there is virtually no methods of coordinated (depended on structure of the system) stochastic introduction into deterministic models. Authors have improved the method of stochastic models construction for the class of one-step processes and illustrated by models of population dynamics. Population dynamics was chosen for study because its deterministic models were sufficiently well explored that allows to compare the results with already known ones. \nPurpose. To optimize the models creation as much as possible some routine operations should be automated. In this case, the process of drawing up the model equations can be algorithmized and implemented in the computer algebra system. Furthermore, on the basis of these results a set of programs for numerical experiment can be obtained. \nMethod. The computer algebra system Axiom is used for analytical calculations implementation. To perform the numerical experiment FORTRAN and Julia languages are used. The method Runge--Kutta method for stochastic differential equations is used as numerical method. \nResults. The program compex for creating stochastic one-step processes models is constructed. Its application is illustrated by the predator-prey population dynamic system. \nConclusions. Computer algebra systems are very convenient for the purposes of rapid prototyping in mathematical models design and analysis.", "venue": "ArXiv", "authors": ["Ekaterina G. Eferina", "Anna V. Korolkova", "M. N. Gevorkyan", "Dmitry S. Kulyabov", "Leonid A. Sevastyanov"], "year": 2015, "n_citations": 9}
{"id": 2696360, "s2_id": "4c56d97b2f9a1a1adb059b0d183026efbaf9a7b2", "title": "On the Efficiency of Solving Boolean Polynomial Systems with the Characteristic Set Method", "abstract": "Abstract An improved characteristic set algorithm for solving Boolean polynomial systems is proposed. This algorithm is based on the idea of converting all the polynomials into monic ones by zero decomposition, and using additions to obtain pseudo-remainders. Three important techniques are applied in the algorithm. The first one is eliminating variables by new generated linear polynomials. The second one is optimizing the strategy of choosing polynomial for zero decomposition. The third one is to compute add-remainders to eliminate the leading variable of new generated monic polynomials. By analyzing the depth of the zero decomposition tree, we present some complexity bounds of this algorithm, which are lower than the complexity bounds of previous characteristic set algorithms. Extensive experimental results show that this new algorithm is more efficient than previous characteristic set algorithms for solving Boolean polynomial systems.", "venue": "J. Symb. Comput.", "authors": ["ZhenYu  Huang", "Yao  Sun", "Dongdai  Lin"], "year": 2021, "n_citations": 4}
{"id": 2707038, "s2_id": "2c8c24291d510aabebc2423c57cb0d837643efa1", "title": "Graphical reasoning in compact closed categories for quantum computation", "abstract": "Compact closed categories provide a foundational formalism for a variety of important domains, including quantum computation. These categories have a natural visualisation as a form of graphs. We present a formalism for equational reasoning about such graphs and develop this into a generic proof system with a fixed logical kernel for reasoning about compact closed categories. A salient feature of our system is that it provides a formal and declarative account of derived results that can include \u2018ellipses\u2019-style notation. We illustrate the framework by instantiating it for a graphical language of quantum computation and show how this can be used to perform symbolic computation.", "venue": "Annals of Mathematics and Artificial Intelligence", "authors": ["Lucas  Dixon", "Ross  Duncan"], "year": 2009, "n_citations": 43}
{"id": 2712428, "s2_id": "82f1bf8fd0f8bd7b934b07b857709009c5417841", "title": "A Maude Implementation of Rewritable Petri Nets: a Feasible Model for Dynamically Reconfigurable Systems", "abstract": "Petri Nets (PN) are a central, theoretically sound model for concurrent or distributed systems but, at least in their classical definition, not expressive enough to represent dynamic reconfiguration capabilities. On the other side, Rewriting Logic has proved to be a natural semantic framework for several formal models of concurrent/distributed systems. We propose a compact, efficient Maude formalization of dynamically reconfigurable PT nets (with inhibitor arcs), using as a running example the specification of a simple, fault-tolerant manufacturing system. We discuss the advantages of such a combined approach, as well as some concerns that it raises.", "venue": "AppFM@FM", "authors": ["Lorenzo  Capra"], "year": 2021, "n_citations": 1}
{"id": 2715293, "s2_id": "eb40642ddde533565ed7f3d74105fb44d0d327bd", "title": "A Proof of a Recursion for Bessel Moments", "abstract": "We provide a proof of a conjecture in [2] on the existence and form of linear recursions for moments of powers of the Bessel function K0.", "venue": "ArXiv", "authors": ["Jonathan M. Borwein", "Bruno  Salvy"], "year": 2007, "n_citations": 26}
{"id": 2718739, "s2_id": "2737c588537f6ef358bd5de243ef35dc578c64f1", "title": "Evaluation of Chebyshev polynomials on intervals and application to root finding", "abstract": "In approximation theory, it is standard to approximate functions by polynomials expressed in the Chebyshev basis. Evaluating a polynomial f of degree n given in the Chebyshev basis can be done in O(n) arithmetic operations using the Clenshaw algorithm. Unfortunately, the evaluation of f on an interval I using the Clenshaw algorithm with interval arithmetic returns an interval of width exponential in n. We describe a variant of the Clenshaw algorithm based on ball arithmetic that returns an interval of width quadratic in n for an interval of small enough width. As an application, our variant of the Clenshaw algorithm can be used to design an efficient root finding algorithm .", "venue": "MACIS", "authors": ["Viviane  Ledoux", "Guillaume  Moroz"], "year": 2019, "n_citations": 0}
{"id": 2721772, "s2_id": "bb59d46b14135d34730efd12a0f4656de522630a", "title": "Efficient sparse polynomial factoring using the Funnel heap", "abstract": "This work is a comprehensive extension of Abu-Salem et al. (2015) that investigates the prowess of the Funnel Heap for implementing sums of products in the polytope method for factoring polynomials, when the polynomials are in sparse distributed representation. We exploit that the work and cache complexity of an Insert operation using Funnel Heap can be refined to de- pend on the rank of the inserted monomial product, where rank corresponds to its lifetime in Funnel Heap. By optimising on the pattern by which insertions and extractions occur during the Hensel lifting phase of the polytope method, we are able to obtain an adaptive Funnel Heap that minimises all of the work, cache, and space complexity of this phase. Additionally, we conduct a detailed empirical study confirming the superiority of Funnel Heap over the generic Binary Heap once swaps to external memory begin to take place. We demonstrate that Funnel Heap is a more efficient merger than the cache oblivious k-merger, which fails to achieve its optimal (and amortised) cache complexity when used for performing sums of products. This provides an empirical proof of concept that the overlapping approach for perform- ing sums of products using one global Funnel Heap is more suited than the serialised approach, even when the latter uses the best merging structures available.", "venue": "ArXiv", "authors": ["Fatima K. Abu Salem", "Khalil  El-Harake", "Karl  Gemayel"], "year": 2016, "n_citations": 1}
{"id": 2722526, "s2_id": "9bfaafb89f69e0f416592a2c25e351c678da63ce", "title": "Applying Genetic Programming to Improve Interpretability in Machine Learning Models", "abstract": "Explainable Artificial Intelligence (or xAI) has become an important research topic in the fields of Machine Learning and Deep Learning. In this paper, we propose a Genetic Programming (GP) based approach, name Genetic Programming Explainer (GPX), to the problem of explaining decisions computed by AI systems. The method generates a noise set located in the neighborhood of the point of interest, whose prediction should be explained, and fits a local explanation model for the analyzed sample. The tree structure generated by GPX provides a comprehensible analytical, possibly non-linear, expression which reflects the local behavior of the complex model. We considered three machine learning techniques that can be recognized as complex black-box models: Random Forest, Deep Neural Network and Support Vector Machine in twenty data sets for regression and classifications problems. Our results indicate that the GPX is able to produce more accurate understanding of complex models than the state of the art. The results validate the proposed approach as a novel way to deploy GP to improve interpretability.", "venue": "2020 IEEE Congress on Evolutionary Computation (CEC)", "authors": ["Leonardo Augusto Ferreira", "Frederico Gadelha Guimaraes", "Rodrigo  Silva"], "year": 2020, "n_citations": 3}
{"id": 2731748, "s2_id": "2e90b7d15e5c4b2d015e5bdc51baf06b2415d9ab", "title": "Symmetric subresultants and applications", "abstract": "Schur's transforms of a polynomial are used to count its roots in the unit disk. These are generalized then by introducing the sequence of symmetric subresultants of two polynomials. Although they do have a determinantal definition, we show that they satisfy a structure theorem which allows us to compute them with a type of Euclidean division. As a consequence, a fast algorithm based on a dichotomic process and FFT is designed. We prove also that these symmetric subresultants have a deep link with Toeplitz matrices. Finally, we propose a new algorithm of inversion for such matrices. It has the same cost as those already known; however it is fraction free and consequently well adapted to computer algebra.", "venue": "J. Symb. Comput.", "authors": ["Philippe Saux Picart", "Cyril  Brunie"], "year": 2007, "n_citations": 5}
{"id": 2733909, "s2_id": "04f6b9dbd687519e4e1eeff33bee57fde367da2d", "title": "Faster One Block Quantifier Elimination for Regular Polynomial Systems of Equations", "abstract": "Quantifier elimination over the reals is a central problem in computational real algebraic geometry, polynomial system solving and symbolic computation. Given a semi-algebraic formula (whose atoms are polynomial constraints) with quantifiers on some variables, it consists in computing a logically equivalent formula involving only unquantified variables. When there is no alternation of quantifiers, one has a one block quantifier elimination problem. This paper studies a variant of the one block quantifier elimination in which we compute an almost equivalent formula of the input. We design a new probabilistic efficient algorithm for solving this variant when the input is a system of polynomial equations satisfying some regularity assumptions. When the input is generic, involves s polynomials of degree bounded by D with n quantified variables and t unquantified ones, we prove that this algorithm outputs semi-algebraic formulas of degree bounded by D using O((n-s+1) 8t D 3t+2(t+D t) arithmetic operations in the ground field where D = 2(n+s) Ds(D-1)n-s+1(ns. In practice, it allows us to solve quantifier elimination problems which are out of reach of the state-of-the-art(up to 8 variables).", "venue": "ISSAC", "authors": ["Huu Phuoc Le", "Mohab Safey El Din"], "year": 2021, "n_citations": 0}
{"id": 2735679, "s2_id": "96f1cde2008354995c0b211744b136b484ee74de", "title": "Symbolic Derivation of Mean-Field PDEs from Lattice-Based Models", "abstract": "Transportation processes, which play a prominent role in the life and social sciences, are typically described by discrete models on lattices. For studying their dynamics a continuous formulation of the problem via partial differential equations (PDE) is employed. In this paper we propose a symbolic computation approach to derive mean-field PDEs from a lattice-based model. We start with the microscopic equations, which state the probability to find a particle at a given lattice site. Then the PDEs are formally derived by Taylor expansions of the probability densities and by passing to an appropriate limit as the time steps and the distances between lattice sites tend to zero. We present an implementation in a computer algebra system that performs this transition for a general class of models. In order to rewrite the mean-field PDEs in a conservative formulation, we adapt and implement symbolic integration methods that can handle unspecified functions in several variables. To illustrate our approach, we consider an application in crowd motion analysis where the dynamics of bidirectional flows are studied. However, the presented approach can be applied to various transportation processes of multiple species with variable size in any dimension, for example, to confirm several proposed mean-field models for cell motility.", "venue": "2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)", "authors": ["Christoph  Koutschan", "Helene  Ranetbauer", "Georg  Regensburger", "Marie-Therese  Wolfram"], "year": 2015, "n_citations": 4}
{"id": 2737278, "s2_id": "e4dff54ac8b17c7099e4252cb2218261080ac111", "title": "High-performance symbolic-numerics via multiple dispatch", "abstract": "As mathematical computing becomes more democratized in high-level languages, high-performance symbolic-numeric systems are necessary for domain scientists and engineers to get the best performance out of their machine without deep knowledge of code optimization. Naturally, users need different term types either to have different algebraic properties for them, or to use efficient data structures. To this end, we developed Symbolics.jl, an extendable symbolic system which uses dynamic multiple dispatch to change behavior depending on the domain needs. In this work we detail an underlying abstract term interface which allows for speed without sacrificing generality. We show that by formalizing a generic API on actions independent of implementation, we can retroactively add optimized data structures to our system without changing the pre-existing term rewriters. We showcase how this can be used to optimize term construction and give a 113x acceleration on general symbolic transformations. Further, we show that such a generic API allows for complementary term-rewriting implementations. Exploiting this feature, we demonstrate the ability to swap between classical term-rewriting simplifiers and e-graphbased term-rewriting simplifiers. We illustrate how this symbolic system improves numerical computing tasks by showcasing an e-graph ruleset which minimizes the number of CPU cycles during expression evaluation, and demonstrate how it simplifies a real-world reaction-network simulation to halve the runtime. Additionally, we show a reaction-diffusion partial differential equation solver which is able to be automatically converted into symbolic expressions via multiple dispatch tracing, which is subsequently accelerated and parallelized to give a 157x simulation speedup. Together, this presents Symbolics.jl as a next-generation symbolic-numeric computing environment geared towards modeling and simulation.", "venue": "ArXiv", "authors": ["Shashi  Gowda", "Yingbo  Ma", "Alessandro  Cheli", "Maja  Gw\u00f3zdz", "Viral B. Shah", "Alan  Edelman", "Christopher  Rackauckas"], "year": 2021, "n_citations": 5}
{"id": 2741451, "s2_id": "74b6191527b49620090d0af585ca8b6b0d6326a0", "title": "An algorithm to determine regular singular Mahler systems", "abstract": "Abstract. This paper is devoted to the study of the analytic properties of Mahler systems at 0. We give an effective characterisation of Mahler systems that are regular singular at 0, that is, systems which are equivalent to constant ones. Similar characterisations already exist for differential and (q-)difference systems but they do not apply in the Mahler case. This work fill in the gap by giving an algorithm which decides whether or not a Mahler system is regular singular at 0.", "venue": "ArXiv", "authors": ["Colin  Faverjon", "Marina  Poulet"], "year": 2021, "n_citations": 0}
{"id": 2741820, "s2_id": "d3befb8be52e8168f8d9f121726bc0c14a5ee105", "title": "Algorithms yield upper bounds in differential algebra", "abstract": "Consider an algorithm computing in a differential field with several commuting derivations such that the only operations it performs with the elements of the field are arithmetic operations, differentiation, and zero testing. We show that, if the algorithm is guaranteed to terminate on every input, then there is a computable upper bound for the size of the output of the algorithm in terms of the input. We also generalize this to algorithms working with models of good enough theories (including for example, difference fields). \nWe then apply this to differential algebraic geometry to show that there exists a computable uniform upper bound for the number of components of any variety defined by a system of polynomial PDEs. We then use this bound to show the existence of a computable uniform upper bound for the elimination problem in systems of polynomial PDEs with delays.", "venue": "Canadian Journal of Mathematics", "authors": ["Wei  Li", "Alexey  Ovchinnikov", "Gleb  Pogudin", "Thomas  Scanlon"], "year": 2021, "n_citations": 2}
{"id": 2744768, "s2_id": "3397b09d54b0c31072d0a17e8dbfa4b1a62a22a4", "title": "Sensitivity analysis in differentially private machine learning using hybrid automatic differentiation", "abstract": "In recent years, formal methods of privacy protection such as differential privacy (DP), capable of deployment to data-driven tasks such as machine learning (ML), have emerged. Reconciling large-scale ML with the closed-form reasoning required for the principled analysis of individual privacy loss requires the introduction of new tools for automatic sensitivity analysis and for tracking an individual\u2019s data and their features through the flow of computation. For this purpose, we introduce a novel hybrid automatic differentiation (AD) system which combines the efficiency of reverse-mode AD with an ability to obtain a closed-form expression for any given quantity in the computational graph. This enables modelling the sensitivity of arbitrary differentiable function compositions, such as the training of neural networks on private data. We demonstrate our approach by analysing the individual DP guarantees of statistical database queries. Moreover, we investigate the application of our technique to the training of DP neural networks. Our approach can enable the principled reasoning about privacy loss in the setting of data processing, and further the development of automatic sensitivity analysis and privacy budgeting systems.", "venue": "ArXiv", "authors": ["Alexander  Ziller", "Dmitrii  Usynin", "Moritz  Knolle", "Kritika  Prakash", "Andrew  Trask", "Rickmer  Braren", "Marcus  Makowski", "Daniel  Rueckert", "Georgios  Kaissis"], "year": 2021, "n_citations": 2}
{"id": 2751714, "s2_id": "80568bb8ae5bdf396c94d35e763d851be7ca78de", "title": "The F5 algorithm in Buchberger\u2019s style", "abstract": "The famous F5 algorithm for computing Gr\u00f6bner basis was presented by Faug\u00e8re in 2002. The original version of F5 is given in programming codes, so it is a bit difficult to understand. In this paper, the F5 algorithm is simplified as F5B in a Buchberger\u2019s style such that it is easy to understand and implement. In order to describe F5B, we introduce F5-reduction, which keeps the signature of labeled polynomials unchanged after reduction. The equivalence between F5 and F5B is also shown. At last, some versions of the F5 algorithm are illustrated.", "venue": "J. Syst. Sci. Complex.", "authors": ["Yao  Sun", "Dingkang  Wang"], "year": 2011, "n_citations": 30}
{"id": 2751880, "s2_id": "df8fb1264d01cbc865aae51ca1f3755514462c38", "title": "Computing the Chow Variety of Quadratic Space Curves", "abstract": "Quadrics in the Grassmannian of lines in 3-space form a 19-dimensional projective space. We study the subvariety of coisotropic hypersurfaces. Following Gel'fand, Kapranov and Zelevinsky, it decomposes into Chow forms of plane conics, Chow forms of pairs of lines, and Hurwitz forms of quadric surfaces. We compute the ideals of these loci.", "venue": "MACIS", "authors": ["Peter  B\u00fcrgisser", "Kathl\u00e9n  Kohn", "Pierre  Lairez", "Bernd  Sturmfels"], "year": 2015, "n_citations": 4}
{"id": 2752557, "s2_id": "0af65299f5a0fe2f7bcbf56d4fe84d01216af93c", "title": "A Note on the Group-theoretic Approach to Fast Matrix Multiplication", "abstract": "In 2003 COHN and UMANS introduced a group-theoretic approach to fast matrix multiplication. This involves finding large subsets S, T and U of a group G satisfying the Triple Product Property (TPP) as a means to bound the exponent $\\omega$ of the matrix multiplication. We show that S, T and U may be be assumed to contain the identity and be otherwise disjoint. We also give a much shorter proof of the upper bound |S|+|T|+|U| <= |G|+2.", "venue": "ArXiv", "authors": ["Ivo  Hedtke"], "year": 2011, "n_citations": 2}
{"id": 2754316, "s2_id": "33ecec40661d9568ca302ca4474ca82f35b4aa64", "title": "On the Equivalence of Forward Mode Automatic Differentiation and Symbolic Differentiation", "abstract": "We show that forward mode automatic differentiation and symbolic differentiation are equivalent in the sense that they both perform the same operations when computing derivatives. This is in stark contrast to the common claim that they are substantially different. The difference is often illustrated by claiming that symbolic differentiation suffers from \"expression swell\" whereas automatic differentiation does not. Here, we show that this statement is not true. \"Expression swell\" refers to the phenomenon of a much larger representation of the derivative as opposed to the representation of the original function.", "venue": "ArXiv", "authors": ["S\u00f6ren  Laue"], "year": 2019, "n_citations": 4}
{"id": 2755170, "s2_id": "293287c769daf25f8da657beacee1fe4c4bc8a7f", "title": "On Drinfel'd associators", "abstract": "In 1986, in order to study the linear representations of the braid group $B_n$ \ncoming from the monodromy of the Knizhnik-Zamolodchikov differential equations, \nDrinfel'd introduced a class of formal power series $\\Phi$ \non noncommutative variables. These formal series can be considered as a class of associators. \nWe here give an interpretation of them as well as some new tools over Noncommutative Evolution \nEquations. Asymptotic phenomena are also discussed.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Ngoc  Minh", "Karol A. Penson"], "year": 2017, "n_citations": 1}
{"id": 2757229, "s2_id": "089539093a2bd96b5ed38baf910fd42a76c1e4b0", "title": "An Efficient Multiplication Algorithm Using Nikhilam Method", "abstract": "Multiplication is one of the most important operation in computer arithmetic. Many integer operations such as squaring, division and computing reciprocal require same order of time as multiplication whereas some other operations such as computing GCD and residue operation require at most a factor of log n time more than multiplication. We propose an integer multiplication algorithm using Nikhilam method of Vedic mathematics which can be used to multiply two binary numbers efficiently.", "venue": "ARTCom 2013", "authors": ["Shri Prakash Dwivedi"], "year": 2013, "n_citations": 17}
{"id": 2762832, "s2_id": "3d5166975fc7618e3f05df54fddbf6bf45234d30", "title": "An Algorithm for the Factorization of Split Quaternion Polynomials", "abstract": "We present an algorithm to compute all factorizations into linear factors of univariate polynomials over the split quaternions, provided such a factorization exists. Failure of the algorithm is equivalent to non-factorizability for which we present also geometric interpretations in terms of rulings on the quadric of non-invertible split quaternions. However, suitable real polynomial multiples of split quaternion polynomials can still be factorized and we describe how to find these real polynomials. Split quaternion polynomials describe rational motions in the hyperbolic plane. Factorization with linear factors corresponds to the decomposition of the rational motion into hyperbolic rotations. Since multiplication with a real polynomial does not change the motion, this decomposition is always possible. Some of our ideas can be transferred to the factorization theory of motion polynomials. These are polynomials over the dual quaternions with real norm polynomial and they describe rational motions in Euclidean kinematics. We transfer techniques developed for split quaternions to compute new factorizations of certain dual quaternion polynomials.", "venue": "Advances in applied Clifford algebras", "authors": ["Daniel F. Scharler", "Hans-Peter  Schr\u00f6cker"], "year": 2021, "n_citations": 0}
{"id": 2772625, "s2_id": "0b350ce81a904edaabaad70f050ac9e63711656b", "title": "Consistency and Completeness of Rewriting in the Calculus of Constructions", "abstract": "Adding rewriting to a proof assistant based on the Curry-Howard isomorphism,\nsuch as Coq, may greatly improve usability of the tool. Unfortunately adding an\narbitrary set of rewrite rules may render the underlying formal system\nundecidable and inconsistent. While ways to ensure termination and confluence,\nand hence decidability of type-checking, have already been studied to some\nextent, logical consistency has got little attention so far. In this paper we\nshow that consistency is a consequence of canonicity, which in turn follows\nfrom the assumption that all functions defined by rewrite rules are complete.\nWe provide a sound and terminating, but necessarily incomplete algorithm to\nverify this property. The algorithm accepts all definitions that follow\ndependent pattern matching schemes presented by Coquand and studied by McBride\nin his PhD thesis. It also accepts many definitions by rewriting, containing\nrules which depart from standard pattern matching.", "venue": "Log. Methods Comput. Sci.", "authors": ["Daria  Walukiewicz-Chrzaszcz", "Jacek  Chrzaszcz"], "year": 2008, "n_citations": 7}
{"id": 2777928, "s2_id": "64782d608c6cfd508dd04531cc0ccada5fa8f951", "title": "Generators of algebraic curvature tensors based on a (2,1)-symmetry", "abstract": "We consider generators of algebraic curvature tensors R which can be constructed by a Young symmetrization of product tensors U*w or w*U, where U and w are covariant tensors of order 3 and 1. We assume that U belongs to a class of the infinite set S of irreducible symmetry classes characterized by the partition (2,1). We show that the set S contains exactly one symmetry class S_0 whose elements U can not play the role of generators of tensors R. The tensors U of all other symmetry classes from S\\{S_0} can be used as generators for tensors R. Using Computer Algebra we search for such generators whose coordinate representations are polynomials with a minimal number of summands. For a generic choice of the symmetry class of U we obtain lengths of 8 summands. In special cases these numbers can be reduced to the minimum 4. If this minimum occurs then U admits an index commutation symmetry. Furthermore minimal lengths are possible if U is formed from torsion-free covariant derivatives of alternating 2-tensor fields. We apply ideals and idempotents of group rings C[S_r] of symmetric groups S_r, Young symmetrizers, discrete Fourier transforms and Littlewood-Richardson products. For symbolic calculations we used the Mathematica packages Ricci and PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2004, "n_citations": 2}
{"id": 2780643, "s2_id": "7b9f737a976a66659326f419dc9437c44082bc06", "title": "Computing the Hermite Form of a Matrix of Ore Polynomials", "abstract": "Let R=F[D;sigma,delta] be the ring of Ore polynomials over a field (or skew field) F, where sigma is a automorphism of F and delta is a sigma-derivation. Given a an m by n matrix A over R, we show how to compute the Hermite form H of A and a unimodular matrix U such that UA=H. The algorithm requires a polynomial number of operations in F in terms of both the dimensions m and n, and the degree of the entries in A. When F=k(z) for some field k, it also requires time polynomial in the degree in z, and if k is the rational numbers Q, it requires time polynomial in the bit length of the coefficients as well. Explicit analyses are provided for the complexity, in particular for the important cases of differential and shift polynomials over Q(z). To accomplish our algorithm, we apply the Dieudonne determinant and quasideterminant theory for Ore polynomial rings to get explicit bounds on the degrees and sizes of entries in H and U.", "venue": "ArXiv", "authors": ["Mark  Giesbrecht", "Myung Sub Kim"], "year": 2011, "n_citations": 23}
{"id": 2788124, "s2_id": "9beffaa30e5b4f2893c34f4542ff7893b9686854", "title": "Computing all identifiable functions of parameters for ODE models", "abstract": "Parameter identifiability is a structural property of an ODE model for recovering the values of parameters from the data (i.e., from the input and output variables). This property is a prerequisite for meaningful parameter identification in practice. In the presence of nonidentifiability, it is important to find all functions of the parameters that are identifiable. The existing algorithms check whether a given function of parameters is identifiable or, under the solvability condition, find all identifiable functions. However, this solvability condition is not always satisfied, which presents a challenge. Our first main result is an algorithm that computes all identifiable functions without any additional assumptions, which is the first such algorithm as far as we know. Our second main result concerns the identifiability from multiple experiments (with generically different inputs and initial conditions among the experiments). For this problem, we prove that the set of functions identifiable from multiple experiments is what would actually be computed by input-output equation-based algorithms (whether or not the solvability condition is fulfilled), which was not known before. We give an algorithm that not only finds these functions but also provides an upper bound for the number of experiments to be performed to identify these functions. We provide an implementation of the presented algorithms.", "venue": "Syst. Control. Lett.", "authors": ["Alexey  Ovchinnikov", "Anand  Pillay", "Gleb  Pogudin", "Thomas  Scanlon"], "year": 2021, "n_citations": 2}
{"id": 2794061, "s2_id": "579b2b13d278b968ac5a288f82d1556a00b4c4f2", "title": "Integration in terms of polylogarithm", "abstract": "This paper provides a Liouville principle for integration in terms of dilogarithm and partial result for polylogarithm.", "venue": "ArXiv", "authors": ["Waldemar  Hebisch"], "year": 2018, "n_citations": 1}
{"id": 2797716, "s2_id": "dc4ced5e9b66541e2b6ff757c58f9c769141239b", "title": "Algorithmic applications of the corestriction of central simple algebras", "abstract": "Let $L$ be a separable quadratic extension of either $\\mathbb{Q}$ or $\\mathbb{F}_q(t)$. We propose efficient algorithms for finding isomorphisms between quaternion algebras over $L$. Our techniques are based on computing maximal one-sided ideals of the corestriction of a central simple $L$-algebra. In order to obtain efficient algorithms in the characteristic 2 case, we propose an algorithm for finding nontrivial zeros of a regular quadratic form in four variables over $\\mathbb{F}_{2^k}(t)$", "venue": "ArXiv", "authors": ["T'imea  Csah'ok", "P'eter  Kutas", "Gergely  Z'abr'adi"], "year": 2020, "n_citations": 0}
{"id": 2804368, "s2_id": "a3f125b87d16592e5e217ba05b8567e7ce680753", "title": "A Constructive Semantic Characterization of Aggregates in ASP", "abstract": "This technical note describes a monotone and continuous fixpoint operator to compute the answer sets of programs with aggregates. The fixpoint operator relies on the notion of aggregate solution. Under certain conditions, this operator behaves identically to the three-valued immediate consequence operator $\\Phi^{aggr}_P$ for aggregate programs, independently proposed Pelov et al. This operator allows us to closely tie the computational complexity of the answer set checking and answer sets existence problems to the cost of checking a solution of the aggregates in the program. Finally, we relate the semantics described by the operator to other proposals for logic programming with aggregates. \nTo appear in Theory and Practice of Logic Programming (TPLP).", "venue": "ArXiv", "authors": ["Tran Cao Son", "Enrico  Pontelli"], "year": 2006, "n_citations": 14}
{"id": 2809747, "s2_id": "dfc10336f32ed95f50262be73a54d8c57dd9cf59", "title": "Factorization of Motion Polynomials", "abstract": "In this paper, we consider the existence of a factorization of a monic, bounded motion polynomial. We prove existence of factorizations, possibly after multiplication with a real polynomial and provide algorithms for computing polynomial factor and factorizations. The first algorithm is conceptually simpler but may require a high degree of the polynomial factor. The second algorithm gives an optimal degree. Let H(t) be the ring of univariate polynomials with quaternion coefficients, with the variable t commuting with the coefficients. The existence of factorizations ofquaternion polynomials into linear factors is a classical result (2). In (3), motion polynomials are defined as elements of DH(t) - the ring of univariate polynomials with dual quaternions - with real norms; these can be used to parametrize rational motions in Euclidean 3- space. The main result there is that a factorization into linear factors allows to construct a mechanical linkage that generates the desired motion. An adaption of the algorithm by (2) to the dual quaternion case indeed allows to factorize \"generic\" polynomials in DH(t), namely those whose primal part has no strictly real factors. For fixed degree, the set of generic motion polynomials is open and dense in the set of all motion polynomials. Since 2012, we have been wondering which non-generic motion polynomials do allow factorization into linear factors. One reason for our curiousity is a paradoxical fact: ratio- nal motions that are parametrized by generic motion polynomials have special properties, namely that their orbit curves have full cyclicity. The question is still not completely solved, but in this paper we give an affirmative answer for \"bounded\"motion polyno- mials. They always admit factorizations into products of linear rotation polynomials, possibly after multiplication with a real polynomial. This changes the motion polynomial but not the motion it parameterizes. Bounded motion polynomials are defined by the condition that the norm polynomials has no real roots. The kinematic meaning of this condition is that the orbits are bounded curves. It is also quite obvious that motions that can be generated by linkages with revolute joints (in particular, no translational joints)", "venue": "J. Symb. Comput.", "authors": ["Zijia  Li", "Josef  Schicho", "Hans-Peter  Schr\u00f6cker"], "year": 2019, "n_citations": 15}
{"id": 2810001, "s2_id": "247d2f004ac13bd3d070ba2a0bda1765e70e417f", "title": "A lattice formulation of the F4 completion procedure", "abstract": "We introduce a new procedure for constructing noncommutative Grobner bases using a lattice formulation of completion. This leads to a lattice description of the noncommutative F4 procedure. Our procedure is based on the lattice structure of reduction operators which provides a lattice description of the confluence property. We relate reduction operators to noncommutative Grobner bases, we show the Diamond Lemma for reduction operators and we deduce the lattice interpretation of the F4 procedure. Finally, we illustrate our procedure with a complete example.", "venue": "ArXiv", "authors": ["Cyrille  Chenavier"], "year": 2017, "n_citations": 1}
{"id": 2811722, "s2_id": "4238a98050dd9681910e9a3cefb2c7a352dc1157", "title": "Frobenius Groups with Perfect Order Classes", "abstract": "The purpose of this paper is to investigate the finite Frobenius groups with \u201cperfect order classes\u201d; that is, those for which the number of elements of each order is a divisor of the order of the group. If a finite Frobenius group has perfect order classes then so too does its Frobenius complement, the Frobenius kernel is a homocyclic group of odd prime power order, and the Frobenius complement acts regularly on the elements of prime order in the Frobenius kernel. The converse is also true. Combined with elementary number-theoretic arguments, we use this to provide characterisations of several important classes of Frobenius groups. The insoluble Frobenius groups with perfect order classes are fully characterised. These turn out to be the perfect Frobenius groups whose Frobenius kernel is a homocyclic 11-group of rank 2. We also determine precisely which nilpotent Frobenius complements have perfect order classes, from which it follows that a Frobenius group with nilpotent complement has perfect order classes only if the Frobenius complement is a cyclic {2, 3}-group of even order. Those Frobenius groups for which the Frobenius complement is a biprimary group are also described fully, and we show that no soluble Frobenius group whose Frobenius complement is a {2, 3, 5}group with order divisible by 30 has perfect order classes.", "venue": "ArXiv", "authors": ["James  McCarron"], "year": 2021, "n_citations": 0}
{"id": 2812394, "s2_id": "65b6827d2415770a5f30cf3bd65a2946c3de4b0b", "title": "The On-Line Shortest Path Problem Under Partial Monitoring", "abstract": "The on-line shortest path problem is considered under various models of partial monitoring. Given a weighted directed acyclic graph whose edge weights can change in an arbitrary (adversarial) way, a decision maker has to choose in each round of a game a path between two distinguished vertices such that the loss of the chosen path (defined as the sum of the weights of its composing edges) be as small as possible. In a setting generalizing the multi-armed bandit problem, after choosing a path, the decision maker learns only the weights of those edges that belong to the chosen path. For this problem, an algorithm is given whose average cumulative loss in n rounds exceeds that of the best path, matched off-line to the entire sequence of the edge weights, by a quantity that is proportional to 1/\u221an and depends only polynomially on the number of edges of the graph. The algorithm can be implemented with complexity that is linear in the number of rounds n (i.e., the average complexity per round is constant) and in the number of edges. An extension to the so-called label efficient setting is also given, in which the decision maker is informed about the weights of the edges corresponding to the chosen path at a total of m \u226a n time instances. Another extension is shown where the decision maker competes against a time-varying path, a generalization of the problem of tracking the best expert. A version of the multi-armed bandit setting for shortest path is also discussed where the decision maker learns only the total weight of the chosen path but not the weights of the individual edges on the path. Applications to routing in packet switched networks along with simulation results are also presented.", "venue": "J. Mach. Learn. Res.", "authors": ["Andr\u00e1s  Gy\u00f6rgy", "Tam\u00e1s  Linder", "G\u00e1bor  Lugosi", "Gy\u00f6rgy  Ottucs\u00e1k"], "year": 2007, "n_citations": 133}
{"id": 2815961, "s2_id": "ea95abcf65d1ad7cd0bf3e0789d821d1711ae1dd", "title": "xPerm: fast index canonicalization for tensor computer algebra", "abstract": "Abstract We present a very fast implementation of the Butler\u2013Portugal algorithm for index canonicalization with respect to permutation symmetries. It is called xPerm , and has been written as a combination of a Mathematica package and a C subroutine. The latter performs the most demanding parts of the computations and can be linked from any other program or computer algebra system. We demonstrate with tests and timings the effectively polynomial performance of the Butler\u2013Portugal algorithm with respect to the number of indices, though we also show a case in which it is exponential. Our implementation handles generic tensorial expressions with several dozen indices in hundredths of a second, or one hundred indices in a few seconds, clearly outperforming all other current canonicalizers. The code has been already under intensive testing for several years and has been essential in recent investigations in large-scale tensor computer algebra. Program summary Program title: xPerm Catalogue identifier: AEBH_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEBH_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 93\u2009582 No. of bytes in distributed program, including test data, etc.: 1\u2009537\u2009832 Distribution format: tar.gz Programming language: C and Mathematica (version 5.0 or higher) Computer: Any computer running C and Mathematica (version 5.0 or higher) Operating system: Linux, Unix, Windows XP, MacOS RAM:: 20 Mbyte Word size: 64 or 32 bits Classification: 1.5, 5 Nature of problem: Canonicalization of indexed expressions with respect to permutation symmetries. Solution method: The Butler\u2013Portugal algorithm. Restrictions: Multiterm symmetries are not considered. Running time: A few seconds with generic expressions of up to 100 indices. The xPermDoc.nb notebook supplied with the distribution takes approximately one and a half hours to execute in full.", "venue": "Comput. Phys. Commun.", "authors": ["Jos\u00e9 M. Mart\u00edn-Garc\u00eda"], "year": 2008, "n_citations": 104}
{"id": 2816494, "s2_id": "2d3626dcd3f111100621f85cbc140b25be9b7d1a", "title": "A Domain-Specific Compiler for Linear Algebra Operations", "abstract": "We present a prototypical linear algebra compiler that automatically exploits domain-specific knowledge to generate high-performance algorithms. The input to the compiler is a target equation together with knowledge of both the structure of the problem and the properties of the operands. The output is a variety of high-performance algorithms, and the corresponding source code, to solve the target equation. Our approach consists in the decomposition of the input equation into a sequence of library-supported kernels. Since in general such a decomposition is not unique, our compiler returns not one but a number of algorithms. The potential of the compiler is shown by means of its application to a challenging equation arising within the genome-wide association study. As a result, the compiler produces multiple \u201cbest\u201d algorithms that outperform the best existing libraries.", "venue": "VECPAR", "authors": ["Diego  Fabregat-Traver", "Paolo  Bientinesi"], "year": 2012, "n_citations": 31}
{"id": 2818955, "s2_id": "a66e11668f67fc3c35aede6847124fa0c8745330", "title": "Lagrangian Constraints and Differential Thomas Decomposition", "abstract": "In this paper we show how to compute algorithmically the full set of algebraically independent constraints for singular mechanical and field-theoretical models with polynomial Lagrangians. If a model under consideration is not singular as a whole but has domains of dynamical (field) variables where its Lagrangian becomes singular, then our approach allows to detect such domains and compute the relevant constraints. In doing so, we assume that the Lagrangian of a model is a differential polynomial and apply the differential Thomas decomposition algorithm to the Euler-Lagrange equations.", "venue": "Adv. Appl. Math.", "authors": ["Vladimir P. Gerdt", "Daniel  Robertz"], "year": 2016, "n_citations": 6}
{"id": 2821238, "s2_id": "85b3d352a757e572aae4e450f3b8a867c608632e", "title": "A fast algorithm for solving linearly recurrent sequences", "abstract": "We present an algorithm which computes the <i>D<sup>th</sup></i> term of a sequence satisfying a linear recurrence relation of order <i>d</i> over a field K in <i>O</i>(M(d\u0304) log(<i>D</i>) + M(<i>d</i>) log(<i>d</i>)) operations in K, where d\u0304 \u2264 <i>d</i> is the degree of the squarefree part of the annihilating polynomial of the recurrence and M is the cost of polynomial multiplication in K. This is a refinement of the previously optimal result of <i>O</i>(M(<i>d</i>) log(<i>D</i>)) operations, due to Fiduccia.", "venue": "ACCA", "authors": ["Seung Gyu Hyun", "Stephen  Melczer", "Catherine  St-Pierre"], "year": 2019, "n_citations": 2}
{"id": 2826371, "s2_id": "8744cd3eaacc4957e2b28b99d1fb422732a5b1eb", "title": "On a Conjecture of Cusick Concerning the Sum of Digits of n and n+t", "abstract": "For a nonnegative integer $t$, let $c_t$ be the asymptotic density of natural numbers $n$ for which $s(n + t) \\geq s(n)$, where $s(n)$ denotes the sum of digits of $n$ in base $2$. We prove that $c_t > 1/2$ for $t$ in a set of asymptotic density $1$, thus giving a partial solution to a conjecture of T. W. Cusick stating that $c_t > 1/2$ for all t. Interestingly, this problem has several equivalent formulations, for example that the polynomial $X(X + 1)\\cdots(X + t - 1)$ has less than $2^t$ zeros modulo $2^{t+1}$. The proof of the main result is based on Chebyshev's inequality and the asymptotic analysis of a trivariate rational function, using methods from analytic combinatorics.", "venue": "SIAM J. Discret. Math.", "authors": ["Michael  Drmota", "Manuel  Kauers", "Lukas  Spiegelhofer"], "year": 2016, "n_citations": 11}
{"id": 2832300, "s2_id": "20d1d0167776baaf43c290c425bf6446d882c7fa", "title": "From approximate factorization to root isolation with application to cylindrical algebraic decomposition", "abstract": "We present an algorithm for isolating all roots of an arbitrary complex polynomial p that also works in the presence of multiple roots provided that (1) the number of distinct roots is given as part of the input and (2) the algorithm can ask for arbitrarily good approximations of the coefficients of p. The algorithm outputs pairwise disjoint disks each containing one of the distinct roots of p and the multiplicity of the root contained in the disk. The algorithm uses approximate factorization as a subroutine. For the case where Pan's algorithm (Pan, 2002) is used for the factorization, we derive complexity bounds for the problems of isolating and refining all roots, which are stated in terms of the geometric locations of the roots only. Specializing the latter bounds to a polynomial of degree d and with integer coefficients of bitsize less than @t, we show that [email\u00a0protected]?(d^3+d^[email\u00a0protected][email\u00a0protected]) bit operations are sufficient to compute isolating disks of size less than 2^-^@k for all roots of p, where @k is an arbitrary positive integer. In addition, we apply our root isolation algorithm to a recent algorithm for computing the topology of a real planar algebraic curve specified as the zero set of a bivariate integer polynomial and for isolating the real solutions of a bivariate polynomial system. For polynomials of degree n and bitsize @t, we improve the currently best running time from [email\u00a0protected]?(n^[email\u00a0protected]+n^[email\u00a0protected]^2) (deterministic) to [email\u00a0protected]?(n^6+n^[email\u00a0protected]) (randomized) for topology computation and from [email\u00a0protected]?(n^8+n^[email\u00a0protected]) (deterministic) to [email\u00a0protected]?(n^6+n^[email\u00a0protected]) (randomized) for solving bivariate systems.", "venue": "J. Symb. Comput.", "authors": ["Kurt  Mehlhorn", "Michael  Sagraloff", "Pengming  Wang"], "year": 2015, "n_citations": 38}
{"id": 2835453, "s2_id": "2b82ce43a690d67d277b6fa8feb156ef783b9e7a", "title": "Polynomial root clustering and explicit deflation", "abstract": "We seek complex roots of a univariate polynomial $P$ with real or complex coefficients. We address this problem based on recent algorithms that use subdivision and have a nearly optimal complexity. They are particularly efficient when only roots in a given Region Of Interest (ROI) are sought. We propose two improvements for root finders. The first one is applied to polynomials having only real coefficients; their roots are either real or appear in complex conjugate pairs. We show how to adapt the subdivision scheme to focus the computational effort on the imaginary positive part of the ROI. In our second improvement we deflate $P$ to decrease its degree and the arithmetic cost of the subdivision.", "venue": "ArXiv", "authors": ["R'emi  Imbach", "Victor Y. Pan"], "year": 2019, "n_citations": 2}
{"id": 2838488, "s2_id": "4b4877c40450454993cc774d7c22067d2d3fd580", "title": "Creative telescoping for rational functions using the griffiths: dwork method", "abstract": "Creative telescoping algorithms compute linear differential equations satisfied by multiple integrals with parameters. We describe a precise and elementary algorithmic version of the Griffiths-Dwork method for the creative telescoping of rational functions. This leads to bounds on the order and degree of the coefficients of the differential equation, and to the first complexity result which is single exponential in the number of variables. One of the important features of the algorithm is that it does not need to compute certificates. The approach is vindicated by a prototype implementation.", "venue": "ISSAC '13", "authors": ["Alin  Bostan", "Pierre  Lairez", "Bruno  Salvy"], "year": 2013, "n_citations": 52}
{"id": 2840571, "s2_id": "5cbe2f00a049cb089394c835e991db856f23de65", "title": "Computing Approximate Greatest Common Right Divisors of Differential Polynomials", "abstract": "Differential (Ore) type polynomials with \u201capproximate\u201d polynomial coefficients are introduced. These provide an effective notion of approximate differential operators, with a strong algebraic structure. We introduce the approximate greatest common right divisor problem (GCRD) of differential polynomials, as a non-commutative generalization of the well-studied approximate GCD problem. Given two differential polynomials, we present an algorithm to find nearby differential polynomials with a non-trivial GCRD, where nearby is defined with respect to a suitable coefficient norm. Intuitively, given two linear differential polynomials as input, the (approximate) GCRD problem corresponds to finding the (approximate) differential polynomial whose solution space is the intersection of the solution spaces of the two inputs. The approximate GCRD problem is proven to be locally well posed. A method based on the singular value decomposition of a differential Sylvester matrix is developed to produce an initial approximation of the GCRD. With a sufficiently good initial approximation, Newton iteration is shown to converge quadratically to an optimal solution. Finally, sufficient conditions for existence of a solution to the global problem are presented along with examples demonstrating that no solution exists when these conditions are not satisfied.", "venue": "Found. Comput. Math.", "authors": ["Mark  Giesbrecht", "Joseph  Haraldson", "Erich  Kaltofen"], "year": 2020, "n_citations": 4}
{"id": 2845953, "s2_id": "f7fabbb3a48bb68b5ca9d5604196a9a4062cf0e2", "title": "Root Radii and Subdivision for Polynomial Root-Finding", "abstract": "The recent subdivision algorithms for univariate polynomial Complex Root Clustering (CRC) and Real Root Isolation (RRI) approximate all roots in a fixed Region of Interest (RoI) and, like the algorithm of Pan (1995, 2002), achieve near optimal bit complexity for the so called benchmark problem. On the other hand, user\u2019s current choice for the approximation of all complex roots of a polynomial is the package MPSolve, implementing Ehrlich \u2013 Aberth\u2019s iterations. Their very fast empirical global convergence (right from the start) is well-known although has no formal support. Subdivision iterations allow robust implementations, one of which is currently the user\u2019s choice for solving the RRI problem, including the task of the approximation of all real roots. Another implementation is slower than MPSolve (by several orders of magnitude) for finding all roots but outperforms MPSolve for solving the CRC problem where the RoI contains only a small number of roots. We analyze and extend a 2000 variant of Sch\u00f6nhage\u2019s algorithm of (1982), which efficiently computes narrow real intervals that contain the moduli of all roots, thus defining a set of annuli covering all the complex roots. We present an implementable version of this algorithm and by using the computed sets of annuli improve in practice subdivision algorithms for CRC and RRI while supporting near optimal bit complexity.", "venue": "CASC", "authors": ["R'emi  Imbach", "Victor Y. Pan"], "year": 2021, "n_citations": 0}
{"id": 2846399, "s2_id": "6451101871a2956627b16c87f9cea8956e0b02b4", "title": "SymFields: An Open Source Symbolic Fields Analysis Tool for General Curvilinear Coordinates in Python", "abstract": "An open source symbolic tool for vector fields analysis \u2019SymFields\u2019 is developed in Python. The SymFields module is constructed upon Python symbolic module sympy, which could only conduct scaler field analysis. With SymFields module, you can conduct vector analysis for general curvilinear coordinates regardless whether it is orthogonal or not. In SymFields, the differential operators based on metric tensor are normalized to real physical values, which means your can use real physical value of the vector fields as inputs. This could greatly free the physicists from the tedious calculation under complicated coordinates.", "venue": "Proceedings of the Future Technologies Conference (FTC) 2021, Volume 1", "authors": ["Nan  Chu"], "year": 2021, "n_citations": 0}
{"id": 2846570, "s2_id": "026879333b16c18c5977715e1cda1dd688b58f88", "title": "Ladder Operators and Endomorphisms in Combinatorial Physics", "abstract": "Starting with the Heisenberg-Weyl algebra, fundamental to quantum physics, we first show how the ordering of the non-commuting operators intrinsic to that algebra gives rise to generalizations of the classical Stirling Numbers of Combinatorics. These may be expressed in terms of infinite, but {\\em row-finite}, matrices, which may also be considered as endomorphisms of $\\C[[x]]$. This leads us to consider endomorphisms in more general spaces, and these in turn may be expressed in terms of generalizations of the ladder-operators familiar in physics.", "venue": "Discret. Math. Theor. Comput. Sci.", "authors": ["G\u00e9rard  Duchamp", "Laurent  Poinsot", "Allan I. Solomon", "Karol A. Penson", "Pawel  Blasiak", "Andrzej  Horzela"], "year": 2010, "n_citations": 6}
{"id": 2848517, "s2_id": "c6f8a6860e5079de764bb0c1a0b6bc7ab7d4639f", "title": "On the minimum of a positive polynomial over the standard simplex", "abstract": "We present a new positive lower bound for the minimum value taken by a polynomial P with integer coefficients in k variables over the standard simplex of R^k, assuming that P is positive on the simplex. This bound depends only on the number of variables k, the degree d and the bitsize @t of the coefficients of P and improves all the previous bounds for arbitrary polynomials which are positive over the simplex.", "venue": "J. Symb. Comput.", "authors": ["Gabriela  Jeronimo", "Daniel  Perrucci"], "year": 2010, "n_citations": 28}
{"id": 2861060, "s2_id": "72146eb3aa362292435f3b73d77fd84698b44a4b", "title": "Smooth points on semi-algebraic sets", "abstract": "Many algorithms for determining properties of semi-algebraic sets rely upon the ability to compute smooth points [1]. We present a simple procedure based on computing the critical points of some well-chosen function that guarantees the computation of smooth points in each connected bounded component of a real atomic semi-algebraic set. Our technique is intuitive in principal, performs well on previously difficult examples, and is straightforward to implement using existing numerical algebraic geometry software. The practical efficiency of our approach is demonstrated by solving a conjecture on the number of equilibria of the Kuramoto model for the n = 4 case. We also apply our method to design an efficient algorithm to compute the real dimension of algebraic sets, the original motivation for this research.", "venue": "ACM Commun. Comput. Algebra", "authors": ["Katherine  Harris", "Jonathan D. Hauenstein", "Agnes  Szanto"], "year": 2020, "n_citations": 4}
{"id": 2861200, "s2_id": "ec3bc0819f11aa22c2df23e800ad3b039b8cbf25", "title": "Fast Computation of the Roots of Polynomials Over the Ring of Power Series", "abstract": "We give an algorithm for computing all roots of polynomials over a univariate power series ring over an exact field K. More precisely, given a precision d, and a polynomial Q whose coefficients are power series in x, the algorithm computes a representation of all power series f(x) such that Q(f(x)) = 0 mod xd. The algorithm works unconditionally, in particular also with multiple roots, where Newton iteration fails. Our main motivation comes from coding theory where instances of this problem arise and multiple roots must be handled. The cost bound for our algorithm matches the worst-case input and output size d deg(Q), up to logarithmic factors. This improves upon previous algorithms which were quadratic in at least one of d and deg(Q). Our algorithm is a refinement of a divide & conquer algorithm by Alekhnovich (2005), where the cost of recursive steps is better controlled via the computation of a factor of $Q$ which has a smaller degree while preserving the roots.", "venue": "ISSAC", "authors": ["Vincent  Neiger", "Johan  Rosenkilde", "\u00c9ric  Schost"], "year": 2017, "n_citations": 11}
{"id": 2871363, "s2_id": "a9e9b716dc5019230196aaf3854db0e63907d0e0", "title": "Fast Coefficient Computation for Algebraic Power Series in Positive Characteristic", "abstract": "We revisit Christol's theorem on algebraic power series in positive characteristic and propose yet another proof for it. This new proof combines several ingredients and advantages of existing proofs, which make it very well-suited for algorithmic purposes. We apply the construction used in the new proof to the design of a new efficient algorithm for computing the $N$th coefficient of a given algebraic power series over a perfect field of characteristic~$p$. It has several nice features: it is more general, more natural and more efficient than previous algorithms. Not only the arithmetic complexity of the new algorithm is linear in $\\log N$ and quasi-linear in~$p$, but its dependency with respect to the degree of the input is much smaller than in the previously best algorithm. {Moreover, when the ground field is finite, the new approach yields an even faster algorithm, whose bit complexity is linear in $\\log N$ and quasi-linear in~$\\sqrt{p}$}.", "venue": "The Open Book Series", "authors": ["Alin  Bostan", "Xavier  Caruso", "Gilles  Christol", "Philippe  Dumas"], "year": 2019, "n_citations": 4}
{"id": 2875200, "s2_id": "af4261a7a42cc1e5a14ab9f4d47906962a7df8da", "title": "Computing the Determinant of a Matrix with Polynomial Entries by Approximation", "abstract": "Computing the determinant of a matrix with the univariate and multivariate polynomial entries arises frequently in the scientific computing and engineering fields. This paper proposes an effective algorithm to compute the determinant of a matrix with polynomial entries using hybrid symbolic and numerical computation. The algorithm relies on the Newton\u2019s interpolation method with error control for solving Vandermonde systems. The authors also present the degree matrix to estimate the degree of variables in a matrix with polynomial entries, and the degree homomorphism method for dimension reduction. Furthermore, the parallelization of the method arises naturally.", "venue": "J. Syst. Sci. Complex.", "authors": ["Xiaolin  Qin", "Zhi  Sun", "Tuo  Leng", "Yong  Feng"], "year": 2018, "n_citations": 2}
{"id": 2882967, "s2_id": "43193b4c9bf1928bff2a2fa364ad63606a3e3381", "title": "Algebraic and Puiseux series solutions of systems of autonomous algebraic ODEs of dimension one in several variables", "abstract": "In this paper we study systems of autonomous algebraic ODEs in several differential indeterminates. We develop a notion of algebraic dimension of such systems by considering them as algebraic systems. Afterwards we apply differential elimination and analyze the behavior of the dimension in the resulting Thomas decomposition. For such systems of algebraic dimension one, we show that all formal Puiseux series solutions can be approximated up to an arbitrary order by convergent solutions. We show that the existence of Puiseux series and algebraic solutions can be decided algorithmically. Moreover, we present a symbolic algorithm to compute all algebraic solutions. The output can either be represented by triangular systems or by their minimal polynomials. keywords. Algebraic autonomous ordinary differential equation, Puiseux series solution, convergent solution, Artin approximation, algebraic solution, Thomas decomposition.", "venue": "ArXiv", "authors": ["Jos\u00e9  Cano", "Sebastian  Falkensteiner", "Daniel  Robertz", "J. Rafael Sendra"], "year": 2021, "n_citations": 0}
{"id": 2883157, "s2_id": "bea44b2934f62c48fa4319660124f20c2f57d23c", "title": "Complexity of creative telescoping for bivariate rational functions", "abstract": "The long-term goal initiated in this work is to obtain fast algorithms and implementations for definite integration in Almkvist and Zeilberger's framework of (differential) creative telescoping. Our complexity-driven approach is to obtain tight degree bounds on the various expressions involved in the method. To make the problem more tractable, we restrict to bivariate rational functions. By considering this constrained class of inputs, we are able to blend the general method of creative telescoping with the well-known Hermite reduction. We then use our new method to compute diagonals of rational power series arising from combinatorics.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Shaoshi  Chen", "Fr\u00e9d\u00e9ric  Chyzak", "Ziming  Li"], "year": 2010, "n_citations": 47}
{"id": 2884791, "s2_id": "8d00a29d8830e32bf833345e97b0fba1fb3d12c7", "title": "Faster integer multiplication using short lattice vectors", "abstract": "We prove that $n$-bit integers may be multiplied in $O(n \\log n \\, 4^{\\log^* n})$ bit operations. This complexity bound had been achieved previously by several authors, assuming various unproved number-theoretic hypotheses. Our proof is unconditional, and depends in an essential way on Minkowski's theorem concerning lattice vectors in symmetric convex sets.", "venue": "The Open Book Series", "authors": ["David  Harvey", "Joris van der Hoeven"], "year": 2019, "n_citations": 35}
{"id": 2887761, "s2_id": "da28d791dd37effd26359601a249ddd23597a218", "title": "Fast Conversion Algorithms for Orthogonal Polynomials", "abstract": "We discuss efficient conversion algorithms for orthogonal polynomials. We describe a known conversion algorithm from an arbitrary orthogonal basis to the monomial basis, and deduce a new algorithm of the same complexity for the converse operation.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Bruno  Salvy", "\u00c9ric  Schost"], "year": 2008, "n_citations": 20}
{"id": 2888623, "s2_id": "c36aedaf138fca03b830f223964227f3037e863c", "title": "The Imandra Automated Reasoning System (System Description)", "abstract": "We describe Imandra, a modern computational logic theorem prover designed to bridge the gap between decision procedures such as SMT, semi-automatic inductive provers of the Boyer-Moore family like ACL2, and interactive proof assistants for typed higher-order logics. Imandra\u2019s logic is computational, based on a pure subset of OCaml in which all functions are terminating, with restrictions on types and higher-order functions that allow conjectures to be translated into multi-sorted first-order logic with theories, including arithmetic and datatypes. Imandra has novel features supporting large-scale industrial applications, including a seamless integration of bounded and unbounded verification, first-class computable counterexamples, efficiently executable models and a cloud-native architecture supporting live multiuser collaboration. The core reasoning mechanisms of Imandra are (i) a semi-complete procedure for finding models of formulas in the logic mentioned above, centered around the lazy expansion of recursive functions, (ii) an inductive waterfall and simplifier which \u201clifts\u201d many Boyer-Moore ideas to our typed higher-order setting. These mechanisms are tightly integrated and subject to many forms of user control.", "venue": "IJCAR", "authors": ["Grant Olney Passmore", "Simon  Cruanes", "Denis  Ignatovich", "Dave  Aitken", "Matt  Bray", "Elijah  Kagan", "Kostya  Kanishev", "Ewen  Maclean", "Nicola  Mometto"], "year": 2020, "n_citations": 10}
{"id": 2890215, "s2_id": "6fe7d9f6029cf785512540ddc95c857a4a6a85f5", "title": "Adleman-Manders-Miller Root Extraction Method Revisited", "abstract": "Adleman, Manders and Miller had mentioned how to extend their square root extraction method to the general rth root extraction over finite fields, but not shown enough details. Actually, there is a dramatic difference between the square root extraction and the general rth root extraction because one has to solve discrete logarithms for rth root extraction. In this paper, we clarify their method and analyze its complexity. Our heuristic presentation is helpful to grasp the method entirely and deeply.", "venue": "Inscrypt", "authors": ["Zhengjun  Cao", "Qian  Sha", "Xiao  Fan"], "year": 2011, "n_citations": 12}
{"id": 2891857, "s2_id": "4a6a2426c81fe94ae63e01baf493a07e89b9872e", "title": "Computing Lower Rank Approximations of Matrix Polynomials", "abstract": "Given an input matrix polynomial whose coefficients are floating point numbers, we consider the problem of finding the nearest matrix polynomial which has rank at most a specified value. This generalizes the problem of finding a nearest matrix polynomial that is algebraically singular with a prescribed lower bound on the dimension given in a previous paper by the authors. In this paper we prove that such lower rank matrices at minimal distance always exist, satisfy regularity conditions, and are all isolated and surrounded by a basin of attraction of non-minimal solutions. In addition, we present an iterative algorithm which, on given input sufficiently close to a rank-at-most matrix, produces that matrix. The algorithm is efficient and is proven to converge quadratically given a sufficiently good starting point. An implementation demonstrates the effectiveness and numerical robustness of our algorithm in practice.", "venue": "J. Symb. Comput.", "authors": ["Mark  Giesbrecht", "Joseph  Haraldson", "George  Labahn"], "year": 2020, "n_citations": 3}
{"id": 2896110, "s2_id": "d1e419bbe5495d4b11b7f6a7533e49dfc5512d15", "title": "Knowledge-Assisted Reasoning of Model-Augmented System Requirements with Event Calculus and Goal-Directed Answer Set Programming", "abstract": "Brendan Hall1 Sarat Chandra Varanasi2 Jan Fiedor3 Joaqu\u00edn Arias4 Kinjal Basu2 Fang Li2 Devesh Bhatt1 Kevin Driscoll1 Elmer Salazar2 Gopal Gupta2 1Honeywell Advanced Technology, Plymouth, USA 2The University of Texas at Dallas, Richardson, USA 3Honeywell International s.r.o & Brno Univ. of Technology, Brno, Czech Republic 4Universidad Rey Juan Carlos, Madrid, Spain 1,3{brendan.hall, jan.fiedor, devesh.bhatt, kevin.driscoll}@honeywell.com 2{sarat-chandra.varanasi, kinjal.basu, fang.li, ees101020, gupta}@utdallas.edu 4joaquin.arias@urjc.es", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Brendan  Hall", "Sarat Chandra Varanasi", "Jan  Fiedor", "Joaqu\u00edn  Arias", "Kinjal  Basu", "Fang  Li", "Devesh  Bhatt", "Kevin  Driscoll", "Elmer  Salazar", "Gopal  Gupta"], "year": 2021, "n_citations": 4}
{"id": 2901148, "s2_id": "fed9bc70c8537b4bf3c35ae7302869846807a2eb", "title": "Desingularization in the q-Weyl algebra", "abstract": "In this paper, we study the desingularization problem in the first $q$-Weyl algebra. We give an order bound for desingularized operators, and thus derive an algorithm for computing desingularized operators in the first $q$-Weyl algebra. Moreover, an algorithm is presented for computing a generating set of the first $q$-Weyl closure of a given $q$-difference operator. As an application, we certify that several instances of the colored Jones polynomial are Laurent polynomial sequences by computing the corresponding desingularized operator.", "venue": "Adv. Appl. Math.", "authors": ["Christoph  Koutschan", "Yi  Zhang"], "year": 2018, "n_citations": 3}
{"id": 2902556, "s2_id": "fec08665d5bd926c2314fc9878fc7291ad96cebd", "title": "Mapping the vacuum structure of gauged maximal supergravities: an application of high-performance symbolic algebra", "abstract": "The analysis of the extremal structure of the scalar potentials of gauged maximally extended supergravity models in five, four, and three dimensions, and hence the determination of possible vacuum states of these models is a computationally challenging task due to the occurrence of the exceptional Lie groups E6, E7, E8 in the definition of these potentials. At present, the most promising approach to gain information about nontrivial vacua of these models is to perform a truncation of the potential to submanifolds of the G/H coset manifold of scalars which are invariant under a subgroup of the gauge group and of sufficiently low dimension to make an analytic treatment possible. New tools are presented which allow a systematic and highly effective study of these potentials up to a previously unreached level of complexity. Explicit forms of new truncations of the potentials of four- and threedimensional models are given, and for N = 16, D = 3 supergravities, which are much more rich in structure than their higher-dimensional cousins, a series of new nontrivial vacua is identified and analysed.", "venue": "ArXiv", "authors": ["Thomas  Fischbacher"], "year": 2003, "n_citations": 10}
{"id": 2904268, "s2_id": "0b46a8b289846f6dbbd447b485fe3cd650ab0670", "title": "Algebraic local cohomology with parameters and parametric standard bases for zero-dimensional ideals", "abstract": "Abstract A computation method of algebraic local cohomology classes, associated with zero-dimensional ideals with parameters, is introduced. This computation method gives us in particular a decomposition of the parameter space depending on the structure of algebraic local cohomology classes. This decomposition informs us on several properties of input ideals and the output of the proposed algorithm completely describes the multiplicity structure of input ideals. An algorithm for computing a parametric standard basis of a given zero-dimensional ideal, with respect to an arbitrary local term order, is also described as an application of the computation method. The algorithm can always output \u201creduced\u201d standard basis of a given zero-dimensional ideal, even if the zero-dimensional ideal has parameters.", "venue": "J. Symb. Comput.", "authors": ["Katsusuke  Nabeshima", "Shinichi  Tajima"], "year": 2017, "n_citations": 23}
{"id": 2905069, "s2_id": "9dad9b6a619df76e50901ad0852abb481cfa5d0f", "title": "Using a Template Engine as a Computer Algebra Tool", "abstract": "Abstract In research problems that involve the use of numerical methods for solving systems of ordinary differential equations (ODEs), it is often required to select the most efficient method for a particular problem. To solve a Cauchy problem for a system of ODEs, Runge\u2013Kutta methods (explicit or implicit ones, with or without step-size control, etc.) are employed. In that case, it is required to search through many implementations of the numerical method and select coefficients or other parameters of its numerical scheme. This paper proposes a library and scripts for automated generation of routine functions in the Julia programming language for a set of numerical schemes of Runge\u2013Kutta methods. For symbolic manipulations, we use a template substitution tool. The proposed approach to automated generation of program code allows us to use a single template for editing, instead of modifying each individual function to be compared. On the one hand, this provides universality in the implementation of a numerical scheme and, on the other hand, makes it possible to minimize the number of errors in the process of modifying the compared implementations of the numerical method. We consider Runge\u2013Kutta methods without step-size control, embedded methods with step-size control, and Rosenbrock methods with step-size control. The program codes for the numerical schemes, which are generated automatically using the proposed library, are tested by solving numerically several well-known problems.", "venue": "Program. Comput. Softw.", "authors": ["M. N. Gevorkyan", "A. V. Korol\u2019kova", "D. S. Kulyabov"], "year": 2021, "n_citations": 0}
{"id": 2906589, "s2_id": "565e20f8308688596191753f4c061d4839156b18", "title": "Tschirnhaus-Weierstrass curves", "abstract": "We define the concept of Tschirnhaus-Weierstrass curve, named after the Weierstrass form of an elliptic curve and Tschirnhaus transformations. Every pointed curve has a Tschirnhaus-Weierstrass form, and this representation is unique up to a scaling of variables. This is useful for computing isomorphisms between curves.", "venue": "Math. Comput.", "authors": ["Josef  Schicho", "David  Sevilla"], "year": 2014, "n_citations": 0}
{"id": 2924207, "s2_id": "3387307abc837bc3a4e42d60cd830393129c13d2", "title": "Algebraic Diagonals and Walks", "abstract": "The diagonal of a multivariate power series $F$ is the univariate power series DiagF generated by the diagonal terms of F. Diagonals form an important class of power series; they occur frequently in number theory, theoretical physics and enumerative combinatorics. We study algorithmic questions related to diagonals in the case where F is the Taylor expansion of a bivariate rational function. It is classical that in this case DiagF is an algebraic function. We propose an algorithm that computes an annihilating polynomial for DiagF. Generically, it is its minimal polynomial and is obtained in time quasi-linear in its size. We show that this minimal polynomial has an exponential size with respect to the degree of the input rational function. We then address the related problem of enumerating directed lattice walks. The insight given by our study leads to a new method for expanding the generating power series of bridges, excursions and meanders. We show that their first N terms can be computed in quasi-linear complexity in N, without first computing a very large polynomial equation.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Louis  Dumont", "Bruno  Salvy"], "year": 2015, "n_citations": 5}
{"id": 2930073, "s2_id": "4d1ce7d9d36ff8f0f677bcbffe10b6f3b80cc363", "title": "Investigating ADR mechanisms with knowledge graph mining and explainable AI", "abstract": "Adverse Drug Reactions (ADRs) are characterized within randomized clinical trials and postmarketing pharmacovigilance, but their molecular mechanism remains unknown in most cases. Aside from clinical trials, many elements of knowledge about drug ingredients are available in open-access knowledge graphs. In addition, drug classifications that label drugs as either causative or not for several ADRs, have been established. We propose to mine knowledge graphs for identifying biomolecular features that may enable reproducing automatically expert classifications that distinguish drug causative or not for a given type of ADR. In an explainable AI perspective, we explore simple classification techniques such as Decision Trees and Classification Rules because they provide human-readable models, which explain the classification itself, but may also provide elements of explanation for molecular mechanisms behind ADRs. In summary, we mine a knowledge graph for features; we train classifiers at distinguishing, drugs associated or not with ADRs; we isolate features that are both efficient in reproducing expert classifications and interpretable by experts (i.e., Gene Ontology terms, drug targets, or pathway names); and we manually evaluate how they may be explanatory. Extracted features reproduce with a good fidelity classifications of drugs causative or not for DILI and SCAR. Experts fully agreed that 73% and 38% of the most discriminative features are possibly explanatory for DILI and SCAR, respectively; and partially agreed (2/3) for 90% and 77% of them. Knowledge graphs provide diverse features to enable simple and explainable models to distinguish between drugs that are causative or not for ADRs. In addition to explaining classifications, most discriminative features appear to be good candidates for investigating ADR mechanisms further.", "venue": "ArXiv", "authors": ["Emmanuel  Bresso", "Pierre  Monnin", "C\u00e9dric  Bousquet", "Fran\u00e7ois-\u00c9lie  Calvier", "Ndeye Coumba Ndiaye", "Nadine  Petitpain", "Malika  Sma\u00efl-Tabbone", "Adrien  Coulet"], "year": 2020, "n_citations": 0}
{"id": 2930135, "s2_id": "9e392ac24829208b0f4b6bfd3c382561dbf30959", "title": "Explicit factors of some iterated resultants and discriminants", "abstract": "In this paper, the result of applying iterative univariate resultant constructions to multivariate polynomials is analyzed. We consider the input polynomials as generic polynomials of a given degree and exhibit explicit decompositions into irreducible factors of several constructions involving two times iterated univariate resultants and discriminants over the integer universal ring of coefficients of the entry polynomials. Cases involving from two to four generic polynomials and resultants or discriminants in one of their variables are treated. The decompositions into irreducible factors we get are obtained by exploiting fundamental properties of the univariate resultants and discriminants and induction on the degree of the polynomials. As a consequence, each irreducible factor can be separately and explicitly computed in terms of a certain multivariate resultant. With this approach, we also obtain as direct corollaries some results conjectured by Collins and McCallum which correspond to the case of polynomials whose coefficients are themselves generic polynomials in other variables. Finally, a geometric interpretation of the algebraic factorization of the iterated discriminant of a single polynomial is detailled.", "venue": "Math. Comput.", "authors": ["Laurent  Bus\u00e9", "Bernard  Mourrain"], "year": 2009, "n_citations": 26}
{"id": 2932411, "s2_id": "074849eb053fc5137a30945ff263fbd978f5f38e", "title": "The complexity of class polynomial computation via floating point approximations", "abstract": "We analyse the complexity of computing class polynomials, that are an important ingredient for CM constructions of elliptic curves, via complex floating point approximations of their roots. The heart of the algorithm is the evaluation of modular functions in several arguments. The fastest one of the presented approaches uses a technique devised by Dupont to evaluate modular functions by Newton iterations on an expression involving the arithmetic-geometric mean. It runs in time $O (|D| \\log^5 |D| \\log \\log |D|) = O (|D|^{1 + \\epsilon}) = O ( h^{2 + \\epsilon})$ for any $\\epsilon > 0$, where $D$ is the CM discriminant and $h$ is the degree of the class polynomial. Another fast algorithm uses multipoint evaluation techniques known from symbolic computation; its asymptotic complexity is worse by a factor of $\\log |D|$. Up to logarithmic factors, this running time matches the size of the constructed polynomials. The estimate also relies on a new result concerning the complexity of enumerating the class group of an imaginary-quadratic order and on a rigorously proven upper bound for the height of class polynomials.", "venue": "Math. Comput.", "authors": ["Andreas  Enge"], "year": 2009, "n_citations": 82}
{"id": 2934350, "s2_id": "ce0c9315f9bd6c22ab54c2b08b18ccc428c68ba1", "title": "Improved Structural Methods for Nonlinear Differential-Algebraic Equations via Combinatorial Relaxation", "abstract": "Differential-algebraic equations (DAEs) are widely used for modeling of dynamical systems. In numerical analysis of DAEs, consistent initialization and index reduction are important preprocessing prior to numerical integration. Existing DAE solvers commonly adopt structural preprocessing methods, which are based on combinatorial optimization. Unfortunately, the structural methods fail if the DAE has numerical or symbolic cancellations. For such DAEs, methods have been proposed to modify them to other DAEs to which the structural methods are applicable. The modification methods are based on the combinatorial relaxation technique. Existing modification methods, however, work only for a class of DAEs that are linear or close to linear. This paper proposes two modification methods for nonlinear DAEs: the substitution method and the augmentation method. Both methods are based on the combinatorial relaxation approach and are applicable to a large class of nonlinear DAEs. The substitution method symbolically solves equations for some derivatives based on the implicit function theorem and substitutes the solution back into the system. Instead of solving equations, the augmentation method modifies DAEs by appending new variables and equations. The augmentation method has advantages that the equation solving is not needed and the sparsity of DAEs is retained. It is shown in numerical experiments that both methods successfully modify high-index DAEs that the DAE solver in MATLAB cannot handle.", "venue": "ISSAC", "authors": ["Taihei  Oki"], "year": 2019, "n_citations": 3}
{"id": 2937620, "s2_id": "05c34b11507cdd51f115ffade8d0af48cc4fc70d", "title": "Duality of Multiple Root Loci", "abstract": "The multiple root loci among univariate polynomials of degree $n$ are indexed by partitions of $n$. We study these loci and their conormal varieties. The projectively dual varieties are joins of such loci where the partitions are hooks. Our emphasis lies on equations and parametrizations that are useful for Euclidean distance optimization. We compute the ED degrees for hooks. Among the dual hypersurfaces are those that demarcate the set of binary forms whose real rank equals the generic complex rank.", "venue": "ArXiv", "authors": ["Hwangrae  Lee", "Bernd  Sturmfels"], "year": 2015, "n_citations": 21}
{"id": 2955698, "s2_id": "06d6c8272212244fa2aaa0fb5d7e11559ef3af85", "title": "Hidden Polynomial(s) Cryptosystems", "abstract": "We propose variations of the class of hidden monomial cryptosystems in order to make it resistant to all known attacks. We use identities built upon a single bivariate polynomial equation with coefficients in a finite field. Indeed, it can be replaced by a ``small'' ideal, as well. Throughout, we set up probabilistic encryption protocols, too. The same ideas extend to digital signature algorithms, as well. Our schemes work as well on differential fields of positive characteristic, and elsewhere.", "venue": "ArXiv", "authors": ["Ilia  Toli"], "year": 2003, "n_citations": 1}
{"id": 2957424, "s2_id": "5bf899eebe49281b618793162ed90bba8d871f16", "title": "A near-optimal algorithm for computing real roots of sparse polynomials", "abstract": "Let <i>p</i> \u2208 Z[<i>x</i>] be an arbitrary polynomial of degree <i>n</i> with <i>k</i> non-zero integer coefficients of absolute value less than 2<sup>\u03c4</sup>. In this paper, we answer the open question whether the real roots of <i>p</i> can be computed with a number of arithmetic operations over the rational numbers that is polynomial in the input size of the sparse representation of <i>p</i>. More precisely, we give a deterministic, complete, and certified algorithm that determines isolating intervals for all real roots of <i>p</i> with <i>O</i>(<i>k</i><sup>3</sup>\u00b7log(<i>n</i>\u03c4)\u00b7log<i>n</i>) many exact arithmetic operations over the rational numbers.\n When using approximate but certified arithmetic, the bit complexity of our algorithm is bounded by \u00d5(<i>k</i><sup>4</sup>\u00b7<i>n</i>\u00b7(\u03c4+<i>k</i>)), where \u00d5(\u00b7) indicates the omission of logarithmic factors. Hence, for sufficiently sparse polynomials (i.e. <i>k</i> = <i>O</i>(log<sup><i>c</i></sup>(<i>n</i>\u03c4)) for a constant <i>c</i>), the bit complexity is \u00d5(<i>n</i>\u03c4), which is optimal up to logarithmic factors.", "venue": "ISSAC", "authors": ["Michael  Sagraloff"], "year": 2014, "n_citations": 17}
{"id": 2958462, "s2_id": "5b2bf7328a79608308faad7a3495d33b0dce9e46", "title": "Complexity and algorithms for Euler characteristic of simplicial complexes", "abstract": "We consider the problem of computing the Euler characteristic of an abstract simplicial complex given by its vertices and facets. We show that this problem is #P-complete and present two new practical algorithms for computing Euler characteristic. The two new algorithms are derived using combinatorial commutative algebra and we also give a second description of them that requires no algebra. We present experiments showing that the two new algorithms can be implemented to be faster than previous Euler characteristic implementations by a large margin.", "venue": "J. Symb. Comput.", "authors": ["Bjarke Hammersholt Roune", "Eduardo  S\u00e1enz-de-Cabez\u00f3n"], "year": 2013, "n_citations": 11}
{"id": 2962842, "s2_id": "17f5c6ed968d4bd4944efda7b47df66b51f8be50", "title": "Neural Variational Inference For Estimating Uncertainty in Knowledge Graph Embeddings", "abstract": "Recent advances in Neural Variational Inference allowed for a renaissance in latent variable models in a variety of domains involving high-dimensional data. While traditional variational methods derive an analytical approximation for the intractable distribution over the latent variables, here we construct an inference network conditioned on the symbolic representation of entities and relation types in the Knowledge Graph, to provide the variational distributions. The new framework results in a highly-scalable method. Under a Bernoulli sampling framework, we provide an alternative justification for commonly used techniques in large-scale stochastic variational inference, which drastically reduce training time at a cost of an additional approximation to the variational lower bound. We introduce two models from this highly scalable probabilistic framework, namely the Latent Information and Latent Fact models, for reasoning over knowledge graph-based representations. Our Latent Information and Latent Fact models improve upon baseline performance under certain conditions. We use the learnt embedding variance to estimate predictive uncertainty during link prediction, and discuss the quality of these learnt uncertainty estimates. Our source code and datasets are publicly available online at this https URL.", "venue": "ArXiv", "authors": ["Alexander Imani Cowen-Rivers", "Pasquale  Minervini", "Tim  Rockt\u00e4schel", "Matko  Bosnjak", "Sebastian  Riedel", "Jun  Wang"], "year": 2019, "n_citations": 1}
{"id": 2968997, "s2_id": "84128943835116e4524fdf1ae52988e2fb7cf4e4", "title": "Telescopers for differential forms with one parameter", "abstract": "Telescopers for a function are linear differential (resp. difference) operators annihilated by the definite integral (resp. definite sum) of this function. They play a key role in Wilf-Zeilberger theory and algorithms for computing them have been extensively studied in the past thirty years. In this paper, we introduce the notion of telescopers for differential forms with D-finite function coefficients. These telescopers appear in several areas of mathematics, for instance parametrized differential Galois theory and mirror symmetry. We give a sufficient and necessary condition for the existence of telescopers for a differential form and describe a method to compute them if they exist. Algorithms for verifying this condition are also given. \u2217S. Chen was partially supported by the NSFC grants 11871067, 11688101, the Fund of the Youth Innovation Promotion Association, CAS, and the National Key Research and Development Project 2020YFA0712300, R. Feng was partially supported by the NSFC grants 11771433, 11688101, Beijing Natural Science Foundation under Grant Z190004, and the National Key Research and Development Project 2020YFA0712300.", "venue": "ArXiv", "authors": ["Shaoshi  Chen", "Ruyong  Feng", "Ziming  Li", "Michael F. Singer", "Stephen  Watt"], "year": 2021, "n_citations": 1}
{"id": 2970384, "s2_id": "b17be31f1901d5dc31bf6f0f70443ab034da8c89", "title": "Decomposition algorithms for tensors and polynomials", "abstract": "We give algorithms to compute decompositions of a given polynomial, or more generally mixed tensor, as sum of rank one tensors, and to establish whether such a decomposition is unique. In particular, we present methods to compute the decomposition of a general plane quintic in seven powers, and of a general space cubic in five powers; the two decompositions of a general plane sextic of rank nine, and the five decompositions of a general plane septic. Furthermore, we give Magma implementations of all our algorithms.", "venue": "ArXiv", "authors": ["Antonio  Laface", "Alex  Massarenti", "Rick  Rischter"], "year": 2021, "n_citations": 0}
{"id": 2971218, "s2_id": "06db6cb75bdd7a5bac8898df99d319c0b0688244", "title": "A Maple Package for Computing Groebner Bases for Linear Recurrence Relations", "abstract": "A Maple package for computing Grobner bases of linear difference ideals is described. The underlying algorithm is based on Janet and Janet-like monomial divisions associated with finite difference operators. The package can be used, for example, for automatic generation of difference schemes for linear partial differential equations and for reduction of multiloop Feynman integrals. These two possible applications are illustrated by simple examples of the Laplace equation and a one-loop scalar integral of propagator type.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt", "Daniel  Robertz"], "year": 2005, "n_citations": 22}
{"id": 2978676, "s2_id": "bc97da1018e53261c2399f4490b2d653d7533d08", "title": "Differential equations for algebraic functions", "abstract": "It is classical that univariate algebraic functions satisfy linear differential equations with polynomial coefficients. Linear recurrences follow for the coefficients of their power series expansions. We show that the linear differential equation of minimal order has coefficients whose degree is cubic in the degree of the function. We also show that there exists a linear differential equation of order linear in the degree whose coefficients are only of quadratic degree. Furthermore, we prove the existence of recurrences of order and degree close to optimal. We study the complexity of computing these differential equations and recurrences. We deduce a fast algorithm for the expansion of algebraic series.", "venue": "ISSAC '07", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Bruno  Salvy", "Gr\u00e9goire  Lecerf", "\u00c9ric  Schost"], "year": 2007, "n_citations": 55}
{"id": 2982067, "s2_id": "b7eadb4a8afab83873bd7b8b79261263282a7c33", "title": "Square root Bound on the Least Power Non-residue using a Sylvester-Vandermonde Determinant", "abstract": "We give a new elementary proof of the fact that the value of the least $k^{th}$ power non-residue in an arithmetic progression $\\{bn+c\\}_{n=0,1...}$, over a prime field $\\F_p$, is bounded by $7/\\sqrt{5} \\cdot b \\cdot \\sqrt{p/k} + 4b + c$. Our proof is inspired by the so called \\emph{Stepanov method}, which involves bounding the size of the solution set of a system of equations by constructing a non-zero low degree auxiliary polynomial that vanishes with high multiplicity on the solution set. The proof uses basic algebra and number theory along with a determinant identity that generalizes both the Sylvester and the Vandermonde determinant.", "venue": "ArXiv", "authors": ["Michael A. Forbes", "Neeraj  Kayal", "Rajat  Mittal", "Chandan  Saha"], "year": 2011, "n_citations": 0}
{"id": 2985372, "s2_id": "411f659e67a40c56bdc537ba7b367daca60f8aa6", "title": "Algebraic number fields and the LLL algorithm", "abstract": "In this paper we analyze the computational cost of various operations performed symbolically in real algebraic number fields where the elements are represented as polynomials of a primitive element of the field. We give bounds on the costs in terms of several parameters, including the degree of the field and the representation size of the input. Beyond the basic field operations we also analyze the cost of the less-than comparison and the integer rounding functions. As an important application we give a polynomial bound on the running time of the LLL lattice reduction algorithm when the vector coordinates are from an algebraic number field and the computations are performed exactly.", "venue": "ArXiv", "authors": ["M. J. Uray"], "year": 2018, "n_citations": 0}
{"id": 2985641, "s2_id": "8ff0e2ddb3aed7432f83d7a1db42ab98083282a4", "title": "A Companion Curve Tracing Method for Rank-deficient Polynomial Systems", "abstract": "We propose a method for tracing implicit real algebraic curves defined by polynomials with rank-deficient Jacobians. \nFor a given curve $f^{-1}(0)$, it first utilizes a regularization technique to compute at least one witness point per connected component of the curve. \nWe improve this step by establishing a sufficient condition for testing the emptiness of $f^{-1}(0)$. \nWe also analyze the convergence rate and carry out an error analysis for refining the witness points. \nThe witness points are obtained by computing the minimum distance of a random point to a smooth manifold embedding the curve while at the same time penalizing the residual of $f$ at the local minima. \nTo trace the curve starting from these witness points, we prove that if one drags the random point along a trajectory inside a tubular neighborhood of the embedded manifold of the curve, the projection of the trajectory on the manifold is unique and can be computed by numerical continuation. \nWe then show how to choose such a trajectory to approximate the curve by computing eigenvectors of certain matrices. \nEffectiveness of the method is illustrated by examples.", "venue": "ArXiv", "authors": ["Wenyuan  Wu", "Changbo  Chen"], "year": 2021, "n_citations": 0}
{"id": 2988403, "s2_id": "15f0d57061338ceb124875d32f64e2a90f5fcb84", "title": "Completeness of the WDS method in Checking Positivity of Integral Forms", "abstract": "Examples show that integral forms can be efficiently proved positive semidefinite by the WDS method, but it was unknown that how many steps of substitutions are needed, or furthermore, which integral forms is this method applicable for. In this paper, we give upper bounds of step numbers of WDS required in proving that an integral form is positive definite, positive semidefinite, or not positive semidefinite, thus deducing that the WDS method is complete.", "venue": "ArXiv", "authors": ["Xiaorong  Hou", "Junwei  Shao"], "year": 2009, "n_citations": 2}
{"id": 2988516, "s2_id": "e88e235ecb8c93a2b7bb005b47a88686dbf227a3", "title": "Rounding Error Analysis of Linear Recurrences Using Generating Series", "abstract": "We develop a toolbox for the error analysis of linear recurrences with constant or polynomial coefficients, based on generating series, Cauchy's method of majorants, and simple results from analytic combinatorics. We illustrate the power of the approach by several nontrivial application examples. Among these examples are a new worst-case analysis of an algorithm for computing Bernoulli numbers, and a new algorithm for evaluating differentially finite functions in interval arithmetic while avoiding interval blow-up.", "venue": "ArXiv", "authors": ["Marc  Mezzarobba"], "year": 2020, "n_citations": 0}
{"id": 2989670, "s2_id": "758b71a086b7e4728fc72b8cf8f25de37af9beeb", "title": "Constructive $D$-module Theory with \\textsc{Singular}", "abstract": "We overview numerous algorithms in computational $D$-module theory together with the theoretical background as well as the implementation in the computer algebra system \\textsc{Singular}. We discuss new approaches to the computation of Bernstein operators, of logarithmic annihilator of a polynomial, of annihilators of rational functions as well as complex powers of polynomials. We analyze algorithms for local Bernstein-Sato polynomials and also algorithms, recovering any kind of Bernstein-Sato polynomial from partial knowledge of its roots. We address a novel way to compute the Bernstein-Sato polynomial for an affine variety algorithmically. All the carefully selected nontrivial examples, which we present, have been computed with our implementation. We address such applications as the computation of a zeta-function for certain integrals and revealing the algebraic dependence between pairwise commuting elements.", "venue": "ArXiv", "authors": ["Daniel  Andres", "Michael  Brickenstein", "Viktor  Levandovskyy", "Jorge  Mart\u00edn-Morales", "Hans  Sch\u00f6nemann"], "year": 2010, "n_citations": 3}
{"id": 2993060, "s2_id": "3cf4bdf34655cb8260d3efc345563a855df512e7", "title": "Faster truncated integer multiplication", "abstract": "We present new algorithms for computing the low n bits or the high n bits of the product of two n-bit integers. We show that these problems may be solved in asymptotically 75% of the time required to compute the full 2n-bit product, assuming that the underlying integer multiplication algorithm relies on computing cyclic convolutions of real sequences.", "venue": "ArXiv", "authors": ["David  Harvey"], "year": 2017, "n_citations": 7}
{"id": 3003253, "s2_id": "edc8fb3cb16fd3c4a499c58691e8c883200180f1", "title": "Multiplying boolean Polynomials with Frobenius Partitions in Additive Fast Fourier Transform", "abstract": "We show a new algorithm and its implementation for multiplying bit-polynomials of large degrees. The algorithm is based on evaluating polynomials at a specific set comprising a natural set for evaluation with additive FFT and a high order element under Frobenius map of $\\mathbb{F}_{2}$. With the high order element, we can derive more values of the polynomials under Frobenius map. Besides, we also adapt the additive FFT to efficiently evaluate polynomials at the set with an encoding process. \nFor the implementation, we reorder the computations in the additive FFT for reducing the number of memory writes and hiding the latency for reads. The algebraic operations, including field multiplication, bit-matrix transpose, and bit-matrix multiplication, are implemented with efficient SIMD instructions. As a result, we effect a software of best known efficiency, shown in our experiments.", "venue": "ArXiv", "authors": ["Ming-Shing  Chen", "Chen-Mou  Cheng", "Po-Chun  Kuo", "Wen-Ding  Li", "Bo-Yin  Yang"], "year": 2018, "n_citations": 7}
{"id": 3005602, "s2_id": "321f4b897b70156ba9bcf6de45642afc6450da60", "title": "A cache-friendly truncated FFT", "abstract": "We describe a cache-friendly version of van der Hoeven's truncated FFT and inverse truncated FFT, focusing on the case of 'large' coefficients, such as those arising in the Schonhage-Strassen algorithm for multiplication in Z[x]. We describe two implementations and examine their performance.", "venue": "Theor. Comput. Sci.", "authors": ["David  Harvey"], "year": 2009, "n_citations": 30}
{"id": 3005718, "s2_id": "fb920db4683f3ddf8646f9816208cbfe645b4913", "title": "On lexicographic Groebner bases of radical ideals in dimension zero: interpolation and structure", "abstract": "Due to the elimination property held by the lexicographic monomial order, the corresponding Groebner bases display strong structural properties from which meaningful informations can easily be extracted. We study these properties for radical ideals of (co)dimension zero. The proof presented relies on a combinatorial decomposition of the finite set of points whereby iterated Lagrange interpolation formulas permit to reconstruct a minimal Groebner basis. This is the first fully explicit interpolation formula for polynomials forming a lexicographic Groebner basis, from which the structure property can easily be read off. The inductive nature of the proof also yield as a byproduct a triangular decomposition algorithm from the Groebner basis.", "venue": "ArXiv", "authors": ["Xavier  Dahan"], "year": 2012, "n_citations": 5}
{"id": 3006035, "s2_id": "a82f53cd50276a119cb3e8ececbb8e82a604b3c6", "title": "Syntactic Abstraction of B Models to Generate Tests", "abstract": "In a model-based testing approach as well as for the verification of properties, B models provide an interesting solution. However, for industrial applications, the size of their state space often makes them hard to handle. To reduce the amount of states, an abstraction function can be used, often combining state variable elimination and domain abstractions of the remaining variables. This paper complements previous results, based on domain abstraction for test generation, by adding a preliminary syntactic abstraction phase, based on variable elimination. We define a syntactic transformation that suppresses some variables from a B event model, in addition to a method that chooses relevant variables according to a test purpose. We propose two methods to compute an abstraction A of an initial model M. The first one computes A as a simulation of M, and the second one computes A as a bisimulation of M. The abstraction process produces a finite state system. We apply this abstraction computation to a Model Based Testing process.", "venue": "TAP@TOOLS", "authors": ["Jacques  Julliand", "Nicolas  Stouls", "Pierre-Christophe  Bu\u00e9", "Pierre-Alain  Masson"], "year": 2010, "n_citations": 2}
{"id": 3009081, "s2_id": "bfe60c9d85d203f7cd60ee7e077d0967c04a3af2", "title": "Choosing the Variable Ordering for Cylindrical Algebraic Decomposition via Exploiting Chordal Structure", "abstract": "Cylindrical algebraic decomposition (CAD) plays an important role in the field of real algebraic geometry and many other areas. As is well-known, the choice of variable ordering while computing CAD has a great effect on the time and memory use of the computation as well as the number of sample points computed. In this paper, we indicate that typical CAD algorithms, if executed with respect to a special kind of variable orderings (called \"the perfect elimination orderings''), naturally preserve chordality, which is well compatible with an important (variable) sparsity pattern called \"the correlative sparsity''. Experimentation suggests that if the associated graph of the polynomial system in question is chordal (resp., is nearly chordal), then a perfect elimination ordering of the associated graph (resp., of a minimal chordal completion of the associated graph) can be a good variable ordering for the CAD computation. That is, by using the perfect elimination orderings, the CAD computation may produce a much smaller full set of projection polynomials than by using other naive variable orderings. More importantly, for the complexity analysis of the CAD computation via a perfect elimination ordering, an (m,d)-property of the full set of projection polynomials obtained via such an ordering is given, through which the \"size'' of this set is characterized. This property indicates that when the corresponding perfect elimination tree has a lower height, the full set of projection polynomials also tends to have a smaller \"size''. This is well consistent with the experimental results, hence the perfect elimination orderings with lower elimination tree height are further recommended to be used in the CAD projection.", "venue": "ISSAC", "authors": ["Haokun  Li", "Bican  Xia", "Huiying  Zhang", "Tao  Zheng"], "year": 2021, "n_citations": 3}
{"id": 3010979, "s2_id": "3a5132efd6779333667e9b797e097642b03a0f92", "title": "A Root-Free Splitting-Lemma for Systems of Linear Differential Equations", "abstract": "We consider the formal reduction of a system of linear differential equations and show that, if the system can be block-diagonalised through transformation with a ramified Shearing-transformation and following application of the Splitting Lemma, and if the spectra of the leading block matrices of the ramified system satisfy a symmetry condition, this block-diagonalisation can also be achieved through an unramified transformation. Combined with classical results by Turritin and Wasow as well as work by Balser, this yields a constructive and simple proof of the existence of an unramified block-diagonal form from which formal invariants such as the Newton polygon can be read directly. Our result is particularly useful for designing efficient algorithms for the formal reduction of the system.", "venue": "ArXiv", "authors": ["Eckhard  Pfl\u00fcgel"], "year": 2019, "n_citations": 0}
{"id": 3015928, "s2_id": "2c0be1e1cadcc946ed72db69a6b00a30bdab0b15", "title": "Nonlinear observability algorithms with known and unknown inputs: analysis and implementation", "abstract": "The observability of a dynamical system is affected by the presence of external inputs, either known (such as control actions) or unknown (disturbances). Inputs of unknown magnitude are especially detrimental for observability, and they also complicate its analysis. Hence the availability of computational tools capable of analysing the observability of nonlinear systems with unknown inputs has been limited until lately. Two symbolic algorithms based on differential geometry, ORC-DF and FISPO, have been recently proposed for this task, but their critical analysis and comparison is still lacking. Here we perform an analytical comparison of both algorithms and evaluate their performance on a set of problems, discussing their strengths and limitations. Additionally, we use these analyses to provide insights about certain aspects of the relationship between inputs and observability. We find that, while ORC-DF and FISPO follow a similar approach, they differ in key aspects that can have a substantial influence on their applicability and computational cost. The FISPO algorithm is more generally applicable, since it can analyse any nonlinear ODE model. The ORC-DF algorithm analyses models that are affine in the inputs, and if those models have known inputs it is sometimes more efficient. Thus, the optimal choice of a method depends on the characteristics of the problem under consideration. To facilitate the use of both algorithms we implement the ORC-DF algorithm in a new version of STRIKE-GOLDD, a MATLAB toolbox for structural identifiability and observability analysis. Since this software tool already had an implementation of the FISPO algorithm, the new release allows modellers and model users the convenience of choosing between different algorithms in a single tool, without changing the coding of their model.", "venue": "ArXiv", "authors": ["Nerea  Mart'inez", "Alejandro F. Villaverde"], "year": 2020, "n_citations": 2}
{"id": 3017399, "s2_id": "62fe4fc2383f2511b50fa113fa918e8511272255", "title": "Implementations of Efficient Univariate Polynomial Matrix Algorithms and Application to Bivariate Resultants", "abstract": "Complexity bounds for many problems on matrices with univariate polynomial entries have been improved in the last few years. Still, for most related algorithms, efficient implementations are not available, which leaves open the question of the practical impact of these algorithms, e.g. on applications such as decoding some error-correcting codes and solving polynomial systems or structured linear systems. In this paper, we discuss implementation aspects for most fundamental operations: multiplication, truncated inversion, approximants, interpolants, kernels, linear system solving, determinant, and basis reduction. We focus on prime fields with a word-size modulus, relying on Shoup's C++ library NTL. Combining these new tools to implement variants of Villard's algorithm for the resultant of generic bivariate polynomials (ISSAC 2018), we get better performance than the state of the art for large parameters.", "venue": "ISSAC", "authors": ["Seung Gyu Hyun", "Vincent  Neiger", "\u00c9ric  Schost"], "year": 2019, "n_citations": 3}
{"id": 3017692, "s2_id": "8ddfea0a155f3fccb45124149029ab9051cf986d", "title": "Tame decompositions and collisions", "abstract": "A univariate polynomial f over a field is decomposable if f = g ? h = g ( h ) with nonlinear polynomials g and h. It is intuitively clear that the decomposable polynomials form a small minority among all polynomials over a finite field F q . The tame case, where the characteristic of F q does not divide n = deg ? f , is fairly well understood, and we have reasonable bounds on the number of decomposables of degree n. However, it is not known how to determine this number exactly if n has more than two prime factors. There is an obvious inclusion-exclusion formula, but to evaluate its summands, one has to determine, under a suitable normalization, the number of collisions, where essentially different components ( g , h ) yield the same f. Ritt's Second Theorem classifies all tame collisions of two such pairs.We present a normal form for tame collisions of any number of decompositions with any number of components and describe exactly the (non)uniqueness of the parameters. This yields the exact number of such collisions over a finite field. We conclude with a fast algorithm for the exact number of decomposable polynomials at degree n over a finite field F q of characteristic coprime to n.", "venue": "J. Symb. Comput.", "authors": ["Konstantin  Ziegler"], "year": 2016, "n_citations": 3}
{"id": 3018848, "s2_id": "506c0625337697436bf818f9c33813b77f8e06ac", "title": "Iterated Elliptic and Hypergeometric Integrals for Feynman Diagrams", "abstract": "We calculate 3-loop master integrals for heavy quark correlators and the 3-loop QCD corrections to the $\\rho$-parameter. They obey non-factorizing differential equations of second order with more than three singularities, which cannot be factorized in Mellin-$N$ space either. The solution of the homogeneous equations is possible in terms of convergent close integer power series as $_2F_1$ Gau\\ss{} hypergeometric functions at rational argument. In some cases, integrals of this type can be mapped to complete elliptic integrals at rational argument. This class of functions appears to be the next one arising in the calculation of more complicated Feynman integrals following the harmonic polylogarithms, generalized polylogarithms, cyclotomic harmonic polylogarithms, square-root valued iterated integrals, and combinations thereof, which appear in simpler cases. The inhomogeneous solution of the corresponding differential equations can be given in terms of iterative integrals, where the new innermost letter itself is not an iterative integral. A new class of iterative integrals is introduced containing letters in which (multiple) definite integrals appear as factors. For the elliptic case, we also derive the solution in terms of integrals over modular functions and also modular forms, using $q$-product and series representations implied by Jacobi's $\\vartheta_i$ functions and Dedekind's $\\eta$-function. The corresponding representations can be traced back to polynomials out of Lambert--Eisenstein series, having representations also as elliptic polylogarithms, a $q$-factorial $1/\\eta^k(\\tau)$, logarithms and polylogarithms of $q$ and their $q$-integrals. Due to the specific form of the physical variable $x(q)$ for different processes, different representations do usually appear. Numerical results are also presented.", "venue": "Journal of Mathematical Physics", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein", "Abilio De Freitas", "Mark van Hoeij", "E.  Imamoglu", "Clemens G. Raab", "C.-S.  Radu", "Carsten  Schneider"], "year": 2018, "n_citations": 90}
{"id": 3018867, "s2_id": "9e75439a57d3efb86b3f888fba2866762db6d05d", "title": "Certification of Bounds of Non-linear Functions: The Templates Method", "abstract": "The aim of this work is to certify lower bounds for real-valued multivariate functions, defined by semialgebraic or transcendental expressions. The certificate must be, eventually, formally provable in a proof system such as Coq. The application range for such a tool is widespread; for instance Hales' proof of Kepler's conjecture yields thousands of inequalities. We introduce an approximation algorithm, which combines ideas of the max-plus basis method (in optimal control) and of the linear templates method developed by Manna et al. (in static analysis). This algorithm consists in bounding some of the constituents of the function by suprema of quadratic forms with a well chosen curvature. This leads to semialgebraic optimization problems, solved by sum-of-squares relaxations. Templates limit the blow up of these relaxations at the price of coarsening the approximation. We illustrate the efficiency of our framework with various examples from the literature and discuss the interfacing with Coq.", "venue": "MKM/Calculemus/DML", "authors": ["Xavier  Allamigeon", "St\u00e9phane  Gaubert", "Victor  Magron", "Benjamin  Werner"], "year": 2013, "n_citations": 8}
{"id": 3019282, "s2_id": "b6a7241a009337e7f555bcf1bbe56c33b90ba747", "title": "Jordan Normal and Rational Normal Form Algorithms", "abstract": "In this paper, we present a determinist Jordan normal form algorithms based on the Fadeev formula: \\[(\\lambda \\cdot I-A) \\cdot B(\\lambda)=P(\\lambda) \\cdot I\\] where $B(\\lambda)$ is $(\\lambda \\cdot I-A)$'s comatrix and $P(\\lambda)$ is $A$'s characteristic polynomial. This rational Jordan normal form algorithm differs from usual algorithms since it is not based on the Frobenius/Smith normal form but rather on the idea already remarked in Gantmacher that the non-zero column vectors of $B(\\lambda_0)$ are eigenvectors of $A$ associated to $\\lambda_0$ for any root $\\lambda_0$ of the characteristical polynomial. The complexity of the algorithm is $O(n^4)$ field operations if we know the factorization of the characteristic polynomial (or $O(n^5 \\ln(n))$ operations for a matrix of integers of fixed size). This algorithm has been implemented using the Maple and Giac/Xcas computer algebra systems.", "venue": "ArXiv", "authors": ["Bernard  Parisse", "Morgane  Vaughan"], "year": 2004, "n_citations": 2}
{"id": 3023191, "s2_id": "dabd1b1128be3461d75e2f8fce4c9dfcfd4d9d5e", "title": "On Decomposition of Tame Polynomials and Rational Functions", "abstract": "In this paper we present algorithmic considerations and theoretical results about the relation between the orders of certain groups associated to the components of a polynomial and the order of the group that corresponds to the polynomial, proving it for arbitrary tame polynomials, and considering the case of rational functions.", "venue": "CASC", "authors": ["Jaime  Gutierrez", "David  Sevilla"], "year": 2006, "n_citations": 1}
{"id": 3033553, "s2_id": "97dee552dc13d6eaaa2252e6a94e302502edaa11", "title": "On the Bit-Size of Non-radical Triangular Sets", "abstract": "We present upper bounds on the bit-size of coefficients of non-radical purely lexicographical Grobner bases (triangular sets) in dimension zero. This extends a previous work [4], constrained to radical triangular sets; it follows the same technical steps, based on interpolation. However, key notion of height of varieties is not available for points with multiplicities; therefore the bounds obtained are thus less universal and depend on some input data. We also introduce a related family of non-monic polynomials that have smaller coefficients, and smaller bounds. It is not obvious to compute them from the initial triangular set though.", "venue": "MACIS", "authors": ["Xavier  Dahan"], "year": 2017, "n_citations": 1}
{"id": 3034463, "s2_id": "97358ecb8fd393f67d6d1cb56959d703cf294d44", "title": "Computing regular meromorphic differential forms via Saito's logarithmic residues", "abstract": "Logarithmic differential forms and logarithmic residues associated to a hypersurface with an isolated singularity are considered in the context of computational complex analysis. An effective method is introduced for computing logarithmic residues. A relation between logarithmic differential forms and the Brieskorn formula on Gauss-Manin connection are discussed. Some examples are also given for illustration.", "venue": "ArXiv", "authors": ["Shinichi  Tajima", "Katsusuke  Nabeshima"], "year": 2020, "n_citations": 1}
{"id": 3034655, "s2_id": "673a3627c6705e6a6bab7c8a8203daf3fca9911d", "title": "Multihomogeneous resultant formulae for systems with scaled support", "abstract": "Constructive methods for matrices of multihomogeneous resultants for unmixed systems have been studied in [7, 13, 15]. We generalize these constructions to mixed systems, whose Newton polytopes are scaled copies of one polytope, thus taking a step towards systems with arbitrary supports. First, we specify matrices whose determinant equals the resultant and characterize the systems that admit such formulae. B\u00e9zout-type determinantal formulae do not exist, but we describe all possible Sylvester-type and hybrid formulae. We establish tight bounds for the corresponding degree vectors, as well as precise domains where these concentrate; the latter are new even for the unmixed case. Second, we make use of multiplication tables and strong duality theory to specify resultant matrices explicitly, in the general case. The encountered matrices are classified; these include a new type of Sylvester-type matrix as well as B\u00e9zout-type matrices, which we call partial Bezoutians. Our public-domain Maple implementation includes efficient storage of complexes in memory, and construction of resultant matrices.", "venue": "ISSAC '09", "authors": ["Ioannis Z. Emiris", "Angelos  Mantzaflaris"], "year": 2009, "n_citations": 20}
{"id": 3037570, "s2_id": "b9f484084912d0de31beb81280d3c272e9b3598e", "title": "Fast Generalized Bruhat Decomposition", "abstract": "The deterministic recursive pivot-free algorithms for computing the generalized Bruhat decomposition of the matrix in the field and for the computation of the inverse matrix are presented. This method has the same complexity as algorithm of matrix multiplication, and it is suitable for the parallel computer systems.", "venue": "CASC", "authors": ["Gennadi I. Malaschonok"], "year": 2010, "n_citations": 21}
{"id": 3038752, "s2_id": "2a4072d56eb929273fd39fb515ccd36e4a0140e2", "title": "Structure of lexicographic Groebner bases in three variables of ideals of dimension zero", "abstract": "We generalize the structural theorem of Lazard in 1985, from 2 variables to 3 variables. We use the Gianni-Kalkbrener result to do this, which implies some restrictions inside which lies the case of a radical ideal.", "venue": "ArXiv", "authors": ["Xavier  Dahan"], "year": 2011, "n_citations": 0}
{"id": 3042381, "s2_id": "ca45caf1f83ce558e2d66c8b91ef70ecd1f0d81d", "title": "Pegasus: sound continuous invariant generation", "abstract": "Continuous invariants are an important component in deductive verification of hybrid and continuous systems. Just like discrete invariants are used to reason about correctness in discrete systems without having to unroll their loops, continuous invariants are used to reason about differential equations without having to solve them. Automatic generation of continuous invariants remains one of the biggest practical challenges to the automation of formal proofs of safety for hybrid systems. There are at present many disparate methods available for generating continuous invariants; however, this wealth of diverse techniques presents a number of challenges, with different methods having different strengths and weaknesses. To address some of these challenges, we develop Pegasus : an automatic continuous invariant generator which allows for combinations of various methods, and integrate it with the KeYmaera\u00a0X theorem prover for hybrid systems. We describe some of the architectural aspects of this integration, comment on its methods and challenges, and present an experimental evaluation on a suite of benchmarks.", "venue": "ArXiv", "authors": ["Andrew  Sogokon", "Stefan  Mitsch", "Yong Kiam Tan", "Katherine  Cordwell", "Andr'e  Platzer"], "year": 2020, "n_citations": 3}
{"id": 3050343, "s2_id": "8859e19d27f83eee3b0bb620ebe5774e933c60a7", "title": "Disabling equational theories in unification for cryptographic protocol analysis through tagging", "abstract": "In this paper, we show a new tagging scheme for cryptographic protocol messages. Under this tagging, equational theories of operators such as exclusive-or, binary addition etc. are effectively disabled, when terms are unified. We believe that this result has a significant impact on protocol analysis and security, since unification is at the heart of symbolic protocol analysis. Hence, disabling equational theories in unification implies disabling them altogether in protocol analysis for most operators and theories.", "venue": "ArXiv", "authors": ["Sreekanth  Malladi"], "year": 2010, "n_citations": 0}
{"id": 3059728, "s2_id": "b88826a96fcf6ebc2cad8c95bd8ab95ca69b80f0", "title": "Vivienne: Relational Verification of Cryptographic Implementations in WebAssembly", "abstract": "We investigate the use of relational symbolic execution to counter timing side channels in WebAssembly programs. We design and implement Vivienne, an open-source tool to automatically analyze WebAssembly cryptographic libraries for constant-time violations. Our approach features various optimizations that leverage the structure of WebAssembly and automated theorem provers, including support for loops via relational invariants. We evaluate Vivienne on 57 real-world cryptographic implementations, including a previously unverified implementation of the HACL* library in WebAssembly. The results indicate that Vivienne is a practical solution for constant-time analysis of cryptographic libraries in WebAssembly.", "venue": "2021 IEEE Secure Development Conference (SecDev)", "authors": ["Rodothea Myrsini Tsoupidi", "Musard  Balliu", "Benoit  Baudry"], "year": 2021, "n_citations": 0}
{"id": 3059834, "s2_id": "b98bfedbac78b530d5b368665330b25ee06c00c5", "title": "The number of realizations of a Laman graph", "abstract": "Laman graphs model planar frameworks that are rigid for a general choice of distances between the vertices. There are finitely many ways, up to isometries, to realize a Laman graph in the plane. Such realizations can be seen as solutions of systems of quadratic equations prescribing the distances between pairs of points. Using ideas from algebraic and tropical geometry, we provide a recursion formula for the number of complex solutions of such systems.", "venue": "SIAM J. Appl. Algebra Geom.", "authors": ["Jose  Capco", "Matteo  Gallet", "Georg  Grasegger", "Christoph  Koutschan", "Niels  Lubbes", "Josef  Schicho"], "year": 2018, "n_citations": 22}
{"id": 3060366, "s2_id": "032f6e119d3e096619ea90f51e3c44d660894015", "title": "Consistency Analysis of Finite Difference Approximations to PDE Systems", "abstract": "We consider finite difference approximations to systems of polynomially-nonlinear partial differential equations the coefficients of which are rational functions over rationals in the independent variables. The notion of strong consistency which we introduced earlier for linear systems is extended to nonlinear ones. For orthogonal and uniform grids we describe an algorithmic procedure for the verification of the strong consistency based on the computation of difference standard bases. The concepts and algorithmic methods of the present paper are illustrated by two finite difference approximations to the two-dimensional Navier-Stokes equations. One of these approximations is strongly consistent, while the other is not.", "venue": "MMCP", "authors": ["Vladimir P. Gerdt"], "year": 2011, "n_citations": 19}
{"id": 3061706, "s2_id": "a3262cfce723535153c58d480961464cefb47ec3", "title": "ParFORM: recent development", "abstract": "We report on the status of our project of parallelization of the symbolic manipulation program FORM. We have now parallel versions of FORM running on Cluster- or SMP-architecture. These versions can be used to run arbitrary FORM programs in parallel.", "venue": "ArXiv", "authors": ["M.  Tentyukov", "J. A. M. Vermaseren", "H. M. Staudenmaier"], "year": 2005, "n_citations": 13}
{"id": 3062729, "s2_id": "29f7f6fe458ef5f7e92e0df2ce84c94e7324a8b1", "title": "A Simple and Fast Algorithm for Computing the N-th Term of a Linearly Recurrent Sequence", "abstract": "We present a simple and fast algorithm for computing the $N$-th term of a given linearly recurrent sequence. Our new algorithm uses $O(\\mathsf{M}(d) \\log N)$ arithmetic operations, where $d$ is the order of the recurrence, and $\\mathsf{M}(d)$ denotes the number of arithmetic operations for computing the product of two polynomials of degree $d$. The state-of-the-art algorithm, due to Charles Fiduccia (1985), has the same arithmetic complexity up to a constant factor. Our algorithm is simpler, faster and obtained by a totally different method. We also discuss several algorithmic applications, notably to polynomial modular exponentiation, powering of matrices and high-order lifting.", "venue": "SOSA", "authors": ["Alin  Bostan", "Ryuhei  Mori"], "year": 2021, "n_citations": 1}
{"id": 3073892, "s2_id": "ab68934973961524b0436ce484299d3f870f47b4", "title": "HLinear: Exact Dense Linear Algebra in Haskell", "abstract": "We present an implementation in the functional programming language Haskell of the PLE decomposition of matrices over division rings. Our benchmarks indicate that it is competitive with the C-based implementation provided in Flint. Describing the guiding principles of our work, we introduce the reader to basic ideas from high-performance functional programming.", "venue": "ArXiv", "authors": ["Alexandru  Ghitza", "Martin  Westerholt-Raum"], "year": 2016, "n_citations": 0}
{"id": 3078799, "s2_id": "7235a3f77f96a9b7a0b8e71b83ca88db5cbf8964", "title": "An implementation of CAD in Maple utilising McCallum projection", "abstract": "Cylindrical algebraic decomposition (CAD) is an important tool for the investigation of semi-algebraic sets. Originally introduced by Collins in the 1970s for use in quantifier elimination it has since found numerous applications within algebraic geometry and beyond. Following from his original work in 1988, McCallum presented an improved algorithm, CADW, which offered a huge increase in the practical utility of CAD. In 2009 a team based at the University of Western Ontario presented a new and quite separate algorithm for CAD, which was implemented and included in the computer algebra system Maple. As part of a wider project at Bath investigating CAD and its applications, Collins and McCallum\u2019s CAD algorithms have been implemented in Maple. This report details these implementations and compares them to Qepcad and the Ontario algorithm. The implementations were originally undertaken to facilitate research into the connections between the algorithms. However, the ability of the code to guarantee order-invariant output has led to its use in new research on CADs which are minimal for certain problems. In addition, the implementation described here is of interest as the only full implementation of CADW, (since Qepcad does not currently make use of McCallum\u2019s delineating polynomials), and hence can solve problems not admissible to other CAD implementations.", "venue": "ArXiv", "authors": ["Matthew  England"], "year": 2013, "n_citations": 11}
{"id": 3079290, "s2_id": "cda9d8e1ee0e4c757af90ded7909a034ef5af28e", "title": "On the Parallelization of Triangular Decomposition of Polynomial Systems", "abstract": "We discuss the parallelization of algorithms for solving polynomial systems symbolically by way of triangular decomposition. Algorithms for solving polynomial systems combine low-level routines for performing arithmetic operations on polynomials and high-level procedures which produce the different components (points, curves, surfaces) of the solution set. The latter \"component-level\" parallelization of triangular decompositions, our focus here, belongs to the class of dynamic irregular parallel applications. Possible speedup factors depend on geometrical properties of the solution set (number of components, their dimensions and degrees); these algorithms do not scale with the number of processors. In this paper we combine two different concurrency schemes, the fork-join model and producer-consumer patterns, to better capture opportunities for component-level parallelization. We report on our implementation with the publicly available BPAS library. Our experimentation with 340 systems yields promising results.", "venue": "ArXiv", "authors": ["Mohammadali  Asadi", "Alexander  Brandt", "Robert H. C. Moir", "Marc Moreno Maza", "Yuzhen  Xie"], "year": 2019, "n_citations": 5}
{"id": 3080595, "s2_id": "fbe2ce0ed0383e40d3acef6b357d3260a2ae1c64", "title": "Automated Synthesis of Tableau Calculi", "abstract": "This paper presents a method for synthesising sound and complete tableau calculi. Given a specification of the formal semantics of a logic, the method generates a set of tableau inference rules which can then be used to reason within the logic. The method guarantees that the generated rules form a calculus which is sound and constructively complete. If the logic can be shown to admit finite filtration with respect to a well-defined first-order semantics then adding a general blocking mechanism produces a terminating tableau calculus. The process of generating tableau rules can be completely automated and produces, together with the blocking mechanism, an automated procedure for generating tableau decision procedures. For illustration we show the workability of the approach for propositional intuitionistic logic.", "venue": "TABLEAUX", "authors": ["Renate A. Schmidt", "Dmitry  Tishkovsky"], "year": 2009, "n_citations": 22}
{"id": 3081127, "s2_id": "bfa770d3792a07f742ba90bb244976612ab5e6d1", "title": "Covering rational surfaces with rational parametrization images", "abstract": "Let S be a rational projective surface given by means of a projective rational parametrization whose base locus satisfies a mild assumption. In this paper we present an algorithm that provides three rational maps f , g , h : A 2 --> S \u2282 P n such that the union of the three images covers S. As a consequence, we present a second algorithm that generates two rational maps f , g \u02dc : A 2 --> S , such that the union of its images covers the affine surface S \u2229 A n . In the affine case, the number of rational maps involved in the cover is in general optimal.", "venue": "ArXiv", "authors": ["Jorge  Caravantes", "J. Rafael Sendra", "David  Sevilla", "Carlos  Villarino"], "year": 2021, "n_citations": 1}
{"id": 3084756, "s2_id": "8f31eaff9a85623d84bd3035a1cd572f15a171f0", "title": "Better Answers to Real Questions", "abstract": "We consider existential problems over the reals. Extended quantifier elimination generalizes the concept of regular quantifier elimination by providing in addition answers, which are descriptions of possible assignments for the quantified variables. Implementations of extended quantifier elimination for the quadratic case via virtual substitution have been successfully applied to various problems in science and engineering. So far, the answers produced by these implementations included infinitesimal and infinite numbers, which are hard to interpret in practice. We introduce here a post-processing procedure to convert, for fixed parameters, all answers into standard real numbers. The relevance of our procedure is demonstrated by application of our implementation to various examples from the literature, where it significantly improves the quality of the results.", "venue": "SMT", "authors": ["Marek  Kosta", "Thomas  Sturm", "Andreas  Dolzmann"], "year": 2014, "n_citations": 10}
{"id": 3085635, "s2_id": "67384ccf4cfdcec8084cda01774433e2bbd49d1c", "title": "Improved Complexity Bounds for Counting Points on Hyperelliptic Curves", "abstract": "We present a probabilistic Las Vegas algorithm for computing the local zeta function of a hyperelliptic curve of genus g defined over $${\\mathbb {F}}_q$$Fq. It is based on the approaches by Schoof and Pila combined with a modelling of the $$\\ell $$\u2113-torsion by structured polynomial systems. Our main result improves on previously known complexity bounds by showing that there exists a constant $$c>0$$c>0 such that, for any fixed g, this algorithm has expected time and space complexity $$O((\\log q)^{c g})$$O((logq)cg) as q grows and the characteristic is large enough.", "venue": "Found. Comput. Math.", "authors": ["Simon  Abelard", "Pierrick  Gaudry", "Pierre-Jean  Spaenlehauer"], "year": 2019, "n_citations": 9}
{"id": 3089728, "s2_id": "e158d6edd58602de3f7c37f9765f1d9d19884c78", "title": "Truth table invariant cylindrical algebraic decomposition", "abstract": "When using cylindrical algebraic decomposition (CAD) to solve a problem with respect to a set of polynomials, it is likely not the signs of those polynomials that are of paramount importance but rather the truth values of certain quantifier free formulae involving them. This observation motivates our article and definition of a Truth Table Invariant CAD (TTICAD).In ISSAC 2013 the current authors presented an algorithm that can efficiently and directly construct a TTICAD for a list of formulae in which each has an equational constraint. This was achieved by generalising McCallum's theory of reduced projection operators. In this paper we present an extended version of our theory which can be applied to an arbitrary list of formulae, achieving savings if at least one has an equational constraint. We also explain how the theory of reduced projection operators can allow for further improvements to the lifting phase of CAD algorithms, even in the context of a single equational constraint.The algorithm is implemented fully in Maple and we present both promising results from experimentation and a complexity analysis showing the benefits of our contributions.", "venue": "J. Symb. Comput.", "authors": ["Russell J. Bradford", "James H. Davenport", "Matthew  England", "Scott  McCallum", "David J. Wilson"], "year": 2016, "n_citations": 54}
{"id": 3089787, "s2_id": "849eee81838eb933f44eb0deb03584609f1edf6f", "title": "Strongly stable ideals and Hilbert polynomials", "abstract": "The \\texttt{StronglyStableIdeals} package for \\textit{Macaulay2} provides a method to compute all saturated strongly stable ideals in a given polynomial ring with a fixed Hilbert polynomial. A description of the main method and auxiliary tools is given.", "venue": "Journal of Software for Algebra and Geometry", "authors": ["Davide  Alberelli", "Paolo  Lella"], "year": 2019, "n_citations": 7}
{"id": 3089945, "s2_id": "b48519116e1fcbb60838f874535b244e5ea8e8df", "title": "Automatic Differentiation With Higher Infinitesimals, or Computational Smooth Infinitesimal Analysis in Weil Algebra", "abstract": "We propose an algorithm to compute the C\u221e-ring structure of arbitrary Weil algebra. It allows us to do some analysis with higher infinitesimals numerically and symbolically. To that end, we first give a brief description of the (Forward-mode) automatic differentiation (AD) in terms of C\u221e-rings. The notion of a C\u221e-ring was introduced by Lawvere [10] and used as the fundamental building block of smooth infinitesimal analysis and synthetic differential geometry [11]. We argue that interpreting AD in terms of C\u221e-rings gives us a unifying theoretical framework and modular ways to express multivariate partial derivatives. In particular, we can \u201cpackage\u201d higher-order Forward-mode AD as a Weil algebra, and take tensor products to compose them to achieve multivariate higher-order AD. The algorithms in the present paper can also be used for a pedagogical purpose in learning and studying smooth infinitesimal analysis as well.", "venue": "CASC", "authors": ["Hiromi  Ishii"], "year": 2021, "n_citations": 1}
{"id": 3090431, "s2_id": "080a819e3f5968efa8d8b16148dff6c0e9710b3f", "title": "Tensor manipulation in GPL Maxima", "abstract": "GPL Maxima is an open-source computer algebra system based on DOE-MACSYMA. GPL Maxima included two tensor manipulation packages from DOE-MACSYMA, but these were in various states of disrepair. One of the two packages, CTENSOR, implemented component-based tensor manipulation; the other, ITENSOR, treated tensor symbols as opaque, manipulating them based on their index properties. The present paper describes the state in which these packages were found, the steps that were needed to make the packages fully functional again, and the new functionality that was implemented to make them more versatile. A third package, ATENSOR, was also implemented; fully compatible with the identically named package in the commercial version of MACSYMA, ATENSOR implements abstract tensor algebras.", "venue": "ArXiv", "authors": ["Viktor T. Toth"], "year": 2005, "n_citations": 18}
{"id": 3093322, "s2_id": "338f654983047c584155a1aa478c3155319c26a6", "title": "Rational Solutions of First Order Algebraic Ordinary Differential Equations", "abstract": "Let $f(t, y,y')=\\sum_{i=0}^d a_i(t, y)y'^i=0$ be a first order ordinary differential equation with polynomial coefficients. Eremenko in 1999 proved that there exists a constant $C$ such that every rational solution of $f(t, y,y')=0$ is of degree not greater than $C$. Examples show that this degree bound $C$ depends not only on the degrees of $f$ in $t,y,y'$ but also on the coefficients of $f$ viewed as polynomial in $t,y,y'$. In this paper, we show that if $$\\max_{i=0}^d \\{{\\rm deg}(a_i,y)-2(d-i)\\}>0 $$ then the degree bound $C$ only depends on the degrees of $f$, and furthermore we present an explicit expression for $C$ in terms of the degrees of $f$.", "venue": "ArXiv", "authors": ["Ruyong  Feng", "Shuang  Feng"], "year": 2020, "n_citations": 0}
{"id": 3098825, "s2_id": "35da8ca98e60f70e5960a24440f681a3f25366fa", "title": "Algorithmic Approach to Strong Consistency Analysis of Finite Difference Approximations to PDE Systems", "abstract": "For a wide class of polynomially nonlinear systems of partial differential equations we suggest an algorithmic approach to the s(trong)-consistency analysis of their finite difference approximations on Cartesian grids. First we apply the differential Thomas decomposition to the input system, resulting in a partition of the solution set. We consider the output simple subsystem that contains a solution of interest. Then, for this subsystem, we suggest an algorithm for verification of s-consistency for its finite difference approximation. For this purpose we develop a difference analogue of the differential Thomas decomposition, both of which jointly allow to verify the s-consistency of the approximation. As an application of our approach, we show how to produce s-consistent difference approximations to the incompressible Navier-Stokes equations including the pressure Poisson equation.", "venue": "ISSAC", "authors": ["Vladimir P. Gerdt", "Daniel  Robertz"], "year": 2019, "n_citations": 1}
{"id": 3100745, "s2_id": "13d7e1b973c09d1cd92450746e8451f9bd6f4359", "title": "Sequence Positivity Through Numeric Analytic Continuation: Uniqueness of the Canham Model for Biomembranes", "abstract": "We prove solution uniqueness for the genus one Canham variational problem arising in the shape prediction of biomembranes. The proof builds on a result of Yu and Chen that reduces the variational problem to proving non-negativity of a sequence defined by a linear recurrence relation with polynomial coefficients. We combine rigorous numeric analytic continuation of D-finite functions with classic bounds from singularity analysis to derive an effective index where the asymptotic behaviour of the sequence, which is positive, dominates the sequence behaviour. Positivity of the finite number of remaining terms is then checked computationally.", "venue": "ArXiv", "authors": ["Stephen  Melczer", "Marc  Mezzarobba"], "year": 2020, "n_citations": 4}
{"id": 3105709, "s2_id": "b8ac80a3f20e434be4d73a482eb507df0cfc62bc", "title": "Automatic Generation of Loop-Invariants for Matrix Operations", "abstract": "In recent years it has been shown that for many linear algebra operations it is possible to create families of algorithms following a very systematic procedure. We do not refer to the fine tuning of a known algorithm, but to a methodology for the actual generation of both algorithms and routines to solve a given target matrix equation. Although systematic, the methodology relies on complex algebraic manipulations and non-obvious pattern matching, making the procedure challenging to be performed by hand, our goal is the development of a fully automated system that from the sole description of a target equation creates multiple algorithms and routines. We present CL1ck, a symbolic system written in Mathematica, that starts with an equation, decomposes it into multiple equations, and returns a set of loop-invariants for the algorithms -- yet to be generated -- that will solve the equation. In a successive step each loop-invariant is then mapped to its corresponding algorithm and routine. For a large class of equations, the methodology generates known algorithms as well as many previously unknown ones. Most interestingly, the methodology unifies algorithms traditionally developed in isolation. As an example, the five well known algorithms for the LU factorization are for the first time unified under a common root.", "venue": "2011 International Conference on Computational Science and Its Applications", "authors": ["Diego  Fabregat-Traver", "Paolo  Bientinesi"], "year": 2011, "n_citations": 24}
{"id": 3119767, "s2_id": "cabddd9ed02a1e5c1c881ef933f2db3d7871fe31", "title": "Multivariate sparse interpolation using randomized Kronecker substitutions", "abstract": "We present new techniques for reducing a multivariate sparse polynomial to a univariate polynomial. The reduction works similarly to the classical and widely-used Kronecker substitution, except that we choose the degrees randomly based on the number of nonzero terms in the multivariate polynomial. The resulting univariate polynomial often has a significantly lower degree than the Kronecker substitution polynomial, at the expense of a small number of term collisions. As an application, we give a new algorithm for multivariate interpolation which uses these new techniques along with any existing univariate interpolation algorithm.", "venue": "ISSAC", "authors": ["Andrew  Arnold", "Daniel S. Roche"], "year": 2014, "n_citations": 21}
{"id": 3127060, "s2_id": "f593e06217e6a92b5130502452b61bc76ae121b6", "title": "On Matrices With Displacement Structure: Generalized Operators and Faster Algorithms", "abstract": "For matrices with displacement structure, basic operations like multiplication, inversion , and linear system solving can all be expressed in terms of the following task: evaluate the product AB, where A is a structured n \u00d7 n matrix of displacement rank \u03b1, and B is an arbitrary n \u00d7 \u03b1 matrix. Given B and a so-called generator of A, this product is classically computed with a cost ranging from O(\u03b1^2 M (n)) to O(\u03b1^2 M (n) log(n)) arithmetic operations, depending on the type of structure of A; here, M is a cost function for polynomial multiplication. In this paper, we first generalize classical displacement operators, based on block diagonal matrices with companion diagonal blocks, and then design fast algorithms to perform the task above for this extended class of struc-tured matrices. The cost of these algorithms ranges from O(\u03b1^{\u03c9\u22121} M (n)) to O(\u03b1^{\u03c9\u22121} M (n) log(n)), with \u03c9 such that two n \u00d7 n matrices over a field can be multiplied using O(n^\u03c9) field operations. By combining this result with classical randomized regularization techniques, we obtain faster Las Vegas algorithms for structured inversion and linear system solving.", "venue": "SIAM J. Matrix Anal. Appl.", "authors": ["Alin  Bostan", "Claude-Pierre  Jeannerod", "Christophe  Mouilleron", "\u00c9ric  Schost"], "year": 2017, "n_citations": 14}
{"id": 3131285, "s2_id": "566c9e3de7988baaaabc8824ffc6dc5bff48bc54", "title": "Computing Characteristic Polynomials of p-Curvatures in Average Polynomial Time", "abstract": "We design a fast algorithm that computes, for a given linear differential operator with coefficients in 918;[x], all the characteristic polynomials of its p-curvatures, for all primes p < N, in asymptoti- cally quasi-linear bit complexity in N. We discuss implementations and applications of our algorithm. We shall see in particular that the good performances of our algorithm are quickly visible.", "venue": "ISSAC", "authors": ["Raphael  Pages"], "year": 2021, "n_citations": 0}
{"id": 3133484, "s2_id": "8c4276c1a4a1f907f5c4c0d02af35c49f6e99277", "title": "Polynomial Circuit Verification using BDDs", "abstract": "Verification is one of the central tasks during circuit design. While most of the approaches have exponential worst-case behaviour, in the following techniques are discussed for proving polynomial circuit verification based on Binary Decision Diagrams (BDDs). It is shown that for circuits with specific structural properties, like e.g. tree-like circuits, and circuits based on multiplexers derived from BDDs complete formal verification can be carried out in polynomial time and space.", "venue": "ArXiv", "authors": ["Rolf  Drechsler"], "year": 2021, "n_citations": 0}
{"id": 3139727, "s2_id": "f546f1a230f7e1003546f6a7f3fa7ecfbd253220", "title": "Telescopers for rational and algebraic functions via residues", "abstract": "We show that the problem of constructing telescopers for rational functions of m + 1 variables is equivalent to the problem of constructing telescopers for algebraic functions of m variables and we present a new algorithm to construct telescopers for algebraic functions of two variables. These considerations are based on analyzing the residues of the input. According to experiments, the resulting algorithm for rational functions of three variables is faster than known algorithms, at least in some examples of combinatorial interest. The algorithm for algebraic functions implies a new bound on the order of the telescopers.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Manuel  Kauers", "Michael F. Singer"], "year": 2012, "n_citations": 41}
{"id": 3146565, "s2_id": "53c634d0f83c8ccc6e38f2e0a2c756a9366b7a14", "title": "Staging Human-computer Dialogs: An Application of the Futamura Projections", "abstract": "We demonstrate an application of the Futamura Projections to human-computer interaction, and particularly to staging human-computer dialogs. Specifically, by providing staging analogs to the classical Futamura Projections, we demonstrate that the Futamura Projections can be applied to the staging of human-computer dialogs in addition to the execution of programs.", "venue": "ArXiv", "authors": ["Brandon M. Williams", "Saverio  Perugini"], "year": 2018, "n_citations": 0}
{"id": 3146698, "s2_id": "645d44427932cd16759eb59039703aade96b88b1", "title": "Converting ALC Connection Proofs into ALC Sequents", "abstract": "The connection method has earned good reputation in the area of automated theorem proving, due to its simplicity, efficiency and rational use of memory. This method has been applied recently in automatic provers that reason over ontologies written in the description logic ALC. However, proofs generated by connection calculi are difficult to understand. Proof readability is largely lost by the transformations to disjunctive normal form applied over the formulae to be proven. Such a proof model, albeit efficient, prevents inference systems based on it from effectively providing justifications and/or descriptions of the steps used in inferences. To address this problem, in this paper we propose a method for converting matricial proofs generated by theALC connection method toALC sequent proofs, which are much easier to understand, and whose translation to natural language is more straightforward. We also describe a calculus that accepts the input formula in a non-clausal ALC format, what simplifies the translation.", "venue": "PxTP", "authors": ["Eunice Palmeira da Silva", "Frederico Luiz Gon\u00e7alves de Freitas", "Jens  Otten"], "year": 2019, "n_citations": 0}
{"id": 3149026, "s2_id": "0047ddc07b58512af88d83cccda0f6eb360e0f6f", "title": "Exploiting Knowledge Graphs for Facilitating Product/Service Discovery", "abstract": "Most of the existing techniques to product discovery rely on syntactic approaches, thus ignoring valuable and specific semantic information of the underlying standards during the process. The product data comes from different heterogeneous sources and formats giving rise to the problem of interoperability. Above all, due to the continuously increasing influx of data, the manual labeling is getting costlier. Integrating the descriptions of different products into a single representation requires organizing all the products across vendors in a single taxonomy. Practically relevant and quality product categorization standards are still limited in number; and that too in academic research projects where we can majorly see only prototypes as compared to industry. This work presents a cost-effective solution for e-commerce on the Data Web by employing an unsupervised approach for data classification and exploiting the knowledge graphs for matching. The proposed architecture describes available products in web ontology language OWL and stores them in a triple store. User input specifications for certain products are matched against the available product categories to generate a knowledge graph. This mullti-phased top-down approach to develop and improve existing, if any, tailored product recommendations will be able to connect users with the exact product/service of their choice.", "venue": "ArXiv", "authors": ["Sarika  Jain"], "year": 2020, "n_citations": 1}
{"id": 3153034, "s2_id": "9741cce23facd47cec4693aff828b726736beac4", "title": "An Algorithm for Computing Invariant Projectors in Representations of Wreath Products", "abstract": "We describe an algorithm for computing the complete set of primitive orthogonal idempotents in the centralizer ring of the permutation representation of a wreath product. This set of idempotents determines the decomposition of the representation into irreducible components. In the formalism of quantum mechanics, these idempotents are projection operators into irreducible invariant subspaces of the Hilbert space of a multipartite quantum system. The C implementation of the algorithm constructs irreducible decompositions of high-dimensional representations of wreath products. Examples of computations are given.", "venue": "CASC", "authors": ["Vladimir V. Kornyak"], "year": 2019, "n_citations": 1}
{"id": 3159832, "s2_id": "4ecde96a035907ecfdde864250e6f1dcd7486407", "title": "Power series solutions of singular (q)-differential equations", "abstract": "We provide algorithms computing power series solutions of a large class of differential or q-differential equations or systems. Their number of arithmetic operations grows linearly with the precision, up to logarithmic terms.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Bruno  Salvy", "Muhammad F. I. Chowdhury", "\u00c9ric  Schost", "Romain  Lebreton"], "year": 2012, "n_citations": 8}
{"id": 3160418, "s2_id": "dde39d99c3492be6964f0efa7d7115c263ec08dc", "title": "Algebraic Problems Equivalent to Beating Exponent 3/2 for Polynomial Factorization over Finite Fields", "abstract": "The fastest known algorithm for factoring univariate polynomials over finite fields is the Kedlaya-Umans (fast modular composition) implementation of the Kaltofen-Shoup algorithm. It is randomized and takes $\\widetilde{O}(n^{3/2}\\log q + n \\log^2 q)$ time to factor polynomials of degree $n$ over the finite field $\\mathbb{F}_q$ with $q$ elements. A significant open problem is if the $3/2$ exponent can be improved. We study a collection of algebraic problems and establish a web of reductions between them. A consequence is that an algorithm for any one of these problems with exponent better than $3/2$ would yield an algorithm for polynomial factorization with exponent better than $3/2$.", "venue": "MFCS", "authors": ["Zeyu  Guo", "Anand Kumar Narayanan", "Christopher  Umans"], "year": 2016, "n_citations": 1}
{"id": 3164209, "s2_id": "5a1f07f2f1a7863f7d3c70853579c95b4da53371", "title": "Compiling LATEX to computer algebra-enabled HTML5", "abstract": "This document explains how to create or modify an existing LATEX document with commands enabling computations in the HTML5 output: when the reader opens the HTML5 output, he can run a computation in his browser, or modify the command to be executed and run it. This is done by combining different softwares: hevea for compilation to HTML5, giac.js for the CAS computing kernel (itself compiled from the C++ Giac library with emscripten), and a modified version of itex2MML for fast and nice rendering in MathML in browsers that support MathML.", "venue": "ArXiv", "authors": ["Bernard  Parisse"], "year": 2017, "n_citations": 0}
{"id": 3166754, "s2_id": "a72c23b2adde7155b8887df96370683bc4c1b33f", "title": "SATURN - Software Deobfuscation Framework Based On LLVM", "abstract": "The strength of obfuscated software has increased over the recent years. Compiler based obfuscation has become the de facto standard in the industry and recent papers also show that injection of obfuscation techniques is done at the compiler level. In this paper we discuss a generic approach for deobfuscation and recompilation of obfuscated code based on the compiler framework LLVM. We show how binary code can be lifted back into the compiler intermediate language LLVM-IR and explain how we recover the control flow graph of an obfuscated binary function with an iterative control flow graph construction algorithm based on compiler optimizations and satisfiability modulo theories (SMT) solving. Our approach does not make any assumptions about the obfuscated code, but instead uses strong compiler optimizations available in LLVM and Souper Optimizer to simplify away the obfuscation. Our experimental results show that this approach can be effective to weaken or even remove the applied obfuscation techniques like constant unfolding, certain arithmetic-based opaque expressions, dead code insertions, bogus control flow or integer encoding found in public and commercial obfuscators. The recovered LLVM-IR can be further processed by custom deobfuscation passes that are now applied at the same level as the injected obfuscation techniques or recompiled with one of the available LLVM backends. The presented work is implemented in a deobfuscation tool called SATURN.", "venue": "SPRO@CCS", "authors": ["Peter  Garba", "Matteo  Favaro"], "year": 2019, "n_citations": 10}
{"id": 3167635, "s2_id": "0a79cce916dd5883f46184f7ff055725fc1cc5c8", "title": "A Sparse Resultant Based Method for Efficient Minimal Solvers", "abstract": "Many computer vision applications require robust and efficient estimation of camera geometry. The robust estimation is usually based on solving camera geometry problems from a minimal number of input data measurements, i.e. solving minimal problems in a RANSAC framework. Minimal problems often result in complex systems of polynomial equations. Many state-of-the-art efficient polynomial solvers to these problems are based on Gr\u00f6bner basis and the action-matrix method that has been automatized and highly optimized in recent years. In this paper we study an alternative algebraic method for solving systems of polynomial equations, i.e., the sparse resultant-based method and propose a novel approach to convert the resultant constraint to an eigenvalue problem. This technique can significantly improve the efficiency and stability of existing resultant-based solvers. We applied our new resultant-based method to a large variety of computer vision problems and show that for most of the considered problems, the new method leads to solvers that are the same size as the the best available Gr\u00f6bner basis solvers and of similar accuracy. For some problems the new sparse-resultant based method leads to even smaller and more stable solvers than the state-of-the-art Gr\u00f6bner basis solvers. Our new method can be fully automatized and incorporated into existing tools for automatic generation of efficient polynomial solvers and as such it represents a competitive alternative to popular Gr\u00f6bner basis methods for minimal problems in computer vision.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Snehal  Bhayani", "Zuzana  Kukelova", "Janne  Heikkil\u00e4"], "year": 2020, "n_citations": 6}
{"id": 3168764, "s2_id": "a444452e8ff66d8bfa2a275c7e05c00b9c9ba6d2", "title": "Model Checking Regular Language Constraints", "abstract": "Even the fastest SMT solvers have performance problems with regular expressions from real programs. Because these performance issues often arise from the problem representation (e.g. non-deterministic finite automata get determinized and regular expressions get unrolled), we revisit Boolean finite automata, which allow for the direct and natural representation of any Boolean combination of regular languages. By applying the IC3 model checking algorithm to Boolean finite automata, not only can we efficiently answer emptiness and universality problems, but through an extension, we can decide satisfiability of multiple variable string membership problems. We demonstrate the resulting system's effectiveness on a number of popular benchmarks and regular expressions.", "venue": "ArXiv", "authors": ["Arlen  Cox", "Jason  Leasure"], "year": 2017, "n_citations": 4}
{"id": 3178868, "s2_id": "bfad9d86d3c0c9d1bb34bd00430564e972194951", "title": "A Simple Rederivation of Onsager\u2019s Solution of the 2D Ising Model Using Experimental Mathematics", "abstract": "In this case study, we illustrate the great potential of experimental mathematics and symbolic computation, by rederiving, ab initio, Onsager's celebrated solution of the twodimensional Ising model in zero magnetic field. Onsager's derivation is extremely complicated and ad hoc, as are all the subsequent proofs. Unlike Onsager's, our derivation is not rigorous, yet it is absolutely certain (even if Onsager did not do it before), and should have been acceptable to physicists who do not share mathematicians' fanatical (and often misplaced) insistence on rigor.", "venue": "The Mathematical Intelligencer", "authors": ["Manuel  Kauers", "Doron  Zeilberger"], "year": 2018, "n_citations": 1}
{"id": 3181228, "s2_id": "cbbf529205b3f55c34c83030a631eebd16b07b84", "title": "A Fast Approach to Creative Telescoping", "abstract": "In this note we reinvestigate the task of computing creative telescoping relations in differential\u2013difference operator algebras. Our approach is based on an ansatz that explicitly includes the denominators of the delta parts. We contribute several ideas of how to make an implementation of this approach reasonably fast and provide such an implementation. A selection of examples shows that it can be superior to existing methods by a large factor.", "venue": "Math. Comput. Sci.", "authors": ["Christoph  Koutschan"], "year": 2010, "n_citations": 72}
{"id": 3191795, "s2_id": "cef81f5d166d6398b948a4ead5fb2ef1a8b35fe5", "title": "Degree bound for toric envelope of a linear algebraic group", "abstract": "Algorithms working with linear algebraic groups often represent them via defining polynomial equations. One can always choose defining equations for an algebraic group to be of the degree at most the degree of the group as an algebraic variety. However, the degree of a linear algebraic group $G \\subset \\mathrm{GL}_n(C)$ can be arbitrarily large even for $n = 1$. One of the key ingredients of Hrushovski's algorithm for computing the Galois group of a linear differential equation was an idea to `approximate' every algebraic subgroup of $\\mathrm{GL}_n(C)$ by a `similar' group so that the degree of the latter is bounded uniformly in $n$. Making this uniform bound computationally feasible is crucial for making the algorithm practical. \nIn this paper, we derive a single-exponential degree bound for such an approximation (we call it toric envelope), which is qualitatively optimal. As an application, we improve the quintuply exponential bound for the first step of the Hrushovski's algorithm due to Feng to a single-exponential bound. For the cases $n = 2, 3$ often arising in practice, we further refine our general bound.", "venue": "ArXiv", "authors": ["Eli  Amzallag", "Andrei  Minchenko", "Gleb  Pogudin"], "year": 2018, "n_citations": 4}
{"id": 3203925, "s2_id": "d862dd0b1499137d2b6d2e2e18414708dea5eb95", "title": "Formal proof of SCHUR conjugate function", "abstract": "The main goal of our work is to formally prove the correctness of the key commands of the SCHUR software, an interactive program for calculating with characters of Lie groups and symmetric functions. The core of the computations relies on enumeration and manipulation of combinatorial structures. As a first \"proof of concept\", we present a formal proof of the conjugate function, written in C. This function computes the conjugate of an integer partition. To formally prove this program, we use the Frama-C software. It allows us to annotate C functions and to generate proof obligations, which are proved using several automated theorem provers. In this paper, we also draw on methodology, discussing on how to formally prove this kind of program.", "venue": "AISC'10/MKM'10/Calculemus'10", "authors": ["Franck  Butelle", "Florent  Hivert", "Micaela  Mayero", "Fr\u00e9d\u00e9ric  Toumazet"], "year": 2010, "n_citations": 6}
{"id": 3205500, "s2_id": "9ffec83b33713e30bf42727567f3cf9761db339f", "title": "ACD Term Rewriting", "abstract": "In this paper we introduce Associative Commutative Distributive Term Rewriting (ACDTR), a rewriting language for rewriting logical formulae. ACDTR extends AC term rewriting by adding distribution of conjunction over other operators. Conjunction is vital for expressive term rewriting systems since it allows us to require that multiple conditions hold for a term rewriting rule to be used. ACDTR uses the notion of a \u201cconjunctive context\u201d, which is the conjunction of constraints that must hold in the context of a term, to enable the programmer to write very expressive and targeted rewriting rules. ACDTR can be seen as a general logic programming language that extends Constraint Handling Rules and AC term rewriting. In this paper we define the semantics of ACDTR and describe our prototype implementation.", "venue": "ICLP", "authors": ["Gregory J. Duck", "Peter J. Stuckey", "Sebastian  Brand"], "year": 2006, "n_citations": 30}
{"id": 3215973, "s2_id": "877146a2c988a6bc8184c76a094e6442785b2a97", "title": "Parametric Toricity of Steady State Varieties of Reaction Networks", "abstract": "We study real steady state varieties of the dynamics of chemical reaction networks. The dynamics are derived using mass action kinetics with parametric reaction rates. The models studied are not inherently parametric in nature. Rather, our interest in parameters is motivated by parameter uncertainty, as reaction rates are typically either measures with limited precision or estimated. We aim at detecting toricity and shifted toricity, using a framework that has been recently introduced and studied for the non-parametric case over both the reals and the complex numbers. While toricity requires that the variety specifies a subgroup of the direct power of the multiplicative group of the underlying field, shifted toricity requires only a coset. In the presence of parameters, we are not faced with decision problems anymore. Instead, we derive necessary and sufficient conditions in the parameters for toricity or shifted toricity to hold. Technically, we use real quantifier elimination methods. Our computations on biological networks here once more confirm shifted toricity as a relevant concept, while toricity holds only for degenerate parameter choices.", "venue": "CASC", "authors": ["Hamid  Rahkooy", "Thomas  Sturm"], "year": 2021, "n_citations": 0}
{"id": 3217510, "s2_id": "163ad562ced7246a9dc034397d5940b577167168", "title": "The fundamental invariants of 3 x 3 x 3 arrays", "abstract": "We determine the three fundamental invariants in the entries of a $3 \\times 3 \\times 3$ array over $\\mathbb{C}$ as explicit polynomials in the 27 variables $x_{ijk}$ for $1 \\le i, j, k \\le 3$. By the work of Vinberg on $\\theta$-groups, it is known that these homogeneous polynomials have degrees 6, 9 and 12; they freely generate the algebra of invariants for the Lie group $SL_3(\\mathbb{C}) \\times SL_3(\\mathbb{C}) \\times SL_3(\\mathbb{C})$ acting irreducibly on its natural representation $\\mathbb{C}^3 \\otimes \\mathbb{C}^3 \\otimes \\mathbb{C}^3$. These generators have respectively 1152, 9216 and 209061 terms; we find compact expressions in terms of the orbits of the finite group $(S_3 \\times S_3 \\times S_3) \\rtimes S_3$ acting on monomials of weight zero for the action of the Lie algebra $\\mathfrak{sl}_3(\\mathbb{C}) \\oplus \\mathfrak{sl}_3(\\mathbb{C}) \\oplus \\mathfrak{sl}_3(\\mathbb{C})$.", "venue": "ArXiv", "authors": ["Murray R. Bremner", "Jiaxiong  Hu"], "year": 2011, "n_citations": 1}
{"id": 3221785, "s2_id": "7e6cfd361468d8c6c7dac035d4b132c38bc207d8", "title": "Search and test algorithms for triple product property triples", "abstract": "Abstract. In 2003 Cohn and Umans introduced a group-theoretic approach to fast matrix multiplication. This involves finding large subsets of a group satisfying the triple product property (TPP) as a means to bound the exponent of matrix multiplication. We present two new characterizations of the TPP, which are used for theoretical considerations and for TPP test algorithms. We describe the algorithms for all known TPP tests and present the runtime differences between their GAP implementations. We prove that the search for non-trivial-sized TPP triples of subgroups of a given group can be restricted to the set of its non-normal subgroups, and apply this, together with other preconditions, to describe brute-force search algorithms for largest-sized TPP triples of subgroups and subsets. In addition we present the results of the subset brute-force search for all groups of order up to 32 and selected results of the subgroup brute-force search for 2-groups, and . Our results for the groups and suggest tentative answers to certain questions posed by Cohn and Umans.", "venue": "Groups Complex. Cryptol.", "authors": ["Ivo  Hedtke", "Sandeep  Murthy"], "year": 2012, "n_citations": 11}
{"id": 3223390, "s2_id": "a88f29e0dbacd705f2d5611c7eac8e0c583a71e1", "title": "A Note on the DQ Analysis of Anisotropic Plates", "abstract": "Recently, Bert, Wang and Striz [1, 2] applied the differential quadrature (DQ) and harmonic differential quadrature (HDQ) methods to analyze static and dynamic behaviors of anisotropic plates. Their studies showed that the methods were conceptually simple and computationally efficient in comparison to other numerical techniques. Based on some recent work by the present author [3, 4], the purpose of this note is to further simplify the formulation effort and improve computing efficiency in applying the DQ and HDQ methods for these cases.", "venue": "ArXiv", "authors": ["W.  Chen", "Weixing  He", "Tingxiu  Zhong"], "year": 2002, "n_citations": 9}
{"id": 3223437, "s2_id": "5086c85d15e363f3352a138457695b7e2ddf22fd", "title": "Automatic Differentiation of Algorithms for Machine Learning", "abstract": "Automatic differentiation---the mechanical transformation of numeric computer programs to calculate derivatives efficiently and accurately---dates to the origin of the computer age. Reverse mode automatic differentiation both antedates and generalizes the method of backwards propagation of errors used in machine learning. Despite this, practitioners in a variety of fields, including machine learning, have been little influenced by automatic differentiation, and make scant use of available tools. Here we review the technique of automatic differentiation, describe its two main modes, and explain how it can benefit machine learning practitioners. To reach the widest possible audience our treatment assumes only elementary differential calculus, and does not assume any knowledge of linear algebra.", "venue": "ArXiv", "authors": ["Atilim Gunes Baydin", "Barak A. Pearlmutter"], "year": 2014, "n_citations": 25}
{"id": 3225113, "s2_id": "a2e38e53cd79e706938a1b7b3e071fba5f058f7a", "title": "Improvement Of Barreto-Voloch Algorithm For Computing $r$th Roots Over Finite Fields", "abstract": "AbstractRoot extraction is a classical problem in computers algebra. It plays an essentialrole in cryptosystems based on elliptic curves. In 2006, Barreto and Voloch proposedan algorithm to compute rth roots in F q m for certain choices of m and q. If r||q \u22121 and (m,r) = 1, they proved that the complexity of their method is Oe(r(logm +loglogq)mlogq). In this paper, we extend the Barreto-Voloch algorithm to the generalcase that r||q m \u2212 1, without the restrictions r||q \u2212 1 and (m,r) = 1. We also specifythe conditions that the Barreto-Voloch algorithm can be preferably applied.Keywords: root extraction; Barreto-Voloch algorithm; Adleman-Manders-Miller al-gorithm 1 Introduction Consider the problem to \ufb01nd a solution to X r = \u03b4 in F q m , where q = p d for some prime pand some integer d > 0. Clearly, it su\ufb03ces to consider the following two cases:(1) (r,q m \u22121) = 1, (2) r|q m \u22121Root extraction is a classical problem in computational algebra and number theory. Itplays an essential role in cryptosystems based on elliptic curves. The typical applications ofroot extraction are point compression in elliptic curves and operation of hashing onto ellipticcurves [3, 4, 9].1", "venue": "ArXiv", "authors": ["Zhengjun  Cao", "Xiao  Fan"], "year": 2011, "n_citations": 0}
{"id": 3225458, "s2_id": "909616c0a3c4d05d30f4090785f4d87d6248109b", "title": "Enumeration of Complex Golay Pairs via Programmatic SAT", "abstract": "We provide a complete enumeration of all complex Golay pairs of length up to 25, verifying that complex Golay pairs do not exist in lengths 23 and 25 but do exist in length 24. This independently verifies work done by F. Fiedler in 2013 that confirms the 2002 conjecture of Craigen, Holzmann, and Kharaghani that complex Golay pairs of length 23 don't exist. Our enumeration method relies on the recently proposed SAT+CAS paradigm of combining computer algebra systems with SAT solvers to take advantage of the advances made in the fields of symbolic computation and satisfiability checking. The enumeration proceeds in two stages: First, we use a fine-tuned computer program and functionality from computer algebra systems to construct a list containing all sequences which could appear as the first sequence in a complex Golay pair (up to equivalence). Second, we use a programmatic SAT solver to construct all sequences (if any) that pair off with the sequences constructed in the first stage to form a complex Golay pair.", "venue": "ISSAC", "authors": ["Curtis  Bright", "Ilias S. Kotsireas", "Albert  Heinle", "Vijay  Ganesh"], "year": 2018, "n_citations": 13}
{"id": 3226608, "s2_id": "34e7483ad8cfcca5de72d4d7c137ffcced59d77b", "title": "Rational Hadamard products via Quantum Diagonal Operators", "abstract": "We use the remark that, through Bargmann-Fock representation, diagonal operators of the Heisenberg-Weyl algebra are scalars for the Hadamard product to give some properties (like the stability of periodic fonctions) of the Hadamard product by a rational fraction. In particular, we provide through this way explicit formulas for the multiplication table of the Hadamard product in the algebra of rational functions in $\\C[[z]]$.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Silvia  Goodenough", "Karol A. Penson"], "year": 2008, "n_citations": 0}
{"id": 3228722, "s2_id": "455ecd83a9dc97169ae2bf1ed86d23b6690c5763", "title": "About a conjectured basis for Multiple Zeta Values", "abstract": "We confirm a conjecture about the construction of basis elements for the multiple zeta values (MZVs) at weight 27 and weight 28. Both show as expected one element that is twofold extended. This is done with some lengthy computer algebra calculations using TFORM to determine explicit bases for the MZVs at these weights.", "venue": "ArXiv", "authors": ["Jan  Kuipers", "J. A. M. Vermaseren"], "year": 2011, "n_citations": 2}
{"id": 3233187, "s2_id": "94b289a2656679af42e9b98a5f233c465a047611", "title": "Algebraic Analysis of Rotation Data", "abstract": "We develop algebraic tools for statistical inference from samples of rotation matrices. This rests on the theory of D-modules in algebraic analysis. Noncommutative Grobner bases are used to design numerical algorithms for maximum likelihood estimation, building on the holonomic gradient method of Sei, Shibata, Takemura, Ohara, and Takayama. We study the Fisher model for sampling from rotation matrices, and we apply our algorithms for data from the applied sciences. On the theoretical side, we generalize the underlying equivariant D-modules from SO(3) to arbitrary Lie groups. For compact groups, our D-ideals encode the normalizing constant of the Fisher model.", "venue": "ArXiv", "authors": ["Michael F. Adamer", "Andr\u00e1s C. Lorincz", "Anna-Laura  Sattelberger", "Bernd  Sturmfels"], "year": 2019, "n_citations": 3}
{"id": 3236021, "s2_id": "9adf4c646ff52befcafc75b604e158f767eb1e5f", "title": "Computing the Characteristic Polynomial of a Finite Rank Two Drinfeld Module", "abstract": "Motivated by finding analogues of elliptic curve point counting techniques, we introduce one deterministic and two new Monte Carlo randomized algorithms to compute the characteristic polynomial of a finite rank-two Drinfeld module. We compare their asymptotic complexity to that of previous algorithms given by Gekeler, Narayanan and Garai-Papikian and discuss their practical behavior. In particular, we find that all three approaches represent either an improvement in complexity or an expansion of the parameter space over which the algorithm may be applied. Some experimental results are also presented.", "venue": "ISSAC", "authors": ["Yossef  Musleh", "\u00c9ric  Schost"], "year": 2019, "n_citations": 1}
{"id": 3249535, "s2_id": "d2c611e8814701f4952b7b1b273c42838dc1a481", "title": "A Geometric Index Reduction Method for Implicit Systems of Differential Algebraic Equations", "abstract": "This paper deals with the index reduction problem for the class of quasi-regular DAE systems. It is shown that any of these systems can be transformed to a generically equivalent first order DAE system consisting of a single purely algebraic (polynomial) equation plus an under-determined ODE (a differential Kronecker representation) in as many variables as the order of the input system. This can be done by means of a Kronecker-type algorithm with bounded complexity.", "venue": "J. Symb. Comput.", "authors": ["Lisi  D'Alfonso", "Gabriela  Jeronimo", "Fran\u00e7ois  Ollivier", "Alexandre  Sedoglavic", "Pablo  Solern\u00f3"], "year": 2011, "n_citations": 8}
{"id": 3250141, "s2_id": "9448721ba472536547731dc19de36413b6f933ad", "title": "Splitting quaternion algebras over quadratic number fields", "abstract": "We propose an algorithm for finding zero divisors in quaternion algebras over quadratic number fields, or equivalently, solving homogeneous quadratic equations in three variables over $\\mathbb{Q}(\\sqrt{d})$ where $d$ is a square-free integer. The algorithm is deterministic and runs in polynomial time if one is allowed to call oracles for factoring integers and polynomials over finite fields.", "venue": "J. Symb. Comput.", "authors": ["P\u00e9ter  Kutas"], "year": 2019, "n_citations": 3}
{"id": 3251493, "s2_id": "f74d66ffaeaa2d34aea42b54eaa9cbf25eda571b", "title": "Intrinsic complexity estimates in polynomial optimization", "abstract": "It is known that point searching in basic semialgebraic sets and the search for globally minimal points in polynomial optimization tasks can be carried out using $(s\\,d)^{O(n)}$ arithmetic operations, where $n$ and $s$ are the numbers of variables and constraints and $d$ is the maximal degree of the polynomials involved.\\spar \\noindent We associate to each of these problems an intrinsic system degree which becomes in worst case of order $(n\\,d)^{O(n)}$ and which measures the intrinsic complexity of the task under consideration.\\spar \\noindent We design non-uniformly deterministic or uniformly probabilistic algorithms of intrinsic, quasi-polynomial complexity which solve these problems.", "venue": "J. Complex.", "authors": ["Bernd  Bank", "Marc  Giusti", "Joos  Heintz", "Mohab Safey El Din"], "year": 2014, "n_citations": 19}
{"id": 3251837, "s2_id": "f550d7f5deb5f83bcd375c986b8b3fee5f42678e", "title": "Probing the Natural Language Inference Task with Automated Reasoning Tools", "abstract": "The Natural Language Inference (NLI) task is an important task in modern NLP, as it asks a broad question to which many other tasks may be reducible: Given a pair of sentences, does the first entail the second? Although the state-of-the-art on current benchmark datasets for NLI are deep learning-based, it is worthwhile to use other techniques to examine the logical structure of the NLI task. We do so by testing how well a machine-oriented controlled natural language (Attempto Controlled English) can be used to parse NLI sentences, and how well automated theorem provers can reason over the resulting formulae. To improve performance, we develop a set of syntactic and semantic transformation rules. We report their performance, and discuss implications for NLI and logic-based NLP.", "venue": "FLAIRS Conference", "authors": ["Zaid  Marji", "Animesh  Nighojkar", "John  Licato"], "year": 2020, "n_citations": 2}
{"id": 3253658, "s2_id": "48accde68ebc9113a825ef923a6ee8714c35b796", "title": "Hybrid system modelling and simulation with Dirac deltas", "abstract": "For a wide variety of problems, creating detailed continuous models of physical systems is impractical. Hybrid models can abstract away short transient behaviour in order to simplify the study of such systems. For example, when modelling a bouncing ball, the bounce can be abstracted as a discontinuous change of the velocity. Impulsive differential equations can be used to model and simulate hybrid systems such as the bouncing ball. In this approach, the force acted on the ball by the floor is abstracted as an impulse. Current simulators cannot handle such approximations well due to the limitations of machine precision. \n \nIn this paper, we present two approaches for the simulation of impulses: symbolic and numerical. Our contribution is a theoretically founded description of both approaches in a Causal Block Diagram simulator, and an analysis of the conditions for which a symbolic approach is better than a numerical one.", "venue": "SpringSim", "authors": ["Cl\u00e1udio  Gomes", "Yentl Van Tendeloo", "Joachim  Denil", "Paul De Meulenaere", "Hans  Vangheluwe"], "year": 2017, "n_citations": 6}
{"id": 3258283, "s2_id": "a6fa735350897faf9b0ebd98b9e237b26058dc6c", "title": "Hermite reduction and creative telescoping for hyperexponential functions", "abstract": "We present a new reduction algorithm that simultaneously extends Hermite's reduction for rational functions and the Hermite-like reduction for hyperexponential functions. It yields a unique additive decomposition that allows to decide hyperexponential integrability. Based on this reduction algorithm, we design a new algorithm to compute minimal telescopers for bivariate hyperexponential functions. One of its main features is that it can avoid the costly computation of certificates. Its implementation outperforms Maple's function DEtools[Zeilberger]. We also derive an order bound on minimal telescopers that is tighter than the known ones.", "venue": "ISSAC '13", "authors": ["Alin  Bostan", "Shaoshi  Chen", "Fr\u00e9d\u00e9ric  Chyzak", "Ziming  Li", "Guoce  Xin"], "year": 2013, "n_citations": 52}
{"id": 3258700, "s2_id": "fd512434ba201fffe9233da78ca810947539a6b1", "title": "Measured Multiseries and Integration", "abstract": "A paper by Bruno Salvy and the author introduced measured multiseries and gave an algorithm to compute these for a large class of elementary functions, modulo a zero-equivalence method for constants. This gave a theoretical background for the implementation that Salvy was developing at that time. The main result of the present article is an algorithm to calculate measured multiseries for integrals of functions of the form h*sin G, where h and G belong to a Hardy field. The process can reiterated with the resulting algebra, and also applied to solutions of a second order differential equation of a particular form.", "venue": "ArXiv", "authors": ["John  Shackell"], "year": 2017, "n_citations": 0}
{"id": 3263180, "s2_id": "96ccf0a01ee103881bc9aad6a1aa56f17f10f337", "title": "Counting invariant subspaces and decompositions of additive polynomials", "abstract": "The functional (de)composition of polynomials is a topic in pure and computer algebra with many applications. The structure of decompositions of (suitably normalized) polynomials f(x) = g(h(x)) in F[x] over a field F is well understood in many cases, but less well when the degree of f is divisible by the positive characteristic p of F. This work investigates the decompositions of r-additive polynomials, where every exponent and also the field size is a power of r, which itself is a power of p. \nThe decompositions of an r-additive polynomial f are intimately linked to the Frobenius-invariant subspaces of its root space V in the algebraic closure of F. We present an efficient algorithm to compute the rational Jordan form of the Frobenius automorphism on V. A formula of Fripertinger (2011) then counts the number of Frobenius-invariant subspaces of a given dimension and we derive the number of decompositions with prescribed degrees.", "venue": "J. Symb. Comput.", "authors": ["Joachim von zur Gathen", "Mark  Giesbrecht", "Konstantin  Ziegler"], "year": 2021, "n_citations": 0}
{"id": 3263567, "s2_id": "f54aabd44509278f190715318026b8633bab6a5f", "title": "On Fast Matrix Inversion via Fast Matrix Multiplication", "abstract": "Volker Strassen first suggested an algorithm to multiply matrices with worst case running time less than the conventional $\\mathcal{O}(n^3)$ operations in 1969. He also presented a recursive algorithm with which to invert matrices, and calculate determinants using matrix multiplication. James R. Bunch & John E. Hopcroft improved upon this in 1974 by providing modifications to the inversion algorithm in the case where principal submatrices were singular, amongst other improvements. We cover the case of multivariate polynomial matrix inversion, where it is noted that conventional methods that assume a field will experience major setbacks. Initially, the author and others published a presentation of a fraction free formulation of inversion via matrix multiplication along with motivations, however analysis of this presentation was rudimentary. We hence provide a discussion of the true complexities of this fraction free method arising from matrix multiplication, and arrive at its limitations.", "venue": "ArXiv", "authors": ["Zak  Tonks"], "year": 2019, "n_citations": 0}
{"id": 3269749, "s2_id": "1554ed45673fd330e18934eb8961d6eb2b45437b", "title": "New data structure for univariate polynomial approximation and applications to root isolation, numerical multipoint evaluation, and other problems", "abstract": "We present a new data structure to approximate accurately and efficiently a polynomial f of degree d given as a list of coefficients. Its properties allow us to improve the state-of-the-art bounds on the bit complexity for the problems of root isolation and approximate multipoint evaluation. This data structure also leads to a new geometric criterion to detect ill-conditioned polynomials, implying notably that the standard condition number of the zeros of a polynomial is at least exponential in the number of roots of modulus less than 1/2 or greater than 2. Given a polynomial f of degree d with \u2016f\u20161 \u2264 2 for \u03c4 \u2265 1, isolating all its complex roots or evaluating it at d points can be done with a quasi-linear number of arithmetic operations. However, considering the bit complexity, the state-of-the-art algorithms require at least d bit operations even for well-conditioned polynomials and when the accuracy required is low. Given a positive integer m, we can compute our new data structure and evaluate f at d points in the unit disk with an absolute error less than 2\u2212m in \u00d5(d(\u03c4 +m)) bit operations, where \u00d5(\u00b7) means that we omit logarithmic factors. We also show that if \u03ba is the absolute condition number of the zeros of f , then we can isolate all the roots of f in \u00d5(d(\u03c4 + log \u03ba)) bit operations. Moreover, our algorithms are simple to implement. For approximating the complex roots of a polynomial, we implemented a small prototype in Python/NumPy that is an order of magnitude faster than the state-of-the-art solver MPSolve for high degree polynomials with random coefficients.", "venue": "ArXiv", "authors": ["Guillaume  Moroz"], "year": 2021, "n_citations": 0}
{"id": 3279447, "s2_id": "cb9cf7d03717d8b678b5ddc462a02a83ca3d8164", "title": "Computing All Space Curve Solutions of Polynomial Systems by Polyhedral Methods", "abstract": "A polyhedral method to solve a system of polynomial equations exploits its sparse structure via the Newton polytopes of the polynomials. We propose a hybrid symbolic-numeric method to compute a Puiseux series expansion for every space curve that is a solution of a polynomial system. The focus of this paper concerns the difficult case when the leading powers of the Puiseux series of the space curve are contained in the relative interior of a higher dimensional cone of the tropical prevariety. We show that this difficult case does not occur for polynomials with generic coefficients. To resolve this case, we propose to apply polyhedral end games to recover tropisms hidden in the tropical prevariety.", "venue": "CASC", "authors": ["Nathan  Bliss", "Jan  Verschelde"], "year": 2016, "n_citations": 1}
{"id": 3281119, "s2_id": "c00c6f8cf428cd21856016b6ba2388e57c40836c", "title": "Computation of unirational fields", "abstract": "One of the main contributions which Volker Weispfenning made to mathematics is related to Grobner bases theory. In this paper we present an algorithm for computing all algebraic intermediate subfields in a separably generated unirational field extension (which in particular includes the zero characteristic case). One of the main tools is Grobner bases theory. Our algorithm also requires computing primitive elements and factoring over algebraic extensions. Moreover, the method can be extended to finitely generated -algebras.", "venue": "J. Symb. Comput.", "authors": ["Jaime  Gutierrez", "David  Sevilla"], "year": 2005, "n_citations": 9}
{"id": 3283914, "s2_id": "0f7e1c72cbeb34dbea6824fa571818618a01c0c9", "title": "Algorithm for computing semi-Fourier sequences of expressions involving exponentiations and integrations", "abstract": "We provide an algorithm for computing semi-Fourier sequences for expressions constructed from arithmetic operations, exponentiations and integrations. The semi-Fourier sequence is a relaxed version of Fourier sequence for polynomials (expressions made of additions and multiplications).", "venue": "ArXiv", "authors": ["Hoon  Hong", "Adam W. Strzebonski"], "year": 2017, "n_citations": 0}
{"id": 3287559, "s2_id": "e5295fce5fbe967c2ac9278410c36a9b8a694d3e", "title": "MACE 2.0 Reference Manual and Guide", "abstract": "MACE is a program that searches for finite models of first-order statements. The statement to be modeled is first translated to clauses, then to relational clauses; finally for the given domain size, the ground instances are constructed. A Davis-Putnam-Loveland-Logeman procedure decides the propositional problem, and any models found are translated to first-order models. MACE is a useful complement to the theorem prover Otter, with Otter searching for proofs and MACE looking for countermodels.", "venue": "ArXiv", "authors": ["William  McCune"], "year": 2001, "n_citations": 76}
{"id": 3288262, "s2_id": "8da746961e32ebdda7b0996b847d4398a6d5e6f0", "title": "Computation of the Similarity Class of the p-Curvature", "abstract": "The p-curvature of a system of linear differential equations in positive characteristic p is a matrix that measures how far the system is from having a basis of polynomial solutions. We show that the similarity class of the p-curvature can be determined without computing the p-curvature itself. More precisely, we design an algorithm that computes the invariant factors of the p-curvature in time quasi-linear in \u221a p. This is much less than the size of the p-curvature, which is generally linear in p. The new algorithm allows to answer a question originating from the study of the Ising model in statistical physics.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Xavier  Caruso", "\u00c9ric  Schost"], "year": 2016, "n_citations": 5}
{"id": 3298268, "s2_id": "e8a8f08fc0b5a5fa9d92367d8a20c4a86c093df4", "title": "Faster integer and polynomial multiplication using cyclotomic coefficient rings", "abstract": "We present an algorithm that computes the product of two n-bit integers in O(n log n (4\\sqrt 2)^{log^* n}) bit operations. Previously, the best known bound was O(n log n 6^{log^* n}). We also prove that for a fixed prime p, polynomials in F_p[X] of degree n may be multiplied in O(n log n 4^{log^* n}) bit operations; the previous best bound was O(n log n 8^{log^* n}).", "venue": "ArXiv", "authors": ["David  Harvey", "Joris van der Hoeven"], "year": 2017, "n_citations": 12}
{"id": 3300867, "s2_id": "efba62d5cc04c1dffcd375db81349aef7061687a", "title": "Stable normal forms for polynomial system solving", "abstract": "The paper describes and analyzes a method for computing border bases of a zero-dimensional ideal I. The criterion used in the computation involves specific commutation polynomials, and leads to an algorithm and an implementation extending the ones in [B. Mourrain, Ph. Trebuchet, Generalised normal forms and polynomial system solving, in: M. Kauers (Ed.), Proc. Intern. Symp. on Symbolic and Algebraic Computation, ACM Press, New-York, 2005, pp. 253-260]. This general border basis algorithm weakens the monomial ordering requirement for Grobner bases computations. It is currently the most general setting for representing quotient algebras, embedding into a single formalism Grobner bases, Macaulay bases and a new representation that does not fit into the previous categories. With this formalism, we show how the syzygies of the border basis are generated by commutation relations. We also show that our construction of normal form is stable under small perturbations of the ideal, if the number of solutions remains constant. This feature has a huge impact on practical efficiency, as illustrated by the experiments on classical benchmark polynomial systems, at the end of the paper.", "venue": "Theor. Comput. Sci.", "authors": ["Bernard  Mourrain", "Philippe  Trebuchet"], "year": 2008, "n_citations": 36}
{"id": 3301609, "s2_id": "a55dd6dda477c6898b6ab04d200050ac2095fa3e", "title": "Solution of a System of Linear Equations in an Integral Ring", "abstract": "A modified Gauss's algorithm for solving a system of linear equations in an integral ring is proposed, as well as an appropriate algorithm for calculating the elements of the adjoint matrix.", "venue": "ArXiv", "authors": ["Gennadi I. Malaschonok"], "year": 2017, "n_citations": 0}
{"id": 3303913, "s2_id": "2d8bfb62de61394b6ef52bcb281ef8d9443ec29a", "title": "Proof-of-work certificates that can be efficiently computed in the cloud", "abstract": "In an emerging computing paradigm, computational capabilities, from processing power to storage capacities, are offered to users over communication networks as a cloud-based service. There, demanding computations are outsourced in order to limit infrastructure costs.", "venue": "CASC", "authors": ["Jean-Guillaume  Dumas"], "year": 2018, "n_citations": 3}
{"id": 3304378, "s2_id": "acb0dc3604ecbca6f1ec043bb690426f9e5b9248", "title": "Implicitization of bihomogeneous parametrizations of algebraic surfaces via linear syzygies", "abstract": "We show that the implicit equation of a surface in 3-dimensional projective space parametrized by bi-homogeneous polynomials of bi-degree (d,d)for a given integer d \u22651 can be represented and computed from the linear syzygies of its parametrization if the base points are isolated and form locally a complete intersection.", "venue": "ISSAC '07", "authors": ["Laurent  Bus\u00e9", "Marc  Dohm"], "year": 2007, "n_citations": 20}
{"id": 3318496, "s2_id": "91788ad3a38995dd8e87b25d473f80eb46a3532c", "title": "Comprehensive Border Bases for Zero Dimensional Parametric Polynomial Ideals", "abstract": "In this paper, we extend the idea of comprehensive Gr\\\"{o}bner bases given by Weispfenning (1992) to border bases for zero dimensional parametric polynomial ideals. For this, we introduce a notion of comprehensive border bases and border system, and prove their existence even in the cases where they do not correspond to any term order. We further present algorithms to compute comprehensive border bases and border system. Finally, we study the relation between comprehensive Gr\\\"{o}bner bases and comprehensive border bases w.r.t. a term order and give an algorithm to compute such comprehensive border bases from comprehensive Gr\\\"{o}bner bases.", "venue": "ArXiv", "authors": ["Abhishek  Dubey", "Ambedkar  Dukkipati"], "year": 2013, "n_citations": 0}
{"id": 3328940, "s2_id": "4315a2febf26efc1ddbb9b183f33a854818cb750", "title": "Series crimes", "abstract": "Puiseux series are power series in which the exponents can be fractional and/or negative rational numbers. Several computer algebra systems have one or more built-in or loadable functions for computing truncated Puiseux series. Some are generalized to allow coefficients containing functions of the series variable that are dominated by any power of that variable, such as logarithms and nested logarithms of the series variable. Some computer algebra systems also have built-in or loadable functions that compute infinite Puiseux series. Unfortunately, there are some little-known pitfalls in computing Puiseux series. The most serious of these is expansions within branch cuts or at branch points that are incorrect for some directions in the complex plane. For example with each series implementation accessible to you.\n Compare the value of (z2 + z3)3/2 with that of its truncated series expansion about z = 0, approximated at z = ?0.01. Does the series converge to a value that is the negative of the correct value?\n Compare the value of ln(z2 + z3) with its truncated series expansion about z = 0, approximated at z = ?0.01 + 0.1i. Does the series converge to a value that is incorrect by 2\u03c0i?\n Compare arctanh(?2 + ln(z)z) with its truncated series expansion about z = 0, approximated at z = ?0.01. Does the series converge to a value that is incorrect by about \u03c0i?\n At the time of this writing, most implementations that accommodate such series exhibit such errors. This article describes how to avoid these errors both for manual derivation of series and when implementing series packages.", "venue": "ACCA", "authors": ["David R. Stoutemyer"], "year": 2012, "n_citations": 1}
{"id": 3329020, "s2_id": "e8b4b0597ff40459221a88adbbb1746dd17ba71f", "title": "Parallel telescoping and parameterized Picard-Vessiot theory", "abstract": "Parallel telescoping is a natural generalization of differential creative-telescoping for single integrals to line integrals. It computes a linear ordinary differential operator L, called a parallel telescoper, for several multivariate functions, such that the application of L to the functions yields partial derivatives of a single function. We present a necessary and sufficient condition guaranteeing the existence of parallel telescopers for differentially finite functions, and develop an algorithm to compute minimal ones for compatible hyperexponential functions. Besides computing annihilators of parametric line integrals, we use the parallel telescoping for determining Galois groups of parameterized partial differential systems of first order.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Ruyong  Feng", "Ziming  Li", "Michael F. Singer"], "year": 2014, "n_citations": 6}
{"id": 3331875, "s2_id": "f5928852e5cd31cb94de6057197a95ffbec98e3e", "title": "FORM facts", "abstract": "Some of the new features of the symbolic manipulation system FORM are discussed. Then some recent results running its multithreaded version TFORM are shown. Finally the plans for the future are presented.", "venue": "ArXiv", "authors": ["J. A. M. Vermaseren"], "year": 2010, "n_citations": 4}
{"id": 3331888, "s2_id": "c9e36ce9a63f3de32db7845af5fa41bb51bbf5b7", "title": "Nonnegative Trigonometric Polynomials, Sturms Theorem, and Symbolic Computation", "abstract": "In this paper, we explain a procedure based on a classical result of Sturm that can be used to determine rigorously whether a given trigonometric polynomial is nonnegative in a certain interval or not. Many examples are given. This technique has been employed by the author in several recent works. The procedure often involves tedious computations that are time-consuming and error-prone. Fortunately, symbolic computation software is available to automate the procedure. In this paper, we give the details of its implementation in MAPLE 13. Some who are strongly attached to a more traditional theoretical research framework may find such details boring or even consider computer-assisted proofs suspicious. However, we emphasize again that the procedure is completely mathematically rigorous.", "venue": "ArXiv", "authors": ["Man Kam Kwong"], "year": 2014, "n_citations": 10}
{"id": 3335927, "s2_id": "f957ff779268c25df5da3f35cfd4909065094ea8", "title": "On fast multiplication of a matrix by its transpose", "abstract": "We present a non-commutative algorithm for the multiplication of a 2 \u00d7 2-block-matrix by its transpose using 5 block products (3 recursive calls and 2 general products) over C or any field of prime characteristic. We use geometric considerations on the space of bilinear forms describing 2 \u00d7 2 matrix products to obtain this algorithm and we show how to reduce the number of involved additions. The resulting algorithm for arbitrary dimensions is a reduction of multiplication of a matrix by its transpose to general matrix product, improving by a constant factor previously known reductions. Finally we propose schedules with low memory footprint that support a fast and memory efficient practical implementation over a prime field. To conclude, we show how to use our result in L \u00b7 D \u00b7 LT factorization.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "Clement  Pernet", "Alexandre  Sedoglavic"], "year": 2020, "n_citations": 2}
{"id": 3336771, "s2_id": "93e94e5b42851d13d5209c9f8e22a926cdad9c79", "title": "A Family of Denominator Bounds for First Order Linear Recurrence Systems", "abstract": "For linear recurrence systems, the problem of finding rational solutions is reduced to the problem of computing polynomial solutions by computing a content bound or a denominator bound. There are several bounds in the literature. The sharpest bound leads to polynomial solutions of lower degrees, but this advantage need not compensate for the time spent on computing that bound. \nTo strike the best balance between sharpness of the bound versus CPU time spent obtaining it, we will give a family of bounds. The $J$'th member of this family is similar to (Abramov, Barkatou, 1998) when $J=1$, similar to (van Hoeij, 1998) when $J$ is large, and novel for intermediate values of $J$, which give the best balance between sharpness and CPU time. \nThe setting for our content bounds are systems $\\tau(Y) = MY$ where $\\tau$ is an automorphism of a UFD, and $M$ is an invertible matrix with entries in its field of fractions. This setting includes the shift case, the $q$-shift case, the multi-basic case and others. We give two versions, a global version, and a version that bounds each entry separately.", "venue": "ArXiv", "authors": ["Mark van Hoeij", "Moulay  Barkatou", "Johannes  Middeke"], "year": 2020, "n_citations": 1}
{"id": 3338793, "s2_id": "3d539b3ef52873bbd56352b61fe54efcb2ffdb1a", "title": "What Can (and Can't) we Do with Sparse Polynomials?", "abstract": "Simply put, a sparse polynomial is one whose zero coefficients are not explicitly stored. Such objects are ubiquitous in exact computing, and so naturally we would like to have efficient algorithms to handle them. However, with this compact storage comes new algorithmic challenges, as fast algorithms for dense polynomials may no longer be efficient. In this tutorial we examine the state of the art for sparse polynomial algorithms in three areas: arithmetic, interpolation, and factorization. The aim is to highlight recent progress both in theory and in practice, as well as opportunities for future work.", "venue": "ISSAC", "authors": ["Daniel S. Roche"], "year": 2018, "n_citations": 32}
{"id": 3339971, "s2_id": "b738c8446023ad9d290644bc3b1f9ce8062c36b9", "title": "Modern Summation Methods for Loop Integrals in Quantum Field Theory: The Packages Sigma, EvaluateMultiSums and SumProduction", "abstract": "A large class of Feynman integrals, like e.g., two-point parameter integrals with at most one mass and containing local operator insertions, can be transformed to multi-sums over hypergeometric expressions. In this survey article we present a difference field approach for symbolic summation that enables one to simplify such definite nested sums to indefinite nested sums. In particular, the simplification is given -if possible- in terms of harmonic sums, generalized harmonic sums, cyclotomic harmonic sums or binomial sums. Special emphasis is put on the developed Mathematica packages Sigma, EvaluateMultiSums and SumProduction that assist in the task to perform these simplifications completely automatically for huge input expressions.", "venue": "ArXiv", "authors": ["Carsten  Schneider"], "year": 2013, "n_citations": 63}
{"id": 3342635, "s2_id": "4a78d160c99ea3ff23987c278cd97518ab49cf34", "title": "Linearly Constrained Gaussian Processes with Boundary Conditions", "abstract": "One goal in Bayesian machine learning is to encode prior knowledge into prior distributions, to model data efficiently. We consider prior knowledge from systems of linear (partial and ordinary) differential equations together with their boundary conditions. We construct multi-output Gaussian process priors with realizations dense in the solution set of such systems, in particular any solution (and only such solutions) can be represented to arbitrary precision by Gaussian process regression. The construction is fully algorithmic via Grobner bases and it does not employ any approximation. It builds these priors combining two parametrizations via a pullback: the first parametrizes the solutions for the system of differential equations and the second parametrizes all functions adhering to the boundary conditions.", "venue": "AISTATS", "authors": ["Markus  Lange-Hegermann"], "year": 2021, "n_citations": 5}
{"id": 3344930, "s2_id": "85a00dee8a2bb1e110a2c4b7c7a35f3d6b308aa4", "title": "Refined Holonomic Summation Algorithms in Particle Physics", "abstract": "An improved multi-summation approach is introduced and discussed that enables one to simultaneously handle sequences generated by indefinite nested sums and products in the setting of difference rings and holonomic sequences described by linear recurrence systems. Relevant mathematics is reviewed and the underlying advanced difference ring machinery is elaborated upon. The flexibility of this new toolbox contributed substantially to evaluating complicated multi-sums coming from particle physics. Illustrative examples of the functionality of the new software package RhoSum are given.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "Mark  Round", "Carsten  Schneider"], "year": 2017, "n_citations": 7}
{"id": 3345834, "s2_id": "936de9eb31558f20116b9c1a69159282aebc357c", "title": "Linear PDE with Constant Coefficients", "abstract": "\n We discuss practical methods for computing the space of solutions to an arbitrary homogeneous linear system of partial differential equations with constant coefficients. These rest on the Fundamental Principle of Ehrenpreis\u2013Palamodov from the 1960s. We develop this further using recent advances in computational commutative algebra.", "venue": "Glasgow Mathematical Journal", "authors": ["Rida Ait El Manssour", "Marc  H\u00e4rk\u00f6nen", "Bernd  Sturmfels"], "year": 2021, "n_citations": 2}
{"id": 3346583, "s2_id": "989eb46d4ee527724a15fb4cdcfdd43606557a37", "title": "Exact Inference for Relational Graphical Models with Interpreted Functions: Lifted Probabilistic Inference Modulo Theories", "abstract": "Probabilistic Inference Modulo Theories (PIMT) is a recent framework that expands exact inference on graphical models to use richer languages that include arithmetic, equalities, and inequalities on both integers and real numbers. In this paper, we expand PIMT to a lifted version that also processes random functions and relations. This enhancement is achieved by adapting Inversion, a method from Lifted First-Order Probabilistic Inference literature, to also be modulo theories. This results in the first algorithm for exact probabilistic inference that efficiently and simultaneously exploits random relations and functions, arithmetic, equalities and inequalities.", "venue": "UAI", "authors": ["Rodrigo de Salvo Braz", "Ciaran  O'Reilly"], "year": 2017, "n_citations": 6}
{"id": 3350529, "s2_id": "fa675a20ae90a879b5fd4989489bf001aa16b8d5", "title": "Normalization of Polynomials in Algebraic Invariants of Three-Dimensional Orthogonal Geometry", "abstract": "In classical invariant theory, the Gr\\\"obner base of the ideal of syzygies and the normal forms of polynomials of invariants are two core contents. To improve the performance of invariant theory in symbolic computing of classical geometry, advanced invariants are introduced via Clifford product. This paper addresses and solves the two key problems in advanced invariant theory: the Gr\\\"obner base of the ideal of syzygies among advanced invariants, and the normal forms of polynomials of advanced invariants. These results beautifully extend the straightening of Young tableaux to advanced invariants.", "venue": "ArXiv", "authors": ["Hongbo  Li"], "year": 2013, "n_citations": 0}
{"id": 3351488, "s2_id": "dad2c58a6a833be5c24ed4078f31ae39fab2e33e", "title": "Interpolation of Shifted-Lacunary Polynomials", "abstract": "Abstract.Given a \u201cblack box\u201d function to evaluate an unknown rational polynomial $$f \\in {\\mathbb{Q}}[x]$$ at points modulo a prime p, we exhibit algorithms to compute the representation of the polynomial in the sparsest shifted power basis. That is, we determine the sparsity $$t \\in {\\mathbb{Z}}_{>0}$$, the shift $$\\alpha \\in {\\mathbb{Q}}$$, the exponents $${0 \\leq e_{1} < e_{2} < \\cdots < e_{t}}$$, and the coefficients $$c_{1}, \\ldots , c_{t} \\in {\\mathbb{Q}} \\setminus \\{0\\}$$ such that\n$$f(x) = c_{1}(x-\\alpha)^{e_{1}}+c_{2}(x-\\alpha)^{e_{2}}+ \\cdots +c_{t}(x-\\alpha)^{e_{t}}$$.The computed sparsity t is absolutely minimal over any shifted power basis. The novelty of our algorithm is that the complexity is polynomial in the (sparse) representation size, which may be logarithmic in the degree of f. Our method combines previous celebrated results on sparse interpolation and computing sparsest shifts, and provides a way to handle polynomials with extremely high degree which are, in some sense, sparse in information.", "venue": "computational complexity", "authors": ["Mark  Giesbrecht", "Daniel S. Roche"], "year": 2010, "n_citations": 26}
{"id": 3355702, "s2_id": "343e8c7807ba3ec35e29bc9df6937695b57c0ac7", "title": "A generalized Apagodu-Zeilberger algorithm", "abstract": "The Apagodu-Zeilberger algorithm can be used for computing annihilating operators for definite sums over hypergeometric terms, or for definite integrals over hyperexponential functions. In this paper, we propose a generalization of this algorithm which is applicable to arbitrary \u0394-finite functions. In analogy to the hypergeometric case, we introduce the notion of proper \u0394-finite functions. We show that the algorithm always succeeds for these functions, and we give a tight a priori bound for the order of the output operator.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Manuel  Kauers", "Christoph  Koutschan"], "year": 2014, "n_citations": 17}
{"id": 3362609, "s2_id": "511d75b7aef92c2381bf71eea304228aeea04a2f", "title": "Tuple Interpretations for Higher-Order Rewriting", "abstract": "We develop a class of algebraic interpretations for many-sorted and higher-order term rewriting systems that takes type information into account. Specifically, base-type terms are mapped to tuples of natural numbers and higher-order terms to functions between those tuples. Tuples may carry information relevant to the type; for instance, a term of type nat may be associated to a pair \u27e8cost, size\u27e9 representing its evaluation cost and size. This class of interpretations results in a more fine-grained notion of complexity than runtime or derivational complexity, which makes it particularly useful to obtain complexity bounds for higher-order rewriting systems. We show that rewriting systems compatible with tuple interpretations admit finite bounds on derivation height. Furthermore, we demonstrate how to mechanically construct tuple interpretations and how to orient \u03b2 and \u03b7 reductions within our technique. Finally, we relate our method to runtime complexity and prove that specific interpretation shapes imply certain runtime complexity bounds. 2012 ACM Subject Classification Theory of computation \u2192 Equational logic and rewriting", "venue": "ArXiv", "authors": ["Deivid  Vale", "Cynthia  Kop"], "year": 2021, "n_citations": 1}
{"id": 3368019, "s2_id": "4303a3f0f13ab787db5141346b8e39b5da9325ac", "title": "Representation, simplification and display of fractional powers of rational numbers in computer algebra", "abstract": "Simplification of fractional powers of positive rational numbers and of sums, products and powers of such numbers is taught in beginning algebra. Such numbers can often be expressed in many ways, as this article discusses in some detail. Since they are such a restricted subset of algebraic numbers, it might seem that good simplification of them must already be implemented in all widely used computer algebra systems. However, the algorithm taught in beginning algebra uses integer factorization, which can consume unacceptable time for the large numbers that often arise within computer algebra. Therefore some systems apparently use various ad hoc techniques that can return an incorrect result because of not simplifying to 0 the difference between two equivalent such expressions. Even systems that avoid this flaw often do not return the same result for all equivalent such input forms, or return an unnecessarily bulky result that does not have any other compensating useful property. This article identifies some of these deficiencies, then describes the advantages and disadvantages of various alternative forms and how to overcome the deficiencies without costly integer factorization.", "venue": "ArXiv", "authors": ["Albert D. Rich", "David R. Stoutemyer"], "year": 2013, "n_citations": 0}
{"id": 3368361, "s2_id": "fd4ed11f8d25f823e2934c475900ffe19a349663", "title": "Obstructions to Genericity in Study of Parametric Problems in Control Theory", "abstract": "We investigate systems of equations, involving parameters from the point of view of both control theory and computer algebra. The equations might involve linear operators such as partial (q-)differentiation, (q-)shift, (q-)difference as well as more complicated ones, which act trivially on the parameters. Such a system can be identified algebraically with a certain left module over a non-commutative algebra, where the operators commute with the parameters. We develop, implement and use in practice the algorithm for revealing all the expressions in parameters, for which e.g. homological properties of a system differ from the generic properties. We use Groebner bases and Groebner basics in rings of solvable type as main tools. In particular, we demonstrate an optimized algorithm for computing the left inverse of a matrix over a ring of solvable type. We illustrate the article with interesting examples. In particular, we provide a complete solution to the \"two pendula, mounted on a cart\" problem from the classical book of Polderman and Willems, including the case, where the friction at the joints is essential . To the best of our knowledge, the latter example has not been solved before in a complete way.", "venue": "ArXiv", "authors": ["Viktor  Levandovskyy", "Eva  Zerz"], "year": 2007, "n_citations": 15}
{"id": 3369808, "s2_id": "351e7dbb298c5bfcc444f03facdd007cf82462c9", "title": "A parallel Buchberger algorithm for multigraded ideals", "abstract": "We demonstrate a method to parallelize the computation of a Gr\\\"obner basis for a homogenous ideal in a multigraded polynomial ring. Our method uses anti-chains in the lattice $\\mathbb N^k$ to separate mutually independent S-polynomials for reduction.", "venue": "ArXiv", "authors": ["Mikael  Vejdemo-Johansson", "Emil  Sk\u00f6ldberg", "Jason  Dusek"], "year": 2011, "n_citations": 0}
{"id": 3370917, "s2_id": "33a972efa6d17207104f72acaf31f9d60938dd6e", "title": "Improved algorithm for computing separating linear forms for bivariate systems", "abstract": "We address the problem of computing a linear separating form of a system of two bivariate polynomials with integer coefficients, that is a linear combination of the variables that takes different values when evaluated at the distinct solutions of the system. The computation of such linear forms is at the core of most algorithms that solve algebraic systems by computing rational parameterizations of the solutions and this is the bottleneck of these algorithms in terms of worst-case bit complexity. We present for this problem a new algorithm of worst-case bit complexity <i>\u00d5</i><sub><i>B</i></sub>(<i>d</i><sup>7</sup> + <i>d</i><sup>6</sup><sub><i>\u03c4</i></sub>) where <i>d</i> and <i>\u03c4</i> denote respectively the maximum degree and bitsize of the input (and where <i>\u00d5</i> refers to the complexity where polylogarithmic factors are omitted and <i>O</i><sub><i>B</i></sub> refers to the bit complexity). This algorithm simplifies and decreases by a factor <i>d</i> the worst-case bit complexity presented for this problem by Bouzidi et al. [5]. This algorithm also yields, for this problem, a probabilistic Las-Vegas algorithm of expected bit complexity <i>\u00d5</i><sub><i>B</i></sub>(<i>d</i><sup>5</sup> + <i>d</i><sup>4</sup><sub><i>\u03c4</i></sub>).", "venue": "ISSAC", "authors": ["Yacine  Bouzidi", "Sylvain  Lazard", "Guillaume  Moroz", "Marc  Pouget", "Fabrice  Rouillier"], "year": 2014, "n_citations": 9}
{"id": 3376753, "s2_id": "70172a75b1698de75bd66958ce750c67529bebd9", "title": "On the complexity of solving a bivariate polynomial system", "abstract": "We study the complexity of computing the real solutions of a bivariate polynomial system using the recently presented algorithm Bisolve [2]. Bisolve is an elimination method which, in a first step, projects the solutions of a system onto the x- and y-axes and, then, selects the actual solutions from the so induced candidate set. However, unlike similar algorithms, Bisolve requires no genericity assumption on the input, and there is no need for any kind of coordinate transformation. Furthermore, extensive benchmarks as presented in [2] confirm that the algorithm is highly practical, that is, a corresponding C++ implementation in Cgal outperforms state of the art approaches by a large factor. In this paper, we focus on the theoretical complexity of Bisolve. For two polynomials f, g \u2208 Z[x, y] of total degree at most n with integer coefficients bounded by 2\u03c4, we show that Bisolve computes isolating boxes for all real solutions of the system f = g = 0 using O(n8 + n7\u03c4) bit operations, thereby improving the previous record bound for the same task by several magnitudes.", "venue": "ISSAC", "authors": ["Pavel  Emeliyanenko", "Michael  Sagraloff"], "year": 2012, "n_citations": 32}
{"id": 3379134, "s2_id": "05e515725f15f830d6d521ee9d8f63574ce83599", "title": "The multithreaded version of FORM", "abstract": "We present TFORM, the version of the symbolic manipulation system FORM that can make simultaneous use of several processors in a shared memory architecture. The implementation uses Posix threads, also called pthreads, and is therefore easily portable between various operating systems. Most existing FORM programs will be able to take advantage of the increased processing power, without the need for modifications. In some cases some minor additions may be needed. For a computer with two processors a typical improvement factor in the running time is 1.7 when compared to the traditional version of FORM. In the case of computers with 4 processors a typical improvement factor in the execution time is slightly above 3.", "venue": "Comput. Phys. Commun.", "authors": ["M.  Tentyukov", "J. A. M. Vermaseren"], "year": 2010, "n_citations": 164}
{"id": 3379557, "s2_id": "5bac1efa0574817e0ebd05b21f76e15b9dd0ef84", "title": "Change-Of-Bases Abstractions for Non-Linear Systems", "abstract": "We present abstraction techniques that transform a given non-linear dynamical system into a linear system or an algebraic system described by polynomials of bounded degree, such that, invariant properties of the resulting abstraction can be used to infer invariants for the original system. The abstraction techniques rely on a change-of-basis transformation that associates each state variable of the abstract system with a function involving the state variables of the original system. We present conditions under which a given change of basis transformation for a non-linear system can define an abstraction. Furthermore, the techniques developed here apply to continuous systems defined by Ordinary Differential Equations (ODEs), discrete systems defined by transition systems and hybrid systems that combine continuous as well as discrete subsystems. The techniques presented here allow us to discover, given a non-linear system, if a change of bases transformation involving degree-bounded polynomials yielding an algebraic abstraction exists. If so, our technique yields the resulting abstract system, as well. This approach is further extended to search for a change of bases transformation that abstracts a given non-linear system into a system of linear differential inclusions. Our techniques enable the use of analysis techniques for linear systems to infer invariants for non-linear systems. We present preliminary evidence of the practical feasibility of our ideas using a prototype implementation.", "venue": "ArXiv", "authors": ["Sriram  Sankaranarayanan"], "year": 2012, "n_citations": 5}
{"id": 3380087, "s2_id": "f63da49fdef495a48e4d7f2fc6a92fe1a5ee59de", "title": "A New General-Purpose Method to Multiply 3x3 Matrices Using Only 23 Multiplications", "abstract": "One of the most famous conjectures in computer algebra is that matrix multiplication might be feasible in nearly quadratic time, (8). The best known exponent is 2.376, due to Coppersmith and Winograd (9). Many attempts to solve this problems in the literature work by solving, fixed-size problems and then apply the solution recursively (6,22,17,21,2). This leads to pure combinatorial optimisation problems with fixed size. These problems are unlikely to be solvable in polynomial time, see (21,15). In 1976 Laderman published a method to multiply two 3x3 matrices using only 23 multiplications. This result is non-commutative, and therefore can be applied recursively to smaller sub-matrices. In 35 years nobody was able to do better and it remains an open problem if this can be done with 22 multiplications. We proceed by solving the so called Brent equations (6). We have im- plemented a method to converting this very hard problem to a SAT problem, and we have attempted to solve it, with our portfolio of some 500 SAT solvers. With this new method we were able to produce new solutions to the Laderman's problem. We present a new fully general non-commutative solution with 23 multi- plications and show that this solution is new and is NOT equivalent to any previously known solution. This result demonstrates that the space of solutions to Laderman's problem is larger than expected, and therefore it becomes now more plausible that a solution with 22 multiplications exists. If it exists, we might be able to find it soon just by running our algorithms longer, or due to further improvements in the SAT solver algorithms.", "venue": "ArXiv", "authors": ["Nicolas  Courtois", "Gregory V. Bard", "Daniel  Hulme"], "year": 2011, "n_citations": 22}
{"id": 3380926, "s2_id": "079e2721ec1ad1c8fdb7fdb43c3a29b36073ee9f", "title": "Computing the Kalman form", "abstract": "We present two algorithms for the computation of the Kalman form of a linear control system. The first one is based on the technique developed by Keller-Gehrig for the computation of the characteristic polynomial. The cost is a logarithmic number of matrix multiplications. To our knowledge, this improves the best previously known algebraic complexity by an order of magnitude. Then we also present a cubic algorithm proven to more efficient in practice.", "venue": "ArXiv", "authors": ["Cl\u00e9ment  Pernet", "Aude  Rondepierre", "Gilles  Villard"], "year": 2005, "n_citations": 1}
{"id": 3382929, "s2_id": "efa407217d078564eff8ec416acbc5e7e29a97bf", "title": "Trading GRH for algebra: Algorithms for factoring polynomials and related structures", "abstract": "In this paper we develop techniques that eliminate the need of the Generalized Riemann Hypothesis (GRH) from various (almost all) known results about deterministic polynomial factoring over finite fields. Our main result shows that given a polynomial f(x) of degree n over a finite field k, we can find in deterministic poly(n log n , log|k|) time either a nontrivial factor of f(x) or a nontrivial automorphism of k[x]/(f(x)) of order n. This main tool leads to various new GRH-free results, most striking of which are: 1. Given a noncommutative algebra A of dimension n over a finite field k. There is a deterministic poly(n logn , log|k|) time algorithm to find a zero divisor in A. This is the best known deterministic GRH-free result since R\u00b4 (1990) first studied the problem of finding zero divisors in finite algebras and showed that this problem has the same complexity as factoring polynomials over finite fields. 2. Given a positive integer r > 4 such that either 4|r or r has two distinct prime factors. There is a deterministic polynomial time algorithm to find a nontrivial factor of ther-th cyclotomic polynomial over a finite field. This is the best known deterministic GRH-free result since Evdokimov (1989) showed that cyclotomic polynomials can be factored over finite fields in deterministic polynomial time assuming GRH. In this paper, following the seminal work of Lenstra (1991) on constructing isomorphisms between finite fields, we further generalize classical Galois theory constructs", "venue": "Math. Comput.", "authors": ["G\u00e1bor  Ivanyos", "Marek  Karpinski", "Lajos  R\u00f3nyai", "Nitin  Saxena"], "year": 2008, "n_citations": 16}
{"id": 3389505, "s2_id": "1a173e3079f86199e955127089197469a5b0957d", "title": "An improvement over the GVW algorithm for inhomogeneous polynomial systems", "abstract": "The GVW algorithm provides a new framework for computing Grobner bases efficiently. If the input system is not homogeneous, some J-pairs with larger signatures but lower degrees may be rejected by GVW's criteria, and instead, GVW has to compute some J-pairs with smaller signatures but higher degrees. Consequently, degrees of polynomials appearing during the computations may unnecessarily grow up higher, and hence, the total computations become more expensive. This phenomenon happens more frequently when the coefficient field is a finite field and the field polynomials are involved in the computations. In this paper, a variant of the GVW algorithm, called M-GVW, is proposed. The concept of mutant pairs is introduced to overcome the inconveniences brought by inhomogeneous inputs. In aspects of implementations, to obtain efficient implementations of GVW/M-GVW over boolean polynomial rings, we take advantages of the famous library M4RI. We propose a new rotating swap method of adapting efficient routines in M4RI to deal with the one-direction reductions in GVW/M-GVW. Our implementations are tested with many examples from Boolean polynomial rings, and the timings show M-GVW usually performs much better than the original GVW algorithm if mutant pairs are found.", "venue": "Finite Fields Their Appl.", "authors": ["Yao  Sun", "ZhenYu  Huang", "Dingkang  Wang", "Dongdai  Lin"], "year": 2016, "n_citations": 6}
{"id": 3392385, "s2_id": "66c388a148a3d90ecda00daa115b7cce3883cc32", "title": "Ideal decompositions and computation of tensor normal forms", "abstract": "Symmetry properties of r-times covariant tensors T can be de- scribed by certain linear subspaces W of the group ring K(Sr) of a symmet- ric group Sr. If for a class of tensors T such a W is known, the elements of the orthogonal subspace W ? of W within the dual space K(Sr) of K(Sr) yield linear identities needed for a treatment of the term combination problem for the coordinates of the T. We give the structure of these W for every situa- tion which appears in symbolic tensor calculations by computer. Characterizing idempotents of such W can be determined by means of an ideal decomposition algorithm which works in every semisimple ring up to an isomorphism. Fur- thermore, we use tools such as the Littlewood-Richardson rule, plethysms and discrete Fourier transforms forSr to increase the ecience of calculations. All described methods were implemented in a Mathematica package called PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2002, "n_citations": 8}
{"id": 3392776, "s2_id": "6d58280d8f22b8d23577594c047c9e53ad1c330d", "title": "Efficient Graph Rewriting", "abstract": "Graph transformation is the rule-based modification of graphs, and is a discipline dating back to the 1970s. The declarative nature of graph rewriting rules comes at a cost. In general, to match the left-hand graph of a fixed rule within a host graph requires polynomial time. To improve matching performance, Dorr proposed to equip rules and host graphs with distinguished root nodes. This model was implemented by Plump and Bak, but unfortunately, is not invertible. We address this problem by defining rootedness using a partial function onto a two-point set rather than pointing graphs with root nodes. We show a new result that the graph class of trees can be recognised by a rooted GT system in linear time, given an input graph of bounded degree. Finally, we define a new notion of confluence modulo garbage and non-garbage critical pairs, showing it is sufficient to require strong joinability of only the non-garbage critical pairs to establish confluence modulo garbage.", "venue": "ArXiv", "authors": ["Graham  Campbell"], "year": 2019, "n_citations": 11}
{"id": 3395068, "s2_id": "cec7ec1d3fd126d4907112efca1dffd943b9bc06", "title": "On the Inverting of A General Heptadiagonal Matrix", "abstract": "In this paper, we developed new numeric and symbolic algorithms to find the inverse of any nonsingular heptadiagonal matrix. Symbolic algorithm will not break and it is without setting any restrictive conditions. The computational cost of our algorithms is $O(n)$. The algorithms are suitable for implementation using computer algebra system such as MAPLE, MATLAB and MATHEMATICA. Examples are given to illustrate the efficiency of the algorithms.", "venue": "ArXiv", "authors": ["A. A. Karawia"], "year": 2014, "n_citations": 1}
{"id": 3396129, "s2_id": "f14fd1f97c057340eb930719a9889e71df2fbb48", "title": "On probabilistic term rewriting", "abstract": "We study the termination problem for probabilistic term rewrite systems. We prove that the interpretation method is sound and complete for a strengthening of positive almost sure termination, when abstract reduction systems and term rewrite systems are considered. Two instances of the interpretation method\u2014polynomial and matrix interpretations\u2014are analyzed and shown to capture interesting and nontrivial examples when automated. We capture probabilistic computation in a novel way by means of multidistribution reduction sequences, thus accounting for both the nondeterminism in the choice of the redex and the probabilism intrinsic in firing each rule.", "venue": "Sci. Comput. Program.", "authors": ["Martin  Avanzini", "Ugo Dal Lago", "Akihisa  Yamada"], "year": 2020, "n_citations": 10}
{"id": 3399873, "s2_id": "47a47f52a54890940d56cb01bc80092ddc0781d3", "title": "Superfast solution of Toeplitz systems based on syzygy reduction", "abstract": "We present a new superfast algorithm for solving Toeplitz systems. This algorithm is based on a relation between the solution of such problems and syzygies of polynomials or moving lines. We show an explicit connection between the generators of a Toeplitz matrix and the generators of the corresponding module of syzygies. We show that this module is generated by two elements and the solution of a Toeplitz system T u=g can be reinterpreted as the remainder of a vector depending on g, by these two generators. We obtain these generators and this remainder with computational complexity O(n log^2 n) for a Toeplitz matrix of size nxn.", "venue": "ArXiv", "authors": ["Houssam  Khalil", "Bernard  Mourrain", "Michelle  Schatzman"], "year": 2013, "n_citations": 3}
{"id": 3403869, "s2_id": "7390bf570daebe0e94cb254c47201f0c03a00c10", "title": "Exact Lower Bounds for Monochromatic Schur Triples and Generalizations", "abstract": "We derive exact and sharp lower bounds for the number of monochromatic generalized Schur triples $(x,y,x+ay)$ whose entries are from the set $\\{1,\\dots,n\\}$, subject to a coloring with two different colors. Previously, only asymptotic formulas for such bounds were known, and only for $a\\in\\mathbb{N}$. Using symbolic computation techniques, these results are extended here to arbitrary $a\\in\\mathbb{R}$. Furthermore, we give exact formulas for the minimum number of monochromatic Schur triples for $a=1,2,3,4$, and briefly discuss the case $0", "venue": "ArXiv", "authors": ["Christoph  Koutschan", "Elaine  Wong"], "year": 2019, "n_citations": 1}
{"id": 3406742, "s2_id": "c4197555268f6f6f2ed5d5dfbcb1d3cdca3a048e", "title": "Comprehensive Involutive Systems", "abstract": "In this paper, we consider parametric ideals and introduce a notion of comprehensive involutive system. This notion plays the same role in theory of involutive bases as the notion of comprehensive Groebner system in theory of Groebner bases. Given a parametric ideal, the space of parameters is decomposed into a finite set of cells. Each cell yields the corresponding involutive basis of the ideal for the values of parameters in that cell. Using the Gerdt-Blinkov algorithm for computing involutive bases and also the Montes algorithm for computing comprehensive Groebner systems, we present an algorithm for construction of comprehensive involutive systems. The proposed algorithm has been implemented in Maple, and we provide an illustrative example showing the step-by-step construction of comprehensive involutive system by our algorithm.", "venue": "CASC", "authors": ["Vladimir P. Gerdt", "Amir  Hashemi"], "year": 2012, "n_citations": 1}
{"id": 3409206, "s2_id": "296588613454160fe938fb2c231d5e59aa8df057", "title": "An Experiment Combining Specialization with Abstract Interpretation", "abstract": "It was previously shown that control-flow refinement can be achieved by a program specializer incorporating property-based abstraction, to improve termination and complexity analysis tools. We now show that this purpose-built specializer can be reconstructed in a more modular way, and that the previous results can be achieved using an off-the-shelf partial evaluation tool, applied to an abstract interpreter. The key feature of the abstract interpreter is the abstract domain, which is the product of the property-based abstract domain with the concrete domain. This language-independent framework provides a practical approach to implementing a variety of powerful specializers, and contributes to a stream of research on using interpreters and specialization to achieve program transformations.", "venue": "VPT/HCVS@ETAPS", "authors": ["John P. Gallagher", "Robert  Gl\u00fcck"], "year": 2020, "n_citations": 0}
{"id": 3413923, "s2_id": "410b69ef8e8d50fe82346100e14e3ae7380e8cf6", "title": "Products of ordinary differential operators by evaluation and interpolation", "abstract": "It is known that multiplication of linear differential operators over ground fields of characteristic zero can be reduced to a constant number of matrix products. We give a new algorithm by evaluation and interpolation which is faster than the previously-known one by a constant factor, and prove that in characteristic zero, multiplication of differential operators and of matrices are computationally equivalent problems. In positive characteristic, we show that differential operators can be multiplied in nearly optimal time. Theoretical results are validated by intensive experiments.", "venue": "ISSAC '08", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Nicolas Le Roux"], "year": 2008, "n_citations": 19}
{"id": 3414035, "s2_id": "4bd78fb5c1d00759d041d8d9e60c3c249f4b4270", "title": "Generalization of the Lee-O'Sullivan list decoding for one-point AG codes", "abstract": "Abstract We generalize the list decoding algorithm for Hermitian codes proposed by Lee and O\u02bcSullivan (2009) based on Grobner bases to general one-point AG codes, under an assumption weaker than one used by Beelen and Brander (2010) . Our generalization enables us to apply the fast algorithm to compute a Grobner basis of a module proposed by Lee and O\u02bcSullivan (2009) , which was not possible in another generalization by Lax (2012) .", "venue": "J. Symb. Comput.", "authors": ["Ryutaroh  Matsumoto", "Diego  Ruano", "Olav  Geil"], "year": 2013, "n_citations": 2}
{"id": 3414425, "s2_id": "24caef6a22791c4f41a9a31ecb418215e32ec655", "title": "Symbolic Expansion of Transcendental Functions", "abstract": "Higher transcendental function occur frequently in the calculation of Feynman integrals in quantum field theory. Their expansion in a small parameter is a non-trivial task. We report on a computer program which allows the systematic expansion of certain classes of functions. The algorithms are based on the Hopf algebra of nested sums. The program is written in C++ and uses the GiNaC library.", "venue": "ArXiv", "authors": ["Stefan  Weinzierl"], "year": 2002, "n_citations": 96}
{"id": 3420303, "s2_id": "3905548dc803a851902addd32e49ff1f3243735f", "title": "Change of Basis for m-primary Ideals in One and Two Variables", "abstract": "Following recent work by van der Hoeven and Lecerf (ISSAC 2017), we discuss the complexity of linear mappings, called untangling and \\emphtangling by those authors, that arise in the context of computations with univariate polynomials. We give a slightly faster tangling algorithm and discuss new applications of these techniques. We show how to extend these ideas to bivariate settings, and use them to give bounds on the arithmetic complexity of certain algebras.", "venue": "ISSAC", "authors": ["Seung Gyu Hyun", "Stephen  Melczer", "\u00c9ric  Schost", "Catherine  St-Pierre"], "year": 2019, "n_citations": 1}
{"id": 3424554, "s2_id": "dcd18696535675a32f447cfdcded498da0fd6121", "title": "Solving Sparse Integer Linear Systems", "abstract": "We propose a new algorithm to solve sparse linear systems of equations over the integers. This algorithm is based on a $p$-adic lifting technique combined with the use of block matrices with structured blocks. It achieves a sub-cubic complexity in terms of machine operations subject to a conjecture on the effectiveness of certain sparse projections. A LinBox-based implementation of this algorithm is demonstrated, and emphasizes the practical benefits of this new method over the previous state of the art.", "venue": "ArXiv", "authors": ["Wayne  Eberly", "Mark  Giesbrecht", "Pascal  Giorgi", "Arne  Storjohann", "Gilles  Villard"], "year": 2006, "n_citations": 8}
{"id": 3424970, "s2_id": "97c7a19b7a60622224e5d6c4adc479ecc88d8125", "title": "Faster Sparse Matrix Inversion and Rank Computation in Finite Fields", "abstract": "We improve the current best running time value to invert sparse matrices over finite fields, lowering it to an expected O (", "venue": "ArXiv", "authors": ["S'ilvia  Casacuberta", "Rasmus  Kyng"], "year": 2021, "n_citations": 1}
{"id": 3427320, "s2_id": "0fb81cb26e2a6aa1db213fa6afb9ab1c49c8a846", "title": "Automated Generation of Non-Linear Loop Invariants Utilizing Hypergeometric Sequences", "abstract": "Analyzing and reasoning about safety properties of software systems becomes an especially challenging task for programs with complex flow and, in particular, with loops or recursion. For such programs one needs additional information, for example in the form of loop invariants, expressing properties to hold at intermediate program points. In this paper we study program loops with non-trivial arithmetic, implementing addition and multiplication among numeric program variables. We present a new approach for automatically generating all polynomial invariants of a class of such programs. Our approach turns programs into linear ordinary recurrence equations and computes closed form solutions of these equations. These closed forms express the most precise inductive property, and hence invariant. We apply Gr\u00f6bner basis computation to obtain a basis of the polynomial invariant ideal, yielding thus a finite representation of all polynomial invariants. Our work significantly extends the class of so-called P-solvable loops by handling multiplication with the loop counter variable. We implemented our method in the Mathematica package Aligator and showcase the practical use of our approach.", "venue": "ISSAC", "authors": ["Andreas  Humenberger", "Maximilian  Jaroschek", "Laura  Kov\u00e1cs"], "year": 2017, "n_citations": 11}
{"id": 3438498, "s2_id": "01b75d9322934e9f58b8e19c7745ca384173ef6e", "title": "Efficient Calculation of Determinants of Symbolic Matrices with Many Variables", "abstract": "Efficient matrix determinant calculations have been studied since the 19th century. Computers expand the range of determinants that are practically calculable to include matrices with symbolic entries. However, the fastest determinant algorithms for numerical matrices are often not the fastest for symbolic matrices with many variables. We compare the performance of two algorithms, fraction-free Gaussian elimination and minor expansion, on symbolic matrices with many variables. We show that, under a simplified theoretical model, minor expansion is faster in most situations. We then propose optimizations for minor expansion and demonstrate their effectiveness with empirical data.", "venue": "ArXiv", "authors": ["Tanya  Khovanova", "Ziv  Scully"], "year": 2013, "n_citations": 0}
{"id": 3439857, "s2_id": "4f8a70ac76559f7edacdd368d804307364921a26", "title": "Symbolic Arithmetic and Integer Factorization", "abstract": "In this paper, we create a systematic and automatic procedure for transforming the integer factorization problem into the problem of solving a system of Boolean equations. Surprisingly, the resulting system of Boolean equations takes on a \"life of its own\" and becomes a new type of integer, which we call a generic integer. \nWe then proceed to use the newly found algebraic structure of the ring of generic integers to create two new integer factoring algorithms, called respectively the Boolean factoring (BF) algorithm, and the multiplicative Boolean factoring (MBF) algorithm. Although these two algorithms are not competitive with current classical integer factoring algorithms, it is hoped that they will become stepping stones to creating much faster and more competitive algorithms, and perhaps be precursors of a new quantum algorithm for integer factoring.", "venue": "ArXiv", "authors": ["Samuel J. Lomonaco"], "year": 2013, "n_citations": 1}
{"id": 3439945, "s2_id": "8460defee7af8b713f43226e7d1c1edc8557b8f8", "title": "Quality Up in Polynomial Homotopy Continuation by Multithreaded Path Tracking", "abstract": "Speedup measures how much faster we can solve the same problem using many cores. If we can afford to keep the execution time fixed, then quality up measures how much better the solution will be computed using many cores. In this paper we describe our multithreaded implementation to track one solution path defined by a polynomial homotopy. Limiting quality to accuracy and confusing accuracy with precision, we strive to offset the cost of multiprecision arithmetic running multithreaded code on many cores.", "venue": "ArXiv", "authors": ["Jan  Verschelde", "Genady  Yoffe"], "year": 2011, "n_citations": 3}
{"id": 3444051, "s2_id": "d930f7fa81bcd74adba314c19d6d2d9f7ad2cc6c", "title": "Triangular Decomposition of Matrices in a Domain", "abstract": "Deterministic recursive algorithms for the computation of matrix triangular decompositions with permutations like LU and Bruhat decomposition are presented for the case of commutative domains. This decomposition can be considered as a generalization of LU and Bruhat decompositions because they both may easily be obtained from this triangular decomposition. Algorithms have the same complexity as the algorithm of matrix multiplication.", "venue": "CASC", "authors": ["Gennadi I. Malaschonok", "Anton  Scherbinin"], "year": 2015, "n_citations": 7}
{"id": 3444456, "s2_id": "57a61bdfa30845469fc531fc06952486aff1392d", "title": "Factoring Polynomials over Finite Fields using Drinfeld Modules with Complex Multiplication", "abstract": "We present novel algorithms to factor polynomials over a finite field $\\F_q$ of odd characteristic using rank $2$ Drinfeld modules with complex multiplication. The main idea is to compute a lift of the Hasse invariant (modulo the polynomial $f(x) \\in \\F_q[x]$ to be factored) with respect to a Drinfeld module $\\phi$ with complex multiplication. Factors of $f(x)$ supported on prime ideals with supersingular reduction at $\\phi$ have vanishing Hasse invariant and can be separated from the rest. A Drinfeld module analogue of Deligne's congruence plays a key role in computing the Hasse invariant lift. We present two algorithms based on this idea. The first algorithm chooses Drinfeld modules with complex multiplication at random and has a quadratic expected run time. The second is a deterministic algorithm with $O(\\sqrt{p})$ run time dependence on the characteristic $p$ of $\\F_q$.", "venue": "ArXiv", "authors": ["Anand Kumar Narayanan"], "year": 2016, "n_citations": 0}
{"id": 3457109, "s2_id": "6356c7e004ed7550fa2d848f97137f97e9ea73e1", "title": "An effective method for computing Grothendieck point residue mappings", "abstract": "Grothendieck point residue is considered in the context of computational complex analysis. A new effective method is proposed for computing Grothendieck point residues mappings and residues. Basic ideas of our approach are the use of Grothendieck local duality and a transformation law for local cohomology classes. A new tool is devised for efficiency to solve the extended ideal membership problems in local rings. The resulting algorithms are described with an example to illustrate them. An extension of the proposed method to parametric cases is also discussed as an application.", "venue": "Journal of Algebra", "authors": ["Shinichi  Tajima", "Katsusuke  Nabeshima"], "year": 2021, "n_citations": 2}
{"id": 3459575, "s2_id": "6aba99ed15cf5581672fba0de8cc9d0c91a98b00", "title": "An Explicit Construction of Gauss-Jordan Elimination Matrix", "abstract": "A constructive approach to get the reduced row echelon form of a given matrix $A$ is presented. It has been shown that after the $k$th step of the Gauss-Jordan procedure, each entry $a^k_{ij}(i j; j > k)$ in the new matrix $A^k$ can always be expressed as a ratio of two determinants whose entries are from the original matrix $A$. The new method also gives a more general generalization of Cramer's rule than existing methods.", "venue": "ArXiv", "authors": ["Yi  Li"], "year": 2009, "n_citations": 3}
{"id": 3463285, "s2_id": "6bbfb871a4157b35007b6e15c50dbd2ee7fe1cc3", "title": "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking", "abstract": "Entity linking (EL), the task of disambiguating mentions in text by linking them to entities in a knowledge graph, is crucial for text understanding, question answering or conversational systems. Entity linking on short text (e.g., single sentence or question) poses particular challenges due to limited context. While prior approaches use either heuristics or blackbox neural methods, here we propose LNNEL, a neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to using rules, LNN-EL performs competitively against SotA black-box neural approaches, with the added benefits of extensibility and transferability. In particular, we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even scores resulting from previous EL methods, thus improving on such methods. For instance, on the LC-QuAD-1.0 dataset, we show more than 4% increase in F1 score over previous SotA. Finally, we show that the inductive bias offered by using logic results in learned rules that transfer well across datasets, even without fine tuning, while maintaining high accuracy.", "venue": "ACL/IJCNLP", "authors": ["Hang  Jiang", "Sairam  Gurajada", "Qiuhao  Lu", "Sumit  Neelam", "Lucian  Popa", "Prithviraj  Sen", "Yunyao  Li", "Alexander  Gray"], "year": 2021, "n_citations": 0}
{"id": 3465003, "s2_id": "0d1d816fe5a095878f0c463b12038a99e392ef84", "title": "On the complexity of computing integral bases of function fields", "abstract": "Let $\\mathcal{C}$ be a plane curve given by an equation $f(x,y)=0$ with $f\\in K[x][y]$ a monic squarefree polynomial. We study the problem of computing an integral basis of the algebraic function field $K(\\mathcal{C})$ and give new complexity bounds for three known algorithms dealing with this problem. For each algorithm, we study its subroutines and, when it is possible, we modify or replace them so as to take advantage of faster primitives. Then, we combine complexity results to derive an overall complexity estimate for each algorithm. In particular, we modify an algorithm due to Bohm et al. and achieve a quasi-optimal runtime.", "venue": "CASC", "authors": ["Simon  Abelard"], "year": 2020, "n_citations": 2}
{"id": 3466242, "s2_id": "ab19ac94d33366c07d328d6237627563c125c407", "title": "Symmetries of Canal Surfaces and Dupin Cyclides", "abstract": "We develop a characterization for the existence of symmetries of canal surfaces defined by a rational spine curve and rational radius function. In turn, this characterization inspires an algorithm for computing the symmetries of such canal surfaces. For Dupin cyclides in canonical form, we apply the characterization to derive an intrinsic description of their symmetries and symmetry groups, which gives rise to a method for computing the symmetries of a Dupin cyclide not necessarily in canonical form. As a final application, we discuss the construction of patches and blends of rational canal surfaces with a prescribed symmetry.", "venue": "Comput. Aided Geom. Des.", "authors": ["Juan Gerardo Alc\u00e1zar", "Heidi E. I. Dahl", "Georg  Muntingh"], "year": 2018, "n_citations": 3}
{"id": 3473898, "s2_id": "8b7df14269c21b9c2a8850502fa61143cfce5ff4", "title": "Notes on Computational Graph and Jacobian Accumulation", "abstract": "The optimal calculation order of a computational graph can be represented by a set of algebraic expressions. Computational graph and algebraic expression both have close relations and significant differences, this paper looks into these relations and differences, making plain their interconvertibility. By revealing different types of multiplication relations in algebraic expressions and their elimination dependencies in line-graph, we establish a theoretical limit on the efficiency of face elimination. 1. Face Elimination and D* Algorithm After a sparse computational graph or subgraph is linearized, i.e., all the derivatives denoted by edges and vertices in the computational graph are evaluated at a point, there are many elimination techniques to accumulate derivative values, including vertex elimination, edge elimination and face elimination. Naumann states in his paper that all the elimination techniques mentioned above \u201care based on the elimination of transitive dependences between variables in F . A variable vj depends transitively on vi via vk if i \u227a k \u227a j. In general, there is no structural representation for eliminating such dependences in G; that is, it cannot be expressed by modifying either V or E. A richer data structure is required, namely, a directed variant of the line graph of G.\u201d \u201cAll intermediate vertices belong to exactly two directed complete bipartite subgraphs of G\u0303. They are minimal in one and maximal in the other. Intermediate vertices in G are mapped onto complete bipartite subgraphs (or bicliques) K\u03bd,\u03bc of G\u0303\u201d, He continues to explain, \u201cThe elimination of transitive dependences can be interpreted as the elimination of edges in G\u0303. The modification of the dual c-graph is referred to as face elimination in order to distinguish between edge elimination in G\u0303 and G.\u201d ([7] 2003, p5-8) Griewank and Walther state in their book that in edge elimination \u201cwe are forced to simultaneously merge them with all their predecessor or successor edges, respectively. Sometimes we may wish to do that only with one of them. However, that desire cannot be realized by a simple modification of the linearized computational graph. Instead we have to consider the so-called line-graph of the computational graph with a slight extension.\u201d They continue: \u201cGeometrically, we may interpret the edges of the line-graph as faces of the extended computational graph. Therefore, we will refer to them as faces.\u201d ([1] 2008, p204)", "venue": "ArXiv", "authors": ["Yichong  Zhou"], "year": 2020, "n_citations": 0}
{"id": 3476133, "s2_id": "c1da18a51d37974733e25ed2b2812062029c144e", "title": "Timed Orchestration for Component-based Systems", "abstract": "Individual machines in flexible production lines explicitly expose capabilities at their interfaces by means of parametric skills. Given such a set of configurable machines, a line integrator is faced with the problem of finding and tuning parameters for each machine such that the overall production line implements given safety and temporal requirements in an optimized and robust fashion. We formalize this problem of configuring and orchestrating flexible production lines as a parameter synthesis problem for systems of parametric timed automata, where interactions are based on skills. Parameter synthesis problems for interaction-level LTL properties are translated to parameter synthesis problems for state-based safety properties. For safety properties, synthesis problems are solved by checking satisfiability of $\\exists\\forall$SMT constraints. For constraint generation, we provide a set of computationally cheap over-approximations of the set of reachable states, together with fence constructions as sufficient conditions for safety formulas. We demonstrate the feasibility of our approach by solving typical machine configuration problems as encountered in industrial automation.", "venue": "ArXiv", "authors": ["Chih-Hong  Cheng", "Lacramioara  Astefanoaei", "Souha Ben Rayana", "Saddek  Bensalem"], "year": 2015, "n_citations": 2}
{"id": 3480529, "s2_id": "4880cecf4d3dd15f40b05aa4d5b6e09aef8dcf3a", "title": "Performance of Buchberger's Improved Algorithm using Prime Based Ordering", "abstract": "Deakin University, Geelong, Australia, 3217AbstractPrime-based ordering which is proved to be admissible, is the encoding of indeterminates inpower-products with prime numbers and ordering them by using the natural number order.Using Ei\ufb00el, four versions of Buchberger\u2019s improved algorithm for obtaining Gr\u00a8obner Baseshave been developed: two total degree versions, representing power products as strings and theother two as integers based on prime-based ordering. The versions are further distinguished byimplementing coe\ufb03cients as 64-bit integers and as multiple-precision integers. By using prime-based power product coding, iterative or recursive operations on power products are replacedwith integer operations. It is found that on a series of example polynomial sets, signi\ufb01cantreductions in computation time of 30% or more are almost always obtained.Key words: Gr\u00a8obner Basis, Buchberger\u2019s Algorithm, Admissible Order, Prime-based Ordering", "venue": "ArXiv", "authors": ["Peter  Horan", "John  Carminati"], "year": 2009, "n_citations": 0}
{"id": 3480832, "s2_id": "00dc46be5a571093cd10633151fa6155dfaf5b6d", "title": "On Algorithmic Estimation of Analytic Complexity for Polynomial Solutions to Hypergeometric Systems", "abstract": "The paper deals with the analytic complexity of solutions to bivariate holonomic hypergeometric systems of the Horn type. We obtain estimates on the analytic complexity of Puiseux polynomial solutions to the hypergeometric systems defined by zonotopes. We also propose algorithms of the analytic complexity estimation for polynomials.", "venue": "ArXiv", "authors": ["Vitaly A. Krasikov"], "year": 2020, "n_citations": 0}
{"id": 3486746, "s2_id": "8f996877a26ff271d1f0697ca07d63882bcda604", "title": "A near-optimal subdivision algorithm for complex root isolation based on the Pellet test and Newton iteration", "abstract": "We describe a subdivision algorithm for isolating the complex roots of a polynomial $F\\in\\mathbb{C}[x]$. Given an oracle that provides approximations of each of the coefficients of $F$ to any absolute error bound and given an arbitrary square $\\mathcal{B}$ in the complex plane containing only simple roots of $F$, our algorithm returns disjoint isolating disks for the roots of $F$ in $\\mathcal{B}$. Our complexity analysis bounds the absolute error to which the coefficients of $F$ have to be provided, the total number of iterations, and the overall bit complexity. It further shows that the complexity of our algorithm is controlled by the geometry of the roots in a near neighborhood of the input square $\\mathcal{B}$, namely, the number of roots, their absolute values and pairwise distances. The number of subdivision steps is near-optimal. For the \\emph{benchmark problem}, namely, to isolate all the roots of a polynomial of degree $n$ with integer coefficients of bit size less than $\\tau$, our algorithm needs $\\tilde O(n^3+n^2\\tau)$ bit operations, which is comparable to the record bound of Pan (2002). It is the first time that such a bound has been achieved using subdivision methods, and independent of divide-and-conquer techniques such as Sch\\\"onhage's splitting circle technique. Our algorithm uses the quadtree construction of Weyl (1924) with two key ingredients: using Pellet's Theorem (1881) combined with Graeffe iteration, we derive a \"soft-test\" to count the number of roots in a disk. Using Schr\\\"oder's modified Newton operator combined with bisection, in a form inspired by the quadratic interval method from Abbot (2006), we achieve quadratic convergence towards root clusters. Relative to the divide-conquer algorithms, our algorithm is quite simple with the potential of being practical. This paper is self-contained: we provide pseudo-code for all subroutines used by our algorithm.", "venue": "J. Symb. Comput.", "authors": ["Ruben  Becker", "Michael  Sagraloff", "Vikram  Sharma", "Chee-Keng  Yap"], "year": 2018, "n_citations": 40}
{"id": 3488814, "s2_id": "f462b506c772976e7d19c8d78b3900a0c9af94f6", "title": "Secure cloud computations: Description of (fully)homomorphic ciphers within the P-adic model of encryption", "abstract": "In this paper we consider the description of homomorphic and fully homomorphic ciphers in the $p$-adic model of encryption. This model describes a wide class of ciphers, but certainly not all. Homomorphic and fully homomorphic ciphers are used to ensure the credibility of remote computing, including cloud technology. The model describes all homomorphic ciphers with respect to arithmetic and coordinate-wise logical operations in the ring of $p$-adic integers $Z_p$. We show that there are no fully homomorphic ciphers for each pair of the considered set of arithmetic and coordinate-wise logical operations on $Z_p$. We formulate the problem of constructing a fully homomorphic cipher as follows. We consider a homomorphic cipher with respect to operation \"$*$\" on $Z_p$. Then, we describe the complete set of operations \"$G$\", for which the cipher is homomorphic. As a result, we construct a fully homomorphic cipher with respect to the operations \"$*$\" and \"$G$\". We give a description of all operations \"$G$\", for which we obtain fully homomorphic ciphers with respect to the operations \"$+$\" and \"$G$\" from the homomorphic cipher constructed with respect to the operation \"$+$\". We also present examples of such \"new\" operations.", "venue": "ArXiv", "authors": ["Andrei  Khrennikov", "Ekaterina  Yurova"], "year": 2016, "n_citations": 2}
{"id": 3507615, "s2_id": "ffa8a584a0e1db1f1a0cd7e25d3bc456e7f598e4", "title": "Viterbi Algorithm Generalized for n-Tape Best-Path Search", "abstract": "We present a generalization of the Viterbi algorithm for identifying the path with minimal (resp. maximal) weight in a n-tape weighted finite-state machine (n-WFSM), that accepts a given n-tuple of input strings (s_1,... s_n). It also allows us to compile the best transduction of a given input n-tuple by a weighted (n+m)-WFSM (transducer) with n input and m output tapes. Our algorithm has a worst-case time complexity of O(|s|^n |E| log (|s|^n |Q|)), where n and |s| are the number and average length of the strings in the n-tuple, and |Q| and |E| the number of states and transitions in the n-WFSM, respectively. A straight forward alternative, consisting in intersection followed by classical shortest-distance search, operates in O(|s|^n (|E|+|Q|) log (|s|^n |Q|)) time.", "venue": "ArXiv", "authors": ["Andr\u00e9  Kempe"], "year": 2006, "n_citations": 5}
{"id": 3507685, "s2_id": "af9bc0a956421219e72ecd933e2598e83c94025e", "title": "The Complexity of Factors of Multivariate Polynomials", "abstract": "The existence of string functions, which are not polynomial time computable, but whose graph is checkable in polynomial time, is a basic assumption in cryptography. We prove that in the framework of algebraic complexity, there are no such families of polynomial functions of p-bounded degree over fields of characteristic zero. The proof relies on a polynomial upper bound on the approximative complexity of a factor g of a polynomial f in terms of the (approximative) complexity of f and the degree of the factor g. This extends a result by Kaltofen (STOC 1986). The concept of approximative complexity allows to cope with the case that a factor has an exponential multiplicity, by using a perturbation argument. Our result extends to randomized (two-sided error) decision complexity.", "venue": "FOCS", "authors": ["Peter  B\u00fcrgisser"], "year": 2001, "n_citations": 8}
{"id": 3509010, "s2_id": "a27a3f885f649e3106c177727e3cbd19c06e1dfc", "title": "Learning a performance metric of Buchberger's algorithm", "abstract": "What can be (machine) learned about the complexity of Buchberger\u2019s algorithm? Given a system of polynomials, Buchberger\u2019s algorithm computes a Gr\u00f6bner basis of the ideal these polynomials generate using an iterative procedure based on multivariate long division. The runtime of each step of the algorithm is typically dominated by a series of polynomial additions, and the total number of these additions is a hardware independent performance metric that is often used to evaluate and optimize various implementation choices. In this work we attempt to predict, using just the starting input, the number of polynomial additions that take place during one run of Buchberger\u2019s algorithm. Good predictions are useful for quickly estimating difficulty and understanding what features make Gr\u00f6bner basis computation hard. Our features and methods could also be used for value models in the reinforcement learning approach to optimize Buchberger\u2019s algorithm introduced in [21]. We show that a multiple linear regression model built from a set of easy-to-compute ideal generator statistics can predict the number of polynomial additions somewhat well, better than an uninformed model, and better than regression models built on some intuitive commutative algebra invariants that are more difficult to compute. We also train a simple recursive neural network that outperforms these linear models. Our work serves as a proof of concept, demonstrating that predicting the number of polynomial additions in Buchberger\u2019s algorithm is a feasible problem from the point of view of machine learning.", "venue": "ArXiv", "authors": ["Jelena  Mojsilovi'c", "Dylan  Peifer", "Sonja  Petrovi'c"], "year": 2021, "n_citations": 0}
{"id": 3509317, "s2_id": "c763e0d0974e81c0b7e20af3b7434fc8c1c7a409", "title": "How to turn a scripting language into a domain specific language for computer algebra", "abstract": "AbstractWe have developed two computer algebra systems, meditor [9] andJAS [12]. These CAS systems are available as Java libraries. For theuse-case of interactively entering and manipulating mathematical expres-sions, there is a need of a scripting front-end for our libraries. Most otherCAS invent and implement their own scripting interface for this purpose.We, however, do not want to reinvent the wheel and propose to use acontemporary scripting language with access to Java code. In this paperwe discuss the requirements for a scripting language in computer algebraand check whether the languages Python, Ruby, Groovy and Scala meetthese requirements. We conclude that, with minor problems, any of theselanguages is suitable for our purpose. 1 Introduction In this paper we summarize the numerous discussions that resulted from ourencounter as developers of two computer algebra systems (CAS) written in Java[9, 12] that have grown independently during the past 7 years (roughly). Thefocus of this paper is the scripting requirements for a computer algebra system.We compare various design choices and solutions and conclude that modernscripting languages are suitable for our tasks. We \ufb01rst give some backgroundinformation on computer algebra systems design and discuss the scripting re-quirements in section 2. In section 3 we investigate whether modern scriptinglanguages are suitable for our needs. In the next section we give an overviewof the state of our software and then conclude with our \ufb01ndings. Although wefocus on computer algebra the topic of this paper is relevant to all kinds ofinteractive scienti\ufb01c software which want to allow users to input mathematicalexpressions.After the construction of the \ufb01rst mature programming languages, like FOR-TRAN or later C, thousands of program libraries have been developed. More-1", "venue": "ArXiv", "authors": ["Raphael  Jolly", "Heinz  Kredel"], "year": 2008, "n_citations": 3}
{"id": 3510171, "s2_id": "cdd8e3fd55e43c93c3b0b38b9599c593ea629583", "title": "Real polynomial root-finding by means of matrix and polynomial iterations", "abstract": "Frequently one seeks approximation to all r real roots of a polynomial of degree n with real coefficients, which also has nonreal roots. We split a polynomial into two factors, one of which has degree r and has r real roots. We approximate them at a low cost, and then decrease the arithmetic time of the known algorithms for this popular problem by roughly a factor of n/k, if k iterations prepare splitting. k is a small integer unless some nonreal roots lie close to the real axis, but even if there nonreal roots near the real axis, we substantially accelerate the known algorithms. We also propose a dual algorithm, operating with the associated structured matrices. At the price of minor increase of the arithmetic time, it facilitates numerical implementation. Our analysis and tests demonstrate the efficiency of our approach.", "venue": "Theor. Comput. Sci.", "authors": ["Victor Y. Pan", "Liang  Zhao"], "year": 2017, "n_citations": 5}
{"id": 3517224, "s2_id": "b2d6ba9764353d23a63032f973715ab582f210a7", "title": "Computing low-degree factors of lacunary polynomials: a Newton-Puiseux approach", "abstract": "We present a new algorithm for the computation of the irreducible factors of degree at most d, with multiplicity, of multivariate lacunary polynomials over fields of characteristic zero. The algorithm reduces this computation to the computation of irreducible factors of degree at most d of univariate lacunary polynomials and to the factorization of low-degree multivariate polynomials. The reduction runs in time polynomial in the size of the input polynomial and in d. As a result, we obtain a new polynomial-time algorithm for the computation of low-degree factors, with multiplicity, of multivariate lacunary polynomials over number fields, but our method also gives partial results for other fields, such as the fields of p-adic numbers or for absolute or approximate factorization for instance.\n The core of our reduction uses the Newton polygon of the input polynomial, and its validity is based on the Newton-Puiseux expansion of roots of bivariate polynomials. In particular, we bound the valuation of f(X, \u03c6) where f is a lacunary polynomial and \u03c6 a Puiseux series whose vanishing polynomial has low degree.", "venue": "ISSAC", "authors": ["Bruno  Grenet"], "year": 2014, "n_citations": 5}
{"id": 3517571, "s2_id": "2154d0a9ed85ad1644cc93e8f77c559876128114", "title": "There are EXACTLY 1493804444499093354916284290188948031229880469556 Ways to Derange a Standard Deck of Cards (ignoring suits) [and many other such useful facts]", "abstract": "You have a1 copies of 1, a2 copies of 2, . . ., an copies of n, in other words you have the multiset 11 . . . nn , and you are interested in the number, let\u2019s call it M(a1, . . . , an), of derangements. In other words, out of the total number of arrangements, given by the multinomial coefficient (a1+ . . .+an)!/(a1! \u00b7 \u00b7 \u00b7 an!), how many are there where each location is different than the original. Here is why such questions are useful.", "venue": "Enumerative Combinatorics and Applications", "authors": ["Shalosh B. Ekhad", "Christoph  Koutschan", "Doron  Zeilberger"], "year": 2021, "n_citations": 0}
{"id": 3524899, "s2_id": "7d5e75ada7b99166c08d797aaffefffc73e94d05", "title": "Detecting symmetries of rational plane and space curves", "abstract": "Abstract This paper addresses the problem of determining the symmetries of a plane or space curve defined by a rational parametrization. We provide effective methods to compute the involution and rotation symmetries for the planar case. As for space curves, our method finds the involutions in all cases, and all the rotation symmetries in the particular case of Pythagorean-hodograph curves. Our algorithms solve these problems without converting to implicit form. Instead, we make use of a relationship between two proper parametrizations of the same curve, which leads to algorithms that involve only univariate polynomials. These algorithms have been implemented and tested in the Sage system.", "venue": "Comput. Aided Geom. Des.", "authors": ["Juan Gerardo Alc\u00e1zar", "Carlos  Hermoso", "Georg  Muntingh"], "year": 2014, "n_citations": 18}
{"id": 3525951, "s2_id": "e6c9e9d16646aea580355c25c7634d3709ca30b0", "title": "A toolbox to solve coupled systems of differential and difference equations", "abstract": "We present algorithms to solve coupled systems of linear differential equations, arising in the calculation of massive Feynman diagrams with local operator insertions at 3-loop order, which do {\\it not} request special choices of bases. Here we assume that the desired solution has a power series representation and we seek for the coefficients in closed form. In particular, if the coefficients depend on a small parameter $\\ep$ (the dimensional parameter), we assume that the coefficients themselves can be expanded in formal Laurent series w.r.t.\\ $\\ep$ and we try to compute the first terms in closed form. More precisely, we have a decision algorithm which solves the following problem: if the terms can be represented by an indefinite nested hypergeometric sum expression (covering as special cases the harmonic sums, cyclotomic sums, generalized harmonic sums or nested binomial sums), then we can calculate them. If the algorithm fails, we obtain a proof that the terms cannot be represented by the class of indefinite nested hypergeometric sum expressions. Internally, this problem is reduced by holonomic closure properties to solving a coupled system of linear difference equations. The underlying method in this setting relies on decoupling algorithms, difference ring algorithms and recurrence solving. We demonstrate by a concrete example how this algorithm can be applied with the new Mathematica package \\texttt{SolveCoupledSystem} which is based on the packages \\texttt{Sigma}, \\texttt{HarmonicSums} and \\texttt{OreSys}. In all applications the representation in $x$-space is obtained as an iterated integral representation over general alphabets, generalizing Poincar\\'{e} iterated integrals.", "venue": "ArXiv", "authors": ["Jakob  Ablinger", "Johannes  Bl\u00fcmlein", "Abilio De Freitas", "Carsten  Schneider"], "year": 2016, "n_citations": 9}
{"id": 3529296, "s2_id": "5645aee1740eb257aa2b77b691ad524b7955803d", "title": "On Exact Polya and Putinar's Representations", "abstract": "We consider the problem of finding exact sums of squares (SOS) decompositions for certain classes of non-negative multivariate polynomials, relying on semidefinite programming (SDP) solvers. We start by providing a hybrid numeric-symbolic algorithm computing exact rational SOS decompositions for polynomials lying in the interior of the SOS cone. It computes an approximate SOS decomposition for a perturbation of the input polynomial with an arbitrary-precision SDP solver. An exact SOS decomposition is obtained thanks to the perturbation terms. We prove that bit complexity estimates on output size and runtime are both polynomial in the degree of the input polynomial and simply exponential in the number of variables. Next, we apply this algorithm to compute exact Polya and Putinar's representations respectively for positive definite forms and positive polynomials over basic compact semi-algebraic sets. We also compare the implementation of our algorithms with existing methods in computer algebra including cylindrical algebraic decomposition and critical point method.", "venue": "ISSAC", "authors": ["Victor  Magron", "Mohab Safey El Din"], "year": 2018, "n_citations": 17}
{"id": 3544631, "s2_id": "a4e9608294776a36abad431cf208f181dc0a5241", "title": "Beyond Linear Algebra", "abstract": "Our title challenges the reader to venture beyond linear algebra in designing models and in thinking about numerical algorithms for identifying solutions. This article accompanies the author\u2019s lecture at the International Congress of Mathematicians 2022. It covers recent advances in the study of critical point equations in optimization and statistics, and it explores the role of nonlinear algebra in the study of linear PDE with constant coefficients. a rX iv :2 10 8. 09 49 4v 1 [ m at h. A G ] 2 1 A ug 2 02 1", "venue": "ArXiv", "authors": ["Bernd  Sturmfels"], "year": 2021, "n_citations": 0}
{"id": 3552641, "s2_id": "314a35278e6ec74ffff4b6222627ab58f26c4bcc", "title": "How to correctly prune tropical trees", "abstract": "We present tropical games, a generalization of combinatorial min-max games based on tropical algebras. Our model breaks the traditional symmetry of rational zero-sum games where players have exactly opposed goals (min vs. max), is more widely applicable than min-max and also supports a form of pruning, despite it being less effective than \u03b1-\u03b2. Actually, min-max games may be seen as particular cases where both the game and its dual are tropical: when the dual of a tropical game is also tropical, the power of \u03b1-\u03b2 is completely recovered. We formally develop the model and prove that the tropical pruning strategy is correct, then conclude by showing how the problem of approximated parsing can be modeled as a tropical game, profiting from pruning.", "venue": "AISC'10/MKM'10/Calculemus'10", "authors": ["Jean-Vincent  Loddo", "Luca  Saiu"], "year": 2010, "n_citations": 0}
{"id": 3558777, "s2_id": "a60929ae5a3cff847c0837e549a33d58702687f7", "title": "Holonomic Tools for Basic Hypergeometric Functions", "abstract": "With the exception of q-hypergeometric summation, the use of computer algebra packages implementing Zeilberger's \"holonomic systems approach\" in a broader mathematical sense is less common in the field of q-series and basic hypergeometric functions. A major objective of this article is to popularize the usage of such tools also in these domains. Concrete case studies showing software in action introduce to the basic techniques. An application highlight is a new computer-assisted proof of the celebrated Ismail-Zhang formula, an important q-analog of a classical expansion formula of plane waves in terms of Gegenbauer polynomials.", "venue": "ArXiv", "authors": ["Christoph  Koutschan", "Peter  Paule"], "year": 2016, "n_citations": 0}
{"id": 3560849, "s2_id": "0c5c6ed9f315c3ac8eba4c4e4c4d1d6ce01f439f", "title": "Groebner basis structure of ideal interpolation", "abstract": "We study the relationship between certain Groebner bases for zero dimensional ideals, and the interpolation condition functionals of ideal interpolation. Ideal interpolation is defined by a linear idempotent projector whose kernel is a polynomial ideal. In this paper, we propose the notion of \"reverse\" complete reduced basis. Based on the notion, we present a fast algorithm to compute the reduced Groebner basis for the kernel of ideal projector under an arbitrary compatible ordering. As an application, we show that knowing the affine variety makes available information concerning the reduced Groebner basis.", "venue": "ArXiv", "authors": ["Yihe  Gong", "Xue  Jiang"], "year": 2020, "n_citations": 0}
{"id": 3566157, "s2_id": "2ee9520b277307ebacc080a8194b16cfc1d786e3", "title": "Round Trip Time Prediction Using the Symbolic Function Network Approach", "abstract": "In this paper, we develop a novel approach to model the Internet round trip time using a recently proposed symbolic type neural network model called symbolic function network. The developed predictor is shown to have good generalization performance and simple representation compared to the multilayer perceptron based predictors.", "venue": "2007 International Symposium on Information Technology Convergence (ISITC 2007)", "authors": ["George S. Eskander", "Amir F. Atiya", "Kil To Chong", "Hyongsuk  Kim", "Sung Goo Yoo"], "year": 2007, "n_citations": 9}
{"id": 3567257, "s2_id": "9823c49a4bb3030a0db4a59d033bc14cf1d0292f", "title": "Decomposing replicable functions", "abstract": "We describe an algorithm to decompose rational functions from which we determine the poset of groups fixing these functions.", "venue": "ArXiv", "authors": ["John  McKay", "David  Sevilla"], "year": 2008, "n_citations": 2}
{"id": 3568865, "s2_id": "e1d4a1d901fe5e24944f1533a6840f1ce61a9dda", "title": "Renormalized Wolfram model exhibiting non-relativistic quantum behavior", "abstract": "We show a Wolfram model whose renormalization generates a sequence of approximations of a wave function having the Pauli-x matrix as Hamiltonian.", "venue": "ArXiv", "authors": ["Jos'e Manuel Rodr'iguez Caballero"], "year": 2021, "n_citations": 0}
{"id": 3580608, "s2_id": "833a081733d046d106de1de20c79f109886222a1", "title": "Fast algorithms for differential equations in positive characteristic", "abstract": "We address complexity issues for linear differential equations in characteristic <i>p</i> >;0: resolution and computation of the <i>p</i>-curvature. For these tasks, our main focus is on algorithms whose complexity behaves well with respect to <i>p</i>. We prove bounds linear in <i>p</i> on the degree of polynomial solutions and propose algorithms for testing the existence of polynomial solutions in sublinear time <i>\u00d5</i>(<i>p</i><sup>1/2</sup>), and for determining a whole basis of the solution space in quasi-linear time <i>\u00d5</i>(<i>p</i>); the <i>\u00d5</i> notation indicates that we hide logarithmic factors. We show that for equations of arbitrary order, the <i>p</i>-curvature can be computed in subquadratic time <i>\u00d5</i>(<i>p</i><sup>1.79</sup>), and that this can be improved to <i>O</i>(log(<i>p</i>)) for first order equations and to <i>\u00d5</i>(<i>p</i>) for classes of second order equations.", "venue": "ISSAC '09", "authors": ["Alin  Bostan", "\u00c9ric  Schost"], "year": 2009, "n_citations": 15}
{"id": 3580935, "s2_id": "8d68336e6bb4d31f292b947c8176957611d28196", "title": "Iterated integrals over letters induced by quadratic forms", "abstract": "An automated treatment of iterated integrals based on letters induced by real-valued quadratic forms and Kummer\u2013Poincar\u00e9 letters is presented. These quantities emerge in analytic single and multi\u2013scale Feynman diagram calculations. To compactify representations, one wishes to apply general properties of these quantities in computer-algebraic implementations. We provide the reduction to basis representations, expansions, analytic continuation and numerical evaluation of these quantities.", "venue": "ArXiv", "authors": ["J.  Ablinger", "J.  Blumlein", "C.  Schneider"], "year": 2021, "n_citations": 1}
{"id": 3584167, "s2_id": "0d39747104ef8c1b197295587d0cf222e840f4b1", "title": "A-Discriminants for Complex Exponents and Counting Real Isotopy Types", "abstract": "We extend the definition of $\\mathcal{A}$-discriminant varieties, and Kapranov's parametrization of $\\mathcal{A}$-discriminant varieties, to complex exponents. As an application, we study the special case where $\\mathcal{A}$ is a fixed real $n\\times (n+3)$ matrix whose columns form the spectrum of an $n$-variate exponential sum $g$ with fixed sign vector for its coefficients: We prove that the number of possible isotopy types for the real zero set of $g$ is $O(n^2)$. The best previous upper bound was $2^{O(n^4)}$. Along the way, we also show that the singular loci of our generalized $\\mathcal{A}$-discriminants are images of low-degree algebraic sets under certain analytic maps.", "venue": "ArXiv", "authors": ["J. Maurice Rojas", "Korben  Rusek"], "year": 2016, "n_citations": 3}
{"id": 3584223, "s2_id": "39f32f033b1ccb1e94e8c90f2bedcf6f443123bd", "title": "Computing Elimination Ideals and Discriminants of Likelihood Equations", "abstract": "We develop a probabilistic algorithm for computing elimination ideals of likelihood equations, which is for larger models by far more efficient than directly computing Groebner bases or the interpolation method proposed in the first author's previous work. The efficiency is improved by a theoretical result showing that the sum of data variables appears in most coefficients of the generator polynomial of elimination ideal. Furthermore, applying the known structures of Newton polytopes of discriminants, we can also efficiently deduce discriminants of the elimination ideals. For instance, the discriminants of 3 by 3 matrix model and one Jukes-Cantor model in phylogenetics (with sizes over 30 GB and 8 GB text files, respectively) can be computed by our methods.", "venue": "ArXiv", "authors": ["Xiaoxian  Tang", "Timo de Wolff", "Rukai  Zhao"], "year": 2018, "n_citations": 0}
{"id": 3588499, "s2_id": "7ec26848533d9842ac03e5021d45ca1afdb493f2", "title": "Computer Algebra in JULIA", "abstract": "Recently, the place of the main programming language for scientific and engineering computations has been little by little taken by Julia. Some users want to work completely within the Julia framework as they work within the Python framework. There are libraries for Julia that cover the majority of scientific and engineering computations demands. The aim of this paper is to combine the usage of Julia framework for numerical computations and for symbolic computations in mathematical modeling problems. The main functional domains determining various variants of the application of computer algebra systems are described. In each of these domains, generic representatives of computer algebra systems in Julia are distinguished. The conclusion is that it is possible (and even convenient) to use computer algebra systems within the Julia framework.", "venue": "Program. Comput. Softw.", "authors": ["Dmitry S. Kulyabov", "Anna V. Korolkova"], "year": 2021, "n_citations": 0}
{"id": 3591418, "s2_id": "071beac5a37e36a6bcde063769e56c36d370cdfb", "title": "Bit Complexity of Jordan Normal Form and Spectral Factorization", "abstract": "We study the bit complexity of two related fundamental computational problems in linear algebra and control theory. Our results are: (1) An \u00d5(na+na+n log(1/\u01eb)) time algorithm for finding an \u01eb\u2212approximation to the Jordan Normal form of an integer matrix with a\u2212bit entries, where \u03c9 is the exponent of matrix multiplication. (2) An \u00d5(nda + nda + nd log(1/\u01eb)) time algorithm for \u01eb-approximately computing the spectral factorization P(x) = Q\u2217(x)Q(x) of a given monic n \u00d7 n rational matrix polynomial of degree 2d which satisfies P(x) 0 for all real x. The first algorithm is used as a subroutine in the second one. Despite its being of central importance, polynomial complexity bounds were not previously known for spectral factorization, and for Jordan form the best previous best boolean running time was an unspecified polynomial of degree at least twelve [Cai94]. Our algorithms are simple and judiciously combine techniques from numerical and symbolic computation, yielding significant advantages over either approach by itself.", "venue": "ArXiv", "authors": ["Papri  Dey", "Ravi  Kannan", "Nick  Ryder", "Nikhil  Srivastava"], "year": 2021, "n_citations": 0}
{"id": 3597251, "s2_id": "7eb8f0132bf3e45a06468178de1906ed8c44ab09", "title": "On sequences, rational functions and decomposition", "abstract": "It is classical that well-known identities and properties of partial quotients furnish rational approximation in $$\\mathbb {F}[[x^{-1}]]$$F[[x-1]]. For a rational function, this is the extended Euclidean algorithm in $$\\mathbb {F}[x]$$F[x]. Berlekamp\u2019s heuristic solution of the \u2018key equation\u2019 essentially approximates an element of $$\\mathbb {F}[x]$$F[x] with constant term 1 via a quotient of reciprocals, and his solutions satisfy a number of identities. In earlier papers we gave a solution of an analogous problem using $$\\mathrm {D}[x^{-1},x], \\mathrm {D}$$D[x-1,x],D a commutative domain. The linear complexity (of a finite initial subsequence) of an infinite sequence over $$\\mathbb {F}$$F has been related to the degrees of its partial quotients by Mills, Cheng, Niederreiter and others. We use first principles and induction to relate these linear complexities to the degrees of its partial quotients. Berlekamp has also described the set of solutions of the key equation. We define a pairing of minimal solutions and a \u2018minimal system\u2019 of a finite sequence over $$\\mathrm {D}$$D. Examples are classical approximation in $$\\mathbb {F}[[x^{-1}]]$$F[[x-1]] and approximation using $$\\mathrm {D}[x^{-1},x]$$D[x-1,x]. We use minimal systems to generalise results of Massey and Niederreiter to arbitrary solutions, including numerators. This includes explicit and unique decomposition of both parts of a solution into a sum of (polynomial) multiples of solutions with minimal degree denominators. The unique multipliers also satisfy degree constraints. We give several applications to gcd\u2019s of sequence polynomials and relate partial-quotient solutions to solutions derived using $$\\mathbb {F}[x^{-1},x]$$F[x-1,x]. We give a precise count of the number of solutions when the field is finite. Our final application concerns when the first component of a minimal solution vanishes at some scalar; a simple modification of our approach gives a new solution, the first component of which does not vanish at the scalar and which has minimal degree. We also describe the corresponding set of solutions. This simplifies and generalises work of Salagean. We conclude that numerators (or second components) of solutions can play a significant role in proofs of properties of denominators (or first components) and that they enjoy similar properties.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Graham H. Norton"], "year": 2015, "n_citations": 1}
{"id": 3601484, "s2_id": "bfdca85c081c848b924b6e354dd0bb095b24252b", "title": "Complexity estimates for two uncoupling algorithms", "abstract": "Uncoupling algorithms transform a linear differential system of first order into one or several scalar differential equations. We examine two approaches to uncoupling: the cyclic-vector method (CVM) and the Danilevski-Barkatou-Z\u00fcrcher algorithm (DBZ). We give tight size bounds on the scalar equations produced by CVM, and design a fast variant of CVM whose complexity is quasi-optimal with respect to the output size. We exhibit a strong structural link between CVM and DBZ enabling to show that, in the generic case, DBZ has polynomial complexity and that it produces a single equation, strongly related to the output of CVM. We prove that algorithm CVM is faster than DBZ by almost two orders of magnitude, and provide experimental results that validate the theoretical complexity analyses.", "venue": "ISSAC '13", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Elie de Panafieu"], "year": 2013, "n_citations": 22}
{"id": 3602110, "s2_id": "b53145e741f7b21fc8d8b4f868cbce8e927d1401", "title": "Segre class computation and practical applications", "abstract": "Let $X \\subset Y$ be closed (possibly singular) subschemes of a smooth projective toric variety $T$. We show how to compute the Segre class $s(X,Y)$ as a class in the Chow group of $T$. Building on this, we give effective methods to compute intersection products in projective varieties, to determine algebraic multiplicity without working in local rings, and to test pairwise containment of subvarieties of $T$. Our methods may be implemented without using Groebner bases; in particular any algorithm to compute the number of solutions of a zero-dimensional polynomial system may be used.", "venue": "Math. Comput.", "authors": ["Corey  Harris", "Martin  Helmer"], "year": 2020, "n_citations": 9}
{"id": 3615540, "s2_id": "adf2b8d645f4423a085a6e7febb8e06e80b10d00", "title": "A Complexity Chasm for Solving Univariate Sparse Polynomial Equations Over p-adic Fields", "abstract": "We reveal a complexity chasm, separating the trinomial and tetranomial cases, for solving univariate sparse polynomial equations over certain local fields. First, for any fixed field K\u2208 Q2,,Q3,Q5, \u2026, we prove that any polynomial f Z [x] with exactly 3 monomial terms, degree d, and all coefficients having absolute value at most H, can be solved over K within deterministic time logO(1) (dH) in the classical Turing model. (The best previous algorithms were of complexity exponential in log d, even for just counting roots in Qp.) In particular, our algorithm generates approximations in Q with bit-length log O(1) (dH) to all the roots of f in K, and these approximations converge quadratically under Newton iteration. On the other hand, we give a unified family of tetranomials requiring \u03a9(d log H) digits to distinguish the base-p expansions of their roots in K.", "venue": "ISSAC", "authors": ["J. Maurice Rojas", "Yuyu  Zhu"], "year": 2021, "n_citations": 2}
{"id": 3617699, "s2_id": "c3893294911e47484c272b21df6d44e9908fb761", "title": "Fast transforms over finite fields of characteristic two", "abstract": "An additive fast Fourier transform over a finite field of characteristic two efficiently evaluates polynomials at every element of an $\\mathbb{F}_2$-linear subspace of the field. We view these transforms as performing a change of basis from the monomial basis to the associated Lagrange basis, and consider the problem of performing the various conversions between these two bases, the associated Newton basis, and the '' novel '' basis of Lin, Chung and Han (FOCS 2014). Existing algorithms are divided between two families, those designed for arbitrary subspaces and more efficient algorithms designed for specially constructed subspaces of fields with degree equal to a power of two. We generalise techniques from both families to provide new conversion algorithms that may be applied to arbitrary subspaces, but which benefit equally from the specially constructed subspaces. We then construct subspaces of fields with smooth degree for which our algorithms provide better performance than existing algorithms.", "venue": "J. Symb. Comput.", "authors": ["Nicholas  Coxon"], "year": 2021, "n_citations": 2}
{"id": 3619352, "s2_id": "600ffb22f4449c102969e396212c3890a1b23cac", "title": "From matrix interpretations over the rationals to matrix interpretations over the naturals", "abstract": "Matrix interpretations generalize linear polynomial interpretations and have been proved useful in the implementation of tools for automatically proving termination of Term Rewriting Systems. In view of the successful use of rational coefficients in polynomial interpretations, we have recently generalized traditional matrix interpretations (using natural numbers in the matrix entries) to incorporate real numbers. However, existing results which formally prove that polynomials over the reals are more powerful than polynomials over the naturals for proving termination of rewrite systems failed to be extended to matrix interpretations. In this paper we get deeper into this problem. We show that, under some conditions, it is possible to transform a matrix interpretation over the rationals satisfying a set of symbolic constraints into a matrix interpretation over the naturals (using bigger matrices) which still satisfies the constraints.", "venue": "AISC'10/MKM'10/Calculemus'10", "authors": ["Salvador  Lucas"], "year": 2010, "n_citations": 3}
{"id": 3623429, "s2_id": "0c40b31aacac1d4f76282075a5502161a470167c", "title": "A Reduction Method for Higher Order Variational Equations of Hamiltonian Systems", "abstract": "Abstract. Let k be a differential field and let [A] : Y \u2032 = AY be a linear differential system where A \u2208 Mat(n , k). We say that A is in a reduced form if A \u2208 g(k\u0304) where g is the Lie algebra of [A] and k\u0304 denotes the algebraic closure of k. We owe the existence of such reduced forms to a result due to Kolchin and Kovacic [Kov71]. This paper is devoted to the study of reduced forms, of (higher order) variational equations along a particular solution of a complex analytical hamiltonian system X. Using a previous result [AW], we will assume that the first order variational equation has an abelian Lie algebra so that, at first order, there are no Galoisian obstructions to Liouville integrability. We give a strategy to (partially) reduce the variational equations at order m+1 if the variational equations at order m are already in a reduced form and their Lie algebra is abelian. Our procedure stops when we meet obstructions to the meromorphic integrability of X. We make strong use both of the lower block triangular structure of the variational equations and of the notion of associated Lie algebra of a linear differential system (based on the works of Wei and Norman in [WN63]). Obstructions to integrability appear when at some step we obtain a non-trivial commutator between a diagonal element and a nilpotent (subdiagonal) element of the associated Lie algebra. We use our method coupled with a reasoning on polylogarithms to give a new and systematic proof of the non-integrability of the H\u00e9non-Heiles system. We conjecture that our method is not only a partial reduction procedure but a complete reduction algorithm. In the context of complex Hamiltonian systems, this would mean that our method would be an effective version of the MoralesRamis-Sim\u00f3 theorem.", "venue": "ArXiv", "authors": ["Ainhoa  Aparicio-Monforte", "Jacques-Arthur  Weil"], "year": 2012, "n_citations": 11}
{"id": 3631943, "s2_id": "6188d37e09dcffc43ffd59a06a6b1b5162e36894", "title": "A new truncated fourier transform algorithm", "abstract": "Truncated Fourier Transforms (TFTs), first introduced by van der Hoeven, refer to a family of algorithms that attempt to smooth ``jumps'' in complexity exhibited by FFT algorithms. We present an in-place TFT whose time complexity, measured in terms of ring operations, is asymptotically equivalent to existing not-in-place TFT methods. We also describe a transformation that maps between two families of TFT algorithms that use different sets of evaluation points.", "venue": "ISSAC '13", "authors": ["Andrew  Arnold"], "year": 2013, "n_citations": 8}
{"id": 3646713, "s2_id": "0968de3d07cc9cab51b212a5c6da784309e42f81", "title": "Fast Matrix Multiplication and Symbolic Computation", "abstract": "The complexity of matrix multiplication (hereafter MM) has been intensively studied since 1969, when Strassen surprisingly decreased the exponent 3 in the cubic cost of the straightforward classical MM to log 2 (7) \u2248 2.8074. Applications to some fundamental problems of Linear Algebra and Computer Science have been immediately recognized, but the researchers in Computer Algebra keep discovering more and more applications even today, with no sign of slowdown. We survey the unfinished history of decreasing the exponent towards its information lower bound 2, recall some important techniques discovered in this process and linked to other fields of computing, reveal sample surprising applications to fast computation of the inner products of two vectors and summation of integers, and discuss the curse of recursion, which separates the progress in fast MM into its most acclaimed and purely theoretical part and into valuable acceleration of MM of feasible sizes. Then, in the second part of our paper, we cover fast MM in realistic symbolic computations and discuss applications and implementation of fast exact matrix multiplication. We first review how most of exact linear algebra can be reduced to matrix multiplication over small finite fields. Then we highlight the differences in the design of approximate and exact implementations of fast MM, taking into account nowadays processor and memory hierarchies. In the concluding section we comment on current perspectives of the study of fast MM.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Victor Y. Pan"], "year": 2016, "n_citations": 13}
{"id": 3647441, "s2_id": "0b3fa370c9aec21523a2cef840d5262524bb4372", "title": "Fast computation of the rank profile matrix and the generalized Bruhat decomposition", "abstract": "The row (resp. column) rank profile of a matrix describes the stair-case shape of its row (resp. column) echelon form. We here propose a new matrix invariant, the rank profile matrix, summarizing all information on the row and column rank profiles of all the leading sub-matrices. We show that this normal form exists and is unique over any ring, provided that the notion of McCoy's rank is used, in the presence of zero divisors. We then explore the conditions for a Gaussian elimination algorithm to compute all or part of this invariant, through the corresponding PLUQ decomposition. This enlarges the set of known Elimination variants that compute row or column rank profiles. As a consequence a new Crout base case variant significantly improves the practical efficiency of previously known implementations over a finite field. With matrices of very small rank, we also generalize the techniques of Storjohann and Yang to the computation of the rank profile matrix, achieving an $(r^\\omega+mn)^{1+o(1)}$ time complexity for an $m \\times n$ matrix of rank $r$, where $\\omega$ is the exponent of matrix multiplication. Finally, by give connections to the Bruhat decomposition, and several of its variants and generalizations. Thus, our algorithmic improvements for the PLUQ factorization, and their implementations, directly apply to these decompositions. In particular, we show how a PLUQ decomposition revealing the rank profile matrix also reveals both a row and a column echelon form of the input matrix or of any of its leading sub-matrices, by a simple post-processing made of row and column permutations.", "venue": "J. Symb. Comput.", "authors": ["Jean-Guillaume  Dumas", "Cl\u00e9ment  Pernet", "Ziad  Sultan"], "year": 2017, "n_citations": 8}
{"id": 3648545, "s2_id": "2026a2a481ae166534598d2ce46c38154b83a9e1", "title": "On the total order of reducibility of a pencil of algebraic plane curves", "abstract": "In this paper, the problem of bounding the number of reducible curves in a pencil of algebraic plane curves is addressed. Unlike most of the previous related works, each reducible curve of the pencil is here counted with its appropriate multiplicity. It is proved that this number of reducible curves, counted with multiplicity, is bounded by d^2-1 where d is the degree of the pencil. Then, a sharper bound is given by taking into account the Newton's polygon of the pencil.", "venue": "ArXiv", "authors": ["Laurent  Bus\u00e9", "Guillaume  Ch\u00e8ze"], "year": 2008, "n_citations": 12}
{"id": 3655168, "s2_id": "1193945835f46555e2abe2331d3207e095bf8e1b", "title": "Fast Algorithms for Refined Parameterized Telescoping in Difference Fields", "abstract": "Parameterized telescoping (including telescoping and creative telescoping) and refined versions of it play a central role in the research area of symbolic summation. In 1981 Karr introduced \\(\\varPi \\varSigma \\)-fields, a general class of difference fields, that enables one to consider this problem for indefinite nested sums and products covering as special cases, e.g., the (\\(q\\)\u2013)hypergeometric case and their mixed versions. This survey article presents the available algorithms in the framework of \\(\\varPi \\varSigma \\)-extensions and elaborates new results concerning efficiency.", "venue": "Computer Algebra and Polynomials", "authors": ["Carsten  Schneider"], "year": 2015, "n_citations": 46}
{"id": 3660222, "s2_id": "7b8ab3872a9ffcab72be4fd931bccd36bfc1436c", "title": "Solving First Order Autonomous Algebraic Ordinary Differential Equations by Places", "abstract": "Given a first order autonomous algebraic ordinary differential equation, we present a method for computing formal power series solutions by means of places. We provide an algorithm for computing a full characterization of possible initial values, classified in terms of the number of distinct formal power series solutions extending them. In addition, if a particular initial value is given, we present a second algorithm that computes all the formal power series solutions, up to a suitable degree, corresponding to it. Furthermore, when the ground field is the field of the complex numbers, we prove that the computed formal power series solutions are all convergent in suitable neighborhoods.", "venue": "Math. Comput. Sci.", "authors": ["Sebastian  Falkensteiner", "J. Rafael Sendra"], "year": 2020, "n_citations": 4}
{"id": 3662318, "s2_id": "677c08eb3de4c2b1332d910bd110d6cb358c0e12", "title": "A New Type of Bases for Zero-dimensional Ideals", "abstract": "We formulate a substantial improvement on Buchberger\u2019s algorithm for Gr\u00f6bner bases of zero-dimensional ideals. The improvement scales down the phenomenon of intermediate expression swell as well as the complexity of Buchberger\u2019s algorithm to a significant degree. The idea is to compute a new type of bases over principal ideal rings instead of over fields like Gr\u00f6bner bases. The generalizations of Buchberger\u2019s algorithm from over fields to over rings are abundant in the literature. However they are limited to either computations of strong Gr\u00f6bner bases or modular computations of the numeral coefficients of ideal bases with no essential improvement on the algorithmic complexity. In this paper we make pseudo-divisions with multipliers to enhance computational efficiency. In particular, we develop a new methodology in determining the authenticity of the factors of the pseudo-eliminant, i.e., we compare the factors with the multipliers of the pseudo-divisions instead of the leading coefficients of the basis elements. In order to find out the exact form of the eliminant, we contrive a modular algorithm of proper divisions over principal quotient rings with zero divisors. The pseudo-eliminant and proper eliminants and their corresponding bases constitute a decomposition of the original ideal. In order to address the ideal membership problem, we elaborate on various characterizations of the new type of bases. In the complexity analysis we devise a scenario linking the rampant intermediate coefficient swell to B\u00e9zout coefficients, partially unveiling the mystery of hight-level complexity associated with the computation of Gr\u00f6bner bases. Finally we make exemplary computations to demonstrate the conspicuous difference between Gr\u00f6bner bases and the new type of bases.", "venue": "ArXiv", "authors": ["Sheng-Ming  Ma"], "year": 2021, "n_citations": 0}
{"id": 3665654, "s2_id": "1ce53cce969f1e978f5b4cd5b32a65eb038ed82e", "title": "Counting Solutions of a Polynomial System Locally and Exactly", "abstract": "We propose a symbolic-numeric algorithm to count the number of solutions of a polynomial system within a local region. More specifically, given a zero-dimensional system $f_1=\\cdots=f_n=0$, with $f_i\\in\\mathbb{C}[x_1,\\ldots,x_n]$, and a polydisc $\\mathbf{\\Delta}\\subset\\mathbb{C}^n$, our method aims to certify the existence of $k$ solutions (counted with multiplicity) within the polydisc. \nIn case of success, it yields the correct result under guarantee. Otherwise, no information is given. However, we show that our algorithm always succeeds if $\\mathbf{\\Delta}$ is sufficiently small and well-isolating for a $k$-fold solution $\\mathbf{z}$ of the system. \nOur analysis of the algorithm further yields a bound on the size of the polydisc for which our algorithm succeeds under guarantee. This bound depends on local parameters such as the size and multiplicity of $\\mathbf{z}$ as well as the distances between $\\mathbf{z}$ and all other solutions. Efficiency of our method stems from the fact that we reduce the problem of counting the roots in $\\mathbf{\\Delta}$ of the original system to the problem of solving a truncated system of degree $k$. In particular, if the multiplicity $k$ of $\\mathbf{z}$ is small compared to the total degrees of the polynomials $f_i$, our method considerably improves upon known complete and certified methods. \nFor the special case of a bivariate system, we report on an implementation of our algorithm, and show experimentally that our algorithm leads to a significant improvement, when integrated as inclusion predicate into an elimination method.", "venue": "ArXiv", "authors": ["Ruben  Becker", "Michael  Sagraloff"], "year": 2017, "n_citations": 0}
{"id": 3667859, "s2_id": "49fb2bd5cb39f1d21acddf6cf3a4e8a264ed5a3b", "title": "Solving Polynomial Equations with Equation Constraints: the Zero-dimensional Case", "abstract": "A zero-dimensional polynomial ideal may have a lot of complex zeros. But sometimes, only some of them are needed. In this paper, for a zero-dimensional ideal I, we study its complex zeros that locate in another variety V(J) where J is an arbitrary ideal. The main problem is that for a point in V(I) \\ V(J) = V(I + J), its multiplicities w.r.t. I and I + J may be different. Therefore, we cannot get the multiplicity of this point w.r.t. I by studying I + J. A straightforward way is that first compute the points of V(I + J), then study their multiplicities w.r.t. I. But the former step is difficult to realize exactly. In this paper, we propose a natural geometric explanation of the localization of a polynomial ring corresponding to a semigroup order. Then, based on this view, using the standard basis method and the border basis method, we introduce a way to compute the complex zeros of I in V(J) with their multiplicities w.r.t. I. As an application, we compute the sum of Milnor numbers of the singular points on a polynomial hypersurface and work out all the singular points on the hypersurface with their Milnor numbers.", "venue": "ArXiv", "authors": ["Ye  Liang"], "year": 2014, "n_citations": 1}
{"id": 3668633, "s2_id": "004129f420492eb8d26cef0add6c741254924fd5", "title": "Pointer Data Structure Synthesis from Answer Set Programming Specifications", "abstract": "We develop an inductive proof-technique to generate imperative programs for pointer data structures from behavioural specifications expressed in the Answer Set Programming (ASP) formalism. ASP is a non-monotonic logic based formalism that employs negation-as-failure which helps emulate the human thought process, allowing domain experts to model desired system behaviour succinctly. We argue in this paper that ASP's reliance on negation-as-failure makes it a better formalism than those based on first-order logic for writing formal specifications. We assume the a domain expert provides the representation of inductively defined data structures along with a specification of its operations. Our procedures combined with our novel proof-technique reason over the specifications and automatically generate an imperative program. Our proof-technique leverages the idea of partial deduction to simplify logical specifications. By algebraically simplifying logical specifications we arrive at a residual specification which can be interpreted as an appropriate imperative program. This work is in the realm of constructing programs that are correct according to a given specification.", "venue": "ArXiv", "authors": ["Sarat Chandra Varanasi", "Neeraj  Mittal", "Gopal  Gupta"], "year": 2020, "n_citations": 0}
{"id": 3671638, "s2_id": "efcac22cb10f1d5ffc1be1f1bb2203e33d14a877", "title": "Simultaneous modular reduction and Kronecker substitution for small finite fields", "abstract": "We present algorithms to perform modular polynomial multiplication or a modular dot product efficiently in a single machine word. We use a combination of techniques. Polynomials are packed into integers by Kronecker substitution; several modular operations are performed at once with machine integer or floating point arithmetic; normalization of modular images is avoided when possible; some conversions back to polynomial coefficients are avoided; the coefficients are recovered efficiently by preparing them before conversion. We discuss precisely the required control on sizes and degrees. We then present applications to polynomial multiplication, prime field linear algebra and small extension field arithmetic, where these techniques lead to practical gains of quite large constant factors.", "venue": "J. Symb. Comput.", "authors": ["Jean-Guillaume  Dumas", "Laurent  Fousse", "Bruno  Salvy"], "year": 2011, "n_citations": 8}
{"id": 3675962, "s2_id": "249895b2cbfda53d30d1fd97fa390049b90c3a2f", "title": "Certificates for Triangular Equivalence and Rank Profiles", "abstract": "In this paper, we give novel certificates for triangular equivalence and rank profiles. These certificates enable to verify the row or column rank profiles or the whole rank profile matrix faster than recomputing them, with a negligible overall overhead. We first provide quadratic time and space non-interactive certificates saving the logarithmic factors of previously known ones. Then we propose interactive certificates for the same problems whose Monte Carlo verification complexity requires a small constant number of matrix-vector multiplications, a linear space, and a linear number of extra field operations. As an application we also give an interactive protocol, certifying the determinant of dense matrices, faster than the best previously known one.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "David  Lucas", "Cl\u00e9ment  Pernet"], "year": 2017, "n_citations": 8}
{"id": 3677751, "s2_id": "99eb122edd056afcff3ed92b9044d7de53acea0c", "title": "The VLSAT-1 Benchmark Suite", "abstract": "This report presents VLSAT-1 (an acronym for ``Very Large Boolean SATisfiability \nproblems''), the first part of a benchmark suite to be used in scientific \nexperiments and software competitions addressing SAT-solving issues. \nVLSAT-1 contains 100~benchmarks of increasing complexity, proposed in DIMACS \nCNF format under a permissive Creative Commons license. These benchmarks have \nbeen used by the 2020 International Competition on Model Counting.", "venue": "ArXiv", "authors": ["Pierre  Bouvier", "Hubert  Garavel"], "year": 2020, "n_citations": 3}
{"id": 3681678, "s2_id": "aaf2c0caeeb3783b0fa6c3140e83a2dc55a71b1d", "title": "It is Time for New Perspectives on How to Fight Bloat in GP", "abstract": "The present and future of evolutionary algorithms depends on the proper use of modern parallel and distributed computing infrastructures. Although still sequential approaches dominate the landscape, available multi-core, many-core and distributed systems will make users and researchers to more frequently deploy parallel version of the algorithms. In such a scenario, new possibilities arise regarding the time saved when parallel evaluation of individuals are performed. And this time saving is particularly relevant in Genetic Programming. This paper studies how evaluation time influences not only time to solution in parallel/distributed systems, but may also affect size evolution of individuals in the population, and eventually will reduce the bloat phenomenon GP features. This paper considers time and space as two sides of a single coin when devising a more natural method for fighting bloat. This new perspective allows us to understand that new methods for bloat control can be derived, and the first of such a method is described and tested. Experimental data confirms the strength of the approach: using computing time as a measure of individuals' complexity allows to control the growth in size of genetic programming individuals.", "venue": "GPTP", "authors": ["Francisco Fern\u00e1ndez de Vega", "Gustavo  Olague", "O  FranciscoCh\u00e1vezdela", "Daniel  Lanza", "Wolfgang  Banzhaf", "Erik D. Goodman"], "year": 2019, "n_citations": 2}
{"id": 3682506, "s2_id": "78d0d492885f782a9a8da524c3da944a677968b8", "title": "Unary primitive recursive functions", "abstract": "Abstract In this article, we study some new characterizations of primitive recursive functions based on restricted forms of primitive recursion, improving the pioneering work of R. M. Robinson and M. D. Gladstone. We reduce certain recursion schemes (mixed/pure iteration without parameters) and we characterize one-argument primitive recursive functions as the closure under substitution and iteration of certain optimal sets.", "venue": "Journal of Symbolic Logic", "authors": ["Daniel E. Sever\u00edn"], "year": 2008, "n_citations": 5}
{"id": 3688996, "s2_id": "c1cc53ec5584b7e1d6469923185e3cbe02746075", "title": "The MathScheme Library: Some Preliminary Experiments", "abstract": "We present some of the e\u7870eriments we have performed to best test our design for a library for MathScheme, the mechanized mathe- matics software s\u7973tem we are building. We wish for our librar y design to use and reect, as much as possible, the mathematical structure present in the objects which populate the library.", "venue": "ArXiv", "authors": ["Jacques  Carette", "William M. Farmer", "Filip  Jeremic", "Vincent  Maccio", "Russell  O'Connor", "Quang M. Tran"], "year": 2011, "n_citations": 9}
{"id": 3722303, "s2_id": "b87f7edabc09c9fb35cf2c0ff8a7e408234fa4ad", "title": "Computing stable resultant-based minimal solvers by hiding a variable", "abstract": "Many computer vision applications require robust and efficient estimation of camera geometry. The robust estimation is usually based on solving camera geometry problems from a minimal number of input data measurements, i.e., solving minimal problems, in a RANSAC-style framework. Minimal problems often result in complex systems of polynomial equations. The existing state-of-the-art methods for solving such systems are either based on Gr\u00f6bner bases and the action matrix method, which have been extensively studied and optimized in the recent years or recently proposed approach based on a resultant computation using an extra variable. In this paper, we study an interesting alternative resultant-based method for solving sparse systems of polynomial equations by hiding one variable. This approach results in a larger eigenvalue problem than the action matrix and extra variable resultant-based methods; however, it does not need to compute an inverse or elimination of large matrices that may be numerically unstable. The proposed approach includes several improvements to the standard sparse resultant algorithms, which significantly improves the efficiency and stability of the hidden variable resultant-based solvers as we demonstrate on several interesting computer vision problems. We show that for the studied problems, our sparse resultant based approach leads to more stable solvers than the state-of-the-art Gr\u00f6bner basis as well as existing resultant-based solvers, especially in close to critical configurations. Our new method can be fully automated and incorporated into existing tools for the automatic generation of efficient minimal solvers.", "venue": "2020 25th International Conference on Pattern Recognition (ICPR)", "authors": ["Snehal  Bhayani", "Zuzana  Kukelova", "Janne  Heikkil\u00e4"], "year": 2021, "n_citations": 1}
{"id": 3722769, "s2_id": "f68cdcbd8d6f7d70b59e9d56589b42f2dc89fda5", "title": "Verifying Buchberger's Algorithm in Reduction Rings", "abstract": "In this paper we present the formal, computer-supported verification of a functional implementation of Buchberger's critical-pair/completion algorithm for computing Gr\\\"obner bases in reduction rings. We describe how the algorithm can be implemented and verified within one single software system, which in our case is the Theorema system. \nIn contrast to existing formal correctness proofs of Buchberger's algorithm in other systems, e. g. Coq and ACL2, our work is not confined to the classical setting of polynomial rings over fields, but considers the much more general setting of reduction rings; this, naturally, makes the algorithm more complicated and the verification more difficult. \nThe correctness proof is essentially based on some non-trivial results from the theory of reduction rings, which we formalized and formally proved as well. This formalization already consists of more than 800 interactively proved lemmas and theorems, making the elaboration an extensive example of higher-order theory exploration in Theorema.", "venue": "ArXiv", "authors": ["Alexander  Maletzky"], "year": 2016, "n_citations": 2}
{"id": 3723417, "s2_id": "1eabe1666ac33e09e09c2d5b6e2824a8cd1bdeae", "title": "Zero Decomposition with Multiplicity of Zero-Dimensional Polynomial Systems", "abstract": "We present a zero decomposition theorem and an algorithm based on Wu's method, which computes a zero decomposition with multiplicity for a given zero-dimensional polynomial system. If the system satisfies some condition, the zero decomposition is of triangular form.", "venue": "ArXiv", "authors": ["Yinglin  Li", "Bican  Xia", "Zhihai  Zhang"], "year": 2010, "n_citations": 5}
{"id": 3724606, "s2_id": "3b5cf4b55949fea43c30d4f5e74c357ac7d1b9d8", "title": "GCD computation of n integers", "abstract": "Greatest Common Divisor (GCD) computation is one of the most important operation of algorithmic number theory. In this paper we present the algorithms for GCD computation of n integers. We extend the Euclid's algorithm and binary GCD algorithm to compute the GCD of more than two integers.", "venue": "2014 Recent Advances in Engineering and Computational Sciences (RAECS)", "authors": ["Shri Prakash Dwivedi"], "year": 2014, "n_citations": 4}
{"id": 3728100, "s2_id": "70082498e8eae195f903789f4de423f42c28ee46", "title": "Solving Satisfiability of Polynomial Formulas By Sample-Cell Projection", "abstract": "A new algorithm for deciding the satisfiability of polynomial formulas over the reals is proposed. The key point of the algorithm is a new projection operator, called sample-cell projection operator, custom-made for Conflict-Driven Clause Learning (CDCL)-style search. Although the new operator is also a CAD (Cylindrical Algebraic Decomposition)-like projection operator which computes the cell (not necessarily cylindrical) containing a given sample such that each polynomial from the problem is sign-invariant on the cell, it is of singly exponential time complexity. The sample-cell projection operator can efficiently guide CDCL-style search away from conflicting states. Experiments show the effectiveness of the new algorithm.", "venue": "ArXiv", "authors": ["Haokun  Li", "Bican  Xia"], "year": 2020, "n_citations": 0}
{"id": 3731044, "s2_id": "4f296ceb66abc9338e01c649d50e1e5a5b18dcb0", "title": "System Description: H-PILoT (Version 1.9)", "abstract": "This system description provides an overview of H-PILoT (Hierarchical Proving by Instantiation in Local Theory extensions), a program for hierarchical reasoning in extensions of logical theories. H-PILoT reduces deduction problems in the theory extension to deduction problems in the base theory. Specialized provers and standard SMT solvers can be used for testing the satisfiability of the formulae obtained after the reduction. For a certain type of theory extension (namely for local theory extensions) this hierarchical reduction is sound and complete and -- if the formulae obtained this way belong to a fragment decidable in the base theory -- H-PILoT provides a decision procedure for testing satisfiability of ground formulae, and can also be used for model generation.", "venue": "ArXiv", "authors": ["Carsten  Ihlemann", "Viorica  Sofronie-Stokkermans"], "year": 2010, "n_citations": 0}
{"id": 3735510, "s2_id": "4eccc2a44a8fea489863586b9c28f03b98b9cd1b", "title": "Fast computation of common left multiples of linear ordinary differential operators", "abstract": "We study tight bounds and fast algorithms for LCLMs of several linear differential operators with polynomial coefficients. We analyse the arithmetic complexity of existing algorithms for LCLMs, as well as the size of their outputs. We propose a new algorithm that recasts the LCLM computation in a linear algebra problem on a polynomial matrix. This algorithm yields sharp bounds on the coefficient degrees of the LCLM, improving by one order of magnitude the best bounds obtained using previous algorithms. The complexity of the new algorithm is almost optimal, in the sense that it nearly matches the arithmetic size of the output.", "venue": "ACCA", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Ziming  Li", "Bruno  Salvy"], "year": 2011, "n_citations": 12}
{"id": 3749746, "s2_id": "aa156521a4ec7abad2f625a1c5ff4fc32dbd0ac9", "title": "Generating functions of Chebyshev-like polynomials", "abstract": "In this short note, we give simple proofs of several results and conjectures formulated by Stolarsky and Tran concerning generating functions of some families of Chebyshev-like polynomials.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Bruno  Salvy", "Khang  Tran"], "year": 2009, "n_citations": 0}
{"id": 3754145, "s2_id": "49640022ce0aa174392e4cd8ff5749509c541bef", "title": "Improving the Use of Equational Constraints in Cylindrical Algebraic Decomposition", "abstract": "When building a cylindrical algebraic decomposition (CAD) savings can be made in the presence of an equational constraint (EC): an equation logically implied by a formula. The present paper is concerned with how to use multiple ECs, propagating those in the input throughout the projection set. We improve on the approach of McCallum in ISSAC 2001 by using the reduced projection theory to make savings in the lifting phase (both to the polynomials we lift with and the cells lifted over). We demonstrate the benefits with worked examples and a complexity analysis.", "venue": "ISSAC", "authors": ["Matthew  England", "Russell J. Bradford", "James H. Davenport"], "year": 2015, "n_citations": 28}
{"id": 3756206, "s2_id": "bd42daba9531d3a17a7ab440392a08933d1ac4d9", "title": "Lecture notes on complexity of quantifier elimination over the reals", "abstract": "These are lecture notes for a course I gave in mid-1990s for MSc students at the University of Bath. It presents an algorithm with singly exponential complexity for the existential theory of the reals, in the spirit of J. Renegar [7]. Some ideas are borrowed from [6] and [5]. The aim was to convey the main underlying ideas, so many of the proofs and finer details of algorithms are either missing or just sketched. Full proofs and algorithms can be found in the aforementioned papers or, in a somewhat different form, in the fundamental monograph [1]. I changed nothing in the original notes except adding references, bibliography, and correcting obvious typos.", "venue": "ArXiv", "authors": ["Nicolai  Vorobjov"], "year": 2021, "n_citations": 0}
{"id": 3756634, "s2_id": "763262764a223ab38432e539eab25a7786c7d8dc", "title": "Fast Computation of Minimal Interpolation Bases in Popov Form for Arbitrary Shifts", "abstract": "We compute minimal bases of solutions for a general interpolation problem, which encompasses Hermite-Pade approximation and constrained multivariate interpolation, and has applications in coding theory and security. This problem asks to find univariate polynomial relations between m vectors of size \u03c3; these relations should have small degree with respect to an input degree shift. For an arbitrary shift, we propose an algorithm for the computation of an interpolation basis in shifted Popov normal form with a cost of O~(m\u03c9-1 \u03c3) field operations, where \u03c9 is the exponent of matrix multiplication and the notation O~(\u00b7) indicates that logarithmic terms are omitted. Earlier works, in the case of Hermite-Pade approximation and in the general interpolation case, compute non-normalized bases. Since for arbitrary shifts such bases may have size \u0398(m2 \u03c3), the cost bound O~(m\u03c9-1 \u03c3) was feasible only with restrictive assumptions on the shift that ensure small output sizes. The question of handling arbitrary shifts with the same complexity bound was left open. To obtain the target cost for any shift, we strengthen the properties of the output bases, and of those obtained during the course of the algorithm: all the bases are computed in shifted Popov form, whose size is always O(m \u03c3). Then, we design a divide-and-conquer scheme. We recursively reduce the initial interpolation problem to sub-problems with more convenient shifts by first computing information on the degrees of the intermediate bases.", "venue": "ISSAC", "authors": ["Claude-Pierre  Jeannerod", "Vincent  Neiger", "\u00c9ric  Schost", "Gilles  Villard"], "year": 2016, "n_citations": 22}
{"id": 3758601, "s2_id": "2d3728542aa532fd6f0bde01083d77b65406fbbd", "title": "Deterministic Genericity for Polynomial Ideals", "abstract": "Abstract We consider several notions of genericity appearing in algebraic geometry and commutative algebra. Special emphasis is put on various stability notions which are defined in a combinatorial manner and for which a number of equivalent algebraic characterisations are provided. It is shown that in characteristic zero the corresponding generic positions can be obtained with a simple deterministic algorithm. In positive characteristic, only adapted stable positions are reachable except for quasi-stability which is obtainable in any characteristic.", "venue": "J. Symb. Comput.", "authors": ["Amir  Hashemi", "Michael  Schweinfurter", "Werner M. Seiler"], "year": 2018, "n_citations": 11}
{"id": 3762563, "s2_id": "69392dd220674351af0cea0a4a0e5c18740ca104", "title": "Computing basepoints of linear series in the plane", "abstract": "We present an algorithm for detecting basepoints of linear series of curves in the plane. Moreover, we give an algorithm for constructing a linear series of curves in the plane for given basepoints. The underlying method of these algorithms is the classical procedure of blowing up points in the plane. We motivate the algorithmic version of this procedure with several applications.", "venue": "ArXiv", "authors": ["Niels  Lubbes"], "year": 2018, "n_citations": 4}
{"id": 3765794, "s2_id": "923ed3309606e5ab8f946a762992ad1043e7dbab", "title": "Rational Invariants of Even Ternary Forms Under the Orthogonal Group", "abstract": "In this article we determine a generating set of rational invariants of minimal cardinality for the action of the orthogonal group $$\\mathrm {O}_{3}$$O3 on the space $$\\mathbb {R}[x,y,z]_{2d}$$R[x,y,z]2d of ternary forms of even degree 2d. The construction relies on two key ingredients: on the one hand, the Slice Lemma allows us to reduce the problem to determining the invariants for the action on a subspace of the finite subgroup $$\\mathrm {B}_{3}$$B3 of signed permutations. On the other hand, our construction relies in a fundamental way on specific bases of harmonic polynomials. These bases provide maps with prescribed $$\\mathrm {B}_{3}$$B3-equivariance properties. Our explicit construction of these bases should be relevant well beyond the scope of this paper. The expression of the $$\\mathrm {B}_{3}$$B3-invariants can then be given in a compact form as the composition of two equivariant maps. Instead of providing (cumbersome) explicit expressions for the $$\\mathrm {O}_{3}$$O3-invariants, we provide efficient algorithms for their evaluation and rewriting. We also use the constructed $$\\mathrm {B}_{3}$$B3-invariants to determine the $$\\mathrm {O}_{3}$$O3-orbit locus and provide an algorithm for the inverse problem of finding an element in $$\\mathbb {R}[x,y,z]_{2d}$$R[x,y,z]2d with prescribed values for its invariants. These computational issues are relevant in brain imaging.", "venue": "Found. Comput. Math.", "authors": ["Paul  G\u00f6rlach", "Evelyne  Hubert", "Th\u00e9o  Papadopoulo"], "year": 2019, "n_citations": 6}
{"id": 3769642, "s2_id": "a15b66460ec949e435cb70bdec82f14f0c6e4587", "title": "A General Solver Based on Sparse Resultants", "abstract": "Sparse elimination exploits the structure of polynomials by measuring their complexity in terms of Newton polytopes instead of total degree. The sparse, or Newton, resultant generalizes the classical homogeneous resultant and its degree is a function of the mixed volumes of the Newton polytopes. We sketch the sparse resultant constructions of Canny and Emiris and show how they reduce the problem of root-finding to an eigenproblem. A novel method for achieving this reduction is presented which does not increase the dimension of the problem. Together with an implementation of the sparse resultant construction, it provides a general solver for polynomial systems. We discuss the overall implementation and illustrate its use by applying it to concrete problems from vision, robotics and structural biology. The high efficiency and accuracy of the solutions suggest that sparse elimination may be the method of choice for systems of moderate size.", "venue": "ArXiv", "authors": ["Ioannis Z. Emiris"], "year": 2012, "n_citations": 6}
{"id": 3771211, "s2_id": "678de41037c0801fbc077f44ea0c758dd58b1907", "title": "When can we decide that a P-finite sequence is positive?", "abstract": "We consider two algorithms which can be used for proving positivity of sequences that are defined by a linear recurrence equation with polynomial coefficients (P-finite sequences). Both algorithms have in common that while they do succeed on a great many examples, there is no guarantee for them to terminate, and they do in fact not terminate for every input. For some restricted classes of P-finite recurrence equations of order up to three we provide a priori criteria that assert the termination of the algorithms.", "venue": "ArXiv", "authors": ["Manuel  Kauers", "Veronika  Pillwein"], "year": 2010, "n_citations": 2}
{"id": 3778428, "s2_id": "c2c384075ac7ca2151d0f79d8f7211e6bbc6147b", "title": "Regular and Singular Boundary Problems in Maple", "abstract": "We describe a new Maple package for treating boundary problems for linear ordinary differential equations, allowing two-/multipoint as well as Stieltjes boundary conditions. For expressing differential operators, boundary conditions, and Green's operators, we employ the algebra of integro-differential operators. The operations implemented for regular boundary problems include computing Green's operators as well as composing and factoring boundary problems. Our symbolic approach to singular boundary problems is new; it provides algorithms for computing compatibility conditions and generalized Green's operators.", "venue": "CASC", "authors": ["Anja  Korporal", "Georg  Regensburger", "Markus  Rosenkranz"], "year": 2011, "n_citations": 13}
{"id": 3779307, "s2_id": "d3c3841516af17fa2a70aed7979bb6bcbdd7703e", "title": "Sparse Representations of Clifford and Tensor Algebras in Maxima", "abstract": "Clifford algebras have broad applications in science and engineering. The use of Clifford algebras can be further promoted in these fields by availability of computational tools that automate tedious routine calculations. We offer an extensive demonstration of the applications of Clifford algebras in electromagnetism using the geometric algebra $${\\mathbb{G}^3 \\equiv C\\ell_{3,0}}$$G3\u2261C\u21133,0 as a computational model in the Maxima computer algebra system. We compare the geometric algebra-based approach with conventional symbolic tensor calculations supported by Maxima, based on the itensor package. The Clifford algebra functionality of Maxima is distributed as two new packages called clifford\u2014for basic simplification of Clifford products, outer products, scalar products and inverses; and cliffordan\u2014for applications of geometric calculus.", "venue": "ArXiv", "authors": ["Dimiter  Prodanov", "Viktor T. Toth"], "year": 2016, "n_citations": 3}
{"id": 3784608, "s2_id": "1d2b0a97ce307832f7eb62cbbeeeb99f5fab575e", "title": "A Logical Programming Language as an Instrument for Specifying and Verifying Dynamic Memory", "abstract": "This work proposes a Prolog-dialect for the found and prioritised problems on expressibility and automation. Given some given C-like program, if dynamic memory is allocated, altered and freed on runtime, then a description of desired dynamic memory is a heap specification. The check of calculated memory state against a given specification is dynamic memory verification. This contribution only considers formal specification and verification in a Hoare calculus. Issues found include: invalid assignment, (temporary) unavailable data in memory cells, excessive memory allocation, (accidental) heap alteration in unexpected regions and others. Excessive memory allocation is nowadays successfully resolved by memory analysers like Valgrind. Essentially, papers in those areas did not bring any big breakthrough. Possible reasons may also include the decrease of tension due to more available memory and parallel threads. However, starting with Apt, problems related to variable modes have not yet been resolved -- neither entirely nor in an acceptable way. Research contributions over the last decades show again and again that heap issues remain and remain complex and still important. A significant contribution was reached in 2016 by Peter O'Hearn, who accepted the G\\\"{o}del prize for his parallel approach on a spatial heap operation.", "venue": "ArXiv", "authors": ["Ren'e  Haberland"], "year": 2021, "n_citations": 0}
{"id": 3786983, "s2_id": "c52ac4ea979118b38fb1fc72fc8dc56d6217224e", "title": "Theorem Proving and Algebra", "abstract": "Rewrite Systems 121 rewrites is the same in either order. If the redexes are not disjoint, then either the rules overlap (in the sense of Definition 5.6.2), or else the subredex results from substituting for a variable in the leftside of the rule producing the larger redex. In the first case, the result terms of the two rewrites rewrite to a common term by hypothesis, since the overlap is a substitution instance of the overlap of some critical pair by Proposition 12.0.1. In the second case, the result of applying both rules is the same in either order, though the subredex may have to be rewritten multiple (or zero) times if the variable involved is non-linear. The full proof is in Appendix B. This and the Newman Lemma (Proposition 5.6.1) give: Corollary 5.6.10 A terminating TRS is Church-Rosser if and only if all its critical pairs are convergent, in which case it is also canonical. Chapter 12 introduces unification, an algorithm that can be used to compute all critical pairs of a TRS, and hence to decide the ChurchRosser property for any terminating TRS. Exercise 5.6.7 Use Corollary 5.6.10 to show the Church-Rosser property, and hence the canonicity, of the following TRS\u2019s: 1. GROUPC of Example 5.2.8; 2. AND of Example 5.5.7; and 3. MONOID of Exercise 5.2.7. 5.7 Abstract Rewrite Systems Many important results about term rewriting are actually special cases of much more general results about a binary relation on a set. Although this abstraction of term rewriting to the one-step rewrite relation ignores the structure of terms, it still includes a great deal. The classical approach takes an unsorted view of the elements to be rewritten, but here we generalize to sorted sets of elements, enabling applications to many-sorted term rewriting and equational deduction that appear to be new. Definition 5.7.1 An abstract rewrite system (abbreviated ARS) consists of a (sorted) set T and a (similarly sorted) binary relation \u2192 on T , i.e., \u2192 \u2286 T \u00d7 T . We may denote such a system as a pair (T ,\u2192), or possibly as a triple (S, T ,\u2192), if the sort set S needs to be emphasized. An ARS (T ,\u2192) is terminating if and only if there is no infinite sequence a1, a2, . . . of elements of T such that ai \u2192 ai+1 for i = 1,2, . . .", "venue": "ArXiv", "authors": ["Joseph A. Goguen"], "year": 2021, "n_citations": 6}
{"id": 3792110, "s2_id": "1b1105e145b5d68b9f65d4081bc14c69e630d7be", "title": "Hypergeometric expressions for generating functions of walks with small steps in the quarter plane", "abstract": "We study nearest-neighbors walks on the two-dimensional square lattice, that is, models of walks on $\\mathbb{Z}^2$ defined by a fixed step set that is a subset of the non-zero vectors with coordinates 0, 1 or $-1$. We concern ourselves with the enumeration of such walks starting at the origin and constrained to remain in the quarter plane $\\mathbb{N}^2$, counted by their length and by the position of their ending point. Bousquet-Melou and Mishna [Contemp. Math., pp. 1--39, Amer. Math. Soc., 2010] identified 19 models of walks that possess a D-finite generating function; linear differential equations have then been guessed in these cases by Bostan and Kauers [FPSAC 2009, Discrete Math. Theor. Comput. Sci. Proc., pp. 201--215, 2009]. We give here the first proof that these equations are indeed satisfied by the corresponding generating functions. As a first corollary, we prove that all these 19 generating functions can be expressed in terms of Gauss' hypergeometric functions that are intimately related to elliptic integrals. As a second corollary, we show that all the 19 generating functions are transcendental, and that among their $19 \\times 4$ combinatorially meaningful specializations only four are algebraic functions.", "venue": "Eur. J. Comb.", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Mark van Hoeij", "Manuel  Kauers", "Lucien  Pech"], "year": 2017, "n_citations": 32}
{"id": 3797566, "s2_id": "8571ca7edc53da6979e908fcd0697e0215d634d3", "title": "Faster polynomial multiplication via multipoint Kronecker substitution", "abstract": "We present several new algorithms for dense polynomial multiplication in Z[x] based on the Kronecker substitution method. Instead of reducing to a single integer multiplication, we reduce to several smaller multiplications. We describe an implementation of multiplication in (Z/nZ)[x] for a word-sized modulus n based on these methods, and compare its performance to that of NTL and Magma.", "venue": "J. Symb. Comput.", "authors": ["David  Harvey"], "year": 2009, "n_citations": 32}
{"id": 3799360, "s2_id": "13dc6c1ed33307a30ffe419c739e455386e7bab6", "title": "Explosive Proofs of Mathematical Truths", "abstract": "Mathematical proofs are both paradigms of certainty and some of the most explicitly-justified arguments that we have in the cultural record. Their very explicitness, however, leads to a paradox, because their probability of error grows exponentially as the argument expands. Here we show that under a cognitively-plausible belief formation mechanism that combines deductive and abductive reasoning, mathematical arguments can undergo what we call an epistemic phase transition: a dramatic and rapidly-propagating jump from uncertainty to near-complete confidence at reasonable levels of claim-to-claim error rates. To show this, we analyze an unusual dataset of forty-eight machine-aided proofs from the formalized reasoning system Coq, including major theorems ranging from ancient to 21st Century mathematics, along with four hand-constructed cases from Euclid, Apollonius, Spinoza, and Andrew Wiles. Our results bear both on recent work in the history and philosophy of mathematics, and on a question, basic to cognitive science, of how we form beliefs, and justify them to others.", "venue": "ArXiv", "authors": ["Scott  Viteri", "Simon  DeDeo"], "year": 2020, "n_citations": 2}
{"id": 3803276, "s2_id": "30f1598d9e4a76b730653500c975337a36262b3f", "title": "Reverse engineering of irreducible polynomials in GF(2m) arithmetic", "abstract": "Current techniques for formally verifying circuits implemented in Galois field (GF) arithmetic are limited to those with a known irreducible polynomial P(x). This paper presents a computer algebra based technique that extracts the irreducible polynomial P(x) used in the implementation of a multiplier in GF(2m). The method is based on first extracting a unique polynomial in Galois field of each output bit independently. P(x) is then obtained by analyzing the algebraic expression in GF(2m) of each output bit. We demonstrate that this method is able to reverse engineer the irreducible polynomial of an n-bit GF multiplier in n threads. Experiments were performed on Mastrovito and Montgomery multipliers with different P(x), including NIST-recommended polynomials and optimal polynomials for different microprocessor architectures.", "venue": "Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017", "authors": ["Cunxi  Yu", "Daniel E. Holcomb", "Maciej J. Ciesielski"], "year": 2017, "n_citations": 4}
{"id": 3804749, "s2_id": "e882bad2bc5e398b7bf74052a3bcd03548f6f4ef", "title": "Compact Formulae in Sparse Elimination", "abstract": "It has by now become a standard approach to use the theory of sparse (or toric) elimination, based on the Newton polytope of a polynomial, in order to reveal and exploit the structure of algebraic systems. This talk surveys compact formulae, including older and recent results, in sparse elimination. We start with root bounds and juxtapose two recent formulae: a generating function of the m-Bezout bound and a closed-form expression for the mixed volume by means of a matrix permanent. For the sparse resultant, a bevy of results have established determinantal or rational formulae for a large class of systems, starting with Macaulay. The discriminant is closely related to the resultant but admits no compact formula except for very simple cases. We offer a new determinantal formula for the discriminant of a sparse multilinear system arising in computing Nash equilibria. We introduce an alternative notion of compact formula, namely the Newton polytope of the unknown polynomial. It is possible to compute it efficiently for sparse resultants, discriminants, as well as the implicit equation of a parameterized variety. This leads us to consider implicit matrix representations of geometric objects.", "venue": "ISSAC", "authors": ["Ioannis Z. Emiris"], "year": 2016, "n_citations": 1}
{"id": 3805073, "s2_id": "3cc43c1ba38eb012bee371f669a49b7507038c28", "title": "Algorithms for Checking Rational Roots of $b$-functions and their Applications", "abstract": "Bernstein-Sato polynomial of a hypersurface is an important object with numerous applications. It is known, that it is complicated to obtain it computationally, as a number of open questions and challenges indicate. In this paper we propose a family of algorithms called \\texttt{checkRoot} for optimized check of whether a given rational number is a root of Bernstein-Sato polynomial and the computations of its multiplicity. This algorithms are used in the new approach to compute the whole global or local Bernstein-Sato polynomial and $b$-function of a holonomic ideal with respect to weights. They are applied in numerous situations, where there is a possibility to compute an upper bound for the polynomial. Namely, it can be achieved by means of embedded resolution, for topologically equivalent singularities or using the formula of A'Campo and spectral numbers. We also present approaches to the logarithmic comparison problem and the intersection homology D-module. Several applications are presented as well as solutions to some challenges which were intractable with the classical methods. One of the main applications consists of computing of a stratification of affine space with the local $b$-function being constant on each stratum. Notably, the algorithm we propose does not employ primary decomposition. Also we apply our results for the computation of Bernstein-Sato polynomials for varieties. The methods from this paper have been implemented in {\\sc Singular:Plural} as libraries {\\tt dmod.lib} and {\\tt bfun.lib}. All the examples from the paper have been computed with this implementation.", "venue": "ArXiv", "authors": ["Viktor  Levandovskyy", "Jorge  Mart\u00edn-Morales"], "year": 2010, "n_citations": 13}
{"id": 3805652, "s2_id": "2d0a95b29c21ca0b403d6068e15c016c9c453a9d", "title": "Symbolic domain decomposition", "abstract": "Decomposing the domain of a function into parts has many uses in mathematics. A domain may naturally be a union of pieces, a function may be defined by cases, or different boundary conditions may hold on different regions. For any particular problem the domain can be given explicitly, but when dealing with a family of problems given in terms of symbolic parameters, matters become more difficult. This article shows how hybrid sets, that is multisets allowing negative multiplicity, may be used to express symbolic domain decompositions in an efficient, elegant and uniform way, simplifying both computation and reasoning. We apply this theory to the arithmetic of piecewise functions and symbolic matrices and show how certain operations may be reduced from exponential to linear complexity.", "venue": "AISC'10/MKM'10/Calculemus'10", "authors": ["Jacques  Carette", "Alan P. Sexton", "Volker  Sorge", "Stephen M. Watt"], "year": 2010, "n_citations": 8}
{"id": 3812059, "s2_id": "25af2d94d8a1c811e5505e03aa84c8c0a686e72e", "title": "Asymptotically fast polynomial matrix algorithms for multivariable systems", "abstract": "We present the asymtotically fastest known algorithms for some basic problems on univariate polynomial matrices: rank; nullspace; determinant; generic inverse reduced form (Giorgi et al. 2003, Storjohann 2003, Jeannerod and Villard 2005, Storjohann and Villard 2005). We show that they essentially can be reduced to two computer algebra techniques, minimal basis computations and matrix fraction expansion/reconstruction, and to polynomial matrix multiplication. Such reductions eventually imply that all these problems can be solved in about the same amount of time as polynomial matrix multiplication. The algorithms are deterministic, or randomized with certified output in a Las Vegas fashion.", "venue": "ArXiv", "authors": ["Claude-Pierre  Jeannerod", "Gilles  Villard"], "year": 2005, "n_citations": 17}
{"id": 3816866, "s2_id": "969c39d3f1bb7714854a03eaae6fddfac209d669", "title": "Counting Complex Disordered States by Efficient Pattern Matching: Chromatic Polynomials and Potts Partition Functions", "abstract": "Counting problems, determining the number of possible states of a large system under certain constraints, play an important role in many areas of science. They naturally arise for complex disordered systems in physics and chemistry, in mathematical graph theory, and in computer science. Counting problems, however, are among the hardest problems to access computationally. Here, we suggest a novel method to access a benchmark counting problem, finding chromatic polynomials of graphs. We develop a vertex-oriented symbolic pattern matching algorithm that exploits the equivalence between the chromatic polynomial and the zero-temperature partition function of the Potts antiferromagnet on the same graph. Implementing this bottom-up algorithm using appropriate computer algebra, the new method outperforms standard top- down methods by several orders of magnitude, already for moderately sized graphs. As a first application, we compute chromatic polynomials of samples of the simple cubic lattice, for the first time computationally accessing three- dimensional lattices of physical relevance. The method offers straightforward generalizations to several other counting problems.", "venue": "ArXiv", "authors": ["Marc  Timme", "Frank Van Bussel", "Denny  Fliegner", "Sebastian  Stolzenberg"], "year": 2009, "n_citations": 3}
{"id": 3821025, "s2_id": "205300a879d706858c704595504044ba40e7b28d", "title": "Interpretable Control by Reinforcement Learning", "abstract": "In this paper, three recently introduced reinforcement learning (RL) methods are used to generate human-interpretable policies for the cart-pole balancing benchmark. The novel RL methods learn human-interpretable policies in the form of compact fuzzy controllers and simple algebraic equations. The representations as well as the achieved control performances are compared with two classical controller design methods and three non-interpretable RL methods. All eight methods utilize the same previously generated data batch and produce their controller offline - without interaction with the real benchmark dynamics. The experiments show that the novel RL methods are able to automatically generate well-performing policies which are at the same time human-interpretable. Furthermore, one of the methods is applied to automatically learn an equation-based policy for a hardware cart-pole demonstrator by using only human-player-generated batch data. The solution generated in the first attempt already represents a successful balancing policy, which demonstrates the methods applicability to real-world problems.", "venue": "ArXiv", "authors": ["Daniel  Hein", "Steffen  Limmer", "Thomas A. Runkler"], "year": 2020, "n_citations": 3}
{"id": 3831521, "s2_id": "390aa47d9f80a5b3b526d2b5dd6fdadd59059f16", "title": "A New Recursive Algorithm For Inverting A General Comrade Matrix", "abstract": "In this paper, the author present a reliable symbolic computational algorithm for inverting a general comrade matrix by using parallel computing along with recursion. The computational cost of our algorithm is O(n^2). The algorithm is implementable to the Computer Algebra System (CAS) such as MAPLE, MATLAB and MATHEMATICA. Three examples are presented for the sake of illustration.", "venue": "Ars Comb.", "authors": ["A. A. Karawia"], "year": 2017, "n_citations": 1}
{"id": 3835866, "s2_id": "b26f14089f444d84ea4e8da8edda89e0b726c107", "title": "The SAT+CAS Method for Combinatorial Search with Applications to Best Matrices", "abstract": "In this paper, we provide an overview of the SAT+CAS method that combines satisfiability checkers (SAT solvers) and computer algebra systems (CAS) to resolve combinatorial conjectures, and present new results vis-\u00e0-vis best matrices. The SAT+CAS method is a variant of the DPLL(T) architecture, where the T solver is replaced by a CAS. We describe how the SAT+CAS method has been used to resolve many open problems from graph theory, combinatorial design theory, and number theory, showing that the method has broad applications across a variety of fields. Additionally, we apply the method to construct the largest best matrices yet known and find new skew Hadamard matrices constructed from best matrices. As a consequence of this we show that a conjecture on the existence of best matrices that was previously known to hold for r \u2264 6 also holds for r = 7.", "venue": "EasyChair Preprints", "authors": ["Curtis  Bright", "Dragomir \u017d. \u0110okovi\u0107", "Ilias S. Kotsireas", "Vijay  Ganesh"], "year": 2019, "n_citations": 2}
{"id": 3837795, "s2_id": "790703de6e986be30a7af98f3cb953cbc079af1e", "title": "Compositions and collisions at degree p2", "abstract": "A univariate polynomial <i>f</i> over a field is decomposable if <i>f</i> = <i>g</i> o <i>h</i> = <i>g</i>(<i>h</i>) for nonlinear polynomials <i>g</i> and <i>h</i>. In order to count the decomposables, one wants to know the number of equal-degree collisions of the form <i>f</i> = <i>g</i> o <i>h</i> = <i>g</i>* o <i>h</i>* with (<i>g</i>, <i>h</i>) \u2260 (<i>g</i>*, <i>h</i>*) and deg <i>g</i> = deg <i>g</i>*. Such collisions only occur in the wild case, where the field characteristic <i>p</i> divides deg <i>f</i>. Reasonable bounds on the number of decomposables over a finite field are known, but they are less sharp in the wild case, in particular for degree <i>p</i><sup>2</sup>.\n We provide a classification of all polynomials of degree <i>p</i><sup>2</sup> with a collision. It yields the exact number of decomposable polynomials of degree <i>p</i><sup>2</sup> over a finite field of characteristic <i>p</i>. We also present an algorithm that determines whether a given polynomial of degree <i>p</i><sup>2</sup> has a collision or not.", "venue": "ISSAC", "authors": ["Raoul  Blankertz", "Joachim von zur Gathen", "Konstantin  Ziegler"], "year": 2012, "n_citations": 8}
{"id": 3845414, "s2_id": "796301662f988874a3250cc5be80c2be6ba77e99", "title": "Generalized homogeneous polynomials for efficient template-based nonlinear invariant synthesis", "abstract": "Abstract The template-based method is one of the most successful approaches to algebraic invariant synthesis. In this method, an algorithm designates a template polynomial p over program variables, generates constraints for p = 0 to be an invariant, and solves the generated constraints. However, this approach often suffers from an increasing template size if the degree of a template polynomial is too high. We propose a technique to make template-based methods more efficient. Our technique is based on the following finding: If p = 0 is an algebraic invariant, then p can be decomposed into the sum of specific polynomials that we call generalized homogeneous polynomials, that are often smaller. This finding justifies using only a smaller template that corresponds to generalized homogeneous polynomials. Concretely, we state and prove our finding above formally. Then, we modify the template-based algorithm proposed by Cachera et al. so that it generates only generalized homogeneous polynomials. This modification is proved to be sound. Furthermore, we also empirically demonstrate the merit of the restriction to generalized homogeneous polynomials. Our implementation outperforms that of Cachera et al. for programs that require a higher-degree template.", "venue": "Theor. Comput. Sci.", "authors": ["Kensuke  Kojima", "Minoru  Kinoshita", "Kohei  Suenaga"], "year": 2018, "n_citations": 1}
{"id": 3845812, "s2_id": "a40495e8083e091694941d50887ada2ea34b1460", "title": "Parallel computation of the rank of large sparse matrices from algebraic K-theory", "abstract": "This paper deals with the computation of the rank and some integer Smith forms of a series of sparse matrices arising in algebraic K-theory. The number of non zero entries in the considered matrices ranges from 8 to 37 millions. The largest rank computation took more than 35 days on 50 processors. We report on the actual algorithms we used to build the matrices, their link to the motivic cohomology and the linear algebra and parallelizations required to perform such huge computations. In particular, these results are part of the first computation of the cohomology of the linear group GL 7(Z).", "venue": "PASCO '07", "authors": ["Jean-Guillaume  Dumas", "Philippe  Elbaz-Vincent", "Pascal  Giorgi", "Anna  Urbanska"], "year": 2007, "n_citations": 16}
{"id": 3847452, "s2_id": "dc10f1559289f8d9f3bceafd4bf1ca16f569d4b8", "title": "A local construction of the Smith normal form of a matrix polynomial", "abstract": "Author(s): Yu, Jia | Advisor(s): Wilkening, Jon A | Abstract: This dissertation consists of two separate chapters. In the first chapter, we present an algorithm for computing a Smith normal form with multipliers of a regular matrix polynomial over a field. This algorithm differs from previous ones in that it computes a local Smith form for each irreducible factor in the determinant separately and combines them into a global Smith form, whereas other algorithms apply a sequence of unimodular operations to the original matrix row by row (or column by column) to obtain the Smith normal form. The performance of the algorithm in exact arithmetic is reported for several test cases.The second chapter is devoted to a numerical method for computing nontrivial time-periodic, gravity-driven water waves with or without surface tension. This method is essentially a shooting method formulated as a minimization problem. The objective function depends on the initial conditions and the proposed period, and measures deviation from time-periodicity. We adapt an adjoint-based optimal control method to rapidly compute the gradient of the functional. The main technical challenge involves handling the nonlocal Dirichlet to Neumann operator of the water wave equations in the adjoint formulation. Several families of traveling waves and symmetric breathers are simulated. In the latter case, we observe disconnections in the bifurcation curves due to nonlinear resonances at critical bifurcation parameters.", "venue": "J. Symb. Comput.", "authors": ["Jon  Wilkening", "Jia  Yu"], "year": 2011, "n_citations": 24}
{"id": 3847457, "s2_id": "831a9f3ac7511407bde9820d7bf25f33a66dca49", "title": "Algorithm for Solving Massively Underdefined Systems of Multivariate Quadratic Equations over Finite Fields", "abstract": "Solving systems of m multivariate quadratic equations in n variables (MQ-problem) over finite fields is NP-hard. The security of many cryptographic systems is based on this problem. Up to now, the best algorithm for solving the underdefined MQ-problem is Hiroyuki Miura et al.'s algorithm, which is a polynomial-time algorithm when \\[n \\ge m(m + 3)/2\\] and the characteristic of the field is even. In order to get a wider applicable range, we reduce the underdefined MQ-problem to the problem of finding square roots over finite field, and then combine with the guess and determine method. In this way, the applicable range is extended to \\[n \\ge m(m + 1)/2\\], which is the widest range until now. Theory analysis indicates that the complexity of our algorithm is \\[O(q{n^\\omega }m{(\\log {\\kern 1pt} {\\kern 1pt} q)^2}){\\kern 1pt} \\] when characteristic of the field is even and \\[O(q{2^m}{n^\\omega }m{(\\log {\\kern 1pt} {\\kern 1pt} q)^2})\\] when characteristic of the field is odd, where \\[2 \\le \\omega \\le 3\\] is the complexity of Gaussian elimination.", "venue": "ArXiv", "authors": ["Heliang  Huang", "Wansu  Bao"], "year": 2015, "n_citations": 0}
{"id": 3855518, "s2_id": "76e8732e8aa2b2b53547ef72e5214f2a08773f4a", "title": "A New Deflation Method For Verifying the Isolated Singular Zeros of Polynomial Systems", "abstract": "In this paper, we develop a new deflation technique for refining or verifying the isolated singular zeros of polynomial systems. Starting from a polynomial system with an isolated singular zero, by computing the derivatives of the input polynomials directly or the linear combinations of the related polynomials, we construct a new system, which can be used to refine or verify the isolated singular zero of the input system. In order to preserve the accuracy in numerical computation as much as possible, new variables are introduced to represent the coefficients of the linear combinations of the related polynomials. To our knowledge, it is the first time that considering the deflation problem of polynomial systems from the perspective of the linear combination. Some acceleration strategies are proposed to reduce the scale of the final system. We also give some further analysis of the tolerances we use, which can help us have a better understanding of our method.The experiments show that our method is effective and efficient. Especially, it works well for zeros with high multiplicities of large systems. It also works for isolated singular zeros of non-polynomial systems.", "venue": "J. Comput. Appl. Math.", "authors": ["Jin-San  Cheng", "Xiaojie  Dou", "Junyi  Wen"], "year": 2020, "n_citations": 1}
{"id": 3860664, "s2_id": "adde45b57b9e444c67cad204393ef1a29d82b5d1", "title": "The weighted difference substitutions and Nonnegativity Decision of Forms", "abstract": "In this paper, we study the weighted difference substitutions from geometrical views. First, we give the geometric meanings of the weighted difference substitutions, and introduce the concept of convergence of the sequence of substitution sets. Then it is proven that the sequence of the successive weighted difference substitution sets is convergent. Based on the convergence of the sequence of the successive weighted difference sets, a new, simpler method to prove that if the form F is positive definite on T_n, then the sequence of sets {SDS^m(F)} is positively terminating is presented, which is different from the one given in [11]. That is, we can decide the nonnegativity of a positive definite form by successively running the weighted difference substitutions finite times. Finally, an algorithm for deciding an indefinite form with a counter-example is obtained, and some examples are listed by using the obtained algorithm.", "venue": "ArXiv", "authors": ["Xiaorong  Hou", "Song  Xu", "Junwei  Shao"], "year": 2009, "n_citations": 0}
{"id": 3861688, "s2_id": "fc9c28becee21466f4a7b6a72c0b09d2e4286fe4", "title": "Discovering and Proving Infinite Binomial Sums Identities", "abstract": "Abstract We consider binomial and inverse binomial sums at infinity and rewrite them in terms of a small set of constants, such as powers of \u03c0 or log\u2009(2). In order to perform these simplifications, we view the series as specializations of generating series. For these generating series, we derive integral representations in terms of root-valued iterated integrals. Using substitutions, we express the iterated integrals as cyclotomic harmonic polylogarithms. Finally, by applying known relations among the cyclotomic harmonic polylogarithms, we derive expressions in terms of several constants.", "venue": "Exp. Math.", "authors": ["Jakob  Ablinger"], "year": 2017, "n_citations": 25}
{"id": 3862570, "s2_id": "f09366ec1c608656338103a632f2876b6dbc8b21", "title": "Optimal monomial quadratization for ODE systems", "abstract": "Transformation of a polynomial ODE system to a special quadratic form has been successfully used recently as a preprocessing step for model order reduction methods. However, to the best of our knowledge, there has been no practical algorithm for performing this step automatically with any optimality guarantees. We present an algorithm that, given a system of polynomial ODEs, finds a transformation into a quadratic ODE system by introducing new variables which are monomials of the original variables. The algorithm is guaranteed to produce an optimal transformation of this form. The algorithm is implemented, and we demonstrate it on examples from the literature.", "venue": "ACM Commun. Comput. Algebra", "authors": ["Andrey  Bychkov", "Gleb  Pogudin"], "year": 2020, "n_citations": 1}
{"id": 3869998, "s2_id": "e69151fc78734545a662d2cc8b043c001cfe50a8", "title": "Reconstruction of rational ruled surfaces from their silhouettes", "abstract": "We provide algorithms to reconstruct rational ruled surfaces in three-dimensional projective space from the `apparent contour' of a single projection to the projective plane. We deal with the case of tangent developables and of general projections to $\\mathbb{p}^3$ of rational normal scrolls. In the first case, we use the fact that every such surface is the projection of the tangent developable of a rational normal curve, while in the second we start by reconstructing the rational normal scroll. In both instances we then reconstruct the correct projection to $\\mathbb{p}^3$ of these surfaces by exploiting the information contained in the singularities of the apparent contour.", "venue": "J. Symb. Comput.", "authors": ["Matteo  Gallet", "Niels  Lubbes", "Josef  Schicho", "Jan  Vrsek"], "year": 2021, "n_citations": 1}
{"id": 3876727, "s2_id": "05f057c34e0fcd05d0067ed504d55671bd9c967f", "title": "Automatic Differentiation for Tensor Algebras", "abstract": "Kjolstad et. al. proposed a tensor algebra compiler. It takes expressions that define a tensor element-wise, such as $f_{ij}(a,b,c,d) = \\exp\\left[-\\sum_{k=0}^4 \\left((a_{ik}+b_{jk})^2\\, c_{ii} + d_{i+k}^3 \\right) \\right]$, and generates the corresponding compute kernel code. \nFor machine learning, especially deep learning, it is often necessary to compute the gradient of a loss function $l(a,b,c,d)=l(f(a,b,c,d))$ with respect to parameters $a,b,c,d$. If tensor compilers are to be applied in this field, it is necessary to derive expressions for the derivatives of element-wise defined tensors, i.e. expressions for $(da)_{ik}=\\partial l/\\partial a_{ik}$. \nWhen the mapping between function indices and argument indices is not 1:1, special attention is required. For the function $f_{ij} (x) = x_i^2$, the derivative of the loss is $(dx)_i=\\partial l/\\partial x_i=\\sum_j (df)_{ij}2x_i$; the sum is necessary because index $j$ does not appear in the indices of $f$. Another example is $f_{i}(x)=x_{ii}^2$, where $x$ is a matrix; here we have $(dx)_{ij}=\\delta_{ij}(df)_i2x_{ii}$; the Kronecker delta is necessary because the derivative is zero for off-diagonal elements. Another indexing scheme is used by $f_{ij}(x)=\\exp x_{i+j}$; here the correct derivative is $(dx)_{k}=\\sum_i (df)_{i,k-i} \\exp x_{k}$, where the range of the sum must be chosen appropriately. \nIn this publication we present an algorithm that can handle any case in which the indices of an argument are an arbitrary linear combination of the indices of the function, thus all the above examples can be handled. Sums (and their ranges) and Kronecker deltas are automatically inserted into the derivatives as necessary. Additionally, the indices are transformed, if required (as in the last example). The algorithm outputs a symbolic expression that can be subsequently fed into a tensor algebra compiler. \nSource code is provided.", "venue": "ArXiv", "authors": ["Sebastian  Urban", "Patrick van der Smagt"], "year": 2017, "n_citations": 1}
{"id": 3876995, "s2_id": "fa24be55cd80f0a825675ff77ba190ccc5eacfe7", "title": "ZpL: a p-adic Precision Package", "abstract": "We present a new package ZpL for the mathematical software system SageMath. It implements a sharp tracking of precision on p-adic numbers, following the theory of ultrametric precision introduced in a previous paper by the same authors. The underlying algorithms are mostly based on automatic differentiation techniques. We introduce them, study their complexity and discuss our design choices. We illustrate the benefits of our package (in comparison with previous implementations) with a large sample of examples coming from linear algebra, commutative algebra and differential equations.", "venue": "ISSAC", "authors": ["Xavier  Caruso", "David  Roe", "Tristan  Vaccon"], "year": 2018, "n_citations": 2}
{"id": 3880607, "s2_id": "6c86e466cc972fc522153d39d6c5096339ed7c03", "title": "Improved complexity bounds for real root isolation using Continued Fractions", "abstract": "We consider the problem of isolating the real roots of a square-free polynomial with integer coefficients using (variants of) the continued fraction algorithm (CF). We introduce a novel way to compute a lower bound on the positive real roots of univariate polynomials. This allows us to derive a worst case bound of $\\sOB( d^6 + d^4\\tau^2 + d^3\\tau^2)$ for isolating the real roots of a polynomial with integer coefficients using the classic variant of CF, where $d$ is the degree of the polynomial and $\\tau$ the maximum bitsize of its coefficients. This improves the previous bound by Sharma \\cite{sharma-tcs-2008} by a factor of $d^3$ and matches the bound derived by Mehlhorn and Ray \\cite{mr-jsc-2009} for another variant of CF; it also matches the worst case bound of the subdivision-based solvers. We present a new variant of CF, we call it iCF, that isolates the real roots of a polynomial with integer coefficients in $\\sOB(d^5+d^4\\tau)$, thus improving the current known bound for the problem by a factor of $d$. If the polynomial has only real roots, then our bound becomes $\\sOB(d^4+d^3\\tau+ d^2\\tau^2)$, thus matching the bound of the numerical algorithms by Reif \\cite{r-focs-1993} and by Ben-Or and Tiwari \\cite{bt-joc-1990}. Actually the latter bound holds in a more general setting, that is under the rather mild assumption that $\\Omega(d/\\lg^c{d})$, where $c\\geq 0$ is a constant, roots contribute to the sign variations of the coefficient list of the polynomial. This is the only bound on exact algorithms that matches the one of the numerical algorithms by Pan \\cite{Pan02jsc} and Schonhage \\cite{Sch82}. To our knowledge the presented bounds are the best known for the problem of real root isolation for algorithms based on exact computations.", "venue": "ArXiv", "authors": ["Elias P. Tsigaridas"], "year": 2010, "n_citations": 7}
{"id": 3885059, "s2_id": "a6887d3a60e267483d81b71e1318f05d8b0df946", "title": "Multi-experiment parameter identifiability of ODEs and model theory", "abstract": "Structural identifiability is a property of an ODE model with parameters that allows for the parameters to be determined from continuous noise-free data. This is natural prerequisite for practical identifiability. Conducting multiple independent experiments could make more parameters or functions of parameters identifiable, which is a desirable property to have. How many experiments are sufficient? In the present paper, we provide an algorithm to determine the exact number of experiments for multi-experiment local identifiability and obtain an upper bound that is off at most by one for the number of experiments for multi-experiment global identifiability. Interestingly, the main theoretical ingredient of the algorithm has been discovered and proved using model theory (in the sense of mathematical logic). We hope that this unexpected connection will stimulate interactions between applied algebra and model theory, and we provide a short introduction to model theory in the context of parameter identifiability. As another related application of model theory in this area, we construct a nonlinear ODE system with one output such that single-experiment and mutiple-experiment identifiability are different for the system. This contrasts with recent results about single-output linear systems. We also present a Monte Carlo randomized version of the algorithm with a polynomial arithmetic complexity. Implementation of the algorithm is provided and its performance is demonstrated on several examples. The source code is available at https://github.com/pogudingleb/ExperimentsBound.", "venue": "ArXiv", "authors": ["Alexey  Ovchinnikov", "Anand  Pillay", "Gleb  Pogudin", "Thomas  Scanlon"], "year": 2020, "n_citations": 6}
{"id": 3889939, "s2_id": "dfa6a47953533aabc113aa90822ed92ac6b75d32", "title": "Confluence by Critical Pair Analysis Revisited (Extended Version)", "abstract": "We present two methods for proving confluence of left-linear term rewrite systems. One is hot-decreasingness, combining the parallel/development closedness theorems with rule labelling based on a terminating subsystem. The other is critical-pair-closing system, allowing to boil down the confluence problem to confluence of a special subsystem whose duplicating rules are relatively terminating.", "venue": "ArXiv", "authors": ["Nao  Hirokawa", "Julian  Nagele", "Vincent van Oostrom", "Michio  Oyamaguchi"], "year": 2019, "n_citations": 1}
{"id": 3890775, "s2_id": "f8054c01764281472d0401bc63d7f5a2886ac47e", "title": "Computing Equilibria of Semi-algebraic Economies Using Triangular Decomposition and Real Solution Classification", "abstract": "In this paper, we are concerned with the problem of determining the existence of multiple equilibria in economic models. We propose a general and complete approach for identifying multiplicities of equilibria in semi-algebraic economies, which may be expressed as semi-algebraic systems. The approach is based on triangular decomposition and real solution classification, two powerful tools of algebraic computation. Its effectiveness is illustrated by three examples of application.", "venue": "ArXiv", "authors": ["Xiaoliang  Li", "Dongming  Wang"], "year": 2013, "n_citations": 8}
{"id": 3897776, "s2_id": "314e43d123f5a752d9103b0b9f2030044b16a0d0", "title": "Automatic differentiation of hybrid models Illustrated by Diffedge Graphic Methodology. (Survey)", "abstract": "We investigate the automatic differentiation of hybrid models, viz. models that may contain delays, logical tests and discontinuities or loops. We consider differentiation with respect to parameters, initial conditions or the time. We emphasize the case of a small number of derivations and iterated differentiations are mostly treated with a foccus on high order iterations of the same derivation. The models we consider may involve arithmetic operations, elementary functions, logical tests but also more elaborate components such as delays, integrators, equations and differential equations solvers. This survey has no pretention to exhaustivity but tries to fil a gap in the litterature where each kind of of component may be documented, but seldom their common use. \nThe general approach is illustrated by computer algebra experiments, stressing the interest of performing differentiation, whenever possible, on high level objects, before any translation in Fortran or C code. We include ordinary differential systems with discontinuity, with a special interest for those comming from discontinuous Lagrangians. \nWe conclude with an overview of the graphic methodology developped in the Diffedge software for Simulink hybrid models. Not all possibilities are covered, but the methodology can be adapted. The result of automatic differentiation is a new block diagram and so it can be easily translated to produce real time embedded programs. \nWe welcome any comments or suggestions of references that we may have missed.", "venue": "ArXiv", "authors": ["John  Masse", "Clara  Masse", "Fran\u00e7ois  Ollivier"], "year": 2017, "n_citations": 0}
{"id": 3898085, "s2_id": "c8a010f4b07173b945aa41a9270b84e7ce43d46f", "title": "SIAN: software for structural identifiability analysis of ODE models", "abstract": "Summary\nBiological processes are often modeled by ordinary differential equations with unknown parameters. The unknown parameters are usually estimated from experimental data. In some cases, due to the structure of the model, this estimation problem does not have a unique solution even in the case of continuous noise-free data. It is therefore desirable to check the uniqueness a priori before carrying out actual experiments. We present a new software SIAN (Structural Identifiability ANalyser) that does this. Our software can tackle problems that could not be tackled by previously developed packages.\n\n\nAvailability\nSIAN is open-source software written in Maple and is available at https://github.com/pogudingleb/SIAN.\n\n\nSupplementary information\nSupplementary data are available at Bioinformatics online.", "venue": "Bioinform.", "authors": ["Hoon  Hong", "Alexey  Ovchinnikov", "Gleb  Pogudin", "Chee-Keng  Yap"], "year": 2019, "n_citations": 39}
{"id": 3898594, "s2_id": "1b4514b9c8304a04b385bc988eff4a8f1b606a14", "title": "Explicit equivalence of quadratic forms over $\\mathbb{F}_q(t)$", "abstract": "We propose a randomized polynomial time algorithm for computing nontrivial zeros of quadratic forms in 4 or more variables over $\\mathbb{F}_q(t)$, where $\\mathbb{F}_q$ is a finite field of odd characteristic. The algorithm is based on a suitable splitting of the form into two forms and finding a common value they both represent. We make use of an effective formula for the number of fixed degree irreducible polynomials in a given residue class. We apply our algorithms for computing a Witt decomposition of a quadratic form, for computing an explicit isometry between quadratic forms and finding zero divisors in quaternion algebras over quadratic extensions of $\\mathbb{F}_q(t)$.", "venue": "ArXiv", "authors": ["G\u00e1bor  Ivanyos", "P\u00e9ter  Kutas", "Lajos  R\u00f3nyai"], "year": 2016, "n_citations": 0}
{"id": 3906026, "s2_id": "d65fdbf8e816c178221fee30758351cbc2586d2e", "title": "Parallel Integer Polynomial Multiplication", "abstract": "We propose a new algorithm for multiplying densepolynomials with integer coefficients in a parallel fashion, targetingmulti-core processor architectures. Complexity estimates andexperimental comparisons demonstrate the advantages of this newapproach.", "venue": "2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)", "authors": ["Changbo  Chen", "Svyatoslav  Covanov", "Farnam  Mansouri", "Marc Moreno Maza", "Ning  Xie", "Yuzhen  Xie"], "year": 2016, "n_citations": 7}
{"id": 3911732, "s2_id": "6924b00a61571e2de7d08c3288bdd58a262df5e3", "title": "Using the Regular Chains Library to Build Cylindrical Algebraic Decompositions by Projecting and Lifting", "abstract": "Cylindrical algebraic decomposition (CAD) is an important tool, both for quantifier elimination over the reals and a range of other applications. Traditionally, a CAD is built through a process of projection and lifting to move the problem within Euclidean spaces of changing dimension. Recently, an alternative approach which first decomposes complex space using triangular decomposition before refining to real space has been introduced and implemented within the RegularChains Library of Maple. We here describe a freely available package ProjectionCAD which utilises the routines within the RegularChains Library to build CADs by projection and lifting. We detail how the projection and lifting algorithms were modified to allow this, discuss the motivation and survey the functionality of the package.", "venue": "ICMS", "authors": ["Matthew  England", "David J. Wilson", "Russell J. Bradford", "James H. Davenport"], "year": 2014, "n_citations": 27}
{"id": 3916792, "s2_id": "884f199803f9a0e869eaebf67ac55a397bf95e18", "title": "Walsh functions, scrambled $(0, m, s)$-nets, and negative covariance: applying symbolic computation to quasi-Monte Carlo integration", "abstract": "Abstract We investigate base b Walsh functions for which the variance of the integral estimator based on a scrambled ( 0 , m , s ) -net in base b is less than or equal to that of the Monte-Carlo estimator based on the same number of points. First we compute the Walsh decomposition for the joint probability density function of two distinct points randomly chosen from a scrambled ( t , m , s ) -net in base b in terms of certain counting numbers and simplify it in the special case t is zero. Using this, we obtain an expression for the covariance of the integral estimator in terms of the Walsh coefficients of the function. Finally, we prove that the covariance of the integral estimator is negative when the Walsh coefficients of the function satisfy a certain decay condition. To do this, we use creative telescoping and recurrence solving algorithms from symbolic computation to find a sign equivalent closed form expression for the covariance term.", "venue": "Math. Comput. Simul.", "authors": ["Jaspar  Wiart", "Elaine  Wong"], "year": 2021, "n_citations": 2}
{"id": 3923804, "s2_id": "96c6d1716d635a596fbf7f60beadd76192440751", "title": "Recursive Matrix Algorithms in Commutative Domain for Cluster with Distributed Memory", "abstract": "We give an overview of the theoretical results for matrix block-recursive algorithms in commutative domains and present the results of experiments that we conducted with new parallel programs based on these algorithms on a supercomputer MVS-10P at the Joint Supercomputer Center of the Russian Academy of Science. To demonstrate a scalability of these programs we measure the running time of the program for a different number of processors and plot the graphs of efficiency factor. Also we present the main application areas in which such parallel algorithms are used. It is concluded that this class of algorithms allows to obtain efficient parallel programs on clusters with distributed memory.", "venue": "2018 Ivannikov Memorial Workshop (IVMEM)", "authors": ["Gennadi I. Malaschonok", "Evgeni  Ilchenko"], "year": 2018, "n_citations": 1}
{"id": 3925160, "s2_id": "a2a29dfbc99ea63f15c6a82e7a2d4884bc1a0fcc", "title": "Improved polynomial remainder sequences for Ore polynomials", "abstract": "Polynomial remainder sequences contain the intermediate results of the Euclidean algorithm when applied to (non-)commutative polynomials. The running time of the algorithm is dependent on the size of the coefficients of the remainders. Different ways have been studied to make these as small as possible. The subresultant sequence of two polynomials is a polynomial remainder sequence in which the size of the coefficients is optimal in the generic case, but when taking the input from applications, the coefficients are often larger than necessary. We generalize two improvements of the subresultant sequence to Ore polynomials and derive a new bound for the minimal coefficient size. Our approach also yields a new proof for the results in the commutative case, providing a new point of view on the origin of the extraneous factors of the coefficients.", "venue": "J. Symb. Comput.", "authors": ["Maximilian  Jaroschek"], "year": 2013, "n_citations": 2}
{"id": 3927674, "s2_id": "36d58b49b7202aabd9f2996095036b700ecef29e", "title": "Compressed Modular Matrix Multiplication", "abstract": "We propose to store several integers modulo a small prime into a single machine word. Modular addition is performed by addition and possibly subtraction of a word containing several times the modulo. Modular Multiplication is not directly accessible but modular dot product can be performed by an integer multiplication by the reverse integer. Modular multiplication by a word containing a single residue is a also possible. Therefore matrix multiplication can be performed on such a compressed storage. We here give bounds on the sizes of primes and matrices for which such a compression is possible. We also explicit the details of the required compressed arithmetic routines.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Laurent  Fousse", "Bruno  Salvy"], "year": 2008, "n_citations": 5}
{"id": 3934459, "s2_id": "9b2bb254de4960c433c9ad72a1b834805b27e020", "title": "Symmetric Determinantal Representation of Formulas and Weakly Skew Circuits", "abstract": "We deploy algebraic complexity theoretic techniques for constructing symmetric determinantal representations of formulas and weakly skew circuits. Our representations produce matrices of much smaller dimensions than those given in the convex geometry literature when applied to polynomials having a concise representation (as a sum of monomials, or more generally as an arithmetic formula or a weakly skew circuit). These representations are valid in any field of characteristic different from 2. In characteristic 2 we are led to an almost complete solution to a question of Burgisser on the VNP-completeness of the partial permanent. In particular, we show that the partial permanent cannot be VNP-complete in a finite field of characteristic 2 unless the polynomial hierarchy collapses.", "venue": "ArXiv", "authors": ["Bruno  Grenet", "Erich  Kaltofen", "Pascal  Koiran", "Natacha  Portier"], "year": 2010, "n_citations": 12}
{"id": 3941325, "s2_id": "395d15b8bb9e21db9d1386c03cfdb5171d8e4dd4", "title": "Deep learning for pedestrians: backpropagation in CNNs", "abstract": "The goal of this document is to provide a pedagogical introduction to the main concepts underpinning the training of deep neural networks using gradient descent; a process known as backpropagation. Although we focus on a very influential class of architectures called \"convolutional neural networks\" (CNNs) the approach is generic and useful to the machine learning community as a whole. Motivated by the observation that derivations of backpropagation are often obscured by clumsy index-heavy narratives that appear somewhat mathemagical, we aim to offer a conceptually clear, vectorized description that articulates well the higher level logic. Following the principle of \"writing is nature's way of letting you know how sloppy your thinking is\", we try to make the calculations meticulous, self-contained and yet as intuitive as possible. Taking nothing for granted, ample illustrations serve as visual guides and an extensive bibliography is provided for further explorations. \n(For the sake of clarity, long mathematical derivations and visualizations have been broken up into short \"summarized views\" and longer \"detailed views\" encoded into the PDF as optional content groups. Some figures contain animations designed to illustrate important concepts in a more engaging style. For these reasons, we advise to download the document locally and open it using Adobe Acrobat Reader. Other viewers were not tested and may not render the detailed views, animations correctly.)", "venue": "ArXiv", "authors": ["Laurent  Bou\u00e9"], "year": 2018, "n_citations": 3}
{"id": 3944271, "s2_id": "4bdeb8277442c5658464c517fcb0a842ff7563c8", "title": "Nearest Points on Toric Varieties", "abstract": "We determine the Euclidean distance degree of a projective toric variety. This extends the formula of Matsui and Takeuchi for the degree of the $A$-discriminant in terms of Euler obstructions. Our primary goal is the development of reliable algorithmic tools for computing the points on a real toric variety that are closest to a given data point.", "venue": "ArXiv", "authors": ["Martin  Helmer", "Bernd  Sturmfels"], "year": 2016, "n_citations": 11}
{"id": 3948222, "s2_id": "3ff296c44b472aa774da00e1099209dfae572db3", "title": "Partial Predicate Abstraction and Counter-Example Guided Refinement", "abstract": "In this paper we present a counter-example guided abstraction and approximation refinement (CEGAAR) technique for {\\em partial predicate abstraction}, which combines predicate abstraction and fixpoint approximations for model checking infinite-state systems. The proposed approach incrementally considers growing sets of predicates for abstraction refinement. The novelty of the approach stems from recognizing source of the imprecision: abstraction or approximation. We use Craig interpolation to deal with imprecision due to abstraction. In the case of imprecision due to approximation, we delay application of the approximation. Our experimental results on a variety of models provide insights into effectiveness of partial predicate abstraction as well as refinement techniques in this context.", "venue": "J. Log. Algebraic Methods Program.", "authors": ["Tuba  Yavuz"], "year": 2020, "n_citations": 3}
{"id": 3952608, "s2_id": "2e1b0997eee91186320a4d2b5565a023e42d330b", "title": "On the Different Shapes Arising in a Family of Rational Curves Depending on a Parameter", "abstract": "Given a family of rational curves depending on a real parameter, defined by its parametric equations, we provide an algorithm to compute a finite partition of the parameter space (${\\Bbb R}$, in general) so that the shape of the family stays invariant along each element of the partition. So, from this partition the topology types in the family can be determined. The algorithm is based on a geometric interpretation of previous work (\\cite{JGRS}) for the implicit case. However, in our case the algorithm works directly with the parametrization of the family, and the implicit equation does not need to be computed. Timings comparing the algorithm in the implicit and the parametric cases are given; these timings show that the parametric algorithm developed here provides in general better results than the known algorithm for the implicit case.", "venue": "ArXiv", "authors": ["Juan Gerardo Alc\u00e1zar"], "year": 2009, "n_citations": 0}
{"id": 3957471, "s2_id": "f88d811d4ea15ec86aecf77a3e056479f3263e2a", "title": "Computing periods of hypersurfaces", "abstract": "We give an algorithm to compute the periods of smooth projective hypersurfaces of any dimension. This is an improvement over existing algorithms which could only compute the periods of plane curves. Our algorithm reduces the evaluation of period integrals to an initial value problem for ordinary differential equations of Picard\u2013Fuchs type. In this way, the periods can be computed to extreme-precision in order to study their arithmetic properties. The initial conditions are obtained by an exact determination of the cohomology pairing on Fermat hypersurfaces with respect to a natural basis.", "venue": "Mathematics of Computation", "authors": ["Emre Can Sertoz"], "year": 2019, "n_citations": 3}
{"id": 3964775, "s2_id": "87b0726077c18b74189811e10123669ec822029f", "title": "Explicit Noether Normalization for Simultaneous Conjugation via Polynomial Identity Testing", "abstract": "Mulmuley [Mul12a] recently gave an explicit version of Noether\u2019s Normalization lemma for ring of invariants of matrices under simultaneous conjugation, under the conjecture that there are deterministic black-box algorithms for polynomial identity testing (PIT). He argued that this gives evidence that constructing such algorithms for PIT is beyond current techniques. In this work, we show this is not the case. That is, we improve Mulmuley\u2019s reduction and correspondingly weaken the conjecture regarding PIT needed to give explicit Noether Normalization. We then observe that the weaker conjecture has recently been nearly settled by the authors ([FS12]), who gave quasipolynomial size hitting sets for the class of read-once oblivious algebraic branching programs (ROABPs). This gives the desired explicit Noether Normalization unconditionally, up to quasipolynomial factors. As a consequence of our proof we give a deterministic parallel polynomial-time algorithm for deciding if two matrix tuples have intersecting orbit closures, under simultaneous conjugation. We also study the strength of conjectures that Mulmuley requires to obtain similar results as ours. We prove that his conjectures are stronger, in the sense that the computational model he needs PIT algorithms for is equivalent to the well-known algebraic branching program (ABP) model, which is provably stronger than the ROABP model. Finally, we consider the depth-3 diagonal circuit model as defined by Saxena [Sax08], as PIT algorithms for this model also have implications in Mulmuley\u2019s work. Previous work (such as [ASS12] and [FS12]) have given quasipolynomial size hitting sets for this model. In this work, we give a much simpler construction of such hitting sets, using techniques of Shpilka and Volkovich [SV09].", "venue": "APPROX-RANDOM", "authors": ["Michael A. Forbes", "Amir  Shpilka"], "year": 2013, "n_citations": 56}
{"id": 3980361, "s2_id": "2b0a7332db45b5bb1eac2478a56703e666a81309", "title": "Asymptotic and Exact Results on the Complexity of the Novelli-Pak-Stoyanovskii Algorithm", "abstract": "The Novelli-Pak-Stoyanovskii algorithm is a sorting algorithm for Young tableaux of a fixed shape that was originally devised to give a bijective proof of the hook-length formula. We obtain new asymptotic results on the average case and worst case complexity of this algorithm as the underlying shape tends to a fixed limit curve. Furthermore, using the summation package Sigma we prove an exact formula for the average case complexity when the underlying shape consists of only two rows. We thereby answer questions posed by Krattenthaler and Muller.", "venue": "Electron. J. Comb.", "authors": ["Carsten  Schneider", "Robin  Sulzgruber"], "year": 2017, "n_citations": 4}
{"id": 3981790, "s2_id": "313e883a7f66075b6573704768f7790e568c1ded", "title": "A Purely Functional Computer Algebra System Embedded in Haskell", "abstract": "We demonstrate how methods in Functional Programming can be used to implement a computer algebra system. As a proof-of-concept, we present the computational-algebra package. It is a computer algebra system implemented as an embedded domain-specific language in Haskell, a purely functional programming language. Utilising methods in functional programming and prominent features of Haskell, this library achieves safety, composability, and correctness at the same time. To demonstrate the advantages of our approach, we have implemented advanced Gr\\\"{o}bner basis algorithms, such as Faug\\`{e}re's $F_4$ and $F_5$, in a composable way.", "venue": "CASC", "authors": ["Hiromi  Ishii"], "year": 2018, "n_citations": 3}
{"id": 3986043, "s2_id": "8519606163522574cf76714e786314028b96b8b7", "title": "A Unified Algebraic Framework for Non-Monotonicity", "abstract": "Tremendous research effort has been dedicated over the years to thoroughly investigate non-monotonic reasoning. With the abundance of non-monotonic logical formalisms, a unified theory that enables comparing the different approaches is much called for. In this paper, we present an algebraic graded logic we refer to as LogAG capable of encompassing a wide variety of non-monotonic formalisms. We build on Lin and Shoham's argument systems first developed to formalize non-monotonic commonsense reasoning. We show how to encode argument systems as LogAG theories, and prove that LogAG captures the notion of belief spaces in argument systems. Since argument systems capture default logic, autoepistemic logic, the principle of negation as failure, and circumscription, our results show that LogAG captures the before-mentioned non-monotonic logical formalisms as well. Previous results show that LogAG subsumes possibilistic logic and any non-monotonic inference relation satisfying Makinson's rationality postulates. In this way, LogAG provides a powerful unified framework for non-monotonicity.", "venue": "TARK", "authors": ["Nourhan  Ehab", "Haythem O. Ismail"], "year": 2019, "n_citations": 2}
{"id": 3986870, "s2_id": "691cf67fc60a50e408ded34c00da15466d59cafb", "title": "Linear Programming Using Limited-Precision Oracles", "abstract": "Linear programming is a foundational tool for many aspects of integer and combinatorial optimization. This work studies the complexity of solving linear programs exactly over the rational numbers through use of an oracle capable of returning limited-precision LP solutions. Under mild assumptions, it is shown that a polynomial number of calls to such an oracle and a polynomial number of bit operations, is sufficient to compute an exact solution to an LP. Previous work has often considered oracles that provide solutions of an arbitrary specified precision. While this leads to polynomial-time algorithms, the level of precision required is often unrealistic for practical computation. In contrast, our work provides a foundation for understanding and analyzing the behavior of the methods that are currently most effective in practice for solving LPs exactly.", "venue": "IPCO", "authors": ["Ambros M. Gleixner", "Daniel E. Steffy"], "year": 2019, "n_citations": 2}
{"id": 3990111, "s2_id": "ae10e4d8e95ea067621e54b35e5a48252dc3ddca", "title": "Converting ALC Connection Proofs into ALC Sequents", "abstract": "The connection method has earned good reputation in the area of automated theorem proving, due to its simplicity, efficiency and rational use of memory. This method has been applied recently in automatic provers that reason over ontologies written in the description logic ALC. However, proofs generated by connection calculi are difficult to understand. Proof readability is largely lost by the transformations to disjunctive normal form applied over the formulae to be proven. Such a proof model, albeit efficient, prevents inference systems based on it from effectively providing justifications and/or descriptions of the steps used in inferences. To address this problem, in this paper we propose a method for converting matricial proofs generated by the ALC connection method to ALC sequent proofs, which are much easier to understand, and whose translation to natural language is more straightforward. We also describe a calculus that accepts the input formula in a non-clausal ALC format, what simplifies the translation.", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Eunice  Palmeira", "Fred  Freitas", "Jens  Otten"], "year": 2019, "n_citations": 0}
{"id": 3995500, "s2_id": "8a23657ab30d380941b73913978c0bc68f0718e7", "title": "On Exact Division and Divisibility Testing for Sparse Polynomials", "abstract": "No polynomial-time algorithm is known to test whether a sparse polynomial G divides another sparse polynomial F. While computing the quotient Q = F quo G can be done in polynomial time with respect to the sparsities of F, G and Q, this is not yet sufficient to get a polynomial-time divisibility test in general. Indeed, the sparsity of the quotient Q can be exponentially larger than the ones of F and G. In the favorable case where the sparsity #Q of the quotient is polynomial, the best known algorithm to compute Q has a non-linear factor #G#Q in the complexity, which is not optimal. In this work, we are interested in the two aspects of this problem. First, we propose a new randomized algorithm that computes the quotient of two sparse polynomials when the division is exact. Its complexity is quasi-linear in the sparsities of F, G and Q. Our approach relies on sparse interpolation and it works over any finite field or the ring of integers. Then, as a step toward faster divisibility testing, we provide a new polynomial-time algorithm when the divisor has a specific shape. More precisely, we reduce the problem to finding a polynomial S such that QS is sparse and testing divisibility by S can be done in polynomial time. We identify some structure patterns in the divisor G for which we can efficiently compute such a polynomial S.", "venue": "ISSAC", "authors": ["Pascal  Giorgi", "Bruno  Grenet", "Armelle Perret du Cray"], "year": 2021, "n_citations": 0}
{"id": 3996706, "s2_id": "4a9c5cf200c0c0a32949cdeca3e2f2fc8cbe9628", "title": "Fast Multiplication for Skew Polynomials", "abstract": "We describe an algorithm for fast multiplication of skew polynomials. It is based on fast modular multiplication of such skew polynomials, for which we give an algorithm relying on evaluation and interpolation on normal bases. Our algorithms improve the best known complexity for these problems, and reaches the optimal asymptotic complexity bound for large degree. We also give an adaptation of our algorithm for polynomials of small degree. Finally, we use our methods to improve on the best known complexities for various arithmetics problems.", "venue": "ISSAC", "authors": ["Xavier  Caruso", "J\u00e9r\u00e9my Le Borgne"], "year": 2017, "n_citations": 18}
{"id": 4000789, "s2_id": "c5d8713577fa26838e8b6da8f9f9dcafa13c61d7", "title": "Denominator Bounds and Polynomial Solutions for Systems of q-Recurrences over K(t) for Constant K", "abstract": "We consider systems Al(t) y(ql t) + ... + A0(t) y(t) = b(t) of higher order q-recurrence equations with rational coefficients. We extend a method for finding a bound on the maximal power of t in the denominator of arbitrary rational solutions y(t) as well as a method for bounding the degree of polynomial solutions from the scalar case to the systems case. The approach is direct and does not rely on uncoupling or reduction to a first order system. Unlike in the scalar case this usually requires an initial transformation of the system.", "venue": "ISSAC", "authors": ["Johannes  Middeke"], "year": 2017, "n_citations": 3}
{"id": 4001278, "s2_id": "73e646439daf4c89adef91913687a8e7881d556a", "title": "The expansion of real forms on the simplex and applications", "abstract": "If n points B1,...,Bn in the standard simplexn are affinely independent, then they can span an (n \u2212 1)\u2212simplex denoted by \ufffd = Con(B1,...,Bn). Herecorresponds to an n\u00d7n matrix (\ufffd) whose columns are B1,...,Bn. In this paper, we firstly proved that ifof diameter sufficiently small contains a point P, and f(P) > 0 (< 0) for a form f \u2208 R(X), then the coefficients of f((\ufffd)X) are all positive (negative). Next, as an application of this result, a necessary and sufficient condition for determining the real zerosonn of a system of homogeneous algebraic equations with integral coefficients is established.", "venue": "ArXiv", "authors": ["Yong  Yao", "Jia  Xu", "Jingzhong  Zhang"], "year": 2012, "n_citations": 0}
{"id": 4001988, "s2_id": "70acaf7102c09ba5f5bbead32f2561b87dc81d53", "title": "Computer Algebra in Systems Biology", "abstract": "Systems biology focuses on the study of entire biological systems rather than on their individual components. With the emergence of high-throughput data generation technologies for molecular biology and the development of advanced mathematical modeling techniques, this field promises to provide important new insights. At the same time, with the availability of increasingly powerful computers, computer algebra has developed into a useful tool for many applications. This article illustrates the use of computer algebra in systems biology by way of a well-known gene regulatory network, the Lac Operon in the bacterium E. coli.", "venue": "Am. Math. Mon.", "authors": ["Reinhard C. Laubenbacher", "Bernd  Sturmfels"], "year": 2009, "n_citations": 26}
{"id": 4005163, "s2_id": "b01b3f6012b124c149487f87a26f7b31b74d0007", "title": "Intertwining Laplace Transformations of Linear Partial Differential Equations", "abstract": "We propose a generalization of Laplace transformations to the case of linear partial differential operators (LPDOs) of arbitrary order in \u211d n . Practically all previously proposed differential transformations of LPDOs are particular cases of this transformation (intertwining Laplace transformation, \\(\\mathcal{ILT}\\)). We give a practical procedure of construction of \\(\\mathcal{ILT}\\) and describe the classes of operators in \u211d n suitable for this transformation.", "venue": "AADIOS", "authors": ["Elena I. Ganzha"], "year": 2012, "n_citations": 9}
{"id": 4007160, "s2_id": "f999fd37625f9811b27d5e6ee39a8c0956bb67fc", "title": "Separability Problems in Creative Telescoping", "abstract": "For given multivariate functions specified by algebraic, differential or difference equations,the separability problem is to decide whether they satisfy linear differential or difference equations in one variable. In this paper, we will explain how separability problems arise naturally in creative telescoping and present some criteria for testing the separability for several classes of special functions,including rational functions, hyperexponential functions, hypergeometric terms, and algebraic functions.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Ruyong  Feng", "Pingchuan  Ma", "Michael F. Singer"], "year": 2021, "n_citations": 0}
{"id": 4007210, "s2_id": "56d708df498dfa582e4a0e5902f13c1f4bfd3fc5", "title": "Object-Level Reasoning with Logics Encoded in HOL Light", "abstract": "We present a generic framework that facilitates object level reasoning with logics that are encoded within the Higher Order Logic theorem proving environment of HOL Light. This involves proving statements in any logic using intuitive forward and backward chaining in a sequent calculus style. It is made possible by automated machinery that take care of the necessary structural reasoning and term matching automatically. Our framework can also handle type theoretic correspondences of proofs, effectively allowing the type checking and construction of computational processes via proof. We demonstrate our implementation using a simple propositional logic and its Curry-Howard correspondence to the \u03bb -calculus, and argue its use with linear logic and its various correspondences to session types.", "venue": "LFMTP", "authors": ["Petros  Papapanagiotou", "Jacques  Fleuriot"], "year": 2020, "n_citations": 0}
{"id": 4012732, "s2_id": "a1bd67a9e042f8b64decc4a3f011a4f91a1fa791", "title": "Computing isomorphisms and embeddings of finite fields", "abstract": "Let <i>q</i> be a prime power and let F<sub><i>q</i></sub> be a field with <i>q</i> elements. Let <i>f</i> and <i>g</i> be irreducible polynomials in F<sub><i>q</i></sub>[<i>X</i>], with deg <i>f</i> dividing deg <i>g.</i> Define <i>k</i> = F<sub><i>q</i></sub>[<i>X</i>]/<i>f</i> and <i>K</i> = F<sub><i>q</i></sub>[<i>X</i>]/<i>g</i>, then there is an embedding <i>\u03c6</i> : <i>k</i> [EQUATION] <i>K</i>, unique up to F<sub><i>q</i></sub>-automorphisms of <i>k.</i> Our goal is to describe algorithms to efficiently represent and evaluate one such embedding.", "venue": "ACCA", "authors": ["Ludovic  Brieulle", "Luca De Feo", "Javad  Doliskani", "Jean-Pierre  Flori", "\u00c9ric  Schost"], "year": 2019, "n_citations": 0}
{"id": 4013036, "s2_id": "fac50cbaf708064000116ab95c532dd8e0ff7459", "title": "Computing syzygies in finite dimension using fast linear algebra", "abstract": "We consider the computation of syzygies of multivariate polynomials in a finite-dimensional setting: for a $\\mathbb{K}[X_1,\\dots,X_r]$-module $\\mathcal{M}$ of finite dimension $D$ as a $\\mathbb{K}$-vector space, and given elements $f_1,\\dots,f_m$ in $\\mathcal{M}$, the problem is to compute syzygies between the $f_i$'s, that is, polynomials $(p_1,\\dots,p_m)$ in $\\mathbb{K}[X_1,\\dots,X_r]^m$ such that $p_1 f_1 + \\dots + p_m f_m = 0$ in $\\mathcal{M}$. Assuming that the multiplication matrices of the $r$ variables with respect to some basis of $\\mathcal{M}$ are known, we give an algorithm which computes the reduced Grobner basis of the module of these syzygies, for any monomial order, using $O(m D^{\\omega-1} + r D^\\omega \\log(D))$ operations in the base field $\\mathbb{K}$, where $\\omega$ is the exponent of matrix multiplication. Furthermore, assuming that $\\mathcal{M}$ is itself given as $\\mathcal{M} = \\mathbb{K}[X_1,\\dots,X_r]^n/\\mathcal{N}$, under some assumptions on $\\mathcal{N}$ we show that these multiplication matrices can be computed from a Grobner basis of $\\mathcal{N}$ within the same complexity bound. In particular, taking $n=1$, $m=1$ and $f_1=1$ in $\\mathcal{M}$, this yields a change of monomial order algorithm along the lines of the FGLM algorithm with a complexity bound which is sub-cubic in $D$.", "venue": "J. Complex.", "authors": ["Vincent  Neiger", "\u00c9ric  Schost"], "year": 2020, "n_citations": 6}
{"id": 4019438, "s2_id": "e07a1e34c15c975f1715b84ae49956f2c8feb9c8", "title": "TeXmacs interfaces to Maxima, MuPAD and REDUCE", "abstract": "GNU TeXmacs is a free wysiwyg word processor providing an excellent typesetting quality of texts and formulae. It can also be used as an interface to Computer Algebra Systems (CASs). In the present work, interfaces to three general-purpose CASs have been implemented.", "venue": "ArXiv", "authors": ["A. G. Grozin"], "year": 2001, "n_citations": 6}
{"id": 4019719, "s2_id": "6a8c9ecaf46f8591c6ddf4af0f4f63dadaaff19c", "title": "An implementation of Sub-CAD in Maple", "abstract": "AbstractCylindrical algebraic decomposition (CAD) is an important tool for the investiga-tion of semi-algebraic sets, with applications in algebraic geometry and beyond. Wehave previously reported on an implementation of CAD in Maple which o\ufb00ers theoriginal projection and lifting algorithm of Collins along with subsequent improve-ments.Here we report on new functionality: speci\ufb01cally the ability to build cylindricalalgebraic sub-decompositions (sub-CADs) where only certain cells are returned. Wehave implemented algorithms to return cells of a prescribed dimensions or higher(layered sub-CADs), and an algorithm to return only those cells on which given poly-nomials are zero (variety sub-CADs). These o\ufb00er substantial savings in output sizeand computation time.The code described and an introductory Maple worksheet / pdf demonstratingthe full functionality of the package should accompany this report. This work is supported by EPSRC grant EP/J003247/1. 1 Introduction This report concerns ProjectionCAD: a Maplepackage for cylindrical algebraic decom-position (CAD) developed at the University of Bath. The extended abstract [18] at ICMS2014 describes how this package utilises recent CAD work in the RegularChainsLibraryof Maple, while still following the classical projection and lifting framework for CADconstruction. The present report is to accompany the release of ProjectionCADversion3, describing the new functionality this introduced. The report should be accompaniedby the code described and an introductory Maple worksheet / pdf demonstrating thefull functionality of the package. The previous two versions of ProjectionCADare hostedalongside similar reports documenting their functionality [16, 17].Version 3 introduces functionality for cylindrical algebraic sub-decompositions(sub-CADs): subsets of CADs su\ufb03cient to describe the solutions of a given formulae.Two distinct types are provided, whose theory was developed in [27]. The \ufb01rst typecontains only those cells of a certain dimension and higher, reducing both the outputsize and computational time by giving only output of the required generality. We haveimplemented both a direct and recursive algorithm to build these layeredsub-CADs. Thesecond type contains only those cells on which given equations are satis\ufb01ed (lie on aprescribed variety). When building a CAD for a formula with an equational constraintthen only these cells can contain the solution set. These varietysub-CADs clearly reducethe output, and can also reduce computation time depending on the rank of the varietyrelative to the variable ordering.1", "venue": "ArXiv", "authors": ["Matthew  England", "David J. Wilson"], "year": 2015, "n_citations": 0}
{"id": 4021729, "s2_id": "32223095dfaba279bb9b00487dc8e0017d1e840a", "title": "Randomized Polynomial-Time Root Counting in Prime Power Rings", "abstract": "Suppose $k,p\\!\\in\\!\\mathbb{N}$ with $p$ prime and $f\\!\\in\\!\\mathbb{Z}[x]$ is a univariate polynomial with degree $d$ and all coefficients having absolute value less than $p^k$. We give a Las Vegas randomized algorithm that computes the number of roots of $f$ in $\\mathbb{Z}/\\!\\left(p^k\\right)$ within time $d^3(k\\log p)^{2+o(1)}$. (We in fact prove a more intricate complexity bound that is slightly better.) The best previous general algorithm had (deterministic) complexity exponential in $k$. We also present some experimental data evincing the potential practicality of our algorithm.", "venue": "Math. Comput.", "authors": ["Leann  Kopp", "Natalie  Randall", "J. Maurice Rojas", "Yuyu  Zhu"], "year": 2020, "n_citations": 17}
{"id": 4031585, "s2_id": "c1bc7591ca24ad12c9ac6bf84e178b66ecbbb4e9", "title": "Exact Safety Verification of Interval Hybrid Systems Based on Symbolic-Numeric Computation", "abstract": "In this paper, we address the problem of safety verification of interval hybrid systems in which the coefficients are intervals instead of explicit numbers. A hybrid symbolic-numeric method, based on SOS relaxation and interval arithmetic certification, is proposed to generate exact inequality invariants for safety verification of interval hybrid systems. As an application, an approach is provided to verify safety properties of non-polynomial hybrid systems. Experiments on the benchmark hybrid systems are given to illustrate the efficiency of our method.", "venue": "ArXiv", "authors": ["Zhengfeng  Yang", "Min  Wu", "Wang  Lin"], "year": 2013, "n_citations": 1}
{"id": 4032465, "s2_id": "4a542851b2e337d52b8267794ee2bf31ecdf93c4", "title": "Towards Solving the Inverse Protein Folding Problem", "abstract": "Accurately assigning folds for divergent protein sequences is a major obstacle to structural studies and underlies the inverse protein folding problem. Herein, we outline our theories for fold-recognition in the \"twilight-zone\" of sequence similarity (<25% identity). Our analyses demonstrate that structural sequence profiles built using Position-Specific Scoring Matrices (PSSMs) significantly outperform multiple popular homology-modeling algorithms for relating and predicting structures given only their amino acid sequences. Importantly, structural sequence profiles reconstitute SCOP fold classifications in control and test datasets. Results from our experiments suggest that structural sequence profiles can be used to rapidly annotate protein folds at proteomic scales. We propose that encoding the entire Protein DataBank (~1070 folds) into structural sequence profiles would extract interoperable information capable of improving most if not all methods of structural modeling.", "venue": "ArXiv", "authors": ["Yoojin  Hong", "Kyung Dae Ko", "Gaurav  Bhardwaj", "Zhenhai  Zhang", "Damian B. van Rossum", "Randen L. Patterson"], "year": 2010, "n_citations": 1}
{"id": 4032821, "s2_id": "bd738be13dd045b4b8c7c9c5a7e47cbdef910dd1", "title": "Cylindrical Algebraic Decomposition with Equational Constraints", "abstract": "Cylindrical Algebraic Decomposition (CAD) has long been one of the most important algorithms within Symbolic Computation, as a tool to perform quantifier elimination in first order logic over the reals. More recently it is finding prominence in the Satisfiability Checking community as a tool to identify satisfying solutions of problems in nonlinear real arithmetic. \nThe original algorithm produces decompositions according to the signs of polynomials, when what is usually required is a decomposition according to the truth of a formula containing those polynomials. One approach to achieve that coarser (but hopefully cheaper) decomposition is to reduce the polynomials identified in the CAD to reflect a logical structure which reduces the solution space dimension: the presence of Equational Constraints (ECs). \nThis paper may act as a tutorial for the use of CAD with ECs: we describe all necessary background and the current state of the art. In particular, we present recent work on how McCallum's theory of reduced projection may be leveraged to make further savings in the lifting phase: both to the polynomials we lift with and the cells lifted over. We give a new complexity analysis to demonstrate that the double exponent in the worst case complexity bound for CAD reduces in line with the number of ECs. We show that the reduction can apply to both the number of polynomials produced and their degree.", "venue": "J. Symb. Comput.", "authors": ["Matthew  England", "Russell J. Bradford", "James H. Davenport"], "year": 2020, "n_citations": 14}
{"id": 4039795, "s2_id": "3c272a023ec3cafee6cd357bd0e5fcc06dbeab21", "title": "Separating linear forms for bivariate systems", "abstract": "We present an algorithm for computing a separating linear form of a system of bivariate polynomials with integer coefficients, that is a linear combination of the variables that takes different values when evaluated at distinct (complex) solutions of the system. In other words, a separating linear form defines a shear of the coordinate system that sends the algebraic system in generic position, in the sense that no two distinct solutions are vertically aligned. The computation of such linear forms is at the core of most algorithms that solve algebraic systems by computing rational parameterizations of the solutions and, moreover, the computation of a separating linear form is the bottleneck of these algorithms, in terms of worst-case bit complexity.\n Given two bivariate polynomials of total degree at most <i>d</i> with integer coefficients of bitsize at most \u03c4, our algorithm computes a separatin linear form in \u00d5<sub>B</sub>(d<sup>8</sup>+d<sup>7</sup>\u03c4+d<sup>5</sup>\u03c4<sup>2</sup>) bit operations in the worst case, where the previously known best bit complexity for this problem was \u00d5<sub>B</sub>(d<sup>10</sup>+d<sup>9</sup>\u03c4) (where\u00d5 refers to the complexity where polylogarithmic factors are omitted and \u00d5<sub>B</sub> refers to the bit complexity)", "venue": "ISSAC '13", "authors": ["Yacine  Bouzidi", "Sylvain  Lazard", "Marc  Pouget", "Fabrice  Rouillier"], "year": 2013, "n_citations": 11}
{"id": 4039796, "s2_id": "127ecb095c6bc392633c48da890cb2d1c1a6c031", "title": "Complexity of a Root Clustering Algorithm", "abstract": "Approximating the roots of a holomorphic function in an input box is a fundamental problem in many domains. Most algorithms in the literature for solving this problem are conditional, i.e., they make some simplifying assumptions, such as, all the roots are simple or there are no roots on the boundary of the input box, or the underlying machine model is Real RAM. Root clustering is a generalization of the root approximation problem that allows for errors in the computation and makes no assumption on the multiplicity of the roots. An unconditional algorithm for computing a root clustering of a holomorphic function was given by Yap, Sagraloff and Sharma in 2013. They proposed a subdivision based algorithm using effective predicates based on Pellet's test while avoiding any comparison with zeros (using soft zero comparisons instead). In this paper, we analyze the running time of their algorithm. We use the continuous amortization framework to derive an upper bound on the size of the subdivision tree. We specialize this bound to the case of polynomials and some simple transcendental functions such as exponential and trigonometric sine. We show that the algorithm takes exponential time even for these simple functions, unlike the case of polynomials. We also derive a bound on the bit-precision used by the algorithm. To the best of our knowledge, this is the first such result for holomorphic functions. We introduce new geometric parameters, such as the relative growth of the function on the input box, for analyzing the algorithm. Thus, our estimates naturally generalize the known results, i.e., for the case of polynomials.", "venue": "ArXiv", "authors": ["Prashant  Batra", "Vikram  Sharma"], "year": 2019, "n_citations": 1}
{"id": 4048802, "s2_id": "3286dd98db67c48556918a47522addec60640bf3", "title": "The geometry of SDP-exactness in quadratic optimization", "abstract": "Consider the problem of minimizing a quadratic objective subject to quadratic equations. We study the semialgebraic region of objective functions for which this problem is solved by its semidefinite relaxation. For the Euclidean distance problem, this is a bundle of spectrahedral shadows surrounding the given variety. We characterize the algebraic boundary of this region and we derive a formula for its degree.", "venue": "Math. Program.", "authors": ["Diego  Cifuentes", "Corey  Harris", "Bernd  Sturmfels"], "year": 2020, "n_citations": 15}
{"id": 4049552, "s2_id": "4c8f63944730159dfbc8e9c3ac2bec5317c06763", "title": "From Moments to Functions in Quantum Chromodynamics", "abstract": "Single-scale quantities, like the QCD anomalous dimensions and Wilson coefficients, obey difference equations. Therefore their analytic form can be determined from a finite number of moments. We demonstrate this in an explicit calculation by establishing and solving large scale recursions by means of computer algebra for the anomalous dimensions and Wilson coefficients in unpolarized deeply inelastic scattering from their Mellin moments to 3-loop order.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "Manuel  Kauers", "Sebastian  Klein", "Carsten  Schneider"], "year": 2009, "n_citations": 8}
{"id": 4067202, "s2_id": "cc2e26143921d4db835b31b92522c5c6f117de50", "title": "Unification and combination of iterative insertion strategies with rudimentary traversals and failure", "abstract": "We introduce a new class of extensions of terms that consists in navigation strategies and insertion of contexts. We introduce an operation of combination on this class which is associative, admits a neutral element and so that each extension is idempotent. The class of extension is also shown to be closed by combination, with a constructive proof. This new framework is general and independent of any application semantics. However it has been introduced for the kernel of a software tool which aims at aiding derivation of multiscale partial differential equation models.", "venue": "ArXiv", "authors": ["Walid  Belkhir", "Nicolas  Ratier", "Duy Duc Nguyen", "Michel  Lenczner"], "year": 2019, "n_citations": 0}
{"id": 4068334, "s2_id": "2213d0cc1a6c94e0a1df1213d1e815689050adde", "title": "Counting and computing regions of $D$-decomposition: algebro-geometric approach", "abstract": "New methods for $D$-decomposition analysis are presented. They are based on topology of real algebraic varieties and computational real algebraic geometry. The estimate of number of root invariant regions for polynomial parametric families of polynomial and matrices is given. For the case of two parametric family more sharp estimate is proven. Theoretic results are supported by various numerical simulations that show higher precision of presented methods with respect to traditional ones. The presented methods are inherently global and could be applied for studying $D$-decomposition for the space of parameters as a whole instead of some prescribed regions. For symbolic computations the Maple v.14 software and its package RegularChains are used.", "venue": "ArXiv", "authors": ["Oleg O. Vasil'ev"], "year": 2012, "n_citations": 1}
{"id": 4069695, "s2_id": "f22dde783b07b57f8383239b655821d6d3c96bed", "title": "Certification of Minimal Approximant Bases", "abstract": "For a given computational problem, a certificate is a piece of data that one (the prover) attaches to the output with the aim of allowing efficient verification (by the verifier) that this output is correct. Here, we consider the minimal approximant basis problem, for which the fastest known algorithms output a polynomial matrix of dimensions m x m and average degree D/m using O~(m\u00f8mega D/m) field operations. We propose a certificate which, for typical instances of the problem, is computed by the prover using O(m\u00f8mega D/m) additional field operations and allows verification of the approximant basis by a Monte Carlo algorithm with cost bound O(m\u00f8mega + m D). Besides theoretical interest, our motivation also comes from the fact that approximant bases arise in most of the fastest known algorithms for linear algebra over the univariate polynomials; thus, this work may help in designing certificates for other polynomial matrix computations. Furthermore, cryptographic challenges such as breaking records for discrete logarithm computations or for integer factorization rely in particular on computing minimal approximant bases for large instances: certificates can then be used to provide reliable computation on outsourced and error-prone clusters.", "venue": "ISSAC", "authors": ["Pascal  Giorgi", "Vincent  Neiger"], "year": 2018, "n_citations": 6}
{"id": 4077942, "s2_id": "9718ec5986e9fc11f513b9ad175a2605277a282c", "title": "On Computing the Hermite Form of a Matrix of Differential Polynomials", "abstract": "Given a matrix over the ring of differential polynomials, we show how to compute the Hermite form H of A and a unimodular matrix U such that UA = H . The algorithm requires a polynomial number of operations in F in terms of n , , . When F = *** it require time polynomial in the bit-length of the rational coefficients as well.", "venue": "CASC", "authors": ["Mark  Giesbrecht", "Myung Sub Kim"], "year": 2009, "n_citations": 12}
{"id": 4085946, "s2_id": "6fc5d4aff0f30462bc064a92192c31f41e9afe56", "title": "Parameter identifiability and input-output equations", "abstract": "Structural parameter identifiability is a property of a differential model with parameters that allows for the parameters to be determined from the model equations in the absence of noise. One of the standard approaches to assessing this problem is via input-output equations and, in particular, characteristic sets of differential ideals. The precise relation between identifiability and input-output identifiability is subtle. The goal of this note is to clarify this relation. The main results are: \n1) identifiability implies input-output identifiability; \n2) these notions coincide if the model does not have rational first integrals; \n3) the field of input-output identifiable functions is generated by the coefficients of a \"minimal\" characteristic set of the corresponding differential ideal. \nWe expect that some of these facts may be known to the experts in the area, but we are not aware of any articles in which these facts are stated precisely and rigorously proved.", "venue": "ArXiv", "authors": ["Alexey  Ovchinnikov", "Gleb  Pogudin", "Peter  Thompson"], "year": 2020, "n_citations": 7}
{"id": 4086929, "s2_id": "66377b3e45f3c76118d615f88807e9e463411d5d", "title": "A Polynomial-time Algorithm to Compute Generalized Hermite Normal Form of Matrices over Z[x]", "abstract": "In this paper, a polynomial-time algorithm is given to compute the generalized Hermite normal form for a matrix F over Z[x], or equivalently, the reduced Groebner basis of the Z[x]-module generated by the column vectors of F. The algorithm is also shown to be practically more efficient than existing algorithms. The algorithm is based on three key ingredients. First, an F4 style algorithm to compute the Groebner basis is adopted, where a novel prolongation is designed such that the coefficient matrices under consideration have polynomial sizes. Second, fast algorithms to compute Hermite normal forms of matrices over Z are used. Third, the complexity of the algorithm are guaranteed by a nice estimation for the degree and height bounds of the polynomials in the generalized Hermite normal form.", "venue": "Theor. Comput. Sci.", "authors": ["Rui-Juan  Jing", "Chun-Ming  Yuan", "Xiao-Shan  Gao"], "year": 2019, "n_citations": 7}
{"id": 4090334, "s2_id": "24b211b7be4f01203f90d04ee75bb94925a15ed6", "title": "Integrality and arithmeticity of solvable linear groups", "abstract": "We develop a practical algorithm to decide whether a finitely generated subgroup of a solvable algebraic group G is arithmetic. This incorporates a procedure to compute a generating set of an arithmetic subgroup of G. We also provide a simple new algorithm for integrality testing of finitely generated solvable-by-finite linear groups over the rational field. The algorithms have been implemented in Magma.", "venue": "J. Symb. Comput.", "authors": ["A. S. Detinko", "Dane L. Flannery", "W. A. de Graaf"], "year": 2015, "n_citations": 6}
{"id": 4092856, "s2_id": "1389564b7e36e9ea9774f646599aa3dab0c7352e", "title": "Formalization and Implementation of Algebraic Methods in Geometry", "abstract": "We describe our ongoing project of formalization of algebraic methods for geometry theorem proving (Wu's method and the Groebner bases method), their implementation and integration in educational tools. The project includes formal verification of the algebraic methods within Isabelle/HOL proof assistant and development of a new, open-source Java implementation of the algebraic methods. The project should fill-in some gaps still existing in this area (e.g., the lack of formal links between algebraic methods and synthetic geometry and the lack of self-contained implementations of algebraic methods suitable for integration with dynamic geometry tools) and should enable new applications of theorem proving in education.", "venue": "ThEdu", "authors": ["Filip  Maric", "Ivan  Petrovic", "Danijela  Petrovic", "Predrag  Janicic"], "year": 2011, "n_citations": 17}
{"id": 4099905, "s2_id": "f304bdee9acfb43d1f62359169eff1496fe2aa53", "title": "Towards Incremental Cylindrical Algebraic Decomposition in Maple", "abstract": "Cylindrical Algebraic Decomposition (CAD) is an important tool within computational real algebraic geometry, capable of solving many problems for polynomial systems over the reals. It has long been studied by the Symbolic Computation community and has found recent interest in the Satisfiability Checking community. The present report describes a proof of concept implementation of an Incremental CAD algorithm in Maple, where CADs are built and then refined as additional polynomial constraints are added. The aim is to make CAD suitable for use as a theory solver for SMT tools who search for solutions by continually reformulating logical formula and querying whether a logical solution is admissible. We describe experiments for the proof of concept, which clearly display the computational advantages compared to iterated re-computation. In addition, the project implemented this work under the recently verified Lazard projection scheme (with corresponding Lazard valuation).", "venue": "ArXiv", "authors": ["Alexander Imani Cowen-Rivers", "Matthew  England"], "year": 2018, "n_citations": 1}
{"id": 4103471, "s2_id": "eb10a74b3e5afd056e130907b96228b8616dbb09", "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding", "abstract": "Despite the importance and abundance of temporal knowledge graphs, most of the current research has been focused on reasoning on static graphs. In this paper, we study the challenging problem of inference over temporal knowledge graphs. In particular, the task of temporal link prediction. In general, this is a difficult task due to data non-stationarity, data heterogeneity, and its complex temporal dependencies. We propose Chronological Rotation embedding (ChronoR), a novel model for learning representations for entities, relations, and time. Learning dense representations is frequently used as an efficient and versatile method to perform reasoning on knowledge graphs. The proposed model learns a kdimensional rotation transformation parametrized by relation and time, such that after each fact\u2019s head entity is transformed using the rotation, it falls near its corresponding tail entity. By using high dimensional rotation as its transformation operator, ChronoR captures rich interaction between the temporal and multi-relational characteristics of a Temporal Knowledge Graph. Experimentally, we show that ChronoR is able to outperform many of the state-of-the-art methods on the benchmark datasets for temporal knowledge graph link prediction.", "venue": "AAAI", "authors": ["Ali  Sadeghian", "Mohammadreza  Armandpour", "Anthony  Colas", "Daisy Zhe Wang"], "year": 2021, "n_citations": 3}
{"id": 4104937, "s2_id": "7e5a748773f3422f757f44eb7a4675282186f12c", "title": "msolve: A Library for Solving Polynomial Systems", "abstract": "We present a new open source C library msolve dedicated to solving multivariate polynomial systems of dimension zero through computer algebra methods. The core algorithmic framework of msolve relies on Gr\u00f6bner bases and linear algebra based algorithms for polynomial system solving. It relies on Gr\u00f6bner basis computation w.r.t. the degree reverse lexicographical order, Gr\u00f6bner conversion to a lexicographical Gr\u00f6bner basis and real solving of univariate polynomials. We explain in detail how these three main steps of the solving process are implemented, how we exploit AVX2 instruction processors and the more general implementation ideas we put into practice to better exploit the computational capabilities of this algorithmic framework. We compare the practical performances of msolve with leading computer algebra systems such as Magma, Maple, Singular on a wide range of systems with finitely many complex solutions, showing that msolve can tackle systems which were out of reach by the computer algebra software state-of-the-art.", "venue": "ISSAC", "authors": ["J'er'emy  Berthomieu", "Christian  Eder", "Mohab Safey El Din"], "year": 2021, "n_citations": 5}
{"id": 4108173, "s2_id": "70c8712cbf41efd399a0bff538bac331f3a7ef39", "title": "Polynomial integration on regions defined by a triangle and a conic", "abstract": "We present an efficient solution to the following problem, of relevance in a numerical optimization scheme: calculation of integrals of the type\n EQUATION\n for quadratic polynomials f, \u03c61, \u03c62 on a plane triangle T. The naive approach would involve consideration of the many possible shapes of T \u2229 {f \u2265 0} (possibly after a convenient transformation) and parameterizing its border, in order to integrate the variables separately. Our solution involves partitioning the triangle into smaller triangles on which integration is much simpler.", "venue": "ISSAC", "authors": ["David  Sevilla", "Daniel  Wachsmuth"], "year": 2010, "n_citations": 7}
{"id": 4108199, "s2_id": "8692f6462741bc60143041f0039e665198fa40ab", "title": "Algorithmic counting of nonequivalent compact Huffman codes", "abstract": "It is known that the following five counting problems lead to the same integer sequence~$f_t(n)$: the number of nonequivalent compact Huffman codes of length~$n$ over an alphabet of $t$ letters, the number of `nonequivalent' canonical rooted $t$-ary trees (level-greedy trees) with $n$~leaves, the number of `proper' words, the number of bounded degree sequences, and the number of ways of writing $1= \\frac{1}{t^{x_1}}+ \\dots + \\frac{1}{t^{x_n}}$ with integers $0 \\leq x_1 \\leq x_2 \\leq \\dots \\leq x_n$. In this work, we show that one can compute this sequence for \\textbf{all} $n<N$ with essentially one power series division. In total we need at most $N^{1+\\varepsilon}$ additions and multiplications of integers of $cN$ bits, $c<1$, or $N^{2+\\varepsilon}$ bit operations, respectively. This improves an earlier bound by Even and Lempel who needed $O(N^3)$ operations in the integer ring or $O(N^4)$ bit operations, respectively.", "venue": "ArXiv", "authors": ["Christian  Elsholtz", "Clemens  Heuberger", "Daniel  Krenn"], "year": 2019, "n_citations": 0}
{"id": 4108515, "s2_id": "5bbc0cd155775348e1662c3a5749568b7911b002", "title": "Nominal Unification from a Higher-Order Perspective", "abstract": "Nominal logic is an extension of first-order logic with equality, name-binding, renaming via name-swapping and freshness of names. Contrarily to lambda-terms, in nominal terms, bindable names, called atoms, and instantiable variables are considered as distinct entities. Moreover, atoms are capturable by instantiations, breaking a fundamental principle of the lambda-calculus. Despite these differences, nominal unification can be seen from a higher-order perspective. From this view, we show that nominal unification can be quadratically reduced to a particular fragment of higher-order unification problems: higher-order pattern unification. We also prove that the translation preserves most generality of unifiers.", "venue": "TOCL", "authors": ["Jordi  Levy", "Mateu  Villaret"], "year": 2012, "n_citations": 32}
{"id": 4108835, "s2_id": "b0c8013286970f61ba7ac7afc130234836d48fb4", "title": "On the computation of the Galois group of linear difference equations", "abstract": "We present an algorithm that determines the Galois group of linear difference equations with rational function coefficients.", "venue": "Math. Comput.", "authors": ["Ruyong  Feng"], "year": 2018, "n_citations": 5}
{"id": 4109973, "s2_id": "4492fa208a5013af06ddf8d2532ff23117006f10", "title": "Improvements in the computation of ideal class groups of imaginary quadratic number fields", "abstract": "We investigate improvements to the algorithm for the computation of ideal class groups described by Jacobson in the imaginary quadratic case. These improvements rely on the large prime strategy and a new method for performing the linear algebra phase. We achieve a significant speed-up and are able to compute ideal class groups with discriminants of 110 decimal digits in less than a week.", "venue": "Adv. Math. Commun.", "authors": ["Jean-Fran\u00e7ois  Biasse"], "year": 2010, "n_citations": 18}
{"id": 4110181, "s2_id": "8367dc4395540f366f9206ccc4d762d873c87146", "title": "The Complexity of Subdivision for Diameter-Distance Tests", "abstract": "We present a general framework for analyzing the complexity of subdivision-based algorithms whose tests are based on the sizes of regions and their distance to certain sets (often varieties) intrinsic to the problem under study. We call such tests diameter-distance tests. We illustrate that diameter-distance tests are common in the literature by proving that many interval arithmetic-based tests are, in fact, diameter-distance tests. For this class of algorithms, we provide both non-adaptive bounds for the complexity, based on separation bounds, as well as adaptive bounds, by applying the framework of continuous amortization. \nUsing this structure, we provide the first complexity analysis for the algorithm by Plantinga and Vegeter for approximating real implicit curves and surfaces. We present both adaptive and non-adaptive a priori worst-case bounds on the complexity of this algorithm both in terms of the number of subregions constructed and in terms of the bit complexity for the construction. Finally, we construct families of hypersurfaces to prove that our bounds are tight.", "venue": "J. Symb. Comput.", "authors": ["Michael A. Burr", "Shuhong  Gao", "Elias P. Tsigaridas"], "year": 2020, "n_citations": 6}
{"id": 4115730, "s2_id": "66b4ab19fced6863158a9011f3288389702cbb26", "title": "Moment State Dynamical Systems for Nonlinear Chance-Constrained Motion Planning", "abstract": "Chance-constrained motion planning requires uncertainty in dynamics to be propagated into uncertainty in state. When nonlinear models are used, Gaussian assumptions on the state distribution do not necessarily apply since almost all random variables propagated through nonlinear dynamics results in non-Gaussian state distributions. To address this, recent works have developed moment-based approaches for enforcing chance-constraints on non-Gaussian state distributions. However, there still lacks fast and accurate moment propagation methods to determine the necessary statistical moments of these state distributions. To address this gap, we present a framework that, given a stochastic dynamical system, can algorithmically search for a new dynamical system in terms of moment state that can be used to propagate moments of disturbance random variables into moments of the state distribution. The key algorithm, TreeRing, can be applied to a large class of nonlinear systems which we refer to as trigonometric polynomial systems. As an example application, we present a distributionally robust RRT (DR-RRT) algorithm that propagates uncertainty through the nonlinear Dubin's car model without linearization.", "venue": "ArXiv", "authors": ["Allen  Wang", "Ashkan  Jasour", "Brian  Williams"], "year": 2020, "n_citations": 2}
{"id": 4117748, "s2_id": "fc4e2ea25705f9400ce53fa60722f1896f94b358", "title": "Abstracting Path Conditions for Effective Symbolic Execution", "abstract": "We present an algorithm for tests generation tools based on symbolic execution. The algorithm is supposed to help in situations, when a tool is repeatedly failing to cover some code by tests. The algorithm then provides the tool a necessary condition strongly narrowing space of program paths, which must be checked for reaching the uncovered code. We also discuss integration of the algorithm into the tools and we provide experimental results showing a potential of the algorithm to be valuable in the tools, when properly implemented there.", "venue": "ArXiv", "authors": ["Marek  Trt\u00edk"], "year": 2011, "n_citations": 1}
{"id": 4120711, "s2_id": "a1e5ca652804c84a03ffc30c15306780aef6a071", "title": "ATLAS: Interactive and Educational Linear Algebra System Containing Non-Standard Methods", "abstract": "While there are numerous linear algebra teaching tools, they tend to be focused on the basics, and not handle the more advanced aspects. This project aims to fill that gap, focusing specifically on methods like Strassen\u2019s fast matrix multiplication.", "venue": "ArXiv", "authors": ["Akhilesh  Pai", "James Harold Davenport"], "year": 2021, "n_citations": 0}
{"id": 4133496, "s2_id": "3ec821f98c323049f7b1c3c5806d4e17ef93d17f", "title": "Rational Solutions of First-Order Algebraic Ordinary Difference Equations", "abstract": "We propose an algebraic geometric approach for studying rational solutions of first-order algebraic ordinary difference equations. For an autonomous first-order algebraic ordinary difference equations, we give an upper bound for the degrees of its rational solutions, and thus derive a complete algorithm for computing corresponding rational solutions.", "venue": "Adv. Appl. Math.", "authors": ["N. Thieu Vo", "Yi  Zhang"], "year": 2020, "n_citations": 0}
{"id": 4138318, "s2_id": "792ee0b1bb92d4ea3cbc9e3617536b3e1d33951c", "title": "Asymptotic Solutions of Polynomial Equations with Exp-Log Coefficients", "abstract": "We present an algorithm for computing asymptotic approximations of roots of polynomials with exp-log function coefficients. The real and imaginary parts of the approximations are given as explicit exp-log expressions. We provide a method for deciding which approximations correspond to real roots. We report on implementation of the algorithm and present empirical data.", "venue": "ArXiv", "authors": ["Adam W. Strzebonski"], "year": 2019, "n_citations": 0}
{"id": 4140889, "s2_id": "ab207bda551b9df0de9cf7d3ad3d214ef1e365dd", "title": "Proceedings Third Symposium on Working Formal Methods", "abstract": "This volume contains the proceedings of FROM 2019: the Third Symposium on Working Formal Methods, held on September 3-5, 2019 in Timisoara (Romania). FROM aims to bring together researchers and practitioners who work on formal methods by contributing new theoretical results, methods, techniques, and frameworks, and/or make the formal methods to work by creating or using software tools that apply theoretical contributions.", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Mircea  Marin", "Adrian  Cruaciun"], "year": 2019, "n_citations": 1}
{"id": 4154998, "s2_id": "69856bff45f255dd61bc0cefd60bee019ed2566c", "title": "Formal Power Series on Algebraic Cryptanalysis", "abstract": "In cryptography, attacks that utilize a Grobner basis have broken several cryptosystems. The complexity of computing a Grobner basis dominates the overall computing and its estimation is important for such cryptanalysis. The complexity is given by using the solving degree, but it is hard to decide this value of a large scale system arisen from cryptography. Thus the degree of regularity and the first fall degree are used as proxies for the solving degree based on a wealth of experiments. If a given system is semi-regular, the complexity is estimated by using the degree of regularity derived from a certain power series, otherwise, by using the first fall degree derived from a construction of a syzygy. The degree of regularity is also defined on a non-semi-regular system and is experimentally larger than the first fall degree, but those relation is not clear theoretically. Moreover, in contrast to the degree of regularity, the first fall degree has been investigated specifically for each cryptosystem and its discussion on generic systems is not given. In this paper, we show an upper bound for the first fall degree of a polynomial system over a sufficiently large field. In detail, we prove that this upper bound for a non-semi-regular system is the degree of regularity. Moreover, we prove that the upper bound for a multi-graded polynomial system is a certain value only decided by its multi-degree. Furthermore, we show that the condition for the order of a field in our results is satisfied in attacks against actual multivariate cryptosystems. Consequently, under a reasonable condition for the order of a field, we clear a relation between the first fall degree and the degree of regularity and provide a theoretical method using a multivariate power series for cryptanalysis.", "venue": "ArXiv", "authors": ["Shuhei  Nakamura"], "year": 2020, "n_citations": 0}
{"id": 4155031, "s2_id": "4d452f833aabbd787714ca354ccafd0624c8aa04", "title": "Sheaves: A Topological Approach to Big Data", "abstract": "This document develops general concepts useful for extracting knowledge embedded in large graphs or datasets that have pair-wise relationships, such as cause-effect-type relations. Almost no underlying assumptions are made, other than that the data can be presented in terms of pair-wise relationships between objects/events. This assumption is used to mine for patterns in the dataset, defining a reduced graph or dataset that boils-down or concentrates information into a more compact form. The resulting extracted structure or set of patterns are manifestly symbolic in nature, as they capture and encode the graph structure of the dataset in terms of a (generative) grammar. This structure is identified as having the formal mathematical structure of a sheaf. In essence, this paper introduces the basic concepts of sheaf theory into the domain of graphical datasets.", "venue": "ArXiv", "authors": ["Linas  Vepstas"], "year": 2019, "n_citations": 1}
{"id": 4159579, "s2_id": "52fcd56517736be3792df6daf3a986d20580c139", "title": "Improved polynomial remainder sequences for ore polynomials", "abstract": "Polynomial remainder sequences contain the intermediate results of the Euclidean algorithm when applied to (non-)commutative polynomials. The running time of the algorithm is dependent on the size of the coefficients of the remainders. Different ways have been studied to make these as small as possible. The subresultant sequence of two polynomials is a polynomial remainder sequence in which the size of the coefficients is optimal in the generic case, but when taking the input from applications, the coefficients are often larger than necessary. We generalize two improvements of the subresultant sequence to Ore polynomials and derive a new bound for the minimal coefficient size. Our approach also yields a new proof for the results in the commutative case, providing a new point of view on the origin of the extraneous factors of the coefficients.", "venue": "ACCA", "authors": ["Maximilian  Jaroschek"], "year": 2013, "n_citations": 4}
{"id": 4162887, "s2_id": "8a601b8d6d08218c2ad789366d077bdd53b19d4a", "title": "Pattern Division Random Access (PDRA) for M2M Communications with Massive MIMO Systems", "abstract": "In this work, we introduce the pattern-domain pilot design paradigm based on a \u201csuperposition of orthogonal-building-blocks\u201d with significantly larger contention space to enhance the massive machinetype communications (mMTC) random access (RA) performance in massive multiple-input multipleoutput (MIMO) systems. Specifically, the pattern-domain pilot is constructed based on the superposition of L cyclically-shifted Zadoff-Chu (ZC) sequences. The pattern-domain pilots exhibit zero correlation values between non-colliding patterns from the same root and low correlation values between patterns from different roots. The increased contention space, i.e., from N to ( N L ) , where ( N L ) denotes the number of all L-combinations of a set N, and low correlation values lead to a significantly lower pilot collision probability without compromising excessively on channel estimation performance for mMTC RA in massive MIMO systems. We present the framework and analysis of the RA success probability of the pattern-domain based scheme with massive MIMO systems. Numerical results demonstrate that the proposed pattern division random access (PDRA) scheme achieves an appreciable performance gain over the conventional one, while preserving the existing physical layer virtually unchanged. The extension of the \u201csuperposition of orthogonal-building-blocks\u201d scheme to \u201csuperposition of quasi-orthogonalbuilding-blocks\u201d is straightforward.", "venue": "IEEE Transactions on Vehicular Technology", "authors": ["Xiaoming  Dai", "Tiantian  Yan", "Qianqian  Li", "Hua  Li", "Xiyuan  Wang"], "year": 2021, "n_citations": 0}
{"id": 4169517, "s2_id": "b073e02fdeb47a05568515df4bbde281b18a85bf", "title": "Imperative Program Synthesis from Answer Set Programs", "abstract": "Our research concerns generating imperative programs from Answer Set Programming Specifications. ASP is highly declarative and is ideal for writing specifications. Further with negation-as-failure it is easy to succinctly represent combinatorial search problems. We are currently working on synthesizing imperative programs from ASP programs by turning the negation into useful computations. This opens up a novel way to synthesize programs from executable specifications.", "venue": "ICLP Technical Communications", "authors": ["Sarat Chandra Varanasi"], "year": 2019, "n_citations": 0}
{"id": 4170343, "s2_id": "5a9d3831816f173778abc772be1dc31a6d3da323", "title": "Software for Evaluating Relevance of Steps in Algebraic Transformations", "abstract": "Students of our department solve algebraic exercises in mathematical logic in a computerized environment. They construct transformations step by step and the program checks the syntax, equivalence of expressions and completion of the task. With our current project, we add a program component for checking relevance of the steps.", "venue": "MKM/Calculemus/DML", "authors": ["Rein  Prank"], "year": 2013, "n_citations": 2}
{"id": 4170962, "s2_id": "975e7f07495ef99dfcca0fd325e27f9e0eca7e7a", "title": "Factorization of Non-Commutative Polynomials", "abstract": "We describe an algorithm for the factorization of non-commutative polynomials over a field. The first sketch of this algorithm appeared in an unpublished manuscript (literally hand written notes) by James H. Davenport more than 20 years ago. This version of the algorithm contains some improvements with respect to the original sketch. An improved version of the algorithm has been fully implemented in the Axiom computer algebra system.", "venue": "ArXiv", "authors": ["Fabrizio  Caruso"], "year": 2010, "n_citations": 5}
{"id": 4177332, "s2_id": "0a094d295687434b264e541b5e665ffa734343a4", "title": "SAT Techniques for Lexicographic Path Orders", "abstract": "This seminar report is concerned with expressing LPO-termination of term rewrite systems as a satisfiability problem in propositional logic. After relevant algorithms are explained, experimental results are reported.", "venue": "ArXiv", "authors": ["Harald  Zankl"], "year": 2006, "n_citations": 3}
{"id": 4182483, "s2_id": "47866ef7e02b063cafc649521be93be9983fb59e", "title": "Hierarchical Comprehensive Triangular Decomposition", "abstract": "The concept of comprehensive triangular decomposition (CTD) was first introduced by Chen et al. in their CASC\u20192007 paper and could be viewed as an analogue of comprehensive Grobner systems for parametric polynomial systems. The first complete algorithm for computing CTD was also proposed in that paper and implemented in the RegularChains library in Maple. Following our previous work on generic regular decomposition for parametric polynomial systems, we introduce in this paper a so-called hierarchical strategy for computing CTDs. Roughly speaking, for a given parametric system, the parametric space is divided into several sub-spaces of different dimensions and we compute CTDs over those sub-spaces one by one. So, it is possible that, for some benchmarks, it is difficult to compute CTDs in reasonable time while this strategy can obtain some \u201cpartial\u201d solutions over some parametric sub-spaces. The program based on this strategy has been tested on a number of benchmarks from the literature. Experimental results on these benchmarks with comparison to RegularChains are reported and may be valuable for developing more efficient triangularization tools.", "venue": "ICMS", "authors": ["Zhenghong  Chen", "Xiaoxian  Tang", "Bican  Xia"], "year": 2014, "n_citations": 0}
{"id": 4189055, "s2_id": "6b74270e7cf9bbfdbd3509830b3ef605b981df7c", "title": "An Incremental Algorithm for Computing Cylindrical Algebraic Decompositions", "abstract": "In this paper, we propose an incremental algorithm for computing cylindrical algebraic decompositions. The algorithm consists of two parts: computing a complex cylindrical tree and refining this complex tree into a cylindrical tree in real space. The incrementality comes from the first part of the algorithm, where a complex cylindrical tree is constructed by refining a previous complex cylindrical tree with a polynomial constraint. We have implemented our algorithm in Maple. The experimentation shows that the proposed algorithm outperforms existing ones for many examples taken from the literature.", "venue": "ASCM", "authors": ["Changbo  Chen", "Marc Moreno Maza"], "year": 2012, "n_citations": 34}
{"id": 4194052, "s2_id": "0906c7c43835b56939afb1d0015db352124ea5e6", "title": "Computer Algebra and Material Design", "abstract": "This article is intended to an introductory lecture in material physics, in which the modern computational group theory and the electronic structure calculation are in collaboration. The effort of mathematicians in field of the group theory, have ripened as a new trend, called \"computer algebra\", outcomes of which now can be available as handy computational packages, and would also be useful to physicists with practical purposes. This article, in the former part, explains how to use the computer algebra for the applications in the solid-state simulation, by means of one of the computer algebra package, the GAP system. The computer algebra enables us to obtain various group theoretical properties with ease, such as the representations, the character tables, the subgroups, etc. Furthermore it would grant us a new perspective of material design, which could be executed in mathematically rigorous and systematic way. Some technical details and some computations which require the knowledge of a little higher mathematics (but computable easily by the computer algebra) are also given. The selected topics will provide the reader with some insights toward the dominating role of the symmetry in crystal, or, the \"mathematical first principles\" in it. In the latter part of the article, we analyze the relation between the structural symmetry and the electronic structure in C$_{60}$ (as an example to the sysmem without periodicity). The principal object of the study is to illustrate the hierarchical change of the quantum-physical properties of the molecule, in accordance with the reduction of the symmetry (as it descends down in the ladder of subgroups). In order to serve the common interest of the researchers, the details of the computations (the required initial data and the small programs developed for the purpose) are explained as minutely as possible.", "venue": "ArXiv", "authors": ["Akihito  Kikuchi"], "year": 2016, "n_citations": 0}
{"id": 4197648, "s2_id": "3b9c7f09a646fd2c7661ae5db9be4e393b4eea70", "title": "Bivariate Extensions of Abramov's Algorithm for Rational Summation", "abstract": "Abramov\u2019s algorithm enables us to decide whether a univariate rational function can be written as a difference of another rational function, which has been a fundamental algorithm for rational summation. In 2014, Chen and Singer have generalized Abramov\u2019s algorithm to the case of rational functions in two (q-)discrete variables. In this paper we solve the remaining three mixed cases, which completes our recent project on bivariate extensions of Abramov\u2019s algorithm for rational summation.", "venue": "ArXiv", "authors": ["Shaoshi  Chen"], "year": 2017, "n_citations": 2}
{"id": 4206239, "s2_id": "4955c8e5d833d0d7941a18f589e809d2da70835e", "title": "An algorithm to compute the differential equations for the logarithm of a polynomial", "abstract": "We present an algorithm to compute the annihilator of (i.e., the linear differential equations for) the multi-valued analytic function <i>f</i><sup>\u03bb</sup>(log <i>f</i>)<sup><i>m</i></sup> in the Weyl algebra <i>D</i><sub><i>n</i></sub> for a given non-constant polynomial <i>f</i>, a non-negative integer <i>m</i>, and a complex number \u03bb. This algorithm essentially consists of the differentiation with respect to <i>s</i> of the annihilator of <i>f</i><sup><i>s</i></sup> in the ring <i>D</i><sub><i>n</i></sub>[<i>s</i>] and ideal quotient computation in <i>D</i><sub><i>n</i></sub>. The obtained differential equations constitute what is called a holonomic system in <i>D</i>-module theory. Hence combined with the integration algorithm for <i>D</i>-modules, this enables us to compute a holonomic system for the integral of a function involving the logarithm of a polynomial with respect to some variables.", "venue": "ISSAC", "authors": ["Toshinori  Oaku"], "year": 2012, "n_citations": 0}
{"id": 4207718, "s2_id": "bd436627472030351b34b737cabc53dcff3dc33e", "title": "Bohemian Upper Hessenberg Matrices", "abstract": "We look at Bohemian matrices, specifically those with entries from $\\{-1, 0, {+1}\\}$. More, we specialize the matrices to be upper Hessenberg, with subdiagonal entries $\\pm1$. Many properties remain after these specializations, some of which surprised us. We find two recursive formulae for the characteristic polynomials of upper Hessenberg matrices. Focusing on only those matrices whose characteristic polynomials have maximal height allows us to explicitly identify these polynomials and give a lower bound on their height. This bound is exponential in the order of the matrix. We count stable matrices, normal matrices, and neutral matrices, and tabulate the results of our experiments. We prove a theorem about the only possible kinds of normal matrices amongst a specific family of Bohemian upper Hessenberg matrices.", "venue": "ArXiv", "authors": ["Eunice Y. S. Chan", "Robert M. Corless", "Laureano  Gonz\u00e1lez-Vega", "J. Rafael Sendra", "Juana  Sendra", "Steven E. Thornton"], "year": 2018, "n_citations": 3}
{"id": 4220586, "s2_id": "1090d8c5de7768bcda03b0ddd3102dd209b3b149", "title": "Verifying the DPLL Algorithm in Dafny", "abstract": "Modern high-performance SAT solvers quickly solve large satisfiability instances that occur in practice. If the instance is satisfiable, then the SAT solver can provide a witness which can be checked independently in the form of a satisfying truth assignment. However, if the instance is unsatisfiable, the certificates could be exponentially large or the SAT solver might not be able to output certificates. The implementation of the SAT solver should then be trusted not to contain bugs. However, the data structures and algorithms implemented by a typical high-performance SAT solver are complex enough to allow for subtle programming errors. To counter this issue, we build a verified SAT solver using the Dafny system. We discuss its implementation in the present article.", "venue": "FROM", "authors": ["Cezar-Constantin  Andrici", "Stefan  Ciobaca"], "year": 2019, "n_citations": 2}
{"id": 4222758, "s2_id": "74e972de8ec189fd3de8ccefc8b2bb8366505cb4", "title": "Generalizing the davenport-mahler-mignotte bound: the weighted case", "abstract": "Root separation bounds play an important role as a complexity measure in understanding the behaviour of various algorithms in computational algebra, e.g., root isolation algorithms. A classic result in the univariate setting is the Davenport-Mahler-Mignotte (DMM) bound. One way to state the bound is to consider a directed acyclic graph (V, E) on a subset of roots of a degree d polynomial f (z) \u2208 C[z], where the edges point from a root of smaller absolute value to one of larger absolute, and the in-degrees of all vertices is at most one. Then the DMM bound is an amortized lower bound on the following product: \u03a0(\u03b1, \u03b2)\u2208E |\u03b1 - \u03b2|. However, the lower bound involves the discriminant of the polynomial f, and becomes trivial if the polynomial is not square-free. This was resolved by Eigenwillig, 2008, by using a suitable subdiscriminant instead of the discriminant. Escorcielo-Perrucci, 2016, further dropped the in-degree constraint on the graph by using the theory of finite differences. Emiris et al., 2019, have generalized their result to handle the case where the exponent of the term |\u03b1 - \u03b2| in the product is at most the multiplicity of either of the roots. In this paper, we generalize these results by allowing arbitrary positive integer weights on the edges of the graph, i.e., for a weight function w : E \u2192 Z<0, we derive an amortized lower bound on \u03a0(\u03b1, \u03b2)\u2208E |\u03b1 - \u03b2|w(\u03b1, \u03b2). Such a product occurs in the complexity estimates of some recent algorithms for root clustering (e.g., Becker et al., 2016), where the weights are usually some function of the multiplicity of the roots. Because of its amortized nature, our bound is arguably better than the bounds obtained by manipulating existing results to accommodate the weights.", "venue": "ISSAC", "authors": ["Vikram  Sharma"], "year": 2020, "n_citations": 0}
{"id": 4224337, "s2_id": "c79dc86a183b6223ff33289cba4a8795d57bc71d", "title": "A Simple Dynamic Mind-map Framework To Discover Associative Relationships in Transactional Data Streams", "abstract": "In this paper, we informally introduce dynamic mind-maps that represent a new approach on the basis of a dynamic construction of connectionist structures during the processing of a data stream. This allows the representation and processing of recursively defined structures and avoids the problem of a more traditional, fixed-size architecture with the processing of input structures of unknown size. For a data stream analysis with association discovery, the incremental analysis of data leads to results on demand. Here, we describe a framework that uses symbolic cells to calculate associations based on transactional data streams as it exists in e.g. bibliographic databases. We follow a natural paradigm of applying simple operations on cells yielding on a mind-map structure that adapts over time.", "venue": "ArXiv", "authors": ["Christoph  Schommer"], "year": 2008, "n_citations": 0}
{"id": 4233594, "s2_id": "3b49f16e0cf339e068439ed5787b7feab8baeb1f", "title": "Power series expansions for the planar monomer-dimer problem", "abstract": "We compute the free energy of the planar monomer-dimer model. Unlike the classical planar dimer model, an exact solution is not known in this case. Even the computation of the low-density power series expansion requires heavy and nontrivial computations. Despite the exponential computational complexity, we compute almost three times more terms than were previously known. Such an expansion provides both lower and upper bounds for the free energy and makes it possible to obtain more accurate numerical values than previously possible. We expect that our methods can be applied to other similar problems.", "venue": "Physical review. E", "authors": ["Gleb  Pogudin"], "year": 2017, "n_citations": 1}
{"id": 4241171, "s2_id": "5c6015c2dc421cb66751f8c064644119e494133f", "title": "Survey on Counting Special Types of Polynomials", "abstract": "Most integers are composite and most univariate polynomials over a finite field are reducible. The Prime Number Theorem and a classical result of Gaus count the remaining ones, approximately and exactly. For polynomials in two or more variables, the situation changes dramatically. Most multivariate polynomials are irreducible. This survey presents counting results for some special classes of multivariate polynomials over a finite field, namely the reducible ones, the \\(s\\)-powerful ones (divisible by the \\(s\\)th power of a nonconstant polynomial), the relatively irreducible ones (irreducible but reducible over an extension field), the decomposable ones, and also for reducible space curves. These come as exact formulas and as approximations with relative errors that essentially decrease exponentially in the input size.", "venue": "Computer Algebra and Polynomials", "authors": ["Joachim von zur Gathen", "Konstantin  Ziegler"], "year": 2015, "n_citations": 0}
{"id": 4244520, "s2_id": "74f0d5273ca83d09de7cfd9df6d204cb007b369c", "title": "Model Counting in Product Configuration", "abstract": "We describe how to use propositional model counting for a quantitative analysis of product configuration data. Our approach computes valuable meta information such as the total number of valid configurations or the relative frequency of components. Thi s information can be used to assess the severity of documentation errors or to measure documentation quality. As an application example we show how we apply these methods to product documentation formulas of the Mercedes-Benz line of vehicles. In order to process these large formulas we developed and implemented a new model counter for non-CNF formulas. Our model counter can process formulas, whose CNF representations could not be processed up till now.", "venue": "LoCoCo", "authors": ["Andreas  K\u00fcbler", "Christoph  Zengler", "Wolfgang  K\u00fcchlin"], "year": 2010, "n_citations": 22}
{"id": 4247437, "s2_id": "0695bfddcc30b20d32dd2a5d14f2f9fcc993bf1a", "title": "A computational definition of the notion of vectorial space", "abstract": "We usually define an algebra by a set, some operations defined on this set and some propositions that the algebra must validate. In some cases, we can replace these propositions by an algorithm on terms constructed upon these operations that the algebra must validate. We show in this note that this is the case for the notion of vectorial space and bilinear function.", "venue": "WRLA", "authors": ["Pablo  Arrighi", "Gilles  Dowek"], "year": 2004, "n_citations": 19}
{"id": 4253352, "s2_id": "caef63cd9a65d1387723268c9d28d7f48ab47ab3", "title": "Factorizations for a class of multivariate polynomial matrices", "abstract": "This paper investigates how to factorize a class of multivariate polynomial matrices. We prove that an $$l\\times m$$ l \u00d7 m multivariate polynomial matrix admits a matrix factorization with respect to a given polynomial if the polynomial and all the $$(l-1)\\times (l-1)$$ ( l - 1 ) \u00d7 ( l - 1 ) reduced minors of the matrix generate a unit ideal. This result is a generalization of a theorem in Liu et al. (Circuits Syst Signal Process 30(3):553\u2013566, 2011). Based on three main theorems presented in the paper and a constructive algorithm proposed by Lin et al. (Circuits Syst Signal Process 20(6):601\u2013618, 2001), we give an algorithm which can be used to factorize more multivariate polynomial matrices. In addition, an illustrative example is given to show the effectiveness of the proposed algorithm.", "venue": "Multidimens. Syst. Signal Process.", "authors": ["Dong  Lu", "Dingkang  Wang", "Fanghui  Xiao"], "year": 2020, "n_citations": 3}
{"id": 4264123, "s2_id": "4777c29856e9e8cc380e84193d58c2b47b5c7525", "title": "On Computational Poisson Geometry I: Symbolic Foundations", "abstract": "We present a computational toolkit for (local) Poisson-Nijenhuis calculus on manifolds. Our Python module $\\textsf{PoissonGeometry}$ implements our algorithms and accompanies this paper. Examples of how our methods can be used are explained, including gauge transformations of Poisson bivector in dimension 3, parametric Poisson bivector fields in dimension 4, and Hamiltonian vector fields of parametric families of Poisson bivectors in dimension 6.", "venue": "Journal of Geometric Mechanics", "authors": ["M. A. Evangelista-Alvarado", "J. C. Ru'iz-Pantale'on", "P.  Su'arez-Serrato"], "year": 2021, "n_citations": 3}
{"id": 4266265, "s2_id": "1232dd5cb247d52ce6dfc1f1196ce0f6d8470706", "title": "Computing the Dimension of Real Algebraic Sets", "abstract": "Let V be the set of real common solutions to F = (f1, \u2026, fs) in \u211c[x1, \u2026;, xn] and D be the maximum total degree of the fi's. We design an algorithm which on input F computes the dimension of V. Letting L be the evaluation complexity of F and s=1, it runs using O\u223c (L D n(d+3)+1) arithmetic operations in \ud835\udcac and at most Dn(d+1) isolations of real roots of polynomials of degree at most Dn. Our algorithm depends on the real geometry of V; its practical behavior is more governed by the number of topology changes in the fibers of some well-chosen maps. Hence, the above worst-case bounds are rarely reached in practice, the factor Dnd being in general much lower on practical examples. We report on an implementation showing its ability to solve problems which were out of reach of the state-of-the-art implementations.", "venue": "ISSAC", "authors": ["Piere  Lairez", "Mohab Safey El Din"], "year": 2021, "n_citations": 0}
{"id": 4269888, "s2_id": "3d1cefb039b4b90fe997e1df7adc39e4547580f1", "title": "Enhancing simultaneous rational function recovery: adaptive error correction capability and new bounds for applications", "abstract": "In this work we present some results that allow to improve the decoding radius in solving polynomial linear systems with errors in the scenario where errors are additive and randomly distributed over a finite field. The decoding radius depends on some bounds on the solution that we want to recover, so their overestimation could significantly decrease our error correction capability. For this reason, we introduce an algorithm that can bridge this gap, introducing some ad hoc parameters that reduce the discrepancy between the estimate decoding radius and the effective error correction capability.", "venue": "ArXiv", "authors": ["Eleonora  Guerrini", "Romain  Lebreton", "Ilaria  Zappatore"], "year": 2020, "n_citations": 1}
{"id": 4270462, "s2_id": "ee320f8ffe634522ab1727eb175a5d24edaf5de2", "title": "Algebraic elimination of epsilon-transitions", "abstract": "We present here algebraic formulas associating a k-automaton to a k-epsilon-automaton. The existence depends on the definition of the star of matrices and of elements in the semiring k. For this reason, we present the theorem which allows the transformation of k-epsilon-automata into k-automata. The two automata have the same behaviour.", "venue": "Discret. Math. Theor. Comput. Sci.", "authors": ["G\u00e9rard  Duchamp", "Hatem Hadj Kacem", "\u00c9ric  Laugerotte"], "year": 2005, "n_citations": 8}
{"id": 4270585, "s2_id": "8a38b3b153f5b99cf3f599a8eff200dcf6a3be71", "title": "Determination of the structure of algebraic curvature tensors by means of Young symmetrizers", "abstract": "For a positive definite fundamental tensor all known examples of Osserman algebraic curvature tensors have a typical structure. They can be produced from a metric tensor and a finite set of skew-symmetric matrices which fulfil Cliord commutation relations. We show by means of Young symmetrizers and a theorem of S. A. Fulling, R. C. King, B. G. Wybourne and C. J. Cummins that every algebraic curvature tensor has a structure which is very similar to that of the above Osserman curvature tensors. We verify our results by means of the Littlewood-Richardson rule and plethysms. For certain symbolic calculations we used the Mathematica packages MathTensor, Ricci and PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2002, "n_citations": 27}
{"id": 4291472, "s2_id": "7f9ac88a188b9da3b369e63321225569fd101e98", "title": "Division and Slope Factorization of p-Adic Polynomials", "abstract": "We study two important operations on polynomials defined over complete discrete valuation fields: Euclidean division and factorization. In particular, we design a simple and efficient algorithm for computing slope factorizations, based on Newton iteration. One of its main features is that we avoid working with fractional exponents. We pay particular attention to stability, and analyze the behavior of the algorithm using several precision models.", "venue": "ISSAC", "authors": ["Xavier  Caruso", "David  Roe", "Tristan  Vaccon"], "year": 2016, "n_citations": 7}
{"id": 4291799, "s2_id": "7d9e8bc799e4bfd31f3a1a27d70ff2e14b64b9bd", "title": "Strassen's Matrix Multiplication Algorithm for Matrices of Arbitrary Order", "abstract": "The well known algorithm of Volker Strassen for matrix multiplication can only be used for $(m2^k \\times m2^k)$ matrices. For arbitrary $(n \\times n)$ matrices one has to add zero rows and columns to the given matrices to use Strassen's algorithm. Strassen gave a strategy of how to set $m$ and $k$ for arbitrary $n$ to ensure $n\\leq m2^k$. In this paper we study the number $d$ of additional zero rows and columns and the influence on the number of flops used by the algorithm in the worst case ($d=n/16$), best case ($d=1$) and in the average case ($d\\approx n/48$). The aim of this work is to give a detailed analysis of the number of additional zero rows and columns and the additional work caused by Strassen's bad parameters. Strassen used the parameters $m$ and $k$ to show that his matrix multiplication algorithm needs less than $4.7n^{\\log_2 7}$ flops. We can show in this paper, that these parameters cause an additional work of approx. 20 % in the worst case in comparison to the optimal strategy for the worst case. This is the main reason for the search for better parameters.", "venue": "ArXiv", "authors": ["Ivo  Hedtke"], "year": 2010, "n_citations": 7}
{"id": 4298101, "s2_id": "cee600ac28179e362132fa89b790ff37459d99a0", "title": "On p-Adic Differential Equations with Separation of Variables", "abstract": "Several algorithms in computer algebra involve the computation of a power series solution of a given ordinary differential equation. Over finite fields, the problem is often lifted in an approximate $p$-adic setting to be well-posed. This raises precision concerns: how much precision do we need on the input to compute the output accurately? In the case of ordinary differential equations with separation of variables, we make use of the recent technique of differential precision to obtain optimal bounds on the stability of the Newton iteration. The results apply, for example, to algorithms for manipulating algebraic numbers over finite fields, for computing isogenies between elliptic curves or for deterministically finding roots of polynomials in finite fields. The new bounds lead to significant speedups in practice.", "venue": "ISSAC", "authors": ["Pierre  Lairez", "Tristan  Vaccon"], "year": 2016, "n_citations": 11}
{"id": 4312805, "s2_id": "6245ead21029a734c75e486afda4fe71490114f9", "title": "Symbolic Computation of Conservation Laws, Generalized Symmetries, and Recursion Operators for Nonlinear Differential-Difference Equations", "abstract": "Algorithms for the symbolic computation of polynomial conservation laws, generalized symmetries, and recursion operators for systems of nonlinear differential\u2013difference equations (DDEs) are presented. The algorithms can be used to test the complete integrability of nonlinear DDEs. The ubiquitous Toda lattice illustrates the steps of the algorithms, which have been implemented in Mathematica. The codes InvariantsSymmetries.m and DDERecursionOperator.m can aid researchers interested in properties of nonlinear DDEs.", "venue": "ArXiv", "authors": ["\u00dcnal  G\u00f6ktas", "Willy  Hereman"], "year": 2011, "n_citations": 4}
{"id": 4318071, "s2_id": "57cff0d69d488623732f536001d37a688b606774", "title": "Recent Advances in Real Geometric Reasoning", "abstract": "In the 1930s Tarski showed that real quantifier elimination was possible, and in 1975 Collins gave a remotely practicable method, albeit with doubly-exponential complexity, which was later shown to be inherent. We discuss some of the recent major advances in Collins method: such as an alternative approach based on passing via the complexes, and advances which come closer to \"solving the question asked\" rather than \"solving all problems to do with these polynomials\".", "venue": "ADG", "authors": ["James H. Davenport", "Matthew  England"], "year": 2014, "n_citations": 4}
{"id": 4319468, "s2_id": "589087ee4ee224e1e19d2bc91c0473aa27154d83", "title": "Neural Collaborative Reasoning", "abstract": "Existing Collaborative Filtering (CF) methods are mostly designed based on the idea of matching, i.e., by learning user and item embeddings from data using shallow or deep models, they try to capture the associative relevance patterns in data, so that a user embedding can be matched with relevant item embeddings using designed or learned similarity functions. However, as a cognition rather than a perception intelligent task, recommendation requires not only the ability of pattern recognition and matching from data, but also the ability of cognitive reasoning in data. In this paper, we propose to advance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which means that each user knows part of the reasoning space, and they collaborate for reasoning in the space to estimate preferences for each other. Technically, we propose a Neural Collaborative Reasoning (NCR) framework to bridge learning and reasoning. Specifically, we integrate the power of representation learning and logical reasoning, where representations capture similarity patterns in data from perceptual perspectives, and logic facilitates cognitive reasoning for informed decision making. An important challenge, however, is to bridge differentiable neural networks and symbolic reasoning in a shared architecture for optimization and inference. To solve the problem, we propose a modularized reasoning architecture, which learns logical operations such as AND (\u2227), OR (\u2228) and NOT (\u00ac) as neural modules for implication reasoning (\u2192). In this way, logical expressions can be equivalently organized as neural networks, so that logical reasoning and prediction can be conducted in a continuous space. Experiments on real-world datasets verified the advantages of our framework compared with both shallow, deep and reasoning models.", "venue": "WWW", "authors": ["Hanxiong  Chen", "Shaoyun  Shi", "Yunqi  Li", "Yongfeng  Zhang"], "year": 2021, "n_citations": 14}
{"id": 4322118, "s2_id": "e6aeb31aec482a89591e1967b2f8a2d55eef86e7", "title": "Computing Chebyshev knot diagrams", "abstract": "A Chebyshev curve $\\mathcal{C}(a,b,c,\\phi)$ has a parametrization of the form \n$ x(t)=T_a(t)$; \\ $y(t)=T_b(t)$; $z(t)= T_c(t + \\phi)$, where $a,b,c$ \nare integers, $T_n(t)$ is the Chebyshev polynomial \nof degree $n$ and $\\phi \\in \\mathbb{R}$. When $\\mathcal{C}(a,b,c,\\phi)$ is nonsingular, \nit defines a polynomial knot. \nWe determine all possible knot diagrams when $\\phi$ varies. \nLet $a,b,c$ be integers, $a$ is odd, $(a,b)=1$, we show that \none can list all possible knots $\\mathcal{C}(a,b,c,\\phi)$ in \n$\\tilde{\\mathcal{O}}(n^2)$ bit operations, with $n=abc$.", "venue": "J. Symb. Comput.", "authors": ["Pierre-Vincent  Koseleff", "Daniel  Pecker", "Fabrice  Rouillier", "Cuong  Tran"], "year": 2018, "n_citations": 1}
{"id": 4322804, "s2_id": "b0da058cd3e68b8171ad17d44e4d6a2caa2a53ce", "title": "Computing Igusa's local zeta function of univariates in deterministic polynomial-time", "abstract": "Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that counts the number of integral roots, $N_{k}(f)$, of $f(\\mathbf x) \\bmod p^k$, for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$ is a rational function in $\\mathbb{Q}(p^s)$. We give an elementary proof of this fact for a univariate polynomial $f$. Our proof is constructive as it gives a closed-form expression for the number of roots $N_{k}(f)$. \nOur proof, when combined with the recent root-counting algorithm of (Dwivedi, Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \\log p$) time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only in the case when $f$ completely splits over $\\mathbb{Q}_p$; it required the rational roots to use the concept of generating function of a tree (Zuniga-Galindo, J.Int.Seq., 2003).", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Ashish  Dwivedi", "Nitin  Saxena"], "year": 2020, "n_citations": 2}
{"id": 4330211, "s2_id": "2c94880c322f7ed788a68108414380c1b3b5a00e", "title": "Computing arithmetic Kleinian groups", "abstract": "Arithmetic Kleinian groups are arithmetic lattices in PSL_2(C). We present an algorithm which, given such a group Gamma, returns a fundamental domain and a finite presentation for Gamma with a computable isomorphism.", "venue": "Math. Comput.", "authors": ["Aurel  Page"], "year": 2015, "n_citations": 30}
{"id": 4330731, "s2_id": "9dca1da1a3066a412a967ba2834d26545f597d1f", "title": "Protocol indepedence through disjoint encryption under Exclusive-OR", "abstract": "Multi-protocol attacks due to protocol interaction has been a notorious problem for security. Gutman-Thayer proved that they can be prevented by ensuring that encrypted messages are distinguishable across protocols, under a free algebra. In this paper, we prove that a similar suggestion prevents these attacks under commonly used operators such as Exclusive-OR, that induce equational theories, breaking the free algebra assumption.", "venue": "ArXiv", "authors": ["Sreekanth  Malladi"], "year": 2010, "n_citations": 4}
{"id": 4332395, "s2_id": "92079e00ebfc8cc3c1742f331d8aa18c620f9c66", "title": "Faster interpolation algorithms for sparse multivariate polynomials given by straight-line programs", "abstract": "In this paper, we propose new deterministic and Monte Carlo interpolation algorithms for sparse multivariate polynomials represented by straight-line programs. Let $f$ be an $n$-variate polynomial given by a straight-line program, which has a degree bound $D$ and a term bound $T$. Our deterministic algorithm is quadratic in $n,T$ and cubic in $\\log D$ in the Soft-Oh sense, which has better complexities than existing deterministic interpolation algorithms in most cases. Our Monte Carlo interpolation algorithms have better complexities than existing Monte Carlo interpolation algorithms and are the first algorithms whose complexities are linear in $nT$ in the Soft-Oh sense. Since $nT$ is a factor of the size of $f$, our Monte Carlo algorithms are optimal in $n$ and $T$ in the Soft-Oh sense.", "venue": "J. Symb. Comput.", "authors": ["Qiao-Long  Huang", "Xiao-Shan  Gao"], "year": 2020, "n_citations": 5}
{"id": 4333739, "s2_id": "fbca72c5b852889c47dfdf2edea8c792d20eb614", "title": "Logic Guided Genetic Algorithms", "abstract": "We present a novel Auxiliary Truth enhanced Genetic Algorithm (GA) that uses logical or mathematical constraints as a means of data augmentation as well as to compute loss (in conjunction with the traditional MSE), with the aim of increasing both data efficiency and accuracy of symbolic regression (SR) algorithms. Our method, logic-guided genetic algorithm (LGGA), takes as input a set of labelled data points and auxiliary truths (ATs) (mathematical facts known a priori about the unknown function the regressor aims to learn) and outputs a specially generated and curated dataset that can be used with any SR method. Three key insights underpin our method: first, SR users often know simple ATs about the function they are trying to learn. Second, whenever an SR system produces a candidate equation inconsistent with these ATs, we can compute a counterexample to prove the inconsistency, and further, this counterexample may be used to augment the dataset and fed back to the SR system in a corrective feedback loop. Third, the value addition of these ATs is that their use in both the loss function and the data augmentation process leads to better rates of convergence, accuracy, and data efficiency. We evaluate LGGA against state-of-the-art SR tools, namely, Eureqa and TuringBot on 16 physics equations from \"The Feynman Lectures on Physics\" book. We find that using these SR tools in conjunction with LGGA results in them solving up to 30.0% more equations, needing only a fraction of the amount of data compared to the same tool without LGGA, i.e., resulting in up to a 61.9% improvement in data efficiency.", "venue": "ArXiv", "authors": ["Dhananjay  Ashok", "Joseph  Scott", "Sebastian  Wetzel", "Maysum  Panju", "Vijay  Ganesh"], "year": 2020, "n_citations": 5}
{"id": 4339040, "s2_id": "0bf09659ea09c646bd088e6412e7b68639fc9d9b", "title": "Inverse Mellin Transform of Holonomic Sequences", "abstract": "We describe a method to compute the inverse Mellin transform of holonomic sequences, that is based on a method to compute the Mellin transform of holonomic functions. Both methods are implemented in the computer algebra package HarmonicSums.", "venue": "ArXiv", "authors": ["Jakob  Ablinger"], "year": 2016, "n_citations": 15}
{"id": 4339456, "s2_id": "4169f2ee1821e6cff7e42fdacdc0c0d66a88883c", "title": "Proof of the Wilf-Zeilberger conjecture for mixed hypergeometric terms", "abstract": "Abstract In 1992, Wilf and Zeilberger conjectured that a hypergeometric term in several discrete and continuous variables is holonomic if and only if it is proper. Strictly speaking the conjecture does not hold, but it is true when reformulated properly: Payne proved a piecewise interpretation in 1997, and independently, Abramov and Petkovsek in 2002 proved a conjugate interpretation. Both results address the pure discrete case of the conjecture. In this paper we extend their work to hypergeometric terms in several discrete and continuous variables and prove the conjugate interpretation of the Wilf\u2013Zeilberger conjecture in this mixed setting.", "venue": "J. Symb. Comput.", "authors": ["Shaoshi  Chen", "Christoph  Koutschan"], "year": 2019, "n_citations": 6}
{"id": 4339623, "s2_id": "d5e4633fa26ccfe76cded0581725b6b20d654393", "title": "Maximum Absolute Determinants of Upper Hessenberg Bohemian Matrices", "abstract": "A matrix is called Bohemian if its entries are sampled from a finite set of integers. We determine the maximum absolute determinant of upper Hessenberg Bohemian Matrices for which the subdiagonal entries are fixed to be $1$ and upper triangular entries are sampled from $\\{0,1,\\cdots,n\\}$, extending previous results for $n=1$ and $n=2$ and proving a recent conjecture of Fasi & Negri Porzio [8]. Furthermore, we generalize the problem to non-integer-valued entries.", "venue": "ArXiv", "authors": ["Jonathan P. Keating", "Ahmet Abdullah Keles"], "year": 2020, "n_citations": 0}
{"id": 4339958, "s2_id": "d592ff1ba69bdda428cfa8f64628a031db6fd70a", "title": "Exact sparse matrix-vector multiplication on GPU's and multicore architectures", "abstract": "We propose different implementations of the sparse matrix-dense vector multiplication (SpMV) for finite fields and rings Z /m Z. We take advantage of graphic card processors (GPU) and multi-core architectures. Our aim is to improve the speed of SpMV in the LinBox library, and henceforth the speed of its black-box algorithms. Besides, we use this library and a new parallelisation of the sigma-basis algorithm in a parallel block Wiedemann rank implementation over finite fields.", "venue": "PASCO", "authors": ["Brice  Boyer", "Jean-Guillaume  Dumas", "Pascal  Giorgi"], "year": 2010, "n_citations": 24}
{"id": 4345519, "s2_id": "afac86cacc241cb45bbc31f4700f641633f15609", "title": "Orthonormal RBF Wavelet and Ridgelet-like Series and Transforms for High- Dimensional Problems", "abstract": "This paper developed a systematic strategy establishing RBF on the wavelet analysis, which includes continuous and discrete RBF orthonormal wavelet transforms respectively in terms of singular fundamental solutions and nonsingular general solutions of differential operators. In particular, the harmonic Bessel RBF transforms were presented for high-dimensional data processing. It was also found that the kernel functions of convection-diffusion operator are feasible to construct some stable ridgelet-like RBF transforms. We presented time-space RBF transforms based on non-singular solution and fundamental solution of time-dependent differential operators. The present methodology was further extended to analysis of some known RBFs such as the MQ, Gaussian and pre-wavelet kernel RBFs.", "venue": "ArXiv", "authors": ["W.  Chen"], "year": 2002, "n_citations": 11}
{"id": 4352682, "s2_id": "cf4ec77cbaf6d0612246f54123c33a90733f5d63", "title": "Finding best possible constant for a polynomial inequality", "abstract": "Given a multi-variant polynomial inequality with a parameter, how to find the best possible value of this parameter that satisfies the inequality? For instance, find the greatest number $k$ that satisfies $ a^3+b^3+c^3+ k(a^2b+b^2c+c^2a)-(k+1)(ab^2+bc^2+ca^2)\\geq 0 $ for all nonnegative real numbers $ a,b,c $. Analogues problems often appeared in studies of inequalities and were dealt with by various methods. In this paper, a general algorithm is proposed for finding the required best possible constant. The algorithm can be easily implemented by computer algebra tools such as Maple.", "venue": "ArXiv", "authors": ["Lu  Yang", "Ju  Zhang"], "year": 2016, "n_citations": 0}
{"id": 4360168, "s2_id": "3eea984be8af3c81dae64274131b40d9c37b8d55", "title": "Theory Presentation Combinators", "abstract": "We motivate and give semantics to theory presentation combinators as the foundational building blocks for a scalable library of theories. The key observation is that the category of contexts and fibered categories are the ideal theoretical tools for this purpose.", "venue": "AISC/MKM/Calculemus", "authors": ["Jacques  Carette", "Russell  O'Connor"], "year": 2012, "n_citations": 15}
{"id": 4364003, "s2_id": "7bf515a76d4109b1e93584bb933132335c0e4a7a", "title": "Multiple-Precision Evaluation of the Airy Ai Function with Reduced Cancellation", "abstract": "The series expansion at the origin of the Airy function Ai(x) is alternating and hence problematic to evaluate for x > 0 due to cancellation. Based on a method recently proposed by Gawronski, Mu\u0308ller, and Rein hard, we exhibit two functions F and G, both with nonnegative Taylor expansions at the origin, such that Ai(x) = G(x)/F(x). The sums are now well-conditioned, but the Taylor coefficients of G turn out to obey an ill-conditioned three-term recurrence. We use the classical Miller algorithm to overcome this issue. We bound all errors and our implementation allows an arbitrary and certified accuracy, that can be used, e.g., for providing correct rounding in arbitrary precision.", "venue": "2013 IEEE 21st Symposium on Computer Arithmetic", "authors": ["Sylvain  Chevillard", "Marc  Mezzarobba"], "year": 2013, "n_citations": 12}
{"id": 4366184, "s2_id": "040c868279c2991ed09c70c04f79a6570b7e224a", "title": "The parametric solution of underdetermined linear ODEs", "abstract": "The purpose of this paper is twofold. An immediate practical use of the presented algorithm is its applicability to the parametric solution of underdetermined linear ordinary differential equations (ODEs) with coefficients that are arbitrary analytic functions in the independent variable. A second conceptual aim is to present an algorithm that is in some sense dual to the fundamental Euclids algorithm, and thus an alternative to the special case of a Gr\u00f6bner basis algorithm as it is used for solving linear ODE-systems. In the paper Euclids algorithm and the new \u201cdual version\u201d are compared and their complementary strengths are analysed on the task of solving underdetermined ODEs. An implementation of the described algorithm is interactively accessible under [7].", "venue": "Programming and Computer Software", "authors": ["Thomas  Wolf"], "year": 2011, "n_citations": 0}
{"id": 4367561, "s2_id": "64c67816064521e7e7bf17a47b3b6c20d51222f7", "title": "Polynomial Reduction and Super Congruences", "abstract": "Based on a reduction processing, we rewrite a hypergeometric term as the sum of the difference of a hypergeometric term and a reduced hypergeometric term (the reduced part, in short). We show that when the initial hypergeometric term has a certain kind of symmetry, the reduced part contains only odd or even powers. As applications, we derived two infinite families of super-congruences.", "venue": "J. Symb. Comput.", "authors": ["Qing-Hu  Hou", "Yan-Ping  Mu", "Doron  Zeilberger"], "year": 2021, "n_citations": 7}
{"id": 4370176, "s2_id": "d00e838f597a50af271364364c523e4067134580", "title": "Using Machine Learning to Improve Cylindrical Algebraic Decomposition", "abstract": "Cylindrical Algebraic Decomposition (CAD) is a key tool in computational algebraic geometry, best known as a procedure to enable Quantifier Elimination over real-closed fields. However, it has a worst case complexity doubly exponential in the size of the input, which is often encountered in practice. It has been observed that for many problems a change in algorithm settings or problem formulation can cause huge differences in runtime costs, changing problem instances from intractable to easy. A number of heuristics have been developed to help with such choices, but the complicated nature of the geometric relationships involved means these are imperfect and can sometimes make poor choices. We investigate the use of machine learning (specifically support vector machines) to make such choices instead. Machine learning is the process of fitting a computer model to a complex function based on properties learned from measured data. In this paper we apply it in two case studies: the first to select between heuristics for choosing a CAD variable ordering; the second to identify when a CAD problem instance would benefit from Gr\u00f6bner Basis preconditioning. These appear to be the first such applications of machine learning to Symbolic Computation. We demonstrate in both cases that the machine learned choice outperforms human developed heuristics.", "venue": "Math. Comput. Sci.", "authors": ["Zongyan  Huang", "Matthew  England", "David J. Wilson", "James H. Davenport", "Lawrence C. Paulson"], "year": 2019, "n_citations": 15}
{"id": 4371790, "s2_id": "1fd8ba1884be7e389643adb389b42db9991adaa8", "title": "Reconstruction algorithms for sums of affine powers", "abstract": "Abstract Let F be any characteristic zero field and let f \u2208 F [ x ] be a univariate polynomial. A sum of affine powers is an expression of the form f ( x ) = \u2211 i = 1 s \u03b1 i ( x \u2212 a i ) e i . Although quite simple, this model is a generalization of two well-studied models: Waring decomposition and Sparsest Shift. We present structural results which compare the expressive power of the three models; and we propose algorithms that find the smallest decomposition of f in the first model (sums of affine powers) for an input polynomial f given in dense representation. This work could be extended in several directions. In particular, just as for Sparsest Shift and Waring decomposition, one could consider extensions to \u201csupersparse\u201d polynomials and study the multivariate version of the problem. We also point out that the basic univariate problem studied in the present paper is far from completely solved: our algorithms all rely on some assumptions for the exponents e i in a decomposition of f, and some algorithms also rely on a distinctness assumption for the shifts a i . It would be very interesting to weaken these assumptions, or even to remove them entirely. Another related and poorly understood issue is that of the bit size of the constants a i , \u03b1 i in an optimal decomposition: is it always polynomially related to the bit size of the input polynomial f given in dense representation?", "venue": "J. Symb. Comput.", "authors": ["Ignacio  Garc\u00eda-Marco", "Pascal  Koiran", "Timoth\u00e9e  Pecatte"], "year": 2020, "n_citations": 0}
{"id": 4373850, "s2_id": "0d4a63719c5f0af2d14b9b9b775e424cb564a8c6", "title": "On Bezout Inequalities for non-homogeneous Polynomial Ideals", "abstract": "We introduce a \"workable\" notion of degree for non-homogeneous polynomial ideals and formulate and prove ideal theoretic B\\'ezout Inequalities for the sum of two ideals in terms of this notion of degree and the degree of generators. We compute probabilistically the degree of an equidimensional ideal.", "venue": "J. Symb. Comput.", "authors": ["Amir  Hashemi", "Joos  Heintz", "Luis M. Pardo", "Pablo  Solern\u00f3"], "year": 2021, "n_citations": 2}
{"id": 4376982, "s2_id": "1e863e0320133e3ea9b96ab290699fc2c8096948", "title": "Homotopy methods for multiplication modulo triangular sets", "abstract": "We study the cost of multiplication modulo triangular families of polynomials. Following previous work by Li, Moreno Maza and Schost, we propose an algorithm that relies on homotopy and fast evaluation-interpolation techniques. We obtain a quasi-linear time complexity for substantial families of examples, for which no such result was known before. Applications are given to notably addition of algebraic numbers in small characteristic.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Muhammad F. I. Chowdhury", "Joris van der Hoeven", "\u00c9ric  Schost"], "year": 2009, "n_citations": 12}
{"id": 4377618, "s2_id": "e89e84a4bb23282d770584afbad7ef2586205a2c", "title": "Deflation and certified isolation of singular zeros of polynomial systems", "abstract": "We develop a new symbolic-numeric algorithm for the certification of singular isolated points, using their associated local ring structure and certified numerical computations. An improvement of an existing method to compute inverse systems is presented, which avoids redundant computation and reduces the size of the intermediate linear systems to solve. We derive a one-step deflation technique, from the description of the multiplicity structure in terms of differentials. The deflated system can be used in Newton-based iterative schemes with quadratic convergence. Starting from a polynomial system and a sufficiently small neighborhood, we obtain a criterion for the existence and uniqueness of a singular root of a given multiplicity structure, applying a well-chosen symbolic perturbation. Standard verification methods, based e.g. on interval arithmetic and a fixed point theorem, are employed to certify that there exists a unique perturbed system with a singular root in the domain. Applications to topological degree computation and to the analysis of real branches of an implicit curve illustrate the method.", "venue": "ISSAC '11", "authors": ["Angelos  Mantzaflaris", "Bernard  Mourrain"], "year": 2011, "n_citations": 42}
{"id": 4393446, "s2_id": "16606891aae022b85d65f571eb01c8aabba9ac56", "title": "Real solution isolation with multiplicity of zero-dimensional triangular systems", "abstract": "Existing algorithms for isolating real solutions of zero-dimensional polynomial systems do not compute the multiplicities of the solutions. In this paper, we define in a natural way the multiplicity of solutions of zero-dimensional triangular polynomial systems and prove that our definition is equivalent to the classical definition of local (intersection) multiplicity. Then we present an effective and complete algorithm for isolating real solutions with multiplicities of zero-dimensional triangular polynomial systems using our definition. The algorithm is based on interval arithmetic and square-free factorization of polynomials with real algebraic coefficients. The computational results on some examples from the literature are presented.", "venue": "Science China Information Sciences", "authors": ["Zhihai  Zhang", "Tian  Fang", "Bican  Xia"], "year": 2010, "n_citations": 7}
{"id": 4394109, "s2_id": "bfd0fd66536da4dcb01c5e6fd6eb2f1c7c80c600", "title": "Four random permutations conjugated by an adversary generate Sn with high probability", "abstract": "We prove a conjecture dating back to a 1978 paper of D.R.\\ Musser~\\cite{musserirred}, namely that four random permutations in the symmetric group $\\mathcal{S}_n$ generate a transitive subgroup with probability $p_n > \\epsilon$ for some $\\epsilon > 0$ independent of $n$, even when an adversary is allowed to conjugate each of the four by a possibly different element of $\\S_n$ (in other words, the cycle types already guarantee generation of $\\mathcal{S}_n$). This is closely related to the following random set model. A random set $M \\subseteq \\mathbb{Z}^+$ is generated by including each $n \\geq 1$ independently with probability $1/n$. The sumset $\\text{sumset}(M)$ is formed. Then at most four independent copies of $\\text{sumset}(M)$ are needed before their mutual intersection is no longer infinite.", "venue": "Random Struct. Algorithms", "authors": ["Robin  Pemantle", "Yuval  Peres", "Igor  Rivin"], "year": 2016, "n_citations": 20}
{"id": 4395074, "s2_id": "b8aa9cfe4a8e16afb4a5ef67ab3c2df0612a18ac", "title": "On FGLM Algorithms with Tate Algebras", "abstract": "Tate introduced in [18] the notion of Tate algebras to serve, in the context of analytic geometry over the p-adics, as a counterpart of polynomial algebras in classical algebraic geometry. In [6,7] the formalism of Gr\u00f6bner bases over Tate algebras has been introduced and advanced signature-based algorithms have been proposed. In the present article, we extend the FGLM algorithm of [8] to Tate algebras. Beyond allowing for fast change of ordering, this strategy has two other important benefits. First, it provides an efficient algorithm for changing the radii of convergence which, in particular, makes effective the bridge between the polynomial setting and the Tate setting and may help in speeding up the computation of Gr\u00f6bner basis over Tate algebras. Second, it gives the foundations for designing a fast algorithm for interreduction, which could serve as a basic primitive in our previous algorithms and accelerate them significantly.", "venue": "ISSAC", "authors": ["Xavier  Caruso", "Tristan  Vaccon", "Thibaut  Verron"], "year": 2021, "n_citations": 0}
{"id": 4395824, "s2_id": "61422cc445666725f3f54a5968ce0dedb8ad0820", "title": "Faster integer multiplication using plain vanilla FFT primes", "abstract": "Assuming a conjectural upper bound for the least prime in an arithmetic progression, we show that n-bit integers may be multiplied in O(n log n 4^(log^* n)) bit operations.", "venue": "Math. Comput.", "authors": ["David  Harvey", "Joris van der Hoeven"], "year": 2019, "n_citations": 16}
{"id": 4399756, "s2_id": "42c6d20af4f8445c708bac2df098bff828f1b49c", "title": "Pattern classification in symbolic streams via semantic annihilation of information", "abstract": "We propose a technique for pattern identification in symbolic streams via selective erasure of observed symbols, in cases where the patterns of interest are represented as Probabilistic Finite State Automata (PFSA). We define an additive abelian group for a slightly restricted set of probabilistic machines, and the group sum is used to formulate pattern-specific semantic annihilators. The annihilators attempt to identify pre-specified patterns via removal of inter-symbol correlations from observed sequences, thereby turning them into symbolic white noise. Thus a perfect annihilation corresponds to a pattern match. This approach of classification via information annihilation is shown to be strictly advantageous, with theoretical guarantees, for a large class of PFSA models. The results are supported by simulation experiments.", "venue": "Proceedings of the 2010 American Control Conference", "authors": ["Ishanu  Chattopadhyay", "Yicheng  Wen", "Asok  Ray"], "year": 2010, "n_citations": 2}
{"id": 4401419, "s2_id": "05d6692927d31eca0a8095c749d3362ca7e1932a", "title": "Real Computational Universality: The Word Problem for a Class of Groups with Infinite Presentation", "abstract": "The word problem for discrete groups is well known to be undecidable by a Turing Machine; more precisely, it is reducible both to and from and thus equivalent to the discrete Halting Problem. The present work introduces and studies a real extension of the word problem for a certain class of groups which are presented as quotient groups of a free group and a normal subgroup. As a main difference to discrete groups these groups may be generated by uncountably many generators with index running over certain sets of real numbers. We study the word problem for such groups within the Blum\u2013Shub\u2013Smale (BSS) model of real number computation. The main result establishes the word problem to be computationally equivalent to the Halting Problem for such machines. It thus gives the first non-trivial example of a problem complete, that is, computationally universal for this model.", "venue": "Found. Comput. Math.", "authors": ["Klaus  Meer", "Martin  Ziegler"], "year": 2009, "n_citations": 3}
{"id": 4408147, "s2_id": "1bbf932941e7de7d0df9f94d199ef6888d327a36", "title": "Computing Puiseux series for algebraic surfaces", "abstract": "In this paper we outline an algorithmic approach to compute Puiseux series expansions for algebraic sets. The series expansions originate at the intersection of the algebraic set with as many coordinate planes as the dimension of the algebraic set. Our approach starts with a polyhedral method to compute cones of normal vectors to the Newton polytopes of the given polynomial system that defines the algebraic set. If as many vectors in the cone as the dimension of the algebraic set define an initial form system that has isolated solutions, then those vectors are potential tropisms for the initial term of the Puiseux series expansion. Our preliminary methods produce exact representations for solution sets of the cyclic n-roots problem, for n = m2, corresponding to a result of Backelin.", "venue": "ISSAC", "authors": ["Danko  Adrovic", "Jan  Verschelde"], "year": 2012, "n_citations": 22}
{"id": 4411739, "s2_id": "836b33902983353d1d50f6681f5dfe07579a8ff3", "title": "Moment matrices, trace matrices and the radical of ideals", "abstract": "Let f1,..., fs be a system of polynomials in K[x1,..., xm] generating a zero-dimensional ideal I , where K is an arbitrary algebraically closed field. Assume that the factor algebra A = K[x1 , . . . , xm]/I is Gorenstein and that we have a bound delta > 0 such that a basis for A can be computed from multiples of f1,..., fs of degrees at most delta. We propose a method using Sylvester or Macaulay type resultant matrices of f1,..., fs and J , where J is a polynomial of degree delta generalizing the Jacobian, to compute moment matrices, and in particular matrices of traces for A. These matrices of traces in turn allow us to compute a system of multiplication matrices {Mxi|i = 1,..., m} of the radical of I, following the approach in the previous work by Janovitz-Freireich, Ronyai and Szanto. Additionally, we give bounds for delta for the case when I has finitely many projective roots.", "venue": "ISSAC '08", "authors": ["Itnuit  Janovitz-Freireich", "\u00c1gnes  Sz\u00e1nt\u00f3", "Bernard  Mourrain", "Lajos  R\u00f3nyai"], "year": 2008, "n_citations": 5}
{"id": 4415551, "s2_id": "eae0570ed3ba7c151863b532ea2291373dd5b9de", "title": "Constructing minimal telescopers for rational functions in three discrete variables", "abstract": "We present a new algorithm for constructing minimal telescopers for rational functions in three discrete variables. This is the first discrete reduction-based algorithm that goes beyond the bivariate case. The termination of the algorithm is guaranteed by a known existence criterion of telescopers. Our approach has the important feature that it avoids the potentially costly computation of certificates. Computational experiments are also provided so as to illustrate the efficiency of our approach.", "venue": "ArXiv", "authors": ["Shaoshi  Chen", "Qing-Hu  Hou", "Hui  Huang", "George  Labahn", "Rong-Hua  Wang"], "year": 2019, "n_citations": 3}
{"id": 4416075, "s2_id": "bc19c30ea921658d4d46a85519403d9b014ff421", "title": "Efficient computation of the characteristic polynomial", "abstract": "We deal with the computation of the characteristic polynomial of dense matrices over word size finite fields and over the integers. We first present two algorithms for finite fields: one is based on Krylov iterates and Gaussian elimination. We compare it to an improvement of the second algorithm of Keller-Gehrig. Then we show that a generalization of Keller-Gehrig's third algorithm could improve both complexity and computational time. We use these results as a basis for the computation of the characteristic polynomial of integer matrices. We first use early termination and Chinese remaindering for dense matrices. Then a probabilistic approach, based on integer minimal polynomial and Hensel factorization, is particularly well suited to sparse and/or structured matrices.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "Cl\u00e9ment  Pernet", "Zhendong  Wan"], "year": 2005, "n_citations": 37}
{"id": 4420306, "s2_id": "f050056ddc24a23c5fbefbdd281346f802d4c8de", "title": "A Modified Abramov-Petkovsek Reduction and Creative Telescoping for Hypergeometric Terms", "abstract": "The Abramov-Petkovsek reduction computes an additive decomposition of a hypergeometric term,which extends the functionality of the Gosper algorithm for indefinite hypergeometric summation. We modify the Abramov-Petkovsek reduction so as to decompose a hypergeometric term as the sum of a summable term and a non-summable one. The outputs of the Abramov-Petkovsek reduction and our modified version share the same required properties. The modified reduction does not solve any auxiliary linear difference equation explicitly. It is also more efficient than the original reduction according to computational experiments. Based on this reduction, we design a new algorithm to compute minimal telescopers for bivariate hypergeometric terms. The new algorithm can avoid the costly computation of certificates.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Hui  Huang", "Manuel  Kauers", "Ziming  Li"], "year": 2015, "n_citations": 30}
{"id": 4421176, "s2_id": "919cdaf9d2fe30141ad3327723b88159e94a0760", "title": "Generalized companion matrix for approximate GCD", "abstract": "We study a variant of the univariate approximate GCD problem, where the coefficients of one polynomial $f (x)$are known exactly, whereas the coefficients of the second polynomial $g (x)$may be perturbed. Our approach relies on the properties of the matrix which describes the operator of multiplication by $g$in the quotient ring $\\mathbb{C}[x] / (f)$. In particular, the structure of the null space of the multiplication matrix contains all the essential information about GCD$(f, g)$. Moreover, the multiplication matrix exhibits a displacement structure that allows us to design a fast algorithm for approximate GCD computation with quadratic complexity w.r.t. polynomial degrees.", "venue": "ArXiv", "authors": ["Paola  Boito", "Olivier  Ruatta"], "year": 2011, "n_citations": 0}
{"id": 4424109, "s2_id": "5ca52ab2c964c82e349fcf6ce8caa8a014f1bdd2", "title": "Symmetric tensor decomposition", "abstract": "We present an algorithm for decomposing a symmetric tensor of dimension n and order d as a sum of of rank-1 symmetric tensors, extending the algorithm of Sylvester devised in 1886 for symmetric tensors of dimension 2. We exploit the known fact that every symmetric tensor is equivalently represented by a homogeneous polynomial in n variables of total degree d. Thus the decomposition corresponds to a sum of powers of linear forms. The impact of this contribution is two-fold. First it permits an efficient computation of the decomposition of any tensor of sub-generic rank, as opposed to widely used iterative algorithms with unproved convergence (e.g. Alternate Least Squares or gradient descents). Second, it gives tools for understanding uniqueness conditions, and for detecting the tensor rank.", "venue": "2009 17th European Signal Processing Conference", "authors": ["J\u00e9r\u00f4me  Brachat", "Pierre  Comon", "Bernard  Mourrain", "Elias P. Tsigaridas"], "year": 2009, "n_citations": 140}
{"id": 4430419, "s2_id": "9f9d5596fea8c8b0948914397e9f5abb39dec074", "title": "A canonical form for some piecewise defined functions", "abstract": "We define a canonical form for piecewise defined functions. We show that this has a wider range of application as well as better complexity properties than previous work.", "venue": "ISSAC 2007", "authors": ["Jacques  Carette"], "year": 2007, "n_citations": 3}
{"id": 4433374, "s2_id": "7ece71a51380711e59dfb6e5b8ccfeeec462ff17", "title": "SAT Solvers and Computer Algebra Systems: A Powerful Combination for Mathematics", "abstract": "Over the last few decades, many distinct lines of research aimed at automating mathematics have been developed, including computer algebra systems (CASs) for mathematical modelling, automated theorem provers for first-order logic, SAT/SMT solvers aimed at program verification, and higher-order proof assistants for checking mathematical proofs. More recently, some of these lines of research have started to converge in complementary ways. One success story is the combination of SAT solvers and CASs (SAT+CAS) aimed at resolving mathematical conjectures. \nMany conjectures in pure and applied mathematics are not amenable to traditional proof methods. Instead, they are best addressed via computational methods that involve very large combinatorial search spaces. SAT solvers are powerful methods to search through such large combinatorial spaces---consequently, many problems from a variety of mathematical domains have been reduced to SAT in an attempt to resolve them. However, solvers traditionally lack deep repositories of mathematical domain knowledge that can be crucial to pruning such large search spaces. By contrast, CASs are deep repositories of mathematical knowledge but lack efficient general search capabilities. By combining the search power of SAT with the deep mathematical knowledge in CASs we can solve many problems in mathematics that no other known methods seem capable of solving. \nWe demonstrate the success of the SAT+CAS paradigm by highlighting many conjectures that have been disproven, verified, or partially verified using our tool MathCheck. These successes indicate that the paradigm is positioned to become a standard method for solving problems requiring both a significant amount of search and deep mathematical reasoning. For example, the SAT+CAS paradigm has recently been used by Heule, Kauers, and Seidl to find many new algorithms for $3\\times3$ matrix multiplication.", "venue": "CASCON", "authors": ["Curtis  Bright", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2019, "n_citations": 5}
{"id": 4434601, "s2_id": "cc28a0219bf5c6e01b0e810bda1495d9669ef29e", "title": "Computing Small Certificates of Inconsistency of Quadratic Fewnomial Systems", "abstract": "Bezout's theorem states that dense generic systems of n multivariate quadratic equations in n variables have 2n solutions over algebraically closed fields. When only a small subset M of monomials appear in the equations (fewnomial systems), the number of solutions may decrease dramatically. We focus in this work on subsets of quadratic monomials M such that generic systems with support M do not admit any solution at all. For these systems, Hilbert's Nullstellensatz ensures the existence of algebraic certificates of inconsistency. However, up to our knowledge all known bounds on the sizes of such certificates ---including those which take into account the Newton polytopes of the polynomials--- are exponential in n. Our main results show that if the inequality 2|M|-2n \u2264 \u221a{1+8\u03bd}-1 holds for a quadratic fewnomial system -- where \u03bd is the matching number of a graph associated with M, and |M| is the cardinality of M -- then there exists generically a certificate of inconsistency of linear size (measured as the number of coefficients in the ground field K). Moreover this certificate can be computed within a polynomial number of arithmetic operations. Next, we evaluate how often this inequality holds, and we give evidence that the probability that the inequality is satisfied depends strongly on the number of squares. More precisely, we show that if M is picked uniformly at random among the subsets of n+k+1 quadratic monomials containing at least \u03a9(n1/2+\u03b5) squares, then the probability that the inequality holds tends to 1 as n grows. Interestingly, this phenomenon is related with the matching number of random graphs in the Erdos-Renyi model. Finally, we provide experimental results showing that certificates in inconsistency can be computed for systems with more than 10000 variables and equations.", "venue": "ISSAC", "authors": ["Jean-Charles  Faug\u00e8re", "Pierre-Jean  Spaenlehauer", "Jules  Svartz"], "year": 2016, "n_citations": 3}
{"id": 4434605, "s2_id": "7980a64d39a985379274dacc282989467ded742e", "title": "VESPo: Verified Evaluation of Secret Polynomials", "abstract": "We consider the problem of efficiently evaluating a secret polynomial at a given public point, when the polynomial is stored on an untrusted server. The server performs the evaluation and returns a certificate, and the client can efficiently check that the evaluation is correct using some pre-computed keys. Our protocols support two important features: the polynomial itself can be encrypted on the server, and it can be dynamically updated by changing individual coefficients cheaply without redoing the entire setup. As an important application, we show how these new techniques can be used to instantiate a Dynamic Proof of Retrievability (DPoR) for arbitrary outsourced data storage that achieves low server storage size and audit complexity. Our methods rely only on linearly homomorphic encryption and pairings, and preliminary timing results indicate reasonable performance for polynomials with millions of coefficients, and efficient DPoR with for instance 1TB size databases.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Aude  Maignan", "Cl'ement  Pernet", "Daniel S. Roche"], "year": 2021, "n_citations": 0}
{"id": 4434689, "s2_id": "55e9ab1df8d62b28916a88ca07245b72e07c69aa", "title": "A note about \"Faster algorithms for computing Hong's bound on absolute positiveness\" by K. Mehlhorn and S. Ray", "abstract": "We show that a linear-time algorithm for computing Hong's bound for positive roots of a univariate polynomial, described by K. Mehlhorn and S. Ray in an article \"Faster algorithms for computing Hong's bound on absolute positiveness\", is incorrect. We present a corrected version.", "venue": "ArXiv", "authors": ["Przemyslaw  Koprowski"], "year": 2016, "n_citations": 1}
{"id": 4437430, "s2_id": "368d3351e074d9f61d4c3a2c5551f5747326765b", "title": "Fast Encoding of AG Codes Over Cab Curves", "abstract": "We investigate algorithms for encoding of one-point algebraic geometry (AG) codes over certain plane curves called <inline-formula> <tex-math notation=\"LaTeX\">$C_{ab}$ </tex-math></inline-formula> curves, as well as algorithms for inverting the encoding map, which we call \u201cunencoding\u201d. Some <inline-formula> <tex-math notation=\"LaTeX\">$C_{ab}$ </tex-math></inline-formula> curves have many points or are even maximal, e.g. the Hermitian curve. Our encoding resp. unencoding algorithms have complexity <inline-formula> <tex-math notation=\"LaTeX\">$ \\tilde { \\mathcal {O}}(\\text {n}^{3/2})$ </tex-math></inline-formula> resp. <inline-formula> <tex-math notation=\"LaTeX\">$ \\tilde { \\mathcal {O}}({\\it\\text { qn}})$ </tex-math></inline-formula> for AG codes over any <inline-formula> <tex-math notation=\"LaTeX\">$C_{ab}$ </tex-math></inline-formula> curve satisfying very mild assumptions, where n is the code length and q the base field size, and <inline-formula> <tex-math notation=\"LaTeX\">$ \\tilde { \\mathcal {O}}$ </tex-math></inline-formula> ignores constants and logarithmic factors in the estimate. For codes over curves whose evaluation points lie on a grid-like structure, for example the Hermitian curve and norm-trace curves, we show that our algorithms have quasi-linear time complexity <inline-formula> <tex-math notation=\"LaTeX\">$ \\tilde { \\mathcal {O}}(\\text {n})$ </tex-math></inline-formula> for both operations. For infinite families of curves whose number of points is a constant factor away from the Hasse-Weil bound, our encoding and unencoding algorithms have complexities <inline-formula> <tex-math notation=\"LaTeX\">$ \\tilde { \\mathcal {O}}(\\text {n}^{5/4})$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$ \\tilde { \\mathcal {O}}(\\text {n}^{3/2})$ </tex-math></inline-formula> respectively.", "venue": "IEEE Transactions on Information Theory", "authors": ["Peter  Beelen", "Johan  Rosenkilde", "Grigory  Solomatov"], "year": 2021, "n_citations": 2}
{"id": 4441091, "s2_id": "b3bb8bb842798c9d1a4ac1a6de18fbe8d005df0b", "title": "About the generalized LM-inverse and the weighted Moore-Penrose inverse", "abstract": "The recursive method for computing the generalized LM-inverse of a constant rectangular matrix augmented by a column vector is proposed in Udwadia and Phohomsiri (2007) [16,17]. The corresponding algorithm for the sequential determination of the generalized LM-inverse is established in the present paper. We prove that the introduced algorithm for computing the generalized LM-inverse and the algorithm for the computation of the weighted Moore-Penrose inverse developed by Wang and Chen (1986) in [23] are equivalent algorithms. Both of the algorithms are implemented in the present paper using the package MATHEMATICA. Several rational test matrices and randomly generated constant matrices are tested and the CPU time is compared and discussed.", "venue": "Appl. Math. Comput.", "authors": ["Milan B. Tasic", "Predrag S. Stanimirovic", "Selver H. Pepic"], "year": 2010, "n_citations": 5}
{"id": 4446374, "s2_id": "3c8a849a238c7a4e00b952691b03045b432b2380", "title": "Ranks of Quotients, Remainders and $p$-Adic Digits of Matrices", "abstract": "For a prime $p$ and a matrix $A \\in \\mathbb{Z}^{n \\times n}$, write $A$ as $A = p (A \\,\\mathrm{quo}\\, p) + (A \\,\\mathrm{rem}\\, p)$ where the remainder and quotient operations are applied element-wise. Write the $p$-adic expansion of $A$ as $A = A^{[0]} + p A^{[1]} + p^2 A^{[2]} + \\cdots$ where each $A^{[i]} \\in \\mathbb{Z}^{n \\times n}$ has entries between $[0, p-1]$. Upper bounds are proven for the $\\mathbb{Z}$-ranks of $A \\,\\mathrm{rem}\\, p$, and $A \\,\\mathrm{quo}\\, p$. Also, upper bounds are proven for the $\\mathbb{Z}/p\\mathbb{Z}$-rank of $A^{[i]}$ for all $i \\ge 0$ when $p = 2$, and a conjecture is presented for odd primes.", "venue": "ArXiv", "authors": ["Mustafa  Elsheikh", "Andrew  Novocin", "Mark  Giesbrecht"], "year": 2014, "n_citations": 0}
{"id": 4447948, "s2_id": "90f75f22bf9788b2d00e528c9942e6e06ff818aa", "title": "A SAT-based Resolution of Lam's Problem", "abstract": "In 1989, computer searches by Lam, Thiel, and Swiercz experimentally resolved Lam's problem from projective geometry$\\unicode{x2014}$the long-standing problem of determining if a projective plane of order ten exists. Both the original search and an independent verification in 2011 discovered no such projective plane. However, these searches were each performed using highly specialized custom-written code and did not produce nonexistence certificates. In this paper, we resolve Lam's problem by translating the problem into Boolean logic and use satisfiability (SAT) solvers to produce nonexistence certificates that can be verified by a third party. Our work uncovered consistency issues in both previous searches$\\unicode{x2014}$highlighting the difficulty of relying on special-purpose search code for nonexistence results.", "venue": "AAAI", "authors": ["Curtis  Bright", "Kevin K. H. Cheung", "Brett  Stevens", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2021, "n_citations": 1}
{"id": 4452271, "s2_id": "7a8d31938049f529b40a9dac4422855ae86b46f7", "title": "Segre-Driven Radicality Testing", "abstract": "We present a probabilistic algorithm to test if a homogeneous polynomial ideal I defining a scheme X in Pn is radical using Segre classes and other geometric notions from intersection theory. Its worst case complexity depends on the geometry of X . If the scheme X has reduced isolated primary components and no embedded components supported the singular locus ofXred = V( \u221a I), then the worst case complexity is doubly exponential in n; in all the other cases the complexity is singly exponential. The realm of the ideals for which our radical testing procedure requires only single exponential time includes examples which are often considered pathological, such as the ones drawn from the famous Mayr-Meyer set of ideals which exhibit doubly exponential complexity for the ideal membership problem.", "venue": "ArXiv", "authors": ["Martin  Helmer", "Elias  Tsigaridas"], "year": 2021, "n_citations": 0}
{"id": 4456698, "s2_id": "524710cd0b0d1a50d0279da933d7d476d48a9b83", "title": "Groebner Bases for Everyone with CoCoA-5 and CoCoALib", "abstract": "We present a survey on the developments on Groebner bases showing explicit examples in CoCoA. The CoCoA project dates back to 1987: its aim was to create a mathematician-friendly laboratory for studying Commutative Algebra, most especially Groebner bases. Since then, always maintaining this \"friendly\" tradition, it has evolved and has been completely rewritten. CoCoA offers Groebner bases for all levels of interest: from the basic quick call in the interactive system CoCoA-5, to problem-specific optimized implementations, to the computer--computer communication with the open source C++ software library, CoCoALib, or the prototype OpenMath-based server. The openness and clean design of CoCoALib and CoCoA-5 are intended to offer different levels of usage, and to encourage external contributions.", "venue": "ArXiv", "authors": ["John  Abbott", "Anna Maria Bigatti"], "year": 2016, "n_citations": 5}
{"id": 4461848, "s2_id": "72541678a7b28278c9f5a2de5cd36ac48a79af4a", "title": "Subresultants in Recursive Polynomial Remainder Sequence", "abstract": "We introduce concepts of \"recursive polynomial remainder sequence (PRS)\" and \"recursive subresultant,\" and investigate their properties. In calculating PRS, if there exists the GCD (greatest common divisor) of initial polynomials, we calculate \"recursively\" with new PRS for the GCD and its derivative, until a constant is derived. We call such a PRS a recursive PRS. We define recursive subresultants to be determinants representing the coefficients in recursive PRS by coefficients of initial polynomials. Finally, we discuss usage of recursive subresultants in approximate algebraic computation, which motivates the present work.", "venue": "ArXiv", "authors": ["Akira  Terui"], "year": 2008, "n_citations": 2}
{"id": 4462324, "s2_id": "d1e224c9d19d5df0bb51840dedb6de0618e0fe94", "title": "A simple and fast algorithm for computing exponentials of power series", "abstract": "As was initially shown by Brent, exponentials of truncated power series can be computed using a constant number of polynomial multiplications. This note gives a relatively simple algorithm with a low constant factor.", "venue": "Inf. Process. Lett.", "authors": ["Alin  Bostan", "\u00c9ric  Schost"], "year": 2009, "n_citations": 8}
{"id": 4469718, "s2_id": "6083a4356a0ac681c8b6b0c4c18b129adb6302a6", "title": "Computing Sparse Multiples of Polynomials", "abstract": "We consider the problem of finding a sparse multiple of a polynomial. Given f\u2208F[x] of degree d over a field F, and a desired sparsity t, our goal is to determine if there exists a multiple h\u2208F[x] of f such that h has at most t non-zero terms, and if so, to find such an h. When F=\u211a and t is constant, we give an algorithm which requires polynomial-time in d and the size of coefficients in h. When F is a finite field, we show that the problem is at least as hard as determining the multiplicative order of elements in an extension field of F (a problem thought to have complexity similar to that of factoring integers), and this lower bound is tight when t=2.", "venue": "Algorithmica", "authors": ["Mark  Giesbrecht", "Daniel S. Roche", "Hrushikesh  Tilak"], "year": 2012, "n_citations": 4}
{"id": 4470189, "s2_id": "da9190f9e783d106d1cbf625a34c2626c1a0ff45", "title": "A closed-form formula for the Kullback-Leibler divergence between Cauchy distributions", "abstract": "We report a closed-form expression for the Kullback-Leibler divergence between Cauchy distributions which involves the calculation of a novel definite integral. The formula shows that the Kullback-Leibler divergence between Cauchy densities is always finite and symmetric.", "venue": "ArXiv", "authors": ["Fr'ed'eric  Chyzak", "Frank  Nielsen"], "year": 2019, "n_citations": 10}
{"id": 4472359, "s2_id": "1ae212cad153aff729fb20a1a3f54f835d0d2ac0", "title": "Recursion formulas for integrated products of Jacobi polynomials", "abstract": "From the literature it is known that orthogonal polynomials as the Jacobi polynomials can be expressed by hypergeometric series. In this paper, the authors derive several contiguous relations for terminating multivariate hypergeometric series. With these contiguous relations one can prove several recursion formulas of those series. This theoretical result allows to compute integrals over products of Jacobi polynomials in a very efficient recursive way. Moreover, the authors present an application to numerical analysis where it can be used in algorithms which compute the approximate solution of boundary value problem of partial differential equations by means of the finite elements method (FEM). With the aid of the contiguous relations, the approximate solution can be computed much faster than using numerical integration. A numerical example illustrates this effect.", "venue": "ArXiv", "authors": ["Sven  Beuchler", "Tim  Haubold", "Veronika  Pillwein"], "year": 2021, "n_citations": 0}
{"id": 4473079, "s2_id": "3c9694764d8b7b0f951bc2a557a288a20d1cbdbb", "title": "Sparse interpolation over finite fields via low-order roots of unity", "abstract": "We present a new Monte Carlo algorithm for the interpolation of a straight-line program as a sparse polynomial f over an arbitrary finite field of size q. We assume a priori bounds D and T are given on the degree and number of terms of f. The approach presented in this paper is a hybrid of the diversified and recursive interpolation algorithms, the two previous fastest known probabilistic methods for this problem. By making effective use of the information contained in the coefficients themselves, this new algorithm improves on the bit complexity of previous methods by a \"soft-Oh\" factor of T, log D, or log q.", "venue": "ISSAC", "authors": ["Andrew  Arnold", "Mark  Giesbrecht", "Daniel S. Roche"], "year": 2014, "n_citations": 20}
{"id": 4491958, "s2_id": "fca959bc6cfb30fcdd38fc1d987ba167654983ff", "title": "An approach to first principles electronic structure calculation by symbolic-numeric computation", "abstract": "This article is an introduction to a new approach to first principles electronic structure calculation. The starting point is the Hartree-Fock-Roothaan equation, in which molecular integrals are approximated by polynomials by way of Taylor expansion with respect to atomic coordinates and other variables. It leads to a set of polynomial equations whose solutions are eigenstate, which is designated as algebraic molecular orbital equation. Symbolic computation, especially, Grobner bases theory, enables us to rewrite the polynomial equations into more trimmed and tractable forms with identical roots, from which we can unravel the relationship between physical parameters (wave function, atomic coordinates, and others) and numerically evaluate them one by one in order. Furthermore, this method is a unified way to solve the electronic structure calculation, the optimization of physical parameters, and the inverse problem as a forward problem.", "venue": "ArXiv", "authors": ["Akihito  Kikuchi"], "year": 2013, "n_citations": 2}
{"id": 4492137, "s2_id": "9671001b5a72d5fb0a4f04ca10afdc34f4701381", "title": "An unexpected application of minimization theory to module decompositions", "abstract": "The aim of this work is to show how we can decompose a module ( if decomposable) into an indecomposable module with the help of the minimization process.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Hatem Hadj Kacem", "\u00c9ric  Laugerotte"], "year": 2004, "n_citations": 0}
{"id": 4497007, "s2_id": "46b544baa83079f1a59bdafc13e63a2583e27f57", "title": "Metatheory.jl: Fast and Elegant Algebraic Computation in Julia with Extensible Equality Saturation", "abstract": "The Julia programming language is a fresh approach to technical computing (Bezanson et al., 2017), disrupting the popular conviction that a programming language cannot be high-level, easy to learn, and performant at the same time. One of the most practical features of Julia is the excellent metaprogramming and macro system, allowing for homoiconicity: programmatic generation and manipulation of expressions as first-class values, a well-known paradigm found in LISP dialects such as Scheme.", "venue": "J. Open Source Softw.", "authors": ["Alessandro  Cheli"], "year": 2021, "n_citations": 2}
{"id": 4498526, "s2_id": "05272de903f0d6ce2bfe6651b53e9147d0d233a5", "title": "Nemo/Hecke: Computer Algebra and Number Theory Packages for the Julia Programming Language", "abstract": "We introduce two new packages, Nemo and Hecke, written in the Julia programming language for computer algebra and number theory. We demonstrate that high performance generic algorithms can be implemented in Julia, without the need to resort to a low-level C implementation. For specialised algorithms, we use Julia's efficient native C interface to wrap existing C/C++ libraries such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke and Nemo and discuss some algorithms that we have implemented to provide high performance basic arithmetic.", "venue": "ISSAC", "authors": ["Claus  Fieker", "William  Hart", "Tommy  Hofmann", "Fredrik  Johansson"], "year": 2017, "n_citations": 52}
{"id": 4499399, "s2_id": "7d4f34d5b8345e7c926dd10c22bc977749aceb64", "title": "Recursive Method for the Solution of Systems of Linear Equations", "abstract": "New solution method for the systems of linear equations in commutative integral domains is proposed. Its complexity is the same that the complexity of the matrix multiplication.", "venue": "ArXiv", "authors": ["Gennadi I. Malaschonok"], "year": 2017, "n_citations": 5}
{"id": 4501982, "s2_id": "f7867011f4e2ae936346978c92f490097654cd37", "title": "Cylindrical algebraic decomposition using local projections", "abstract": "We present an algorithm which computes a cylindrical algebraic decomposition of a semialgebraic set using projection sets computed for each cell separately. Such local projection sets can be significantly smaller than the global projection set used by the Cylindrical Algebraic Decomposition (CAD) algorithm. This leads to reduction in the number of cells the algorithm needs to construct. A restricted version of the algorithm was introduced in Strzebonski (2014). The full version presented here can be applied to quantified formulas and makes use of equational constraints. We give an empirical comparison of our algorithm and the classical CAD algorithm.", "venue": "J. Symb. Comput.", "authors": ["Adam W. Strzebonski"], "year": 2016, "n_citations": 38}
{"id": 4502178, "s2_id": "8a2620b53a14de52597039b77d280a96846b2c78", "title": "An Extensible Ad Hoc Interface between Lean and Mathematica", "abstract": "We implement a user-extensible ad hoc connection between the Lean proof assistant and the computer algebra system Mathematica. By reflecting the syntax of each system in the other and providing a flexible interface for extending translation, our connection allows for the exchange of arbitrary information between the two systems. We show how to make use of the Lean metaprogramming framework to verify certain Mathematica computations, so that the rigor of the proof assistant is not compromised.", "venue": "PxTP", "authors": ["Robert Y. Lewis"], "year": 2017, "n_citations": 7}
{"id": 4503936, "s2_id": "30472406ac79bb073ca2505f09edf80027591d89", "title": "FORM development", "abstract": "I give an overview of FORM development based on a few pilot projects, explaining how they have influenced the FORM capabilities. Next I explain what is happnening right now in the field of Open Sourcing and the FORM Forum.", "venue": "ArXiv", "authors": ["J. A. M. Vermaseren"], "year": 2011, "n_citations": 3}
{"id": 4504127, "s2_id": "4dff7c2267852013e31d9e2e424df247525d0dc7", "title": "A worst-case bound for topology computation of algebraic curves", "abstract": "Computing the topology of an algebraic plane curve C means computing a combinatorial graph that is isotopic to C and thus represents its topology in R^2. We prove that, for a polynomial of degree n with integer coefficients bounded by 2^@r, the topology of the induced curve can be computed with O@?(n^8@r(n+@r)) bit operations (O@? indicates that we omit logarithmic factors). Our analysis improves the previous best known complexity bounds by a factor of n^2. The improvement is based on new techniques to compute and refine isolating intervals for the real roots of polynomials, and on the consequent amortized analysis of the critical fibers of the algebraic curve.", "venue": "J. Symb. Comput.", "authors": ["Michael  Kerber", "Michael  Sagraloff"], "year": 2012, "n_citations": 33}
{"id": 4504587, "s2_id": "38ef4fa6da57a3aedd8810885b5422e545619a88", "title": "Can one design a geometry engine? On the (un)decidability of affine Euclidean geometries", "abstract": "We survey the status of decidabilty of the consequence relation in various axiomatizations of Euclidean geometry. We draw attention to a widely overlooked result by Martin Ziegler from 1980, which proves Tarski's conjecture on the undecidability of finitely axiomatizable theories of fields. We elaborate on how to use Ziegler's theorem to show that the consequence relations for the first order theory of the Hilbert plane and the Euclidean plane are undecidable. As new results we add: (A) The first order consequence relations for Wu's orthogonal and metric geometries (Wen-Tsun Wu, 1984), and for the axiomatization of Origami geometry (J. Justin 1986, H. Huzita 1991)are undecidable. \nIt was already known that the universal theory of Hilbert planes and Wu's orthogonal geometry is decidable. We show here using elementary model theoretic tools that (B) the universal first order consequences of any geometric theory $T$ of Pappian planes which is consistent with the analytic geometry of the reals is decidable.", "venue": "ArXiv", "authors": ["Johann A. Makowsky"], "year": 2017, "n_citations": 4}
{"id": 4504790, "s2_id": "75cc6a857327fc1bf1c1a9d56437466ecf82fba7", "title": "Special values of generalized log-sine integrals", "abstract": "We study generalized log-sine integrals at special values. At \u03c0 and multiples thereof explicit evaluations are obtained in terms of Nielsen polylogarithms at \u00b11. For general arguments we present algorithmic evaluations involving Nielsen polylogarithms at related arguments. In particular, we consider log-sine integrals at \u03c0/3 which evaluate in terms of polylogarithms at the sixth root of unity. An implementation of our results for the computer algebra systems Mathematica and SAGE is provided.", "venue": "ISSAC '11", "authors": ["Jonathan M. Borwein", "Armin  Straub"], "year": 2011, "n_citations": 28}
{"id": 4506517, "s2_id": "dc600857dca13084b2e6bde37b0c8e8dbe4748a6", "title": "Highly Scalable Multiplication for Distributed Sparse Multivariate Polynomials on Many-Core Systems", "abstract": "We present a highly scalable algorithm for multiplying sparse multivariate polynomials represented in a distributed format. This algorithm targets not only the shared memory multicore computers, but also computers clusters or specialized hardware attached to a host computer, such as graphics processing units or many-core coprocessors. The scalability on the large number of cores is ensured by the lacks of synchronizations, locks and false-sharing during the main parallel step.", "venue": "CASC", "authors": ["Micka\u00ebl  Gastineau", "Jacques  Laskar"], "year": 2013, "n_citations": 15}
{"id": 4526162, "s2_id": "4326eb7dc59b031cd427e41a2a585715b926ed5b", "title": "Computing the Rank Profile Matrix", "abstract": "The row (resp. column) rank profile of a matrix describes the stair case shape of its row (resp. column) echelon form. In an ISSAC'13 paper, we proposed a recursive Gaussian elimination that can compute simultaneously the row and column rank profiles of a matrix, as well as those of all of its leading sub-matrices, in the same time as state of the art Gaussian elimination algorithms. Here we first study the conditions making a Gaussian elimination algorithm reveal this information. We propose the definition of a new matrix invariant, the rank profile matrix, summarizing all information on the row and column rank profiles of all the leading sub-matrices. We also explore the conditions for a Gaussian elimination algorithm to compute all or part of this invariant, through the corresponding PLUQ decomposition. As a consequence, we show that the classical iterative CUP decomposition algorithm can actually be adapted to compute the rank profile matrix. Used, in a Crout variant, as a base-case to our ISSAC'13 implementation, it delivers a significant improvement in efficiency. Second, the row (resp. column) echelon form of a matrix are usually computed via different dedicated triangular decompositions. We show here that, from some PLUQ decompositions, it is possible to recover the row and column echelon forms of a matrix and of any of its leading sub-matrices thanks to an elementary post-processing algorithm.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "Cl\u00e9ment  Pernet", "Ziad  Sultan"], "year": 2015, "n_citations": 17}
{"id": 4526465, "s2_id": "f7d87297420f70e22081c164d5c7f3adf59a394d", "title": "Some Results on the Functional Decomposition of Polynomials", "abstract": "If g and h are functions over some field, we can consider their composition f = g(h). The inverse problem is decomposition: given f, determine the ex- istence of such functions g and h. In this thesis we consider functional decom- positions of univariate and multivariate polynomials, and rational functions over a field F of characteristic p. In the polynomial case, \"wild\" behaviour occurs in both the mathematical and computational theory of the problem if p divides the degree of g. We consider the wild case in some depth, and deal with those polynomials whose decompositions are in some sense the \"wildest\": the additive polynomials. We determine the maximum number of decompositions and show some polynomial time algorithms for certain classes of polynomials with wild decompositions. For the rational function case we present a definition of the problem, a normalised version of the problem to which the general problem reduces, and an exponential time solution to the normal problem.", "venue": "ArXiv", "authors": ["Mark  Giesbrecht"], "year": 2010, "n_citations": 12}
{"id": 4527487, "s2_id": "d1e7558606a6edadb513f1a46cced7f17d59811f", "title": "Detecting lacunary perfect powers and computing their roots", "abstract": "We consider solutions to the equation f=h^r for polynomials f and h and integer r>=2. Given a polynomial f in the lacunary (also called sparse or super-sparse) representation, we first show how to determine if f can be written as h^r and, if so, to find such an r. This is a Monte Carlo randomized algorithm whose cost is polynomial in the number of non-zero terms of f and in logdegf, i.e., polynomial in the size of the lacunary representation, and it works over F\"q[x] (for large characteristic) as well as Q[x]. We also give two deterministic algorithms to compute the perfect root h given f and r. The first is output-sensitive (based on the sparsity of h) and works only over Q[x]. A sparsity-sensitive Newton iteration forms the basis for the second approach to computing h, which is extremely efficient and works over both F\"q[x] (for large characteristic) and Q[x], but depends on a number-theoretic conjecture. Work of Erdos, Schinzel, Zannier, and others suggests that both of these algorithms are unconditionally polynomial-time in the lacunary size of the input polynomial f. Finally, we demonstrate the efficiency of the randomized detection algorithm and the latter perfect root computation algorithm with an implementation in the C++ library NTL.", "venue": "J. Symb. Comput.", "authors": ["Mark  Giesbrecht", "Daniel S. Roche"], "year": 2011, "n_citations": 9}
{"id": 4533557, "s2_id": "abaa78571dd9e4795c3579214acb14130bf4fe8b", "title": "Differential elimination by differential specialization of Sylvester style matrices", "abstract": "Differential resultant formulas are defined, for a system $\\mathcal{P}$ of $n$ ordinary Laurent differential polynomials in $n-1$ differential variables. These are determinants of coefficient matrices of an extended system of polynomials obtained from $\\mathcal{P}$ through derivations and multiplications by Laurent monomials. To start, through derivations, a system $ps(\\mathcal{P})$ of $L$ polynomials in $L-1$ algebraic variables is obtained, which is non sparse in the order of derivation. This enables the use of existing formulas for the computation of algebraic resultants, of the multivariate sparse algebraic polynomials in $ps(\\mathcal{P})$, to obtain polynomials in the differential elimination ideal generated by $\\mathcal{P}$. The formulas obtained are multiples of the sparse differential resultant defined by Li, Yuan and Gao, and provide order and degree bounds in terms of mixed volumes in the generic case.", "venue": "Adv. Appl. Math.", "authors": ["Sonia L. Rueda"], "year": 2016, "n_citations": 6}
{"id": 4534970, "s2_id": "0dc8f5833d77228f6d3ef139a85e93ad64e5ebfa", "title": "A field-theory motivated approach to symbolic computer algebra", "abstract": "Field theory is an area in physics with a deceptively compact notation. Although general purpose computer algebra systems, built around generic list-based data structures, can be used to represent and manipulate field-theory expressions, this often leads to cumbersome input formats, unexpected side-effects, or the need for a lot of special-purpose code. This makes a direct translation of problems from paper to computer and back needlessly time-consuming and error-prone. A prototype computer algebra system is presented which features TEX-like input, graph data structures, lists with Young-tableaux symmetries and a multiple-inheritance property system. The usefulness of this approach is illustrated with a number of explicit field-theory problems. 1. Field theory versus general-purpose computer algebra For good reasons, the area of general-purpose computer algebra programs has historically been dominated by what one could call \u201clist-based\u201d systems. These are systems which are centred on the idea that, at the lowest level, mathematical expressions are nothing else but nested lists (or equivalently: nested functions, trees, directed acyclic graphs, . . . ). There is no doubt that a lot of mathematics indeed maps elegantly to problems concerning the manipulation of nested lists, as the success of a large class of LISP-based computer algebra systems illustrates (either implemented in LISP itself or in another language with appropriate list data structures). However, there are certain problems for which a pure list-based approach may not be the most elegant, efficient or robust one. That a pure list-based approach does not necessarily lead to the fastest algorithms is of course well-known. For e.g. polynomial manipulation, there exists a multitude of other representations which are often more appropriate for the problem at hand. An area for Email address: kasper.peeters@aei.mpg.de (Kasper Peeters).", "venue": "ArXiv", "authors": ["Kasper  Peeters"], "year": 2006, "n_citations": 119}
{"id": 4541507, "s2_id": "d4b0c1a4d71709960caaf538830a8c5414e9c62a", "title": "Hexapods with a small linear span", "abstract": "The understanding of mobile hexapods, i.e., parallel manipulators with six legs, is one of the driving questions in theoretical kinematics. We aim at contributing to this understanding by employing techniques from algebraic geometry. The set of configurations of a mobile hexapod with one degree of freedom has the structure of a projective curve, which hence has a degree and an embedding dimension. Our main result is a classification of configuration curves of hexapods that satisfy some restrictions on their embedding dimension.", "venue": "ArXiv", "authors": ["Hans-Christian Graf von Bothmer", "Matteo  Gallet", "Josef  Schicho"], "year": 2020, "n_citations": 1}
{"id": 4545853, "s2_id": "1705e2f1927eb004ebb677de6b9cc03fd062fc80", "title": "A Low-Level Index for Distributed Logic Programming", "abstract": "A distributed logic programming language with support for meta-programming and stream processing offers a variety of interesting research problems, such as: How can a versatile and stable data structure for the indexing of a large number of expressions be implemented with simple low-level data structures? Can low-level programming help to reduce the number of occur checks in Robinson's unification algorithm? This article gives the answers.", "venue": "ICLP Technical Communications", "authors": ["Thomas  Prokosch"], "year": 2020, "n_citations": 0}
{"id": 4550384, "s2_id": "7b2ed4127908ee66e9d46fbb2a298350e6f2da67", "title": "The Invar tensor package", "abstract": "Abstract The Invar package is introduced, a fast manipulator of generic scalar polynomial expressions formed from the Riemann tensor of a four-dimensional metric-compatible connection. The package can maximally simplify any polynomial containing tensor products of up to seven Riemann tensors within seconds. It has been implemented both in Mathematica and Maple algebraic systems. Program summary Program title: Invar Tensor Package Catalogue identifier: ADZK_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/ADZK_v1_0.html Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 136\u2009240 No. of bytes in distributed program, including test data, etc.: 2\u2009711\u2009923 Distribution format: tar.gz Programming language: Mathematica and Maple Computer: Any computer running Mathematica versions 5.0 to 5.2 or Maple versions 9 and 10 Operating system: Linux, Unix, Windows XP RAM: 30 Mb Word size: 64 or 32 bits Classification: 5 External routines: The Mathematica version requires the xTensor and xPerm packages. These are freely available at http://metric.iem.csic.es/Martin-Garcia/xAct Nature of problem: Manipulation and simplification of tensor expressions. Special attention on simplifying scalar polynomial expressions formed from the Riemann tensor on a four-dimensional metric-compatible manifold. Solution method: Algorithms of computational group theory to simplify expressions with tensors that obey permutation symmetries. Tables of syzygies of the scalar invariants of the Riemann tensor. Restrictions: The present versions do not fully address the problem of reducing differential invariants or monomials of the Riemann tensor with free indices. Running time: Less than a second to fully reduce a monomial of the Riemann tensor of degree 7 in terms of independent invariants.", "venue": "Comput. Phys. Commun.", "authors": ["Jos\u00e9 M. Mart\u00edn-Garc\u00eda", "Renato  Portugal", "Leon R. U. Manssur"], "year": 2007, "n_citations": 68}
{"id": 4554815, "s2_id": "49b926d5689fb906aaa4329cd1b0e30c21a94c12", "title": "Model-based construction of Open Non-uniform Cylindrical Algebraic Decompositions", "abstract": "In this paper we introduce the notion of an Open Non-uniform Cylindrical Algebraic Decomposition (NuCAD), and present an efficient model-based algorithm for constructing an Open NuCAD from an input formula. A NuCAD is a generalization of Cylindrical Algebraic Decomposition (CAD) as defined by Collins in his seminal work from the early 1970s, and as extended in concepts like Hong's partial CAD. A NuCAD, like a CAD, is a decomposition of n-dimensional real space into cylindrical cells. But unlike a CAD, the cells in a NuCAD need not be arranged cylindrically. It is in this sense that NuCADs are not uniformly cylindrical. However, NuCADs--- like CADs --- carry a tree-like structure that relates different cells. It is a very different tree but, as with the CAD tree structure, it allows some operations to be performed efficiently, for example locating the containing cell for an arbitrary input point.", "venue": "ArXiv", "authors": ["Christopher W. Brown"], "year": 2014, "n_citations": 1}
{"id": 4559729, "s2_id": "c029ac11e30127030e95171045ac51c5aaf363a1", "title": "Polynomial modular product verification and its implications", "abstract": "Polynomial multiplication is known to have quasi-linear complexity in both the dense and the sparse cases. Yet no truly linear algorithm has been given in any case for the problem, and it is not clear whether it is even possible. This leaves room for a better algorithm for the simpler problem of verifying a polynomial product. While finding deterministic methods seems out of reach, there exist probabilistic algorithms for the problem that are optimal in number of algebraic operations. We study the generalization of the problem to the verification of a polynomial product modulo a sparse divisor. We investigate its bit complexity for both dense and sparse multiplicands. In particular, we are able to show the primacy of the verification over modular multiplication when the divisor has a constant sparsity and a second highest-degree monomial that is not too large. We use these results to obtain new bounds on the bit complexity of the standard polynomial multiplication verification. In particular, we provide optimal algorithms in the bit complexity model in the dense case by improving a result of Kaminski and develop the first quasi-optimal algorithm for verifying sparse polynomial product.", "venue": "ArXiv", "authors": ["Pascal  Giorgi", "Bruno  Grenet", "Armelle Perret du Cray"], "year": 2021, "n_citations": 0}
{"id": 4561158, "s2_id": "7b0c0daed50e406fb168bd147be6c7547450ca9e", "title": "Fast Approximate Polynomial Multipoint Evaluation and Applications", "abstract": "It is well known that, using fast algorithms for polynomial multiplication and division, evaluation of a polynomial F 2 C[x] of degree n at n complex-valued points can be done with ~ O(n) exact eld operations in C; where ~ O( ) means that we omit polylogarithmic factors. We complement this result by an analysis of approximate multipoint evaluation of F to a precision of L bits after the binary point and prove a bit complexity of ~ O(n(L + +n)) ; where 2 and 2 ; with ; 2 N 1; are bounds on the magnitude of the coecients of F and the evaluation points, respectively. In particular, in the important case where the precision demand dominates the other input parameters, the complexity is soft-linear in n and L: Our result on approximate multipoint evaluation has some interesting consequences on the bit complexity of three further approximation algorithms which all use polynomial evaluation as a key subroutine. This comprises an algorithm to approximate the real roots of a polynomial, an algorithm for polynomial interpolation, and a method for computing a Taylor shift of a polynomial. For all of the latter algorithms, we derive near optimal running times.", "venue": "ArXiv", "authors": ["Alexander  Kobel", "Michael  Sagraloff"], "year": 2013, "n_citations": 17}
{"id": 4576617, "s2_id": "268fc2b1cb4afa59f088b1aa7e47e1b4abb0d1b5", "title": "First Neural Conjecturing Datasets and Experiments", "abstract": "We describe several datasets and first experiments with creating conjectures by neural methods. The datasets are based on the Mizar Mathematical Library processed in several forms and the problems extracted from it by the MPTP system and proved by the E prover using the ENIGMA guidance. The conjecturing experiments use the Transformer architecture and in particular its GPT-2 implementation.", "venue": "CICM", "authors": ["Josef  Urban", "Jan  Jakubuv"], "year": 2020, "n_citations": 12}
{"id": 4577031, "s2_id": "d820d156a6e6a93c2ed5f3a4e1e67865aca3b297", "title": "On the computation of the topology of a non-reduced implicit space curve", "abstract": "An algorithm is presented for the computation of the topology of a non-reduced space curve defined as the intersection of two implicit algebraic surfaces.\n It computes a Piecewise Linear Structure (PLS) isotopic to the original space curve.\n The algorithm is designed to provide the exact result for all inputs. It's a symbolic-numeric algorithm based on subresultant computation. Simple algebraic criteria are given to certify the output of the algorithm.\n The algorithm uses only one projection of the non-reduced space curve augmented with adjacency information around some \"particular points\" of the space curve.\n The algorithm is implemented with the Mathemagix Computer Algebra System (CAS) using the SYNAPS library as a backend.", "venue": "ISSAC '08", "authors": ["Daouda Niang Diatta", "Bernard  Mourrain", "Olivier  Ruatta"], "year": 2008, "n_citations": 43}
{"id": 4580521, "s2_id": "ac9f142e03d6ebf600b3dc59ebfa095a9d49147a", "title": "Fast Computation of the Nth Term of an Algebraic Series over a Finite Prime Field", "abstract": "We address the question of computing one selected term of an algebraic power series. In characteristic zero, the best algorithm currently known for computing the~Nth coefficient of an algebraic series uses differential equations and has arithmetic complexity quasi-linear in \u221aN. We show that over a prime field of positive characteristic p, the complexity can be lowered to O(log N). The mathematical basis for this dramatic improvement is a classical theorem stating that a formal power series with coefficients in a finite field is algebraic if and only if the sequence of its coefficients can be generated by an automaton. We revisit and enhance two constructive proofs of this result for finite prime fields. The first proof uses Mahler equations, whose sizes appear to be prohibitively large. The second proof relies on diagonals of rational functions; we turn it into an efficient algorithm, of complexity linear in log N and quasi-linear in p.", "venue": "ISSAC", "authors": ["Alin  Bostan", "Gilles  Christol", "Philippe  Dumas"], "year": 2016, "n_citations": 5}
{"id": 4583701, "s2_id": "915d8d981842f6a0f2808ab1de63f1daeb6ce052", "title": "Analogical Proportions", "abstract": "Analogy-making is at the core of human intelligence and creativity with applications to such diverse tasks as commonsense reasoning, learning, language acquisition, and story telling. This paper contributes to the foundations of artificial general intelligence by introducing an abstract algebraic framework of analogical proportions of the form `$a$ is to $b$ what $c$ is to $d$' in the general setting of universal algebra. This enables us to compare mathematical objects possibly across different domains in a uniform way which is crucial for AI-systems. The main idea is to define solutions to analogical equations in terms of generalizations and to derive abstract terms of concrete elements from a `known' source domain which can then be instantiated in an `unknown' target domain to obtain analogous elements. We extensively compare our framework with two prominent and recently introduced frameworks of analogical proportions from the literature in the concrete domains of sets, numbers, and words, and show that our framework yields strictly more reasonable solutions in all of these cases which provides evidence for the applicability of our framework. In a broader sense, this paper is a first step towards an algebraic theory of analogical reasoning and learning systems with potential applications to fundamental AI-problems like commonsense reasoning and computational learning and creativity.", "venue": "ArXiv", "authors": ["Christian  Anti'c"], "year": 2020, "n_citations": 4}
{"id": 4584703, "s2_id": "821b205bfe8b867bf5672bf35aa4d519d3f14886", "title": "Characteristic Polynomials of p-adic Matrices", "abstract": "We analyze the precision of the characteristic polynomial XM of an nxn p-adic matrix M using differential precision methods developed previously. When M is an integral matrix whose entries are all given at the same precision O(pN), we give a criterion (checkable within \u00d5(n\u03c9) operations in Fp) for the existence of a coefficient of XM with more accuracy than O(pN). In general, we provide two algorithms for determining the optimal precision of the coefficients of XM and of M's eigenvalues. We provide evidence showing that classical algorithms do not reach this optimal precision in general.", "venue": "ISSAC", "authors": ["Xavier  Caruso", "David  Roe", "Tristan  Vaccon"], "year": 2017, "n_citations": 8}
{"id": 4584890, "s2_id": "ef05c66e7ad25364fe5fa6cedf4a3ff2f9bc11ec", "title": "SPECTRA \u2013 a Maple library for solving linear matrix inequalities in exact arithmetic", "abstract": "This document describes our freely distributed Maple library spectra, for Semidefinite Programming solved Exactly with Computational Tools of Real Algebra. It solves linear matrix inequalities with symbolic computation in exact arithmetic and it is targeted to small-size, possibly degenerate problems for which symbolic infeasibility or feasibility certificates are required.", "venue": "Optim. Methods Softw.", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2019, "n_citations": 14}
{"id": 4586787, "s2_id": "720a47f0f22ad4032f1fb12a6d7ff6cec474369e", "title": "Factoring Differential Operators in n Variables", "abstract": "In this paper, we present a new algorithm and an experimental implementation for factoring elements in the polynomial n'th Weyl algebra, the polynomial n'th shift algebra, and ZZ^n-graded polynomials in the n'th q-Weyl algebra. \nThe most unexpected result is that this noncommutative problem of factoring partial differential operators can be approached effectively by reducing it to the problem of solving systems of polynomial equations over a commutative ring. In the case where a given polynomial is ZZ^n-graded, we can reduce the problem completely to factoring an element in a commutative multivariate polynomial ring. \nThe implementation in Singular is effective on a broad range of polynomials and increases the ability of computer algebra systems to address this important problem. We compare the performance and output of our algorithm with other implementations in commodity computer algebra systems on nontrivial examples.", "venue": "ArXiv", "authors": ["Mark  Giesbrecht", "Albert  Heinle", "Viktor  Levandovskyy"], "year": 2014, "n_citations": 2}
{"id": 4598745, "s2_id": "b441b2beba7a45e7ad7587e2744d29b4eda220cd", "title": "A generic position based method for real root isolation of zero-dimensional polynomial systems", "abstract": "We improve the local generic position method for isolating the real roots of a zero-dimensional bivariate polynomial system with two polynomials and extend the method to general zero-dimensional polynomial systems. The method mainly involves resultant computation and real root isolation of univariate polynomial equations. The roots of the system have a linear univariate representation. The complexity of the method is O ? B ( N 10 ) for the bivariate case, where N = max ? ( d , ? ) , d resp., ? is an upper bound on the degree, resp., the maximal coefficient bitsize of the input polynomials. The algorithm is certified with probability 1 in the multivariate case. The implementation shows that the method is efficient, especially for bivariate polynomial systems.", "venue": "J. Symb. Comput.", "authors": ["Jin-San  Cheng", "Kai  Jin"], "year": 2015, "n_citations": 13}
{"id": 4604430, "s2_id": "94469145f0ddb3191a2e698ed2d84020fc9ffdee", "title": "A variational autoencoder for music generation controlled by tonal tension", "abstract": "Many of the music generation systems based on neural networks are fully autonomous and do not offer control over the generation process. In this research, we present a controllable music generation system in terms of tonal tension. We incorporate two tonal tension measures based on the Spiral Array Tension theory into a variational autoencoder model. This allows us to control the direction of the tonal tension throughout the generated piece, as well as the overall level of tonal tension. Given a seed musical fragment, stemming from either the user input or from directly sampling from the latent space, the model can generate variations of this original seed fragment with altered tonal tension. This altered music still resembles the seed music rhythmically, but the pitch of the notes are changed to match the desired tonal tension as conditioned by the user.", "venue": "ArXiv", "authors": ["Rui  Guo", "Ivor  Simpson", "Thor  Magnusson", "Chris  Kiefer", "Dorien  Herremans"], "year": 2020, "n_citations": 2}
{"id": 4609027, "s2_id": "8341b93dbfa43d5c14014d7ba729b6e4103c8224", "title": "High Degree Sum of Squares Proofs, Bienstock-Zuckerberg hierarchy and Chvatal-Gomory cuts", "abstract": "Chvatal-Gomory (CG) cuts and the Bienstock-Zuckerberg hierarchy capture useful linear programs that the standard bounded degree Lasserre/Sum-of-Squares SOS hierarchy fails to capture. \nIn this paper we present a novel polynomial time SOS hierarchy for 0/1 problems with a custom subspace of high degree polynomials (not the standard subspace of low-degree polynomials). We show that the new SOS hierarchy recovers the Bienstock-Zuckerberg hierarchy. Our result implies a linear program that reproduces the Bienstock-Zuckerberg hierarchy as a polynomial sized, efficiently constructive extended formulation that satisfies all constant pitch inequalities. The construction is also very simple, and it is fully defined by giving the supporting polynomials (one paragraph). Moreover, for a class of polytopes (e.g. set covering and packing problems) it optimizes, up to an arbitrarily small error, over the polytope resulting from any constant rounds of CG cuts. \nArguably, this is the first example where different basis functions can be useful in asymmetric situations to obtain a hierarchy of relaxations.", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Monaldo  Mastrolilli"], "year": 2017, "n_citations": 0}
{"id": 4611561, "s2_id": "a160174429eb4551491205d3d5cd2618934b5038", "title": "In Praise of Sequence (Co-)Algebra and its implementation in Haskell", "abstract": "What is Sequence Algebra? This is a question that any teacher or student of mathematics or computer science can engage with. Sequences are in Calculus, Combinatorics, Statistics and Computation. They are foundational, a step up from number arithmetic. Sequence operations are easy to implement from scratch (in Haskell) and afford a wide variety of testing and experimentation. When bits and pieces of sequence algebra are pulled together from the literature, there emerges a claim for status as a substantial pre-analysis topic. Here we set the stage by bringing together a variety of sequence algebra concepts for the first time in one paper. This provides a novel economical overview, intended to invite a broad mathematical audience to cast an eye over the subject. A complete, yet succinct, basic implementation of sequence operations is presented, ready to play with. The implementation also serves as a benchmark for introducing Haskell by mathematical example.", "venue": "ArXiv", "authors": ["Kieran  Clenaghan"], "year": 2018, "n_citations": 0}
{"id": 4620374, "s2_id": "72bed806bdf4cb6d4a945d03376608f5a6ab0e7c", "title": "Computations with p-adic numbers", "abstract": "This document contains the notes of a lecture I gave at the \"Journ\\'ees Nationales du Calcul Formel\" (JNCF) on January 2017. The aim of the lecture was to discuss low-level algorithmics for p-adic numbers. It is divided into two main parts: first, we present various implementations of p-adic numbers and compare them and second, we introduce a general framework for studying precision issues and apply it in several concrete situations.", "venue": "ArXiv", "authors": ["Xavier  Caruso"], "year": 2017, "n_citations": 16}
{"id": 4622038, "s2_id": "ee0da3c6eb95f262cca715dab28f9b3de2e20da0", "title": "Truth Table Invariant Cylindrical Algebraic Decomposition by Regular Chains", "abstract": "A new algorithm to compute cylindrical algebraic decompositions (CADs) is presented, building on two recent advances. Firstly, the output is truth table invariant (a TTICAD) meaning given formulae have constant truth value on each cell of the decomposition. Secondly, the computation uses regular chains theory to first build a cylindrical decomposition of complex space (CCD) incrementally by polynomial. Significant modification of the regular chains technology was used to achieve the more sophisticated invariance criteria. Experimental results on an implementation in the RegularChains Library for Maple verify that combining these advances gives an algorithm superior to its individual components and competitive with the state of the art.", "venue": "CASC", "authors": ["Russell J. Bradford", "Changbo  Chen", "James H. Davenport", "Matthew  England", "Marc Moreno Maza", "David J. Wilson"], "year": 2014, "n_citations": 36}
{"id": 4626302, "s2_id": "93487dc9b8f8aee82dc3d0c0f54e30eff36c6f99", "title": "Noetherian operators and primary decomposition", "abstract": "Noetherian operators are differential operators that encode primary components of a polynomial ideal. We develop a framework, as well as algorithms, for computing Noetherian operators with local dual spaces, both symbolically and numerically. For a primary ideal, such operators provide an alternative representation to one given by a set of generators. This description fits well with numerical algebraic geometry, taking a step toward the goal of numerical primary decomposition.", "venue": "J. Symb. Comput.", "authors": ["Justin  Chen", "Marc  H\u00e4rk\u00f6nen", "Robert  Krone", "Anton  Leykin"], "year": 2022, "n_citations": 4}
{"id": 4630278, "s2_id": "3a2177f886ca246c254cc0259ed251553f6175ff", "title": "A symbolic transformation language and its application to a multiscale method", "abstract": "The context of this work is the design of a software, called MEMSALab, dedicated to the automatic derivation of multiscale models of arrays of micro- and nanosystems. In this domain a model is a partial differential equation. Multiscale methods approximate it by another partial differential equation which can be numerically simulated in a reasonable time. The challenge consists in taking into account a wide range of geometries combining thin and periodic structures with the possibility of multiple nested scales. In this paper we present a transformation language that will make the development of MEMSALab more feasible. It is proposed as a Maple package for rule-based programming, rewriting strategies and their combination with standard Maple code. We illustrate the practical interest of this language by using it to encode two examples of multiscale derivations, namely the two-scale limit of the derivative operator and the two-scale model of the stationary heat equation.", "venue": "J. Symb. Comput.", "authors": ["Walid  Belkhir", "Alain  Giorgetti", "Michel  Lenczner"], "year": 2014, "n_citations": 18}
{"id": 4634171, "s2_id": "6b2886881ddec32793c5f81fad803b689cf5562d", "title": "Modular techniques for effective localization and double ideal quotient", "abstract": "By double ideal quotient, we mean (I : (I : J)) where I and J are ideals. In our previous work [12], double ideal quotient and its variants are shown to be very useful for checking prime divisors and generating primary components. Combining those properties, we can compute \"direct localization\" effectively, comparing with full primary decomposition. In this paper, we apply modular techniques effectively to computation of such double ideal quotient and its variants, where first we compute them modulo several prime numbers and then lift them up over rational numbers by Chinese Remainder Theorem and rational reconstruction. As a new modular technique for double ideal quotient and its variants, we devise criteria for output from modular computations. Also, we apply modular techniques to intermediate primary decomposition. We examine the effectiveness of our modular techniques for several examples by preliminary computational experiments in Singular.", "venue": "ISSAC", "authors": ["Yuki  Ishihara"], "year": 2020, "n_citations": 0}
{"id": 4635922, "s2_id": "274b16e920e30ff992b54c0a1f0a1c384f5639f5", "title": "Lazy Hermite Reduction and Creative Telescoping for Algebraic Functions", "abstract": "Bronstein's lazy Hermite reduction is a symbolic integration technique that reduces algebraic functions to integrands with only simple poles without the prior computation of an integral basis. We sharpen the lazy Hermite reduction by combining it with the polynomial reduction to solve the decomposition problem of algebraic functions. The sharpened reduction is then used to design a reduction-based telescoping algorithm for algebraic functions in two variables.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Lixin  Du", "Manuel  Kauers"], "year": 2021, "n_citations": 0}
{"id": 4637127, "s2_id": "072f729d8d55e2cf1033aedea72e2a7259c775de", "title": "Generating Loop Invariants by Computing Vanishing Ideals of Sample Points", "abstract": "Loop invariants play a very important role in proving correctness of programs. In this paper, we address the problem of generating invariants of polynomial loop programs. We present a new approach, for generating polynomial equation invariants of polynomial loop programs through computing vanishing ideals of sample points. We apply rational function interpolation, based on early termination technique, to generate invariants of loop programs with symbolic initial values. Our approach avoids first-order quantifier elimination and cylindrical algebraic decomposition(CAD). An algorithm for generating polynomial invariants is proposed and some examples are given to illustrate the algorithm. Furthermore, we demonstrate on a set of loop programs with symbolic initial values that our algorithm can yield polynomial invariants with degrees high up to 15.", "venue": "ArXiv", "authors": ["Bin  Wu", "Li-Yong  Shen", "Min  Wu", "Zhengfeng  Yang", "Zhenbing  Zeng"], "year": 2011, "n_citations": 0}
{"id": 4637640, "s2_id": "9802b7ccebaad95e913aed3f904643574d73dd7d", "title": "The Newton Polytope of the Implicit Equation", "abstract": "We apply tropical geometry to study the image of a map defined by Laurent polynomials with generic coecients. If this image is a hypersurface then our approach gives a construction of its Newton polytope.", "venue": "ArXiv", "authors": ["Bernd  Sturmfels", "Jenia  Tevelev", "Josephine  Yu"], "year": 2006, "n_citations": 47}
{"id": 4643626, "s2_id": "75a377c0480249962e08d6f9554961f996f0b263", "title": "Sparse differential resultant for laurent differential polynomials", "abstract": "In this poster, we first introduce the concept of Laurent differentially essential systems and give a criterion for them in terms of their supports. Then the sparse differential resultant for a Laurent differentially essential system is defined and its basic properties are given. In particular, order and degree bounds for the sparse differential resultant, as well as a BKK-type degree bound for the differential resultant, are given. Based on these bounds, an algorithm to compute the sparse differential resultant is proposed, which is single exponential.", "venue": "ACCA", "authors": ["Wei  Li", "Chun-Ming  Yuan", "Xiao-Shan  Gao"], "year": 2013, "n_citations": 18}
{"id": 4644899, "s2_id": "e89cdf4216c2a607514cb88984b2d8c3956d9d2c", "title": "A Neuro-Symbolic Method for Solving Differential and Functional Equations", "abstract": "When neural networks are used to solve differential equations, they usually produce solutions in the form of black-box functions that are not directly mathematically interpretable. We introduce a method for generating symbolic expressions to solve differential equations while leveraging deep learning training methods. Unlike existing methods, our system does not require learning a language model over symbolic mathematics, making it scalable, compact, and easily adaptable for a variety of tasks and configurations. As part of the method, we propose a novel neural architecture for learning mathematical expressions to optimize a customizable objective. The system is designed to always return a valid symbolic formula, generating a useful approximation when an exact analytic solution to a differential equation is not or cannot be found. We demonstrate through examples how our method can be applied on a number of differential equations, often obtaining symbolic approximations that are useful or insightful. Furthermore, we show how the system can be effortlessly generalized to find symbolic solutions to other mathematical tasks, including integration and functional equations.", "venue": "ArXiv", "authors": ["Maysum  Panju", "Ali  Ghodsi"], "year": 2020, "n_citations": 1}
{"id": 4646482, "s2_id": "8fdd35a4c755ce200d4082f58bf91b6968dcd272", "title": "Tropical Effective Primary and Dual Nullstellens\"atze", "abstract": "Tropical algebra is an emerging field with a number of applications in various areas of mathematics. In many of these applications appeal to tropical polynomials allows to study properties of mathematical objects such as algebraic varieties and algebraic curves from the computational point of view. This makes it important to study both mathematical and computational aspects of tropical polynomials. \n \nIn this paper we prove tropical Nullstellensatz and moreover we show effective formulation of this theorem. Nullstellensatz is a next natural step in building algebraic theory of tropical polynomials and \neffective version is relevant for computational aspects of this field.", "venue": "STACS", "authors": ["Dima  Grigoriev", "Vladimir V. Podolskii"], "year": 2015, "n_citations": 3}
{"id": 4647223, "s2_id": "2afe7cd44815a41868122cc1e74fab577e87dbd4", "title": "Computing semi-algebraic invariants for polynomial dynamical systems", "abstract": "In this paper, we consider an extended concept of invariant for polynomial dynamical systems (PDSs) with domain and initial condition, and establish a sound and complete criterion for checking semi-algebraic invariants (SAIs) for such PDSs. The main idea is encoding relevant dynamical properties as conditions on the high order Lie derivatives of polynomials occurring in the SAI. A direct consequence of this criterion is a relatively complete method of SAI generation based on template assumption and semi-algebraic constraint solving. Relative completeness means if there is an SAI in the form of a predefined template, then our method can indeed find one.", "venue": "2011 Proceedings of the Ninth ACM International Conference on Embedded Software (EMSOFT)", "authors": ["Jiang  Liu", "Naijun  Zhan", "Hengjun  Zhao"], "year": 2011, "n_citations": 107}
{"id": 4653687, "s2_id": "a57447817c564ad6a14df700ed11b00f8d1c8a88", "title": "Complexity of model testing for dynamical systems with toric steady states", "abstract": "In this paper we investigate the complexity of model selection and model testing for dynamical systems with toric steady states. Such systems frequently arise in the study of chemical reaction networks. We do this by formulating these tasks as a constrained optimization problem in Euclidean space. This optimization problem is known as a Euclidean distance problem; the complexity of solving this problem is measured by an invariant called the Euclidean distance (ED) degree. We determine closed-form expressions for the ED degree of the steady states of several families of chemical reaction networks with toric steady states and arbitrarily many reactions. To illustrate the utility of this work we show how the ED degree can be used as a tool for estimating the computational cost of solving the model testing and model selection problems.", "venue": "Adv. Appl. Math.", "authors": ["Michael F. Adamer", "Martin  Helmer"], "year": 2019, "n_citations": 7}
{"id": 4673425, "s2_id": "f4a2d8bf38f9746ba57bbb912e6f5f4258fcf92a", "title": "Kaltofen's division-free determinant algorithm differentiated for matrix adjoint computation", "abstract": "Kaltofen has proposed a new approach in Kaltofen (1992) for computing matrix determinants without divisions. The algorithm is based on a baby steps/giant steps construction of Krylov subspaces, and computes the determinant as the constant term of the characteristic polynomial. For matrices over an abstract ring, by the results of Baur and Strassen (1983), the determinant algorithm, actually a straight-line program, leads to an algorithm with the same complexity for computing the adjoint of a matrix. However, the latter adjoint algorithm is obtained by the reverse mode of automatic differentiation, and hence is in some way not ''explicit''. We present an alternative (still closely related) algorithm for obtaining the adjoint that can be implemented directly, without resorting to an automatic transformation. The algorithm is deduced partly by applying program differentiation techniques ''by hand'' to Kaltofen's method, and is completely described. As a subproblem, we study the differentiation of the computation of minimum polynomials of linearly generated sequences, and we use a lazy polynomial evaluation mechanism for reducing the cost of Strassen's avoidance of divisions in our case.", "venue": "J. Symb. Comput.", "authors": ["Gilles  Villard"], "year": 2011, "n_citations": 2}
{"id": 4675717, "s2_id": "4c829dc2e99127e233a216bd894059670ff0e40a", "title": "On the Generation of Positivstellensatz Witnesses in Degenerate Cases", "abstract": "One can reduce the problem of proving that a polynomial is nonnegative, or more generally of proving that a system of polynomial inequalities has no solutions, to finding polynomials that are sums of squares of polynomials and satisfy some linear equality (Positivstellen-satz). This produces a witness for the desired property, from which it is reasonably easy to obtain a formal proof of the property suitable for a proof assistant such as Coq. \n \nThe problem of finding a witness reduces to a feasibility problem in semidefinite programming, for which there exist numerical solvers. Unfortunately, this problem is in general not strictly feasible, meaning the solution can be a convex set with empty interior, in which case the numerical optimization method fails. Previously published methods thus assumed strict feasibility; we propose a workaround for this difficulty. \n \nWe implemented our method and illustrate its use with examples, including extractions of proofs to Coq.", "venue": "ITP", "authors": ["David  Monniaux", "Pierre  Corbineau"], "year": 2011, "n_citations": 25}
{"id": 4676006, "s2_id": "6b8258cd8ade2bd31194cea18e8c489e2112c600", "title": "Rational Solutions of Underdetermined Polynomial Equations", "abstract": "In this paper we report on an application of computer algebra in which mathematical puzzles are generated of a type that had been widely used in mathematics contests by a large number of participants worldwide. \n \nThe algorithmic aspect of our work provides a method to compute rational solutions of single polynomial equations that are typically large with 10^2 ... 10^5 terms and that are heavily underdetermined. \n \nIt was possible to obtain this functionality by adding a number of new modules for a new type of splitting of equations to the existing package CRACK that is normally used to solve polynomial algebraic and differential systems of equations.", "venue": "ArXiv", "authors": ["Thomas  Wolf", "Chimaobi  Amadi"], "year": 2016, "n_citations": 0}
{"id": 4688749, "s2_id": "a73c379ffb47da8e84a91d480d57d4a829decaa2", "title": "Set unification", "abstract": "The unification problem in algebras capable of describing sets has been tackled, directly or indirectly, by many researchers and it finds important applications in various research areas, e.g. deductive databases, theorem proving, static analysis, rapid software prototyping. The various solutions proposed are spread across a large literature. In this paper we provide a uniform presentation of unification of sets, formalizing it at the level of set theory. We address the problem of deciding existence of solutions at an abstract level. This provides also the ability to classify different types of set unification problems. Unification algorithms are uniformly proposed to solve the unification problem in each of such classes. The algorithms presented are partly drawn from the literature \u2013 and properly revisited and analyzed \u2013 and partly novel proposals. In particular, we present a new goal-driven algorithm for general $ACI1$ unification and a new simpler algorithm for general $(Ab)(C\\ell)$ unification.", "venue": "Theory and Practice of Logic Programming", "authors": ["Agostino  Dovier", "Enrico  Pontelli", "Gianfranco  Rossi"], "year": 2006, "n_citations": 33}
{"id": 4688973, "s2_id": "55f35028c0f57eb806dd644f1135d3b807fe8476", "title": "On finding multiplicities of characteristic polynomial factors of black-box matrices", "abstract": "We present algorithms and heuristics to compute the characteristic polynomial of a matrix given its minimal polynomial. The matrix is represented as a black-box, i.e., by a function to compute its matrix-vector product. The methods apply to matrices either over the integers or over a large enough finite field. Experiments show that these methods perform efficiently in practice. Combined in an adaptive strategy, these algorithms reach significant speedups in practice for some integer matrices arising in an application from graph theory.", "venue": "ISSAC '09", "authors": ["Jean-Guillaume  Dumas", "Cl\u00e9ment  Pernet", "B. David Saunders"], "year": 2009, "n_citations": 6}
{"id": 4690223, "s2_id": "3aa778dfd7cc955a1b3983c4c01a60b1f8de618e", "title": "On the asymptotic and practical complexity of solving bivariate systems over the reals", "abstract": "This paper is concerned with exact real solving of well-constrained, bivariate polynomial systems. The main problem is to isolate all common real roots in rational rectangles, and to determine their intersection multiplicities. We present three algorithms and analyze their asymptotic bit complexity, obtaining a bound of [email\u00a0protected]?\"B(N^1^4) for the purely projection-based method, and [email\u00a0protected]?\"B(N^1^2) for two subresultant-based methods: this notation ignores polylogarithmic factors, where N bounds the degree, and the bitsize of the polynomials. The previous record bound was [email\u00a0protected]?\"B(N^1^4). Our main tool is signed subresultant sequences. We exploit recent advances on the complexity of univariate root isolation, and extend them to sign evaluation of bivariate polynomials over algebraic numbers, and real root counting for polynomials over an extension field. Our algorithms apply to the problem of simultaneous inequalities; they also compute the topology of real plane algebraic curves in [email\u00a0protected]?\"B(N^1^2), whereas the previous bound was [email\u00a0protected]?\"B(N^1^4). All algorithms have been implemented in maple, in conjunction with numeric filtering. We compare them against fgb/rs, system solvers from synaps, and maple libraries insulate and top, which compute curve topology. Our software is among the most robust, and its runtimes are comparable, or within a small constant factor, with respect to the C/C++ libraries.", "venue": "J. Symb. Comput.", "authors": ["Dimitrios I. Diochnos", "Ioannis Z. Emiris", "Elias P. Tsigaridas"], "year": 2009, "n_citations": 61}
{"id": 4693147, "s2_id": "6076eaa673bacbb33b4ee639329b39b7f0ba3389", "title": "Machine Learning for Mathematical Software", "abstract": "While there has been some discussion on how Symbolic Computation could be used for AI there is little literature on applications in the other direction. However, recent results for quantifier elimination suggest that, given enough example problems, there is scope for machine learning tools like Support Vector Machines to improve the performance of Computer Algebra Systems. We survey the authors own work and similar applications for other mathematical software. \nIt may seem that the inherently probabilistic nature of machine learning tools would invalidate the exact results prized by mathematical software. However, algorithms and implementations often come with a range of choices which have no effect on the mathematical correctness of the end result but a great effect on the resources required to find it, and thus here, machine learning can have a significant impact.", "venue": "ICMS", "authors": ["Matthew  England"], "year": 2018, "n_citations": 13}
{"id": 4701103, "s2_id": "db81d93363bcfc2e378e0066d61fe1854515e37e", "title": "Finding Liouvillian first integrals of rational ODEs of any order in finite terms", "abstract": "It is known, due to Mordukhai-Boltovski, Ritt, Prelle, Singer, Christopher and others, that if a given rational ODE has a Liouvillian first integral then the corresponding integrating factor of the ODE must be of a very special form of a product of powers and exponents of irreducible polynomials. These results lead to a partial algorithm for finding Liouvillian first integrals. However, there are two main complications on the way to ob- taining polynomials in the integrating factor form. First of all, one has to find an upper bound for the degrees of the polynomials in the product above, an unsolved problem, and then the set of coefficients for each of the polynomials by the computationally-intensive method of undetermined parameters. As a result, this approach was implemented in CAS only for first and relatively simple second order ODEs. We propose an algebraic method for finding polynomials of the integrating factors for rational ODEs of any order, based on examination of the resultants of the polynomials in the numerator and the denominator of the right-hand side of such equation. If both the numerator and the denominator of the right-hand side of such ODE are not constants, the method can determine in finite terms an explicit expression of an integrating factor if the ODE permits integrating factors of the above mentioned form and then the Liouvillian first integral. The tests of this procedure based on the proposed method, implemented in Maple in the case of rational integrating factors, confirm the consistence and efficiency of the method.", "venue": "ArXiv", "authors": ["Yuri N. Kosovtsov"], "year": 2005, "n_citations": 0}
{"id": 4710328, "s2_id": "33eeb79ffa59e5eb2cc8fd7b6180d800fe18b265", "title": "Composition collisions and projective polynomials", "abstract": "The functional decomposition of polynomials has been a topic of great interest and importance in pure and computer algebra and their applications. The structure of compositions of (suitably normalized) polynomials f = g h in Fq[x] is well understood in many cases, but quite poorly when the degrees of both components are divisible by the characteristic p. This work investigates the decomposition of polynomials whose degree is a power of p. An (equal-degree) icollision is a set of i distinct pairs (g;h) of polynomials, all with the", "venue": "ArXiv", "authors": ["Joachim von zur Gathen", "Mark  Giesbrecht", "Konstantin  Ziegler"], "year": 2010, "n_citations": 11}
{"id": 4717514, "s2_id": "39fa22a347bde9160b49381038975e1a9a35f2c8", "title": "Generic regular decompositions for generic zero-dimensional systems", "abstract": "Two new concepts, generic regular decomposition and regular-decomposition-unstable (RDU) variety for generic zero-dimensional systems, are introduced in this paper and an algorithm is proposed for computing a generic regular decomposition and the associated RDU variety of a given generic zero-dimensional system simultaneously. The solutions of the given system can be expressed by finitely many zero-dimensional regular chains if the parameter value is not on the RDU variety. The so called weakly relatively simplicial decomposition plays a crucial role in the algorithm, which is based on the theories of subresultants. Furthermore, the algorithm can be naturally adopted to compute a non-redundant Wu\u2019s decomposition and the decomposition is stable at any parameter value that is not on the RDU variety. The algorithm has been implemented with Maple 16 and experimented with a number of benchmarks from the literature. Empirical results are also presented to show the good performance of the algorithm.", "venue": "Science China Information Sciences", "authors": ["Xiaoxian  Tang", "Zhenghong  Chen", "Bican  Xia"], "year": 2013, "n_citations": 2}
{"id": 4720089, "s2_id": "171e8db8172f2dd39c677a16d920e745365cab11", "title": "Polynomial-time algorithms for quadratic isomorphism of polynomials: The regular case", "abstract": "Let f = ( f 1 , ? , f m ) and g = ( g 1 , ? , g m ) be two sets of m ? 1 nonlinear polynomials in K x 1 , ? , x n ] ( K being a field). We consider the computational problem of finding-if any-an invertible transformation on the variables mapping f to g . The corresponding equivalence problem is known as Isomorphism of Polynomials with one Secret (IP1S) and is a fundamental problem in multivariate cryptography. Amongst its applications, we can cite Graph Isomorphism (GI) which reduces to equivalence of cubic polynomials with respect to an invertible linear change of variables, according to Agrawal and Saxena. The main result is a randomized polynomial-time algorithm for solving IP1S for quadratic instances-a particular case of importance in cryptography.To this end, we show that IP1S for quadratic polynomials can be reduced to a variant of the classical module isomorphism problem in representation theory. We show that we can essentially linearize the problem by reducing quadratic-IP1S to test the orthogonal simultaneous similarity of symmetric matrices; this latter problem was shown by Chistov, Ivanyos and Karpinski (ISSAC 1997) to be equivalent to finding an invertible matrix in the linear space K n i? n of n i? n matrices over K and to compute the square root in a certain representation in a matrix algebra. While computing square roots of matrices can be done efficiently using numerical methods, it seems difficult to control the bit complexity of such methods. However, we present exact and polynomial-time algorithms for computing a representation of the square root of a matrix in K n i? n , for various fields (including finite fields), as a product of two matrices. Each coefficient of these matrices lies in an extension field of K of polynomial degree. We then consider #IP1S, the counting version of IP1S for quadratic instances. In particular, we provide a (complete) characterization of the automorphism group of homogeneous quadratic polynomials. Finally, we also consider the more general Isomorphism of Polynomials (IP) problem where we allow an invertible linear transformation on the variables and on the set of polynomials. A randomized polynomial-time algorithm for solving IP when f = ( x 1 d , ? , x n d ) is presented. From an algorithmic point of view, the problem boils down to factoring the determinant of a linear matrix (i.e. ?a matrix whose components are linear polynomials). This extends to IP a result of Kayal obtained for PolyProj.", "venue": "J. Complex.", "authors": ["J\u00e9r\u00e9my  Berthomieu", "Jean-Charles  Faug\u00e8re", "Ludovic  Perret"], "year": 2015, "n_citations": 8}
{"id": 4720127, "s2_id": "2b948c4d51db51ca523f13ac968e51bf06d366e2", "title": "PTOPO: Computing the Geometry and the Topology of Parametric Curves", "abstract": "We consider the problem of computing the topology and describing the geometry of a parametric curve in Rn. We present an algorithm, PTOPO, that constructs an abstract graph that is isotopic to the curve in the embedding space. Our method exploits the benefits of the parametric representation and does not resort to implicitization. Most importantly, we perform all computations in the parameter space and not in the implicit space. When the parametrization involves polynomials of degree at most d and maximum bitsize of coefficients \u03c4, then the worst case bit complexity of PTOPO is \u00d5B(nd + nd5\u03c4 + d4(n2 + n\u03c4) + d3(n2\u03c4+n3)+n3d2\u03c4). This bound matches the current record bound \u00d5B(d +d5\u03c4) for the problem of computing the topology of a plane algebraic curve given in implicit form. For plane and space curves, if N = max{d, \u03c4}, the complexity of PTOPO becomes \u00d5B(N), which improves the stateof-the-art result, due to Alc\u00e1zar and D\u0131\u0301az-Toca [CAGD\u201910], by a factor of N10. In the same time complexity, we obtain a graph whose straight-line embedding is isotopic to the curve. However, visualizing the curve on top of the abstract graph construction, increases the bound to \u00d5B(N). For curves of general dimension, we can also distinguish between ordinary and non-ordinary real singularities and determine their multiplicities in the same expected complexity of PTOPO by employing the algorithm of Blasco and P\u00e9rez-D\u0131\u0301az [CAGD\u201919]. We have implemented PTOPO in maple for the case of plane and space curves. Our experiments illustrate its practical nature.", "venue": "ArXiv", "authors": ["Christina  Katsamaki", "Fabrice  Rouillier", "Elias  Tsigaridas"], "year": 2021, "n_citations": 0}
{"id": 4725803, "s2_id": "6120a73e31c9ff44a8c7d24ca254afc37535be97", "title": "Computing the fixing group of a rational function", "abstract": "Let G=Aut_K (K(x)) be the Galois group of the transcendental degree one pure field extension K(x)/K. In this paper we describe polynomial time algorithms for computing the field Fix(H) fixed by a subgroup H < G and for computing the fixing group G_f of a rational function f in K(x).", "venue": "ArXiv", "authors": ["Jaime  Gutierrez", "Rosario  Rubio", "David  Sevilla"], "year": 2008, "n_citations": 0}
{"id": 4731684, "s2_id": "254b1bd644b9f2ab51a63865be36412596bd5c47", "title": "Critical Point Computations on Smooth Varieties: Degree and Complexity Bounds", "abstract": "Let V \u2282 Cn be an equidimensional algebraic set and g be an n-variate polynomial with rational coefficients. Computing the critical points of the map that evaluates g at the points of V is a cornerstone of several algorithms in real algebraic geometry and optimization. Under the assumption that the critical locus is finite and that the projective closure of V is smooth, we provide sharp upper bounds on the degree of the critical locus which depend only on deg(g) and the degrees of the generic polar varieties associated to V. Hence, in some special cases where the degrees of the generic polar varieties do not reach the worst-case bounds, this implies that the number of critical points of the evaluation map of g is less than the currently known degree bounds. We show that, given a lifting fiber of V, a slight variant of an algorithm due to Bank, Giusti, Heintz, Lecerf, Matera and Solerno computes these critical points in time which is quadratic in this bound up to logarithmic factors, linear in the complexity of evaluating the input system and polynomial in the number of variables and the maximum degree of the input polynomials.", "venue": "ISSAC", "authors": ["Mohab Safey El Din", "Pierre-Jean  Spaenlehauer"], "year": 2016, "n_citations": 8}
{"id": 4742990, "s2_id": "c183396feaf87c6baa130b87b30c6c8ee44c1fc5", "title": "D-finite Numbers", "abstract": "D-finite functions and P-recursive sequences are defined in terms of linear differential and recurrence equations with polynomial coefficients. In this paper, we introduce a class of numbers closely related to D-finite functions and P-recursive sequences. It consists of the limits of convergent P-recursive sequences. Typically, this class contains many well-known mathematical constants in addition to the algebraic numbers. Our definition of the class of D-finite numbers depends on two subrings of the field of complex numbers. We investigate how different choices of these two subrings affect the class. Moreover, we show that D-finite numbers are essentially limits of D-finite functions at the point one, and evaluating D-finite functions at non-singular algebraic points typically yields D-finite numbers. This result makes it easier to recognize certain numbers to be D-finite.", "venue": "International Journal of Number Theory", "authors": ["Hui  Huang", "Manuel  Kauers"], "year": 2018, "n_citations": 1}
{"id": 4744082, "s2_id": "0603679b9e500106c342ee8674296192971c585a", "title": "Building counterexamples to generalizations for rational functions of Ritt's decomposition theorem", "abstract": "Abstract The classical Ritt's theorems state several properties of univariate polynomial decomposition. In this paper we present new counterexamples to the First Ritt Theorem, which states the equality of length of decomposition chains of a polynomial, in the case of rational functions. Namely, we provide an explicit example of a rational function with coefficients in Q and two decompositions of different length. Another aspect is the use of some techniques that could allow for other counterexamples, namely, relating groups and decompositions and using the fact that the alternating group A 4 has two subgroup chains of different lengths; and we provide more information about the generalizations of another property of polynomial decomposition: the stability of the base field. We also present an algorithm for computing the fixing group of a rational function providing the complexity over the rational number field.", "venue": "ArXiv", "authors": ["Jaime  Gutierrez", "David  Sevilla"], "year": 2008, "n_citations": 19}
{"id": 4745658, "s2_id": "9780d56345be8e9845af4cfba6affc2c7b9eef9d", "title": "An Elimination Method for Solving Bivariate Polynomial Systems: Eliminating the Usual Drawbacks", "abstract": "We present an exact and complete algorithm to isolate the real solutions of a zero-dimensional bivariate polynomial system. The proposed algorithm constitutes an elimination method which improves upon existing approaches in a number of points. First, the amount of purely symbolic operations is significantly reduced, that is, only resultant computation and square-free factorization is still needed. Second, our algorithm neither assumes generic position of the input system nor demands for any change of the coordinate system. The latter is due to a novel inclusion predicate to certify that a certain region is isolating for a solution. Our implementation exploits graphics hardware to expedite the resultant computation. Furthermore, we integrate a number of filtering techniques to improve the overall performance. Efficiency of the proposed method is proven by a comparison of our implementation with two state-of-the-art implementations, that is, Lgp and Maple's Isolate. For a series of challenging benchmark instances, experiments show that our implementation outperforms both contestants.", "venue": "ALENEX", "authors": ["Eric  Berberich", "Pavel  Emeliyanenko", "Michael  Sagraloff"], "year": 2011, "n_citations": 36}
{"id": 4751020, "s2_id": "b7a43b2e1347ba3e6e2153a9f16ebd7c05be102f", "title": "Riemann Tensor Polynomial Canonicalization by Graph Algebra Extension", "abstract": "Tensor expression simplification is an \"ancient\" topic in computer algebra, a representative of which is the canonicalization of Riemann tensor polynomials. Practically fast algorithms exist for monoterm canonicalization, but not for multiterm canonicalization. Targeting the multiterm difficulty, in this paper we establish the extension theory of graph algebra, and propose a canonicalization algorithm for Riemann tensor polynomials based on this theory.", "venue": "ISSAC", "authors": ["Hongbo  Li", "Zhang  Li", "Yang  Li"], "year": 2017, "n_citations": 4}
{"id": 4762472, "s2_id": "d58719570e0ef8158033bd541e8b05510be18aea", "title": "A formally verified proof of the prime number theorem", "abstract": "The prime number theorem, established by Hadamard and de la Vall\u00e9e Poussin independently in 1896, asserts that the density of primes in the positive integers is asymptotic to 1/ln x. Whereas their proofs made serious use of the methods of complex analysis, elementary proofs were provided by Selberg and Erd\u00f6s in 1948. We describe a formally verified version of Selberg's proof, obtained using the Isabelle proof assistant.", "venue": "TOCL", "authors": ["Jeremy  Avigad", "Kevin  Donnelly", "David  Gray", "Paul  Raff"], "year": 2007, "n_citations": 93}
{"id": 4763039, "s2_id": "392f6ac4490dc1d483cb9d46cfac2d117a71d2ed", "title": "Group-Theoretic Partial Matrix Multiplication", "abstract": "A generalization of recent group-theoretic matrix multiplication algorithms to an analogue of the theory of partial matrix multiplication is presented. We demonstrate that the added flexibility of this approach can in some cases improve upper bounds on the exponent of matrix multiplication yielded by group-theoretic full matrix multiplication. The group theory behind our partial matrix multiplication algorithms leads to the problem of maximizing a quantity representing the \"fullness\" of a given partial matrix pattern. This problem is shown to be NP-hard, and two algorithms, one optimal and another non-optimal but polynomial-time, are given for solving it.", "venue": "ArXiv", "authors": ["Richard Strong Bowen", "Bo  Chen", "Hendrik  Orem", "Martijn van Schaardenburg"], "year": 2009, "n_citations": 2}
{"id": 4764295, "s2_id": "95a419d0368d28150e09fa2df20b4334a1b1a9e7", "title": "Non-linear Associative-Commutative Many-to-One Pattern Matching with Sequence Variables", "abstract": "Pattern matching is a powerful tool which is part of many functional programming languages as well as computer algebra systems such as Mathematica. Among the existing systems, Mathematica offers the most expressive pattern matching. Unfortunately, no open source alternative has comparable pattern matching capabilities. Notably, these features include support for associative and/or commutative function symbols and sequence variables. While those features have individually been subject of previous research, their comprehensive combination has not yet been investigated. Furthermore, in many applications, a fixed set of patterns is matched repeatedly against different subjects. This many-to-one matching can be sped up by exploiting similarities between patterns. Discrimination nets are the state-of-the-art solution for many-to-one matching. In this thesis, a generalized discrimination net which supports the full feature set is presented. All algorithms have been implemented as an open-source library for Python. In experiments on real world examples, significant speedups of many-to-one over one-to-one matching have been observed.", "venue": "ArXiv", "authors": ["Manuel  Krebber"], "year": 2017, "n_citations": 11}
{"id": 4764757, "s2_id": "8806f2771d827f3be7db4693794672189f34bc3b", "title": "A lower bound on the positive semidefinite rank of convex bodies", "abstract": "The positive semidefinite rank of a convex body $C$ is the size of its smallest positive semidefinite formulation. We show that the positive semidefinite rank of any convex body $C$ is at least $\\sqrt{\\log d}$, where $d$ is the smallest degree of a polynomial that vanishes on the boundary of the polar of $C$. This improves upon the existing bound, which relies on results from quantifier elimination. Our proof relies on the Bezout bound applied to the Karush--Kuhn--Tucker conditions of optimality. We discuss the connection with the algebraic degree of semidefinite programming and show that the bound is tight (up to constant factor) for random spectrahedra of suitable dimension.", "venue": "SIAM J. Appl. Algebra Geom.", "authors": ["Hamza  Fawzi", "Mohab Safey El Din"], "year": 2018, "n_citations": 8}
{"id": 4767855, "s2_id": "8d2a992b0c2d29169d15784bb40130721eb3431c", "title": "A non-commutative algorithm for multiplying 5 $\\times$ 5 matrices using 99 multiplications", "abstract": "We present a non-commutative algorithm for multiplying (7\u00d7 7) matrices using 250 multiplications and a non-commutative algorithm for multiplying (9\u00d7 9) matrices using 520 multiplications. These algorithms are obtained using the same divide-and-conquer technique that could be applied to any suitable matrix sizes.", "venue": "ArXiv", "authors": ["Alexandre  Sedoglavic"], "year": 2017, "n_citations": 0}
{"id": 4768535, "s2_id": "458e7f5f8f82b4413ac233bb68184885119f4221", "title": "Wilf Classes of Non-symmetric Operads", "abstract": "Two operads are said to belong to the same Wilf class if they have the same generating series. We discuss possible Wilf classifications of non-symmetric operads with monomial relations. As a corollary, this would give the same classification for the operads with a finite Groebner basis. Generally, there is no algorithm to decide whether two finitely presented operads belong to the same Wilf class. Still, we show that if an operad has a finite Groebner basis, then the monomial basis of the operad forms an unambiguous context-free language. Moreover, we discuss the deterministic grammar which defines the language. The generating series of the operad can be obtained as a result of an algorithmic elimination of variables from the algebraic system of equations defined by the Chomsky-Sch\u00fc tzenberger enumeration theorem. We then focus on the case of binary operads with a single relation. The approach is based on the results by Rowland on pattern avoidance in binary trees. We improve and refine Rowland's calculations and empirically confirm his conjecture. Here we use both the algebraic elimination and the direct calculation of formal power series from algebraic systems of equations. Finally, we discuss the connection of Wilf classes with algorithms for the calculation of the Quillen homology of operads.", "venue": "ISSAC", "authors": ["Andrey T. Cherkasov", "Dmitri  Piontkovski"], "year": 2021, "n_citations": 0}
{"id": 4768572, "s2_id": "198387525eb00f36bfc29526ea4ab18939d131d8", "title": "An Algebraic Model For Quorum Systems", "abstract": "Quorum systems are a key mathematical abstraction in distributed fault-tolerant computing for capturing trust assumptions. A quorum system is a collection of subsets of all processes, called quorums, with the property that each pair of quorums have a non-empty intersection. They can be found at the core of many reliable distributed systems, such as cloud computing platforms, distributed storage systems and blockchains. In this paper we give a new interpretation of quorum systems, starting with classical majority-based quorum systems and extending this to Byzantine quorum systems. We propose an algebraic representation of the theory underlying quorum systems making use of multivariate polynomial ideals, incorporating properties of these systems, and studying their algebraic varieties. To achieve this goal we will exploit properties of Boolean Groebner bases. The nice nature of Boolean Groebner bases allows us to avoid part of the combinatorial computations required to check consistency and availability of quorum systems. Our results provide a novel approach to test quorum systems properties from both algebraic and algorithmic perspectives.", "venue": "ArXiv", "authors": ["Alex  Pellegrini", "Luca  Zanolini"], "year": 2020, "n_citations": 0}
{"id": 4771551, "s2_id": "27bb5098e4f1b35685e02c70378d1253cbd52b6f", "title": "A localized version of the basic triangle theorem", "abstract": "In this short note, we give a localized version of the basic triangle theorem, first published in 2011 (see [4]) in order to prove the independence of hyperlogarithms over various function fields. This version provides direct access to rings of scalars and avoids the recourse to fraction fields as that of meromorphic functions for instance.", "venue": "ArXiv", "authors": ["G.  Duchamp", "Nihar  Gargava"], "year": 2019, "n_citations": 1}
{"id": 4772564, "s2_id": "f5261584e5494f714062744fb86eee9fb6461fa1", "title": "Effective problem solving using SAT solvers", "abstract": "In this article we demonstrate how to solve a variety of problems and puzzles using the built-in SAT solver of the computer algebra system Maple. Once the problems have been encoded into Boolean logic, solutions can be found (or shown to not exist) automatically, without the need to implement any search algorithm. In particular, we describe how to solve the $n$-queens problem, how to generate and solve Sudoku puzzles, how to solve logic puzzles like the Einstein riddle, how to solve the 15-puzzle, how to solve the maximum clique problem, and finding Graeco-Latin squares.", "venue": "MC", "authors": ["Curtis  Bright", "Jurgen  Gerhard", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2019, "n_citations": 4}
{"id": 4774861, "s2_id": "246fe994a366d48debd62f7731f7a2f1ebb0b7ab", "title": "Computing singular elements modulo squares", "abstract": "The group of singular elements was first introduced by Helmut Hasse and later it has been studied by numerous authors including such well known mathematicians as: Cassels, Furtwangler, Hecke, Knebusch, Takagi and of course Hasse himself; to name just a few. The aim of the present paper is to present algorithms that explicitly construct groups of singular and $S$-singular elements (modulo squares) in a global function field.", "venue": "Fundam. Informaticae", "authors": ["Przemyslaw  Koprowski"], "year": 2021, "n_citations": 3}
{"id": 4782086, "s2_id": "f45579f33a46c1e08036d2eb9fb5e21d3c545f30", "title": "Strong Consistency and Thomas Decomposition of Finite Difference Approximations to Systems of Partial Differential Equations", "abstract": "For a wide class of polynomially nonlinear systems of partial differential equations we suggest an algorithmic approach that combines differential and difference algebra to analyze s(trong)-consistency of finite difference approximations. Our approach is applicable to regular solution grids. For the grids of this type we give a new definition of s-consistency for finite difference approximations which generalizes our definition given earlier for Cartesian grids. The algorithmic verification of s-consistency presented in the paper is based on the use of both differential and difference Thomas decomposition. First, we apply the differential decomposition to the input system, resulting in a partition of its solution space. Then, to the output subsystem that contains a solution of interest we apply a difference analogue of the differential Thomas decomposition which allows to check the s-consistency. For linear and some quasi-linear differential systems one can also apply difference \\Gr bases for the s-consistency analysis. We illustrate our methods and algorithms by a number of examples, which include Navier-Stokes equations for viscous incompressible flow.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt", "Daniel  Robertz", "Yuri A. Blinkov"], "year": 2020, "n_citations": 2}
{"id": 4783773, "s2_id": "2269ccc33758b79a765baddb03afd1a3932c501d", "title": "Real root finding for determinants of linear matrices", "abstract": "Let A 0 , A 1 , ? , A n be given square matrices of size m with rational coefficients. The paper focuses on the exact computation of one point in each connected component of the real determinantal variety { x ? R n : det ? ( A 0 + x 1 A 1 + ? + x n A n ) = 0 } . Such a problem finds applications in many areas such as control theory, computational geometry, optimization, etc. Under some genericity assumptions on the coefficients of the matrices, we provide an algorithm solving this problem whose runtime is essentially polynomial in the binomial coefficient ( n + m n ) . We also report on experiments with a computer implementation of this algorithm. Its practical performance illustrates the complexity estimates. In particular, we emphasize that for subfamilies of this problem where m is fixed, the complexity is polynomial in n.", "venue": "J. Symb. Comput.", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2016, "n_citations": 14}
{"id": 4789015, "s2_id": "92da03f9d8caceccf15d482992213a6dcb94312c", "title": "LDU factorization", "abstract": "LU-factorization of matrices is one of the fundamental algorithms of linear algebra. The widespread use of supercomputers with distributed memory requires a review of traditional algorithms, which were based on the common memory of a computer. Matrix block recursive algorithms are a class of algorithms that provide coarse-grained parallelization. The block recursive LU factorization algorithm was obtained in 2010. This algorithm is called LEU-factorization. It, like the traditional LU-algorithm, is designed for matrices over number fields. However, it does not solve the problem of numerical instability. We propose a generalization of the LEU algorithm to the case of a commutative domain and its field of quotients. This LDU factorization algorithm decomposes the matrix over the commutative domain into a product of three matrices, in which the matrices L and U belong to the commutative domain, and the elements of the weighted truncated permutation matrix D are the elements inverse to the product of some pair of minors. All elements are calculated without errors, so the problem of instability does not arise.", "venue": "ArXiv", "authors": ["Gennadi  Malaschonok"], "year": 2020, "n_citations": 0}
{"id": 4789446, "s2_id": "969f6be09cd72546bf63c9f6b5fad5c2c5b91eb5", "title": "Conversion methods for improving structural analysis of differential-algebraic equation systems", "abstract": "Structural analysis (SA) of a system of differential-algebraic equations (DAEs) is used to determine its index and which equations to be differentiated and how many times. Both Pantelides\u2019s algorithm and Pryce\u2019s $$\\varSigma $$\u03a3-method are equivalent: if one of them finds correct structural information, the other does also. Nonsingularity of the Jacobian produced by SA indicates success, which occurs on many problems of interest. However, these methods can fail on simple, solvable DAEs and give incorrect structural information including the index. This article investigates $$\\varSigma $$\u03a3-method\u2019s failures and presents two conversion methods for fixing them. Under certain conditions, both methods reformulate a DAE system on which the $$\\varSigma $$\u03a3-method fails into a locally equivalent problem on which SA is more likely to succeed. Aiming at achieving global equivalence between the original DAE system and the converted one, we provide a rationale for choosing a conversion from the applicable ones.", "venue": "ArXiv", "authors": ["Guangning  Tan", "Nedialko S. Nedialkov", "John D. Pryce"], "year": 2016, "n_citations": 12}
{"id": 4793929, "s2_id": "a552d32bc991baaf108028efa1411e2a5081d4c6", "title": "Probabilistic Algorithm for Polynomial Optimization over a Real Algebraic Set", "abstract": "Let $f, f_1, \\ldots, f_{s}$ be $n$-variate polynomials with rational coefficients of maximum degree $D$ and let $V$ be the set of common complex solutions of $\\mathbf{F}=(f_1,\\ldots, f_{s})$. We give an algorithm which, up to some regularity assumptions on $\\mathbf{F}$, computes an exact representation of the global infimum $f^\\star$ of the restriction of the map $x\\to f(x)$ to ${V\\cap\\mathbb{R}^n}$, i.e., a univariate polynomial vanishing at $f^\\star$ and an isolating interval for $f^\\star$. Furthermore, it decides whether $f^\\star$ is reached, and if so, it returns $x^\\star\\in V\\cap\\mathbb{R}^n$ such that $f(x^\\star)=f^\\star$. This algorithm is probabilistic. It makes use of the notion of polar varieties. Its complexity is essentially cubic in $(s D)^n$ and linear in the complexity of evaluating the input. This fits within the best known deterministic complexity class $D^{O(n)}$. We report on some practical experiments of a first implementation that is available as a Maple package. It appears that it ca...", "venue": "SIAM J. Optim.", "authors": ["Aur\u00e9lien  Greuet", "Mohab Safey El Din"], "year": 2014, "n_citations": 38}
{"id": 4798291, "s2_id": "c069ac5a04122b6cb093cfb372e55aedfb1f20d8", "title": "Bad Primes in Computational Algebraic Geometry", "abstract": "Computations over the rational numbers often suffer from intermediate coefficient swell. One solution to this problem is to apply the given algorithm modulo a number of primes and then lift the modular results to the rationals. This method is guaranteed to work if we use a sufficiently large set of good primes. In many applications, however, there is no efficient way of excluding bad primes. In this note, we describe a technique for rational reconstruction which will nevertheless return the correct result, provided the number of good primes in the selected set of primes is large enough. We give a number of illustrating examples which are implemented using the computer algebra system Singular and the programming language Julia. We discuss applications of our technique in computational algebraic geometry.", "venue": "ICMS", "authors": ["Janko  B\u00f6hm", "Wolfram  Decker", "Claus  Fieker", "Santiago  Laplagne", "Gerhard  Pfister"], "year": 2016, "n_citations": 7}
{"id": 4802603, "s2_id": "6fc0c2e04a71afa58a0553b7d28a4154ebe2f2d5", "title": "Simplex Subdivisions and Nonnegativity Decision of Forms", "abstract": "This paper mainly studies nonnegativity decision of forms based on variable substitutions. Unlike existing research, the paper regards simplex subdivisions as new perspectives to study variable substitutions, gives some subdivisions of the simplex T_n, introduces the concept of convergence of the subdivision sequence, and presents a sufficient and necessary condition for the convergent self-similar subdivision sequence. Then the relationships between subdivisions and their corresponding substitutions are established. Moreover, it is proven that if the form F is indefinite on T_n and the sequence of the successive L-substitution sets is convergent, then the sequence of sets {SLS^(m)(F)} is negatively terminating, and an algorithm for deciding indefinite forms with a counter-example is obtained. Thus, various effective substitutions for deciding positive semi-definite forms and indefinite forms are gained, which are beyond the weighted difference substitutions characterized by \"difference\".", "venue": "ArXiv", "authors": ["Xiaorong  Hou", "Song  Xu"], "year": 2009, "n_citations": 0}
{"id": 4802668, "s2_id": "2cb957614aac49be5f9629be1daca1a34cee0acd", "title": "An Overview of Ontologies and Tool Support for COVID-19 Analytics", "abstract": "Context: The outbreak of the SARS-CoV-2 pandemic of the new COVID-19 disease (COVID-19 for short) demands empowering existing medical, economic, and social emergency backend systems with data analytics capabilities. An impediment in taking advantages of data analytics in these systems is the lack of a unified framework or reference model. Ontologies are highlighted as a promising solution to bridge this gap by providing a formal representation of COVID-19 concepts such as symptoms, infections rate, contact tracing, and drug modelling. Ontology-based solutions enable the integration of diverse data sources that leads to a better understanding of pandemic data, management of smart lockdowns by identifying pandemic hotspots, and knowledge-driven inference, reasoning, and recommendations to tackle surrounding issues.Objective: This study aims to investigate COVID-19 related challenges that can benefit from ontology-based solutions, analyse available tool support, and identify emerging challenges that impact research and development of ontologies for COVID-19. Moreover, reference architecture models are presented to facilitate the design and development of innovative solutions that rely on ontology-based solutions and relevant tool support to address a multitude of challenges related to COVID-19.Method: We followed the formal guidelines of systematic mapping studies and systematic reviews to identify a total of 56 solutions \u2013 published research on ontology models for COVID-19 \u2013 and qualitatively selected 10 of them for the review.Results: Thematic analysis of the investigated solutions pinpoints five research themes including telehealth, health monitoring, disease modelling, data intelligence, and drug modelling. Each theme is supported by tool(s) enabling automation and user-decision support. Furthermore, we present four reference architectures that can address recurring challenges towards the development of the next generation of ontology-based solutions for COVID-19 analytics.", "venue": "2021 IEEE 25th International Enterprise Distributed Object Computing Workshop (EDOCW)", "authors": ["Aakash  Ahmad", "Madhushi  Bandara", "Mahdi  Fahmideh", "Henderik A. Proper", "Giancarlo  Guizzardi", "Jeffrey  Soar"], "year": 2021, "n_citations": 0}
{"id": 4802704, "s2_id": "e15133cfd09c2a2eb98c38468a897866a904d125", "title": "NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with Error Approximations", "abstract": "Physics-informed neural networks (PINNs) are an increasingly powerful way to solve partial differential equations, generate digital twins, and create neural surrogates of physical models. In this manuscript we detail the various methodologies of PINNs and showcase the various types of problems a PINN software can solve. We then detail the inner workings of NeuralPDE.jl and show how a formulation structured around numerical quadrature gives rise to new loss functions which allow for adaptivity towards bounded error tolerances. We describe the various ways one can use the tool, detailing mathematical techniques like using extended loss functions for parameter estimation and operator discovery, to help potential users adopt these PINN-based techniques into their workflow. We showcase how NeuralPDE uses a purely symbolic formulation so that all of the underlying training code is generated from an abstract formulation, and show how to make use of GPUs and solve systems of PDEs. Afterwards we give a detailed performance analysis which showcases the trade-off between training techniques on a large set of PDEs. From these comprehensive performance benchmarks we provide guidelines for users of PINN software, such as mixing ADAM optimizers with techniques like BFGS and mixing robust quadrature techniques with faster quasi-random samplers. We end by focusing on a complex multiphysics example, the \u2217Massachusetts Institute of Technology \u2020Julia Computing \u2021University of Turin \u00a7University of Ottawa \u00b6Carnegie Mellon University \u2016Indian Institute of Technology, Roorkee \u2217\u2217Ford Motor Company", "venue": "ArXiv", "authors": ["Kirill  Zubov", "Zoe  McCarthy", "Yingbo  Ma", "Francesco  Calisto", "Valerio  Pagliarino", "Simone  Azeglio", "Luca  Bottero", "Emmanuel  Luj'an", "Valentin  Sulzer", "Ashutosh  Bharambe", "Nand  Vinchhi", "Kaushik  Balakrishnan", "Devesh  Upadhyay", "Chris  Rackauckas"], "year": 2021, "n_citations": 0}
{"id": 4803114, "s2_id": "1bd0bf574864f92bbd2cada70e158eab09b5a7f2", "title": "Semantic Reasoning with Differentiable Graph Transformations", "abstract": "This paper introduces a differentiable semantic reasoner, where rules are presented as a relevant set of graph transformations. These rules can be written manually or inferred by a set of facts and goals presented as a training set. While the internal representation uses embeddings in a latent space, each rule can be expressed as a set of predicates conforming to a subset of Description Logic. Keywords\u2013Semantic Reasoning, Semantic Graphs, Graph Transformations, Differentiable Computing.", "venue": "ArXiv", "authors": ["Alberto  Cetoli"], "year": 2021, "n_citations": 0}
{"id": 4807622, "s2_id": "1b1512a89eadf11b0a905946d2512bfdc3dd6c8f", "title": "Chordal Graphs in Triangular Decomposition in Top-Down Style", "abstract": "In this paper, we first prove that when the associated graph of a polynomial set is chordal, a particular triangular set computed by a general algorithm in top-down style for computing the triangular decomposition of this polynomial set has an associated graph as a subgraph of this chordal graph. Then for Wang's method and a subresultant-based algorithm for triangular decomposition in top-down style and for a subresultant-based algorithm for regular decomposition in top-down style, we prove that all the polynomial sets appearing in the process of triangular decomposition with any of these algorithms have associated graphs as subgraphs of this chordal graph. These theoretical results can be viewed as non-trivial polynomial generalization of existing ones for sparse Gaussian elimination, inspired by which we further propose an algorithm for sparse triangular decomposition in top-down style by making use of the chordal structure of the polynomial set. The effectiveness of the proposed algorithm for triangular decomposition, when the polynomial set is chordal and sparse with respect to the variables, is demonstrated by preliminary experimental results.", "venue": "J. Symb. Comput.", "authors": ["Chenqi  Mou", "Yang  Bai", "Jiahua  Lai"], "year": 2021, "n_citations": 8}
{"id": 4807850, "s2_id": "7565a2d1843f5625f7a35d4991b7e504b1d69e39", "title": "Automatic Differentiation for Adjoint Stencil Loops", "abstract": "Stencil loops are a common motif in computations including convolutional neural networks, structured-mesh solvers for partial differential equations, and image processing. Stencil loops are easy to parallelise, and their fast execution is aided by compilers, libraries, and domain-specific languages. Reverse-mode automatic differentiation, also known as algorithmic differentiation, autodiff, adjoint differentiation, or back-propagation, is sometimes used to obtain gradients of programs that contain stencil loops. Unfortunately, conventional automatic differentiation results in a memory access pattern that is not stencil-like and not easily parallelisable. In this paper we present a novel combination of automatic differentiation and loop transformations that preserves the structure and memory access pattern of stencil loops, while computing fully consistent derivatives. The generated loops can be parallelised and optimised for performance in the same way and using the same tools as the original computation. We have implemented this new technique in the Python tool PerforAD, which we release with this paper along with test cases derived from seismic imaging and computational fluid dynamics applications.", "venue": "ICPP", "authors": ["Jan  H\u00fcckelheim", "Navjot  Kukreja", "Sri Hari Krishna Narayanan", "Fabio  Luporini", "Gerard  Gorman", "Paul D. Hovland"], "year": 2019, "n_citations": 8}
{"id": 4812819, "s2_id": "8118d5f8488e3f7d4b738aa00fe7b6f266c36326", "title": "A new bound on Hrushovski\u2019s algorithm for computing the Galois group of a linear differential equation", "abstract": "Abstract The complexity of computing the Galois group of a linear differential equation is of general interest. In a recent work, Feng gave the first degree bound on Hrushovski\u2019s algorithm for computing the Galois group of a linear differential equation. This bound is the degree bound of the polynomials used in the first step of the algorithm for finding a proto-Galois group (see Definition 2.7) and is sextuply exponential in the order of the differential equation. In this paper, we use Sz\u00e1nt\u00f3\u2019s algorithm of triangular representation for algebraic sets to analyze the complexity of computing the Galois group of a linear differential equation and we give a new bound which is triple exponential in the order of the given differential equation.", "venue": "Communications in Algebra", "authors": ["Mengxiao  Sun"], "year": 2019, "n_citations": 4}
{"id": 4817985, "s2_id": "957a9e3784a8bdb9e6b8c5bcd2f8936ae0f1d379", "title": "A Simple and Efficient Tensor Calculus for Machine Learning", "abstract": "Computing derivatives of tensor expressions, also known as tensor calculus, is a fundamental task in machine learning. A key concern is the efficiency of evaluating the expressions and their derivatives that hinges on the representation of these expressions. Recently, an algorithm for computing higher order derivatives of tensor expressions like Jacobians or Hessians has been introduced that is a few orders of magnitude faster than previous state-of-the-art approaches. Unfortunately, the approach is based on Ricci notation and hence cannot be incorporated into automatic differentiation frameworks from deep learning like TensorFlow, PyTorch, autograd, or JAX that use the simpler Einstein notation. This leaves two options, to either change the underlying tensor representation in these frameworks or to develop a new, provably correct algorithm based on Einstein notation. Obviously, the first option is impractical. Hence, we pursue the second option. Here, we show that using Ricci notation is not necessary for an efficient tensor calculus and develop an equally efficient method for the simpler Einstein notation. It turns out that turning to Einstein notation enables further improvements that lead to even better efficiency. The methods that are described in this paper for computing derivatives of matrix and tensor expressions have been implemented in the online tool www.MatrixCalculus.org.", "venue": "Fundamenta Informaticae", "authors": ["Soren  Laue", "Matthias  Mitterreiter", "Joachim  Giesen"], "year": 2020, "n_citations": 1}
{"id": 4819391, "s2_id": "3c4256c6ced04b26e060ab90462929e0006178ef", "title": "Integral P-Recursive Sequences", "abstract": "In an earlier paper, the notion of integrality known from algebraic number fields and fields of algebraic functions has been extended to D-finite functions. The aim of the present paper is to extend the notion to the case of P-recursive sequences. In order to do so, we formulate a general algorithm for finding all integral elements for valued vector spaces and then show that this algorithm includes not only the algebraic and the D-finite cases but also covers the case of P-recursive sequences.", "venue": "ArXiv", "authors": ["Shaoshi  Chen", "Lixin  Du", "Manuel  Kauers", "Thibaut  Verron"], "year": 2020, "n_citations": 0}
{"id": 4822108, "s2_id": "f91e9374d586e0acc82b883bb13488be736f80c8", "title": "Faster Multiplication for Long Binary Polynomials", "abstract": "We set new speed records for multiplying long polynomials over finite fields of characteristic two. Our multiplication algorithm is based on an additive FFT (Fast Fourier Transform) by Lin, Chung, and Huang in 2014 comparing to previously best results based on multiplicative FFTs. Both methods have similar complexity for arithmetic operations on underlying finite field; however, our implementation shows that the additive FFT has less overhead. For further optimization, we employ a tower field construction because the multipliers in the additive FFT naturally fall into small subfields, which leads to speed-ups using table-lookup instructions in modern CPUs. Benchmarks show that our method saves about $40 \\%$ computing time when multiplying polynomials of $2^{28}$ and $2^{29}$ bits comparing to previous multiplicative FFT implementations.", "venue": "ArXiv", "authors": ["Ming-Shing  Chen", "Chen-Mou  Cheng", "Po-Chun  Kuo", "Wen-Ding  Li", "Bo-Yin  Yang"], "year": 2017, "n_citations": 8}
{"id": 4824246, "s2_id": "a400dd28f4185325e9faa5d15b56a81c5ce5cb2e", "title": "xTras: A field-theory inspired xAct package for mathematica", "abstract": "Abstract We present the tensor computer algebra package xTras , which provides functions and methods frequently needed when doing (classical) field theory. Amongst others, it can compute contractions, make Ansatze, and solve tensorial equations. It is built upon the tensor computer algebra system xAct , a collection of packages for Mathematica. Program summary Program title: xTras Catalogue identifier: AESH_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AESH_v1_0.html Program obtainable from: CPC Program Library, Queen\u2019s University, Belfast, N. Ireland Licensing provisions: GNU General Public License, version 3 No. of lines in distributed program, including test data, etc.: 155\u00a0879 No. of bytes in distributed program, including test data, etc.: 565\u00a0389 Distribution format: tar.gz Programming language: Mathematica. Computer: Any computer running Mathematica 6 or newer. Operating system: Linux, Unix, Windows, OS X. RAM: 100 Mb Classification: 5. External routines: xACT ( www.xact.es ) Subprograms used: Cat Id Title Reference AEBH_v1_0 xPerm CPC 179 (2008) 597 ADZK_v2_0 Invar Tensor Package 2.0 CPC 179 (2008) 586 Nature of problem: Common problems in classical field theory: making Ansatze, computing contractions, solving tensorial equations, etc. Solution method: Various (group theory, brute-force, built-in Mathematica functions, etc.) Running time: 1\u201360\u00a0s", "venue": "Comput. Phys. Commun.", "authors": ["Teake  Nutma"], "year": 2014, "n_citations": 132}
{"id": 4828801, "s2_id": "028c945232c5c57a5b2ec8df54c7951cafd0ca5d", "title": "The MMO problem", "abstract": "We consider a two polynomials analogue of the polynomial interpolation problem. Namely, we consider the Mixing Modular Operations (MMO) problem of recovering two polynomials <i>f</i> \u2208 Z<sub><i>p</i></sub>[<i>x</i>] and <i>g</i> \u2208 Z<sub><i>q</i></sub>[<i>x</i>] of known degree, where <i>p</i> and <i>q</i> are two (un)known positive integers, from the values of <i>f</i>(<i>t</i>) mod <i>p</i>+<i>g</i>(<i>t</i>) mod <i>q</i> at polynomially many points <i>t</i> \u2208 Z. We show that if <i>p</i> and <i>q</i> are known, the MMO problem can be reduced to computing a close vector in a lattice with respect to the infinity norm. Using the Gaussian heuristic we also implemented in the SAGE system a polynomial-time algorithm. If <i>p</i> and <i>q</i> are kept secret, we do not know how to solve this problem. This problem is motivated by several potential cryptographic applications.", "venue": "ISSAC", "authors": ["\u00d3scar  Garc\u00eda-Morch\u00f3n", "Ronald  Rietman", "Ludo  Tolhuizen", "Domingo  G\u00f3mez-P\u00e9rez", "Jaime  Gutierrez"], "year": 2014, "n_citations": 9}
{"id": 4830933, "s2_id": "2c18adafbf8c08edc16b3a0ecad9d9bc025cf3b0", "title": "Parallel Software to Offset the Cost of Higher Precision", "abstract": "Hardware double precision is often insufficient to solve large scientific problems accurately. Computing in higher precision defined by software causes significant computational overhead. The application of parallel algorithms compensates for this overhead. Newton's method to develop power series expansions of algebraic space curves is the use case for this application.", "venue": "ArXiv", "authors": ["Jan  Verschelde"], "year": 2020, "n_citations": 2}
{"id": 4836251, "s2_id": "e6bd1df45d2a334337e1a121ce59fd94546510cb", "title": "Output-Sensitive Algorithms for Sumset and Sparse Polynomial Multiplication", "abstract": "We present randomized algorithms to compute the sumset (Minkowski sum) of two integer sets, and to multiply two univariate integer polynomials given by sparse representations. Our algorithm for sumset has cost softly linear in the combined size of the inputs and output. This is used as part of our sparse multiplication algorithm, whose cost is softly linear in the combined size of the inputs, output, and the sumset of the supports of the inputs. As a subroutine, we present a new method for computing the coefficients of a sparse polynomial, given a set containing its support. Our multiplication algorithm extends to multivariate Laurent polynomials over finite fields and rational numbers. Our techniques are based on sparse interpolation algorithms and results from analytic number theory.", "venue": "ISSAC", "authors": ["Andrew  Arnold", "Daniel S. Roche"], "year": 2015, "n_citations": 24}
{"id": 4838337, "s2_id": "6487988f8951d55e2493667e975edaf829957c8d", "title": "Ultimate Positivity of Diagonals of Quasi-rational Functions", "abstract": "The problem to decide whether a given multivariate (quasi-)rational function has only positive coefficients in its power series expansion has a long history. It dates back to Szego in 1933 who showed certain quasi-rational function to be positive, in the sense that all the series coefficients are positive, using an involved theory of special functions. In contrast to the simplicity of the statement, the method was surprisingly difficult. This dependency motivated further research for positivity of (quasi-)rational functions. More and more (quasi-)rational functions have been proven to be positive, and some of the proofs are even quite simple. However, there are also others whose positivity are still open conjectures. In this talk, we focus on a less difficult but also interesting question to decide whether the diagonal of a given quasi-rational function is ultimately positive, especially for the one conjectured to be positive by Kauers in 2007. To solve this question, it suffices to compute the asymptotics of the diagonal coefficients, which can be done by the multivariate singularity analysis developed by Baryshnikov, Pemantle and Wilson. Note that the ultimate positivity is a necessary condition for the positivity, and therefore can be used to either exclude the nonpositive cases or further support the conjectural positivity.", "venue": "ArXiv", "authors": ["Hui  Huang"], "year": 2017, "n_citations": 0}
{"id": 4838368, "s2_id": "f484d4105795820e6ba760b19fd16f9c9343d1b4", "title": "Numerical method for real root isolation of semi-algebraic system and its applications", "abstract": "In this paper, based on the homotopy continuation method and the interval Newton method, an efficient algorithm is introduced to isolate the real roots of semi-algebraic system. \nTests on some random examples and a variety of problems including transcendental functions arising in many applications show that the new algorithm reduces the cost substantially compared with the traditional symbolic approaches.", "venue": "ArXiv", "authors": ["Zhenyi  Ji", "Wenyuan  Wu", "Yi  Li", "Yong  Feng"], "year": 2013, "n_citations": 2}
{"id": 4839383, "s2_id": "95bf34c08a40d19fca9b0893dacff82c7fd6ef29", "title": "Implementing a Method for Stochastization of One-Step Processes in a Computer Algebra System", "abstract": "When modeling such phenomena as population dynamics, controllable flows, etc., a problem arises of adapting the existing models to a phenomenon under study. For this purpose, we propose to derive new models from the first principles by stochastization of one-step processes. Research can be represented as an iterative process that consists in obtaining a model and its further refinement. The number of such iterations can be extremely large. This work is aimed at software implementation (by means of computer algebra) of a method for stochastization of one-step processes. As a basis of the software implementation, we use the SymPy computer algebra system. Based on a developed algorithm, we derive stochastic differential equations and their interaction schemes. The operation of the program is demonstrated on the Verhulst and Lotka\u2013Volterra models.", "venue": "Programming and Computer Software", "authors": ["M. N. Gevorkyan", "Anastasiya V. Demidova", "Tatiana R. Velieva", "Anna V. Korolkova", "Dmitry S. Kulyabov", "Leonid A. Sevastyanov"], "year": 2018, "n_citations": 10}
{"id": 4843375, "s2_id": "470db8cadc900e4945776573836090c18714b0b1", "title": "Partial denominator bounds for partial linear difference equations", "abstract": "We investigate which polynomials can possibly occur as factors in the denominators of rational solutions of a given partial linear difference equation (PLDE). Two kinds of polynomials are to be distinguished, we call them periodic and aperiodic. The main result is a generalization of a well-known denominator bounding technique for univariate equations to PLDEs. This generalization is able to find all the aperiodic factors of the denominators for a given PLDE.", "venue": "ISSAC", "authors": ["Manuel  Kauers", "Carsten  Schneider"], "year": 2010, "n_citations": 6}
{"id": 4845208, "s2_id": "a9c854e71a7a1d58e3a2d0921ef47dc36f49ff8a", "title": "Baby-Step Giant-Step Algorithms for the Symmetric Group", "abstract": "We study discrete logarithms in the setting of group actions. Suppose that G is a group that acts on a set S. When r and s are elements of S, a solution g to rg = s can be thought of as a kind of logarithm. In this paper, we study the case where G = Sn, and develop analogs to the Shanks baby-step / giant-step procedure for ordinary discrete logarithms. Specifically, we compute two subsets A and B of Sn, such that every permutation in Sn can be written as a product ab of elements from A and B. Our deterministic procedure is close to optimal, in the sense that A and B can be computed efficiently and |A| and |B| are not too far from sqrt(n!) in size. We also analyze randomized \"collision\" algorithms for the same problem.", "venue": "ISSAC", "authors": ["Eric  Bach", "Bryce  Sandlund"], "year": 2016, "n_citations": 0}
{"id": 4848273, "s2_id": "526c517cec9a078d831f141bc0decd4bf64868fa", "title": "On Symbolic Approaches for Computing the Matrix Permanent", "abstract": "Counting the number of perfect matchings in bipartite graphs, or equivalently computing the permanent of 0-1 matrices, is an important combinatorial problem that has been extensively studied by theoreticians and practitioners alike. The permanent is #P-Complete; hence it is unlikely that a polynomial-time algorithm exists for the problem. Researchers have therefore focused on finding tractable subclasses of matrices for permanent computation. One such subclass that has received much attention is that of sparse matrices i.e. matrices with few entries set to 1, the rest being 0. For this subclass, improved theoretical upper bounds and practically efficient algorithms have been developed. In this paper, we ask whether it is possible to go beyond sparse matrices in our quest for developing scalable techniques for the permanent, and answer this question affirmatively. Our key insight is to represent permanent computation symbolically using Algebraic Decision Diagrams (ADDs). ADD-based techniques naturally use dynamic programming, and hence avoid redundant computation through memoization. This permits exploiting the hidden structure in a large class of matrices that have so far remained beyond the reach of permanent computation techniques. The availability of sophisticated libraries implementing ADDs also makes the task of engineering practical solutions relatively straightforward. While a complete characterization of matrices admitting a compact ADD representation remains open, we provide strong experimental evidence of the effectiveness of our approach for computing the permanent, not just for sparse matrices, but also for dense matrices and for matrices with \"similar\" rows.", "venue": "CP", "authors": ["Supratik  Chakraborty", "Aditya A. Shrotri", "Moshe Y. Vardi"], "year": 2019, "n_citations": 0}
{"id": 4852511, "s2_id": "1c428ccd7d1aa35217112d3dbbc1496dff3b01ba", "title": "Computing zeta functions of sparse nondegenerate hypersurfaces", "abstract": "Using the cohomology theory of Dwork, as developed by Adolphson and Sperber, we exhibit a deterministic algorithm to compute the zeta function of a nondegenerate hypersurface defined over a finite field. This algorithm is particularly well-suited to work with polynomials in small characteristic that have few monomials (relative to their dimension). Our method covers toric, affine, and projective hypersurfaces and also can be used to compute the L-function of an exponential sum. Let p be prime and let Fq be a finite field with q = p a elements. Let V be a variety defined over Fq, described by the vanishing of a finite set of polynomial equations with coefficients in Fq. We encode the number of points #V (Fqr ) on V over the extensions Fqr of Fq in an exponential generating series, called the zeta function of V : Z(V , T ) = exp ( \u221e \u2211 r=1 #V (Fqr ) T r r ) \u2208 1 + TZ[[T ]]. The zeta function Z(V , T ) is a rational function in T , a fact first proved using p-adic methods by Dwork [16, 17]. The algorithmic problem of computing Z(V , T ) efficiently is of significant foundational interest, owing to many practical and theoretical applications (see e.g. Wan [58] for a discussion). From a modern point of view, we consider Z(V , T ) cohomologically: we build a p-adic cohomology theory that functorially associates to V certain vector spaces H over a p-adic field K, each equipped with a (semi-)linear operator Frobi, such that Z(V , T ) is given by an alternating product of the characteristic polynomials of Frobi acting on the spaces H . The theory of l-adic \u00e9tale cohomology, for example, was used by Deligne to show that Z(V , T ) satisfies a Riemann hypothesis when V is smooth and projective. Parallel developments have followed in the p-adic (de Rham) framework, including the theories of Monsky-Washnitzer, crystalline, and rigid cohomology (see Kedlaya [35] for an introduction). In this paper, for a toric hypersurface V defined by a (nondegenerate) Laurent polynomial f in n variables over Fq, we employ the cohomology theory of Dwork, working with a space H (\u03a9) obtained as the quotient of a p-adic power series ring over K in n+ 1 variables by the subspace generated by the images of n+ 1 differential operators. Efforts to make these cohomology theories computationally effective have been extensive. Schoof\u2019s algorithm for counting points on an elliptic curve [54] (generalized by Edixhoven and his coauthors [22] to compute coefficients of modular forms) can be viewed in this light, using the theory of mod l \u00e9tale cohomology. A number of results on the p-adic side have also emerged in recent years. In early work, Wan [59] and Lauder and Wan [47] demonstrated 2000 Mathematics Subject Classification 11Y16 (primary), 11M38, 14D10, 14F30 (secondary). The second author was partially supported by the National Security Agency under Grant Number H9823009-1-0037. Page 2 of 37 STEVEN SPERBER AND JOHN VOIGHT that the p-adic methods of Dwork can be used to efficiently compute zeta functions in small (fixed) characteristic. Lauder and Wan use the Dwork trace formula and calculate the trace of Frobenius acting on a p-adic Banach space, following the original method of Dwork and working on the \u201cchain level\u201d. In this paper, we instead work with the extension of Dwork\u2019s theory due to Adolphson and Sperber [3]; this point of view was also pursued computationally by Lauder and Wan in the special case of Artin-Schreier curves [48, 49]. Under the hypothesis that the Laurent polynomial f is nondegenerate (see below for the precise definition), the zeta function can be recovered from the action of Frobenius on a certain single cohomology space H(\u03a9). This method works with exponential sums and so extends naturally to the case of toric, affine, or projective hypersurfaces [4]. (It suffices to consider the case of hypersurfaces to compute the zeta function of any variety defined over a finite field using inclusion-exclusion or the Cayley trick.) The method of Dwork takes into account the terms that actually occur in the Laurent polynomial f ; these methods are especially well-suited when the monomial support of f is small, so that certain combinatorial aspects are simple. This condition that f have few monomials in its support, in which case we say (loosely) that f is fewnomial (a term coined by Kouchnirenko [42]), is a natural one to consider. For example, many explicit families of hypersurfaces of interest, including the well-studied (projective) Dwork family x 0 + \u00b7 \u00b7 \u00b7+ x n + \u03bbx0x1 \u00b7 \u00b7 \u00b7xn = 0 of Calabi-Yau hypersurfaces [18] (as well as more general monomial deformations of Fermat hypersurfaces [19]) can be written with few monomials. In cryptographic applications, the condition of fewnomialness also often arises. Finally, the running time of algorithms on fewnomial input are interesting to study from the point of view of complexity theory: see, for example, work of Bates, Bihan, and Sottile [5]. To introduce our result precisely, we now set some notation. Let V be a toric hypersurface, the closed subset of Gm defined by the vanishing of a Laurent polynomial f = \u2211 \u03bd\u2208Zn a\u03bdx \u03bd \u2208 Fq[x] = Fq[x1 , . . . , xn ]. We use multi-index notation, so x = x1 1 \u00b7 \u00b7 \u00b7x\u03bdn n . We sometimes write Z(f, T ) = Z(V , T ). Let \u2206 = \u2206(f) be the Newton polytope of f , the convex hull of its support supp(f) = {\u03bd \u2208 Z : a\u03bd 6= 0} in R. For simplicity, we assume throughout that dim(\u2206) = n. For a face \u03c4 \u2286 \u2206, let f |\u03c4 = \u2211 \u03bd\u2208\u03c4 a\u03bdx \u03bd . Then we say f is (\u2206-)nondegenerate if for all faces \u03c4 \u2286 \u2206 (including \u2206 itself), the system of equations f |\u03c4 = x1 \u2202f |\u03c4 \u2202x1 = \u00b7 \u00b7 \u00b7 = xn \u2202f |\u03c4 \u2202xn = 0 has no solution in F \u00d7n q , where Fq is an algebraic closure of Fq. The set of \u2206-nondegenerate polynomials with respect to a polytope \u2206 forms an open subset in the affine space parameterizing their coefficients (a\u03bd)\u03bd\u2208\u2206\u2229Zn : under mild hypothesis, such as when \u2206 contains a unimodular simplex, then this subset is Zariski dense. (See Batyrev and Cox [6] as a reference for this notion as well as the work of Castryck and the second author [11] for a detailed analysis of nondegenerate curves.) We distinguish here between \u2206(f) and \u2206\u221e(f) which is the convex closure of \u2206(f) \u222a {0}: for the Laurent polynomial wf in n+ 1 variables, f is \u2206-nondegenerate if and only if wf is nondegenerate with respect to \u2206\u221e(f) in the sense of Kouchnirenko [41], Adophson and Sperber [3], and others. Nondegenerate hypersurfaces are an attractive class to consider because many of their geometric properties can be deduced from the combinatorics of their Newton polytopes. Let s = #supp(f) and let U be the (n+ 1)\u00d7 s-matrix with entries in Z whose columns are the vectors (1, \u03bd) \u2208 Z for \u03bd \u2208 supp(f). Let \u03c1 be the rank of U modulo p. Let v = Vol(\u2206) = COMPUTING ZETA FUNCTIONS Page 3 of 37 n! vol(\u2206) be the normalized volume of \u2206, so that a unit hypercube [0, 1] has normalized volume n! and the unit simplex \u03c3 = {(a1, . . . , an) \u2208 R\u22650 : \u2211 i ai \u2264 1} has normalized volume 1. We say that \u2206 is confined if \u2206 is contained in an orthotope (box) with side lengths b1, . . . , bn with b1 \u00b7 \u00b7 \u00b7 bn \u2264 nv. We say that f is confined if \u2206(f) is confined. A slight extension of a theorem of Lagarias and Ziegler [43] shows that every polytope \u2206 is GLn(Z)-equivalent to a confined polytope; this existence can also be made effective. (See section 3 for more detail.) In other words, for each Laurent polynomial f there is a computable monomial change of basis of Fq[x ], giving rise to an equality of zeta functions, under which f is confined. (In the theorem below, at the expense of introducing a factor of log \u03b4, where \u03b4 = \u03b4(S) = max\u03bd\u2208S |\u03bd| where |\u03bd| = maxi |\u03bdi|, one can remove the assumption that \u2206 is confined.) For functions f, g : Z\u22650 \u2192 R\u22650, we say that f = O(g) if there exists c \u2208 R>0 and N \u2208 Z\u22650 such that for every x = (x1, . . . , xm) \u2208 Z\u2265N we have g(x) \u2264 cf(x). (The reader is warned that not all properties familiar to big-Oh notation for functions of one variable extend to the multivariable case; see Howell [29]. In fact, our analysis also holds with Howell\u2019s more restrictive definition, but we will not pursue this further here.) We further use the \u201csoft-Oh\u201d notation, where f = \u00d5(g) if f = O(g log g) for some k \u2265 1. Our main result is as follows. Theorem A. Let n \u2208 Z\u22651. Then there exists an explicit algorithm that, on input a nondegenerate Laurent polynomial f \u2208 Fq[x1 , . . . , xn ] with p \u2265 3 and an integer N \u2265 1, computes as output Z(f, T ) modulo p . If further f is confined, then this algorithm uses \u00d5 ( s + pN log q + p(6N + n)(vN log q) )", "venue": "ArXiv", "authors": ["Steven  Sperber", "John  Voight"], "year": 2011, "n_citations": 3}
{"id": 4853490, "s2_id": "2fa9f901a2c74660bc7ba5c08138003cfee1c175", "title": "An example of Clifford algebras calculations with GiNaC", "abstract": "Abstract.This is an example of C++ code of Clifford algebra calculations with the GiNaC computer algebra system. This code makes both symbolic and numeric computations. It was used to produce illustrations for paper [14, 12].Described features of GiNaC are already available at PyGiNaC [3] and due to course should propagate into other software like GNU Octave [7] and gTybalt [18] which use GiNaC library as their back-end.", "venue": "ArXiv", "authors": ["Vladimir V. Kisil"], "year": 2004, "n_citations": 6}
{"id": 4854722, "s2_id": "d301d00e9af59a9156644875c7debd48516e038f", "title": "Rational Solutions of High-Order Algebraic Ordinary Differential Equations", "abstract": "This paper considers algebraic ordinary differential equations (AODEs) and study their polynomial and rational solutions. The authors first prove a sufficient condition for the existence of a bound on the degree of the possible polynomial solutions to an AODE. An AODE satisfying this condition is called noncritical. Then the authors prove that some common classes of low-order AODEs are noncritical. For rational solutions, the authors determine a class of AODEs, which are called maximally comparable, such that the possible poles of any rational solutions are recognizable from their coefficients. This generalizes the well-known fact that any pole of rational solutions to a linear ODE is contained in the set of zeros of its leading coefficient. Finally, the authors develop an algorithm to compute all rational solutions of certain maximally comparable AODEs, which is applicable to 78.54% of the AODEs in Kamke\u2019s collection of standard differential equations.", "venue": "J. Syst. Sci. Complex.", "authors": ["Ngoc Thieu Vo", "Yi  Zhang"], "year": 2020, "n_citations": 1}
{"id": 4855253, "s2_id": "f01f7bd05488ae3aa4297025077fbb511044ff86", "title": "Revisit Sparse Polynomial Interpolation Based on Randomized Kronecker Substitution", "abstract": "In this paper, a new reduction based interpolation algorithm for black-box multivariate polynomials over finite fields is given. The method is based on two main ingredients. A new Monte Carlo method is given to reduce black-box multivariate polynomial interpolation to black-box univariate polynomial interpolation over any ring. The reduction algorithm leads to multivariate interpolation algorithms with better or the same complexities most cases when combining with various univariate interpolation algorithms. We also propose a modified univariate Ben-or and Tiwarri algorithm over the finite field, which has better total complexity than the Lagrange interpolation algorithm. Combining our reduction method and the modified univariate Ben-or and Tiwarri algorithm, we give a Monte Carlo multivariate interpolation algorithm, which has better total complexity in most cases for sparse interpolation of black-box polynomial over finite fields.", "venue": "CASC", "authors": ["Qiao-Long  Huang", "Xiao-Shan  Gao"], "year": 2019, "n_citations": 4}
{"id": 4863497, "s2_id": "16efd94deaa2726c06619c563452ea0837f6dab2", "title": "Roots Multiplicity without Companion Matrices", "abstract": "We show a method for constructing a polynomial interpolating roots' multiplicities of another polynomial, that does not use companion matrices. This leads to a modification to Guersenzvaig--Szechtman square-free decomposition algorithm that is more efficient both in theory and in practice.", "venue": "Fundam. Informaticae", "authors": ["Przemyslaw  Koprowski"], "year": 2017, "n_citations": 1}
{"id": 4864697, "s2_id": "2c790cfd0531772ea72f6cba0082d8fc2a8f16b7", "title": "Quasi-stability versus Genericity", "abstract": "Quasi-stable ideals appear as leading ideals in the theory of Pommaret bases. We show that quasi-stable leading ideals share many of the properties of the generic initial ideal. In contrast to genericity, quasi-stability is a characteristic independent property that can be effectively verified. We also relate Pommaret bases to some invariants associated with local cohomology, exhibit the existence of linear quotients in Pommaret bases and prove some results on componentwise linear ideals.", "venue": "CASC", "authors": ["Amir  Hashemi", "Michael  Schweinfurter", "Werner M. Seiler"], "year": 2012, "n_citations": 11}
{"id": 4868185, "s2_id": "543e0c8c4512fb830722f8bc5891baf78692964b", "title": "Bounds on the coefficients of the characteristic and minimal polynomials", "abstract": "This note presents absolute bounds on the size of the coefficients of the character- istic and minimal polynomials depending on the size of the coefficients of the associated matrix. Moreover, we present algorithms to compute more precise input-dependant bounds on these co- efficients. Such bounds are e.g. useful to perform deterministic Chinese remaindering of the characteristic or minimal polynomial of an integer matrix.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas"], "year": 2006, "n_citations": 6}
{"id": 4869343, "s2_id": "0225fa6a4f909ff6c2bfdffe6276642370ea6153", "title": "Improved Computation of Involutive Bases", "abstract": "In this paper, we describe improved algorithms to compute Janet and Pommaret bases. To this end, based on the method proposed by Moller et al. [20], we present a more efficient variant of Gerdt\u2019s algorithm (than the algorithm presented in [16]) to compute minimal involutive bases. Furthermore, by using an involutive version of the Hilbert driven technique along with the new variant of Gerdt\u2019s algorithm, we modify the algorithm given in [23] to compute a linear change of coordinates for a given homogeneous ideal so that the new ideal (after performing this change) possesses a finite Pommaret basis. All the proposed algorithms have been implemented in Maple and their efficiency is discussed via a set of benchmark polynomials.", "venue": "CASC", "authors": ["Bentolhoda  Binaei", "Amir  Hashemi", "Werner M. Seiler"], "year": 2016, "n_citations": 4}
{"id": 4877519, "s2_id": "27249b0c7ce8695c86bf36d34df3525db1d1b457", "title": "Exact linear modeling using Ore algebras", "abstract": "Linear exact modeling is a problem coming from system identification: given a set of observed trajectories, the goal is to find a model (usually, a system of partial differential and/or difference equations) that explains the data as precisely as possible. The case of operators with constant coefficients is well studied and known in the systems theoretic literature, whereas operators with varying coefficients were addressed only recently. This question can be tackled either using Grobner bases for modules over Ore algebras or by following the ideas from differential algebra and computing in commutative rings. In this paper, we present algorithmic methods for computing ''most powerful unfalsified models'' (MPUM) and their counterparts with variable coefficients (V MPUM) for polynomial and polynomial-exponential signals. We also study the structural properties of the resulting models, discuss computer algebraic techniques behind the algorithms and provide several examples.", "venue": "J. Symb. Comput.", "authors": ["Viktor  Levandovskyy", "Eva  Zerz", "Kristina  Schindelar"], "year": 2011, "n_citations": 3}
{"id": 4884023, "s2_id": "61554a5962906f289516dd304cb7159087d0ba28", "title": "A \"Hybrid\" Approach for Synthesizing Optimal Controllers of Hybrid Systems: A Case Study of the Oil Pump Industrial Example", "abstract": "We propose an approach to reduce the optimal controller synthesis problem of hybrid systems to quantifier elimination; furthermore, we also show how to combine quantifier elimination with numerical computation in order to make it more scalable but at the same time, keep arising errors due to discretization manageable and within bounds. A major advantage of our approach is not only that it avoids errors due to numerical computation, but it also gives a better optimal controller. In order to illustrate our approach, we use the real industrial example of an oil pump provided by the German company HYDAC within the European project Quasimodo as a case study throughout this paper, and show that our method improves (up to 7.5%) the results reported in [4] based on game theory and model checking.", "venue": "FM", "authors": ["Hengjun  Zhao", "Naijun  Zhan", "Deepak  Kapur", "Kim G.  Larsen"], "year": 2012, "n_citations": 18}
{"id": 4887011, "s2_id": "982a74bcf4eb404a5b08e7749e68e710838aec8b", "title": "Computing discrete logarithms in subfields of residue class rings", "abstract": "Recent breakthrough methods \\cite{gggz,joux,bgjt} on computing discrete logarithms in small characteristic finite fields share an interesting feature in common with the earlier medium prime function field sieve method \\cite{jl}. To solve discrete logarithms in a finite extension of a finite field $\\F$, a polynomial $h(x) \\in \\F[x]$ of a special form is constructed with an irreducible factor $g(x) \\in \\F[x]$ of the desired degree. The special form of $h(x)$ is then exploited in generating multiplicative relations that hold in the residue class ring $\\F[x]/h(x)\\F[x]$ hence also in the target residue class field $\\F[x]/g(x)\\F[x]$. An interesting question in this context and addressed in this paper is: when and how does a set of relations on the residue class ring determine the discrete logarithms in the finite fields contained in it? We give necessary and sufficient conditions for a set of relations on the residue class ring to determine discrete logarithms in the finite fields contained in it. We also present efficient algorithms to derive discrete logarithms from the relations when the conditions are met. The derived necessary conditions allow us to clearly identify structural obstructions intrinsic to the special polynomial $h(x)$ in each of the aforementioned methods, and propose modifications to the selection of $h(x)$ so as to avoid obstructions.", "venue": "ArXiv", "authors": ["Ming-Deh  Huang", "Anand Kumar Narayanan"], "year": 2014, "n_citations": 0}
{"id": 4890769, "s2_id": "d82b27941cb4ea3e80605e70187fd506ec77f350", "title": "Preferred extensions as stable models*", "abstract": "Abstract Given an argumentation framework AF, we introduce a mapping function that constructs a disjunctive logic program P, such that the preferred extensions of AF correspond to the stable models of P, after intersecting each stable model with the relevant atoms. The given mapping function is of polynomial size w.r.t. AF. In particular, we identify that there is a direct relationship between the minimal models of a propositional formula and the preferred extensions of an argumentation framework by working on representing the defeated arguments. Then we show how to infer the preferred extensions of an argumentation framework by using UNSAT algorithms and disjunctive stable model solvers. The relevance of this result is that we define a direct relationship between one of the most satisfactory argumentation semantics and one of the most successful approach of nonmonotonic reasoning i.e., logic programming with the stable model semantics.", "venue": "Theory and Practice of Logic Programming", "authors": ["Juan Carlos Nieves", "Ulises  Cort\u00e9s", "Mauricio  Osorio"], "year": 2008, "n_citations": 72}
{"id": 4892416, "s2_id": "a5270baabdd936d81d06d9a3e5752e273a54eb3b", "title": "Quasi-optimal Arithmetic for Quaternion Polynomials", "abstract": "Fast algorithms for arithmetic on real or complex polynomials are well-known and have proven to be not only asymptotically efficient but also very practical. Based on Fast Fourier Transform, they for instance multiply two polynomials of degree up to n or multi-evaluate one at n points simultaneously within quasi-linear time \\(\\mathcal{O}\\)(n \u00b7 polylog n). An extension to (and in fact the mere definition of) polynomials over fields \u211d and \u2102 to the skew-field \u210d of quaternions is promising but still missing. The present work proposes three approaches which in the commutative case coincide but for \u210d turn out to differ, each one satisfying some desirable properties while lacking others. For each notion, we devise algorithms for according arithmetic; these are quasi-optimal in that their running times match lower complexity bounds up to polylogarithmic factors.", "venue": "ISAAC", "authors": ["Martin  Ziegler"], "year": 2003, "n_citations": 5}
{"id": 4892679, "s2_id": "4c0f7d23d950e6f659e07d5906ee4d13c9bd6727", "title": "Liouvillian Solutions of Difference-Differential Equations", "abstract": "For a field k$with an automorphism \\sigma and a derivation \\delta, we introduce the notion of liouvillian solutions of linear difference-differential systems {\\sigma(Y) = AY, \\delta(Y) = BY} over k and characterize the existence of liouvillian solutions in terms of the Galois group of the systems. We will give an algorithm to decide whether such a system has liouvillian solutions when k = C(x,t), \\sigma(x) = x+1, \\delta = d/dt$ and the size of the system is a prime.", "venue": "ArXiv", "authors": ["Ruyong  Feng", "Michael F. Singer", "Min  Wu"], "year": 2008, "n_citations": 2}
{"id": 4893950, "s2_id": "7d9cc06cb492fd249884f06fef88fa80ac704261", "title": "Review of Recent Techniques on Heap Specification and Verification", "abstract": "This review paper provides an overview of recent approaches and techniques in specifying and verifying dynamic memory with class objects. Dynamic memory verification may be used in order to show for instance the absence of memory leaks and to show valid-only memory accesses.", "venue": "ArXiv", "authors": ["Ren'e  Haberland"], "year": 2019, "n_citations": 0}
{"id": 4899448, "s2_id": "d6d8c5a577540c90b462e68d6d799e5d90b5507a", "title": "Sum of Squares Decompositions of Polynomials over their Gradient Ideals with Rational Coefficients", "abstract": "Assessing non-negativity of multivariate polynomials over the reals, through the computation of certificates of non-negativity, is a topical issue in polynomial optimization. This is usually tackled through the computation of sums-of-squares decompositions which rely on efficient numerical solvers for semi-definite programming. This method faces two difficulties. The first one is that the certificates obtained this way are approximate and then non-exact. The second one is due to the fact that not all non-negative polynomials are sums-of-squares. In this paper, we build on previous works by Parrilo, Nie, Demmel and Sturmfels who introduced certificates of non-negativity modulo gradient ideals. We prove that, actually, such certificates can be obtained exactly, over the rationals if the polynomial under consideration has rational coefficients and we provide exact algorithms to compute them. We analyze the bit complexity of these algorithms and deduce bit size bounds of such certificates.", "venue": "ArXiv", "authors": ["Victor  Magron", "Mohab Safey El Din", "Trung-Hieu  Vu"], "year": 2021, "n_citations": 0}
{"id": 4899579, "s2_id": "fb319291bcabb4212a2c816b01151cef075bbe84", "title": "Topology of 2D and 3D rational curves", "abstract": "In this paper we present algorithms for computing the topology of planar and space rational curves defined by a parametrization. The algorithms given here work directly with the parametrization of the curve, and do not require to compute or use the implicit equation of the curve (in the case of planar curves) or of any projection (in the case of space curves). Moreover, these algorithms have been implemented in Maple; the examples considered and the timings obtained show good performance skills.", "venue": "Comput. Aided Geom. Des.", "authors": ["Juan Gerardo Alc\u00e1zar", "Gema Mar\u00eda D\u00edaz-Toca"], "year": 2010, "n_citations": 15}
{"id": 4899910, "s2_id": "afafb2405bdfd30933e3e7f0f7ee0a8b9d45a75a", "title": "The Power of Vocabulary: The Case of Cyclotomic Polynomials", "abstract": "We observe that the vocabulary used to construct the \"answer\" to problems in computer algebra can have a dramatic effect on the computational complexity of solving that problem. We recall a formalization of this observation and explain the classic example of sparse polynomial arithmetic. For this case, we show that it is possible to extend the vocabulary so as reap the benefits of conciseness whilst avoiding the obvious pitfall of repeating the problem statement as the \"solution\". \nIt is possible to extend the vocabulary either by irreducible cyclotomics or by $x^n-1$: we look at the options and suggest that the pragmatist might opt for both.", "venue": "ArXiv", "authors": ["Jacques  Carette", "James H. Davenport"], "year": 2010, "n_citations": 0}
{"id": 4901831, "s2_id": "1ec5f40b4f936363691897d26d07aa621142096f", "title": "Generating Program Invariants via Interpolation", "abstract": "This article focuses on automatically generating polynomial equations that are inductive loop invariants of computer programs. We propose a new algorithm for this task, which is based on polynomial interpolation. Though the proposed algorithm is not complete, it is efficient and can be applied to a broader range of problems compared to existing methods targeting similar problems. The efficiency of our approach is testified by experiments on a large collection of programs. The current implementation of our method is based on dense interpolation, for which a total degree bound is needed. On the theoretical front, we study the degree and dimension of the invariant ideal of loops which have no branches and where the assignments define a P-solvable recurrence. In addition, we obtain sufficient conditions for non-trivial polynomial equation invariants to exist (resp. not to exist).", "venue": "ArXiv", "authors": ["Marc Moreno Maza", "Rong  Xiao"], "year": 2012, "n_citations": 1}
{"id": 4905432, "s2_id": "10e005202e610611826c7845433991896a07f078", "title": "Sparse difference resultant", "abstract": "In this paper, the concept of sparse difference resultant for a Laurent transformally essential system of Laurent difference polynomials is introduced and its properties are proved. In particular, order and degree bounds for the sparse difference resultant are given. Based on these bounds, an algorithm to compute the sparse difference resultant is proposed, which is single exponential in terms of the number of variables, the Jacobi number, and the size of the system. Also, the precise order, degree, a determinant representation, and a Poisson-type product formula for the difference resultant are given.", "venue": "ISSAC '13", "authors": ["Wei  Li", "Chun-Ming  Yuan", "Xiao-Shan  Gao"], "year": 2013, "n_citations": 6}
{"id": 4906655, "s2_id": "b5cd69fd2496bb20afba383dd6f8b25547281be4", "title": "The z-Transform and Automata-Recognizable Systems of Nonhomogeneous Linear Recurrence Equations over Semirings", "abstract": "A nonhomogeneous system of linear recurrence equations can be recognized by an automaton $\\mathcal{A}$ over a one-letter alphabet $A = \\{z\\}$. Conversely, the automaton $\\mathcal{A}$ generates precisely this nonhomogeneous system of linear recurrence equations. We present the solutions of these systems and apply the $z$-transform to these solutions to obtain their series representation. Finally, we show some results that simplify the series representation of the $z$-transform of these solutions. We consider single systems as well as the composition of two systems.", "venue": "CSC", "authors": ["Edoardo  Carta-Gerardino"], "year": 2009, "n_citations": 0}
{"id": 4913997, "s2_id": "3477ab0980d76174eaa8b1d9195af19b3a913571", "title": "\"On the engineers' new toolbox\" or Analog Circuit Design, using Symbolic Analysis, Computer Algebra, and Elementary Network Transformations", "abstract": "In this paper, by way of three examples - a fourth order low pass active RC filter, a rudimentary BJT amplifier, and an LC ladder - we show, how the algebraic capabilities of modern computer algebra systems can, or in the last example, might be brought to use in the task of designing analog circuits.", "venue": "ArXiv", "authors": ["Eberhard H.-A. Gerbracht"], "year": 2011, "n_citations": 3}
{"id": 4915137, "s2_id": "dd1475205c4682b8046c234509059c5bf0328468", "title": "A symbolic summation approach to Feynman integral calculus", "abstract": "Given a Feynman parameter integral, depending on a single discrete variable N and a real parameter @e, we discuss a new algorithmic framework to compute the first coefficients of its Laurent series expansion in @e. In a first step, the integrals are expressed by hypergeometric multi-sums by means of symbolic transformations. Given this sum format, we develop new summation tools to extract the first coefficients of its series expansion whenever they are expressible in terms of indefinite nested product-sum expressions. In particular, we enhance the known multi-sum algorithms to derive recurrences for sums with complicated boundary conditions, and we present new algorithms to find formal Laurent series solutions of a given recurrence relation.", "venue": "J. Symb. Comput.", "authors": ["Johannes  Bl\u00fcmlein", "Sebastian  Klein", "Carsten  Schneider", "Flavia  Stan"], "year": 2012, "n_citations": 47}
{"id": 4917077, "s2_id": "0974e493bed26bb1de815f7e3590526ed652b38f", "title": "Local shape of generalized offsets to algebraic curves", "abstract": "Offsetting is an important operation in computer aided design, with applications also in other contexts like robot path planning or tolerance analysis. In this paper we study the local behavior of an algebraic curve under a variation of the usual offsetting construction, namely the generalized offsetting process (Sendra and Sendra, 2000a). More precisely, here we discuss when and how this geometric construction may cause local changes in the shape of an algebraic curve, and we compare our results with those obtained for the case of classical offsets (Alcazar and Sendra, 2007). For these purposes, we use well-known notions of Differential Geometry, and also the notion of local shape introduced in Alcazar and Sendra (2007). Our analysis shows important differences between the topological properties of classical and generalized offsets, both at regular and singular points.", "venue": "J. Symb. Comput.", "authors": ["Juan Gerardo Alc\u00e1zar"], "year": 2012, "n_citations": 1}
{"id": 4917799, "s2_id": "57c792c2709ccc0faaa8f93ab9a634783c2dd118", "title": "Conversion Methods, Block Triangularization, and Structural Analysis of Differential-Algebraic Equation Systems", "abstract": "In a previous article, the authors developed two conversion methods to improve the $\\Sigma$-method for structural analysis (SA) of differential-algebraic equations (DAEs). These methods reformulate a DAE on which the $\\Sigma$-method fails into an equivalent problem on which this SA is more likely to succeed with a generically nonsingular Jacobian. The basic version of these methods processes the DAE as a whole. This article presents the block version that exploits block triangularization of a DAE. Using a block triangular form of a Jacobian sparsity pattern, we identify which diagonal blocks of the Jacobian are identically singular and then perform a conversion on each such block. This approach improves the efficiency of finding a suitable conversion for fixing SA's failures. All of our conversion methods can be implemented in a computer algebra system so that every conversion can be automated.", "venue": "ArXiv", "authors": ["Guangning  Tan", "Nedialko S. Nedialkov", "John D. Pryce"], "year": 2016, "n_citations": 1}
{"id": 4918748, "s2_id": "327ab79f25d1795ca61a1897af367520e262d327", "title": "Melikyan algebra is a deformation of a Poisson algebra", "abstract": "We prove, using computer, that the restricted Melikyan algebra of dimension 125 is a deformation of a Poisson algebra.", "venue": "ArXiv", "authors": ["Hayk M. Melikyan", "Pasha  Zusmanovich"], "year": 2014, "n_citations": 3}
{"id": 4920205, "s2_id": "73db88f8215e17fd82b72dd025761897be07688d", "title": "A Strongly Consistent Finite Difference Scheme for Steady Stokes Flow and its Modified Equations", "abstract": "We construct and analyze a strongly consistent second-order finite difference scheme for the steady two-dimensional Stokes flow. The pressure Poisson equation is explicitly incorporated into the scheme. Our approach suggested by the first two authors is based on a combination of the finite volume method, difference elimination, and numerical integration. We make use of the techniques of the differential and difference Janet/Grobner bases. In order to prove strong consistency of the generated scheme we correlate the differential ideal generated by the polynomials in the Stokes equations with the difference ideal generated by the polynomials in the constructed difference scheme. Additionally, we compute the modified differential system of the obtained scheme and analyze the scheme\u2019s accuracy and strong consistency by considering this system. An evaluation of our scheme against the established marker-and-cell method is carried out.", "venue": "CASC", "authors": ["Yury A. Blinkov", "Vladimir P. Gerdt", "Dmitry A. Lyakhov", "Dominik Ludewig Michels"], "year": 2018, "n_citations": 1}
{"id": 4937341, "s2_id": "f25fc6e7f6f732054cb5ab06cea37bfdc83aff1f", "title": "Efficient Diagonalization of Symmetric Matrices Associated with Graphs of Small Treewidth", "abstract": "Let M = (mij) be a symmetric matrix of order n and let G be the graph with vertex set {1, . . . , n} such that distinct vertices i and j are adjacent if and only if mij 6= 0. We introduce a dynamic programming algorithm that finds a diagonal matrix that is congruent to M . If G is given with a tree decomposition T of width k, then this can be done in time O(k|T |+ k2n), where |T | denotes the number of nodes in T . 2012 ACM Subject Classification Computing methodologies \u2192 Linear algebra algorithms; Theory of computation \u2192 Fixed parameter tractability; Mathematics of computing \u2192 Graph theory", "venue": "ICALP", "authors": ["Martin  F\u00fcrer", "Carlos  Hoppen", "Vilmar  Trevisan"], "year": 2020, "n_citations": 1}
{"id": 4941150, "s2_id": "f23eaec7a0543855ba3f1f125b3b5ca193b1988a", "title": "Orbits of monomials and factorization into products of linear forms", "abstract": "This paper is devoted to the factorization of multivariate polynomials into products of linear forms, a problem which has applications to differential algebra, to the resolution of systems of polynomial equations and to Waring decomposition (i.e., decomposition in sums of d-th powers of linear forms; this problem is also known as symmetric tensor decomposition). We provide three black box algorithms for this problem. Our main contribution is an algorithm motivated by the application to Waring decomposition. This algorithm reduces the corresponding factorization problem to simultaenous matrix diagonalization, a standard task in linear algebra. The algorithm relies on ideas from invariant theory, and more specifically on Lie algebras. Our second algorithm reconstructs a factorization from several bi-variate projections. Our third algorithm reconstructs it from the determination of the zero set of the input polynomial, which is a union of hyperplanes.", "venue": "ArXiv", "authors": ["Pascal  Koiran", "Nicolas  Ressayre"], "year": 2018, "n_citations": 3}
{"id": 4943436, "s2_id": "62745402b9e9b42911dfce15c2ffa0b741a89f76", "title": "Reconstruction of eye movements during blinks", "abstract": "In eye movement research in reading, the amount of data plays a crucial role for the validation of results. A methodological problem for the analysis of the eye movement in reading are blinks, when readers close their eyes. Blinking rate increases with increasing reading time, resulting in high data losses, especially for older adults or reading impaired subjects. We present a method, based on the symbolic sequence dynamics of the eye movements, that reconstructs the horizontal position of the eyes while the reader blinks. The method makes use of an observed fact that the movements of the eyes before closing or after opening contain information about the eyes movements during blinks. Test results indicate that our reconstruction method is superior to methods that use simpler interpolation approaches. In addition, analyses of the reconstructed data show no significant deviation from the usual behavior observed in readers.", "venue": "Chaos", "authors": ["Murilo S. Baptista", "Christiane  Bohn", "Reinhold  Kliegl", "Ralf  Engbert", "J\u00fcrgen  Kurths"], "year": 2008, "n_citations": 5}
{"id": 4946541, "s2_id": "1651e2fce343e81340676117d6a83362a58ce01f", "title": "Efficiently factoring polynomials modulo p4", "abstract": "Polynomial factoring has famous practical algorithms over fields-- finite, rational \\& $p$-adic. However, modulo prime powers it gets hard as there is non-unique factorization and a combinatorial blowup ensues. For example, $x^2+p \\bmod p^2$ is irreducible, but $x^2+px \\bmod p^2$ has exponentially many factors! We present the first randomized poly(deg $f, \\log p$) time algorithm to factor a given univariate integral $f(x)$ modulo $p^k$, for a prime $p$ and $k \\leq 4$. Thus, we solve the open question of factoring modulo $p^3$ posed in (Sircana, ISSAC'17). \nOur method reduces the general problem of factoring $f(x) \\bmod p^k$ to that of {\\em root finding} in a related polynomial $E(y) \\bmod\\langle p^k, \\varphi(x)^\\ell \\rangle$ for some irreducible $\\varphi \\bmod p$. We could efficiently solve the latter for $k\\le4$, by incrementally transforming $E(y)$. Moreover, we discover an efficient and strong generalization of Hensel lifting to lift factors of $f(x) \\bmod p$ to those $\\bmod\\ p^4$ (if possible). This was previously unknown, as the case of repeated factors of $f(x) \\bmod p$ forbids classical Hensel lifting.", "venue": "J. Symb. Comput.", "authors": ["Ashish  Dwivedi", "Rajat  Mittal", "Nitin  Saxena"], "year": 2021, "n_citations": 3}
{"id": 4950249, "s2_id": "6b8ae0e8cbaee1b335325e700416c1ea0fa4cc18", "title": "Computer-Aided Derivation of Multi-scale Models: A Rewriting Framework", "abstract": "We introduce a framework for computer-aided derivation of multi-scale models. It relies on a combination of an asymptotic method used in the field of partial differential equations with term rewriting techniques coming from computer science. \nIn our approach, a multi-scale model derivation is characterized by the features taken into account in the asymptotic analysis. Its formulation consists in a derivation of a reference model associated to an elementary nominal model, and in a set of transformations to apply to this proof until it takes into account the wanted features. In addition to the reference model proof, the framework includes first order rewriting principles designed for asymptotic model derivations, and second order rewriting principles dedicated to transformations of model derivations. We apply the method to generate a family of homogenized models for second order elliptic equations with periodic coefficients that could be posed in multi-dimensional domains, with possibly multi-domains and/or thin domains.", "venue": "ArXiv", "authors": ["Bin  Yang", "Walid  Belkhir", "Michel  Lenczner"], "year": 2013, "n_citations": 10}
{"id": 4957017, "s2_id": "36ee1f2932fb594e45b2cec2535a7f004ab7f3fe", "title": "Machine-Assisted Proofs (ICM 2018 Panel)", "abstract": "This submission to arXiv is the report of a panel session at the 2018 International Congress of Mathematicians (Rio de Janeiro, August). It is intended that, while v1 is that report, this stays a living document containing the panelists', and others', reflections on the topic.", "venue": "ArXiv", "authors": ["James H. Davenport", "Bjorn  Poonen", "James  Maynard", "Harald  Helfgott", "Pham Huu Tiep", "Lu\u00eds  Cruz-Filipe"], "year": 2018, "n_citations": 3}
{"id": 4967521, "s2_id": "6186c84f6104462402efcdbbf139bdd863349d23", "title": "A new algorithmic scheme for computing characteristic sets", "abstract": "[email\u00a0protected]?s algorithm of characteristic sets is the most representative for triangularizing sets of multivariate polynomials. Pseudo-division is the main operation used in this algorithm. In this paper we present a new algorithmic scheme for computing generalized characteristic sets by introducing other admissible reductions than pseudo-division. A concrete subalgorithm is designed to triangularize polynomial sets using selected admissible reductions and several effective elimination strategies and to replace the algorithm of basic sets (used in [email\u00a0protected]?s algorithm). The proposed algorithm has been implemented and experimental results show that it performs better than [email\u00a0protected]?s algorithm in terms of computing time and simplicity of output for a number of non-trivial test examples.", "venue": "J. Symb. Comput.", "authors": ["Meng  Jin", "Xiaoliang  Li", "Dongming  Wang"], "year": 2013, "n_citations": 12}
{"id": 4970060, "s2_id": "3b89469217a13ff51bad91786a1c3846f86122f0", "title": "Probabilistic Saturations and Alt's Problem", "abstract": "Alt's problem, formulated in 1923, is to count the number of four-bar linkages whose coupler curve interpolates nine general points in the plane. This problem can be phrased as counting the number of solutions to a system of polynomial equations which was first solved numerically using homotopy continuation by Wampler, Morgan, and Sommese in 1992. Since there is still not a proof that all solutions were obtained, we consider upper bounds for Alt's problem by counting the number of solutions outside of the base locus to a system arising as the general linear combination of polynomials. In particular, we derive effective symbolic and numeric methods for studying such systems using probabilistic saturations that can be employed using both finite fields and floating-point computations. We give bounds on the size of finite field required to achieve a desired level of certainty. These methods can also be applied to many other problems where similar systems arise such as computing the volumes of Newton-Okounkov bodies and computing intersection theoretic invariants including Euler characteristics, Chern classes, and Segre classes.", "venue": "ArXiv", "authors": ["Jonathan D. Hauenstein", "Martin  Helmer"], "year": 2019, "n_citations": 1}
{"id": 4972504, "s2_id": "26aa35f4178a5a1808513393444bc5cb1f606521", "title": "Deriving Theorems in Implicational Linear Logic, Declaratively", "abstract": "The problem we want to solve is how to generate all theorems of a given size in the implicational fragment of propositional intuitionistic linear logic. We start by filtering for linearity the proof terms associated by our Prolog-based theorem prover for Implicational Intuitionistic Logic. This works, but using for each formula a PSPACE-complete algorithm limits it to very small formulas. We take a few walks back and forth over the bridge between proof terms and theorems, provided by the Curry-Howard isomorphism, and derive step-by-step an efficient algorithm requiring a low polynomial effort per generated theorem. The resulting Prolog program runs in O(N) space for terms of size N and generates in a few hours 7,566,084,686 theorems in the implicational fragment of Linear Intuitionistic Logic together with their proof terms in normal form. As applications, we generate datasets for correctness and scalability testing of linear logic theorem provers and training data for neural networks working on theorem proving challenges. The results in the paper, organized as a literate Prolog program, are fully replicable. \nKeywords: combinatorial generation of provable formulas of a given size, intuitionistic and linear logic theorem provers, theorems of the implicational fragment of propositional linear intuitionistic logic, Curry-Howard isomorphism, efficient generation of linear lambda terms in normal form, Prolog programs for lambda term generation and theorem proving.", "venue": "ICLP Technical Communications", "authors": ["Paul  Tarau", "Valeria de Paiva"], "year": 2020, "n_citations": 2}
{"id": 4973609, "s2_id": "b44952e9525074134e91d295fc6f4229abff37ff", "title": "Stability of Triangular Decomposition and Comprehensive Triangular Decomposition", "abstract": "A new concept, decomposition-unstable (DU) variety of a parametric polynomial system, is introduced in this paper and the stabilities of several triangular decomposition methods, such as characteristic set decomposition, relatively simplicial decomposition and regular chain decomposition, for parametric polynomial systems are discussed in detail. The concept leads to a definition of weakly comprehensive triangular decomposition (WCTD) and a new algorithm for computing comprehensive triangular decomposition (CTD) which was first introduced in [4] for computing an analogue of comprehensive Groebner systems for parametric polynomial systems. Our algorithm takes advantage of a hierarchical solving strategy and a self-adaptive order of parameters. The algorithm has been implemented with Maple 15 and experimented with a number of benchmarks from the literature. Comparison with the Maple package RegularChains, which contains an implementation of the algorithm in [4], is provided and the results illustrate that the time costs by our program for computing CTDs of most examples are no more than those by RegularChains.", "venue": "ArXiv", "authors": ["Xiaoxian  Tang", "Bican  Xia"], "year": 2011, "n_citations": 0}
{"id": 4982045, "s2_id": "50da4a1c9f830e729d6e5f448298b81e34bdd003", "title": "The algebra of Kleene stars of the plane and polylogarithms", "abstract": "We extend the definition and study the algebraic properties of the polylogarithm Li(T) , where T is rational series over the alphabet X = {x 0 , x 1 } belonging to suitable subalgebras of rational series.", "venue": "ArXiv", "authors": ["Ngoc  Hoang", "G\u00e9rard  Duchamp", "Vincel Hoang Ngoc Minh"], "year": 2016, "n_citations": 0}
{"id": 4989372, "s2_id": "00812f7c50e0fcb44a69ea6cb77ea6c9a0fe2d64", "title": "gTybalt - a free computer algebra system", "abstract": "Abstract This article documents the free computer algebra system \u201cgTybalt\u201d. The program is build on top of other packages, among others GiNaC, TeXmacs and Root. It offers the possibility of interactive symbolic calculations within the C++ programming language. Mathematical formulae are visualized using fonts. Program summary Title of program: gTybalt Version: 1.0.0 Catalogue identifier: ADSI Program summary URL: http://cpc.cs.qub.ac.uk.summaries/ADSI Program obtained from: CPC Program Library, Queen's University of Belfast, N. Ireland License: GNU Public License Computers: all Operating system: GNU/Linux Program language: C++ Distribution format: tar gzip file No. of bytes in distributed program, including test data, etc.: 499583 Memory required to execute: 64 MB recommended Other programs called: see Appendix\u00a0A External files needed: none Keywords: Symbolic calculations, Computer algebra Nature of the physical problem: Symbolic calculations occur nowadays in all areas of science. gTybalt is a free computer algebra system based on the C++ language. Method of solution: gTybalt is a \u201cbazaar\u201d-style program, it relies on existing, freely-available packages for specific sub-tasks. Restrictions on complexity of the problem: gTybalt does not try to cover every domain of mathematics. Some desirable algorithms, like symbolic integration are not implemented. It can however easily be extended in new directions. Apart from that, standard restrictions due to the available hardware apply. Typical running time: Depending on the complexity of the problem.", "venue": "ArXiv", "authors": ["Stefan  Weinzierl"], "year": 2003, "n_citations": 2}
{"id": 4992300, "s2_id": "bd8a431395b68218145ada071c94d75dc4d843a3", "title": "Quadratization of ODEs: Monomial vs. Non-Monomial", "abstract": "Quadratization is a transform of a system of ODEs with polynomial right-hand side into a system of ODEs with at most quadratic right-hand side via the introduction of new variables. It has been recently used as a pre-processing step for new model order reduction methods, so it is important to keep the number of new variables small. Several algorithms have been designed to search for a quadratization with the new variables being monomials in the original variables. To understand the limitations and potential ways of improving such algorithms, we study the following question: can quadratizations with not necessarily monomial new variables produce a model of substantially smaller dimension than quadratization with only monomial new variables? \nTo do this, we restrict our attention to scalar polynomial ODEs. Our first result is that a scalar polynomial ODE $\\dot{x}=p(x)=a_nx^n+a_{n-1}x^{n-1}+\\ldots + a_0$ with $n\\geqslant 5$ and $a_n\\neq0$ can be quadratized using exactly one new variable if and only if $p(x-\\frac{a_{n-1}}{n\\cdot a_n})=a_nx^n+ax^2+bx$ for some $a, b \\in \\mathbb{C}$. In fact, the new variable can be taken $z:=(x-\\frac{a_{n-1}}{n\\cdot a_n})^{n-1}$. Our second result is that two non-monomial new variables are enough to quadratize all degree $6$ scalar polynomial ODEs. Based on these results, we observe that a quadratization with not necessarily monomial new variables can be much smaller than a monomial quadratization even for scalar ODEs. \nThe main results of the paper have been discovered using computational methods of applied nonlinear algebra (Grobner bases), and we describe these computations.", "venue": "ArXiv", "authors": ["Foyez  Alauddin"], "year": 2020, "n_citations": 1}
{"id": 4997001, "s2_id": "50feb9ed6a93cfde60359954a1197d342256a82e", "title": "TheoryGuru: A Mathematica Package to apply Quantifier Elimination", "abstract": "We consider the use of Quantifier Elimination (QE) technology for automated reasoning in economics. There is a great body of work considering QE applications in science and engineering but we demonstrate here that it also has use in the social sciences. We explain how many suggested theorems in economics could either be proven, or even have their hypotheses shown to be inconsistent, automatically via QE. \nHowever, economists who this technology could benefit are usually unfamiliar with QE, and the use of mathematical software generally. This motivated the development of a Mathematica Package TheoryGuru, whose purpose is to lower the costs of applying QE to economics. We describe the package's functionality and give examples of its use.", "venue": "ICMS", "authors": ["Casey B. Mulligan", "James H. Davenport", "Matthew  England"], "year": 2018, "n_citations": 9}
{"id": 4997080, "s2_id": "94d73323b919a19592b1bc8756242f5efba0ce14", "title": "Lower Bounds on the Number of Realizations of Rigid Graphs", "abstract": "ABSTRACT Computing the number of realizations of a minimally rigid graph is a notoriously difficult problem. Toward this goal, for graphs that are minimally rigid in the plane, we take advantage of a recently published algorithm, which is the fastest available method, although its complexity is still exponential. Combining computational results with the theory of constructing new rigid graphs by gluing, we give a new lower bound on the maximal possible number of (complex) realizations for graphs with a given number of vertices. We extend these ideas to rigid graphs in three dimensions and we derive similar lower bounds, by exploiting data from extensive Gr\u00f6bner basis computations.", "venue": "Exp. Math.", "authors": ["Georg  Grasegger", "Christoph  Koutschan", "Elias P. Tsigaridas"], "year": 2020, "n_citations": 7}
{"id": 5004477, "s2_id": "195b5d402acea1e7e8f78b49430cf304f94678c8", "title": "When Newton meets Descartes: a simple and fast algorithm to isolate the real roots of a polynomial", "abstract": "We introduce a novel algorithm denoted NewDsc to isolate the real roots of a univariate square-free polynomial f with integer coefficients. The algorithm iteratively subdivides an initial interval which is known to contain all real roots of f and performs exact (rational) operations on the coefficients of f in each step. For the subdivision strategy, we combine Descartes' Rule of Signs and Newton iteration. More precisely, instead of using a fixed subdivision strategy such as bisection in each iteration, a Newton step based on the number of sign variations for an actual interval is considered, and, only if the Newton step fails, we fall back to bisection. Following this approach, quadratic convergence towards the real roots is achieved in most iterations. In terms of complexity, our method induces a recursion tree of almost optimal size O(n\u00b7log(n\u03c4)), where n denotes the degree of the polynomial and \u03c4 the bitsize of its coefficients. The latter bound constitutes an improvement by a factor of \u03c4 upon all existing subdivision methods for the task of isolating the real roots. We further provide a detailed complexity analysis which shows that NewDsc needs only \u00d5(n3\u03c4) bit operations to isolate all real roots of f. In comparison to existing asymptotically fast numerical algorithms (e.g. the algorithms by V. Pan and A. Sch\u00f6nhage), NewDsc is much easier to access and, due to its similarities to the classical Descartes method, it seems to be well suited for an efficient implementation.", "venue": "ISSAC", "authors": ["Michael  Sagraloff"], "year": 2012, "n_citations": 54}
{"id": 5004989, "s2_id": "4422a11a4375cf7598778e7aa79af0f46d5018f7", "title": "Poisson Homology in Degree 0 for some Rings of Symplectic Invariants", "abstract": "Abstract Let g be a finite-dimensional semi-simple Lie algebra, h a Cartan subalgebra of g , and W its Weyl group. The group W acts diagonally on V : = h \u2295 h \u2217 , as well as on C [ V ] . The purpose of this article is to study the Poisson homology of the algebra of invariants C [ V ] W endowed with the standard symplectic bracket. To begin with, we give general results about the Poisson homology space in degree 0, denoted by HP 0 ( C [ V ] W ) , in the case where g is of type B n \u2212 C n or D n , results which support Alev's conjecture. Then we are focusing the interest on the particular cases of ranks 2 and 3, by computing the Poisson homology space in degree 0 in the cases where g is of type B 2 ( so 5 ), D 2 ( so 4 ), then B 3 ( so 7 ), and D 3 = A 3 ( so 6 \u2243 sl 4 ). In order to do this, we make use of a functional equation introduced by Y. Berest, P. Etingof and V. Ginzburg. We recover, by a different method, the result established by J. Alev and L. Foissy, according to which the dimension of HP 0 ( C [ V ] W ) equals 2 for B 2 . Then we calculate the dimension of this space and we show that it is equal to 1 for D 2 . We also calculate it for the rank 3 cases, we show that it is equal to 3 for B 3 \u2212 C 3 and 1 for D 3 = A 3 .", "venue": "ArXiv", "authors": ["Fr\u00e9d\u00e9ric  Butin"], "year": 2008, "n_citations": 5}
{"id": 5006833, "s2_id": "fbe8106c82ec3244bf1f2ba2e3bef4183117e932", "title": "Computing zero-dimensional tropical varieties via projections", "abstract": "We present an algorithm for computing zero-dimensional tropical varieties using projections. Our main tools are fast unimodular transforms of lexicographical Grobner bases. We prove that our algorithm requires only a polynomial number of arithmetic operations if given a Grobner basis, and we demonstrate that our implementation compares favourably to other existing implementations. Applying it to the computation of general positive-dimensional tropical varieties, we argue that the complexity for calculating tropical links is dominated by the complexity of the Grobner walk.", "venue": "ArXiv", "authors": ["Paul  G\u00f6rlach", "Yue  Ren", "Leon  Zhang"], "year": 2019, "n_citations": 3}
{"id": 5011617, "s2_id": "d4eeacd7d5d05fddf68547d5601e5c41b141db8b", "title": "Semantic Preserving Bijective Mappings for Expressions involving Special Functions in Computer Algebra Systems and Document Preparation Systems", "abstract": "Purpose \u2013\nModern mathematicians and scientists of math-related disciplines often use Document Preparation Systems (DPS) to write and Computer Algebra Systems (CAS) to calculate mathematical expressions. Usually, they translate the expressions manually between DPS and CAS. This process is time-consuming and error-prone. The purpose of this paper is to automate this translation. This paper uses Maple and Mathematica as the CAS, and LaTeX as the DPS.\n\n\nDesign/methodology/approach \u2013\nBruce Miller at the National Institute of Standards and Technology (NIST) developed a collection of special LaTeX macros that create links from mathematical symbols to their definitions in the NIST Digital Library of Mathematical Functions (DLMF). The authors are using these macros to perform rule-based translations between the formulae in the DLMF and CAS. Moreover, the authors develop software to ease the creation of new rules and to discover inconsistencies.\n\n\nFindings \u2013\nThe authors created 396 mappings and translated 58.8 percent of DLMF formulae (2,405 expressions) successfully between Maple and DLMF. For a significant percentage, the special function definitions in Maple and the DLMF were different. An atomic symbol in one system maps to a composite expression in the other system. The translator was also successfully used for automatic verification of mathematical online compendia and CAS. The evaluation techniques discovered two errors in the DLMF and one defect in Maple.\n\n\nOriginality/value \u2013\nThis paper introduces the first translation tool for special functions between LaTeX and CAS. The approach improves error-prone manual translations and can be used to verify mathematical online compendia and CAS.", "venue": "Aslib J. Inf. Manag.", "authors": ["Andr\u00e9  Greiner-Petter", "Moritz  Schubotz", "Howard S. Cohl", "Bela  Gipp"], "year": 2019, "n_citations": 4}
{"id": 5012233, "s2_id": "b62414698371fce3440a8dcbcb95901ee0ce320a", "title": "Effective partitioning method for computing weighted Moore-Penrose inverse", "abstract": "We introduce a method and an algorithm for computing the weighted Moore-Penrose inverse of multiple-variable polynomial matrix and the related algorithm which is appropriated for sparse polynomial matrices. These methods and algorithms are generalizations of algorithms developed in [M.B. Tasic, P.S. Stanimirovic, M.D. Petkovic, Symbolic computation of weighted Moore-Penrose inverse using partitioning method, Appl. Math. Comput. 189 (2007) 615-640] to multiple-variable rational and polynomial matrices and improvements of these algorithms on sparse matrices. Also, these methods are generalizations of the partitioning method for computing the Moore-Penrose inverse of rational and polynomial matrices introduced in [P.S. Stanimirovic, M.B. Tasic, Partitioning method for rational and polynomial matrices, Appl. Math. Comput. 155 (2004) 137-163; M.D. Petkovic, P.S. Stanimirovic, Symbolic computation of the Moore-Penrose inverse using partitioning method, Internat. J. Comput. Math. 82 (2005) 355-367] to the case of weighted Moore-Penrose inverse. Algorithms are implemented in the symbolic computational package MATHEMATICA.", "venue": "Comput. Math. Appl.", "authors": ["Marko D.  Petkovi\u0107", "Predrag S.  Stanimirovi\u0107", "Milan B.  Tasi\u0107"], "year": 2008, "n_citations": 19}
{"id": 5018261, "s2_id": "d7ec358e61cb51313a0786c6afc8412980f644e4", "title": "A Condition for Multiplicity Structure of Univariate Polynomials", "abstract": "We consider the problem of finding a condition for a univariate polynomial having a given multiplicity structure when the number of distinct roots is given. It is well known that such conditions can be written as conjunctions of several polynomial equations and one inequation in the coefficients, by using repeated parametric gcd's. In this paper, we give a novel condition which is not based on repeated gcd's. Furthermore, it is shown that the number of polynomials in the condition is optimal and the degree of polynomials is smaller than that in the previous condition based on repeated gcd's.", "venue": "J. Symb. Comput.", "authors": ["Hoon  Hong", "Jing  Yang"], "year": 2021, "n_citations": 0}
{"id": 5019120, "s2_id": "a30b2a767468cfdfadf900370128344c10faba47", "title": "Applications of Continuous Amortization to Bisection-based Root Isolation", "abstract": "Continuous amortization is a technique for computing the complexity of algorithms, and it was first presented by the author in Burr, Krahmer, & Yap (2009). Continuous amortization can result in simpler and more straight-forward complexity analyses, and it was used in Burr, Krahmer, & Yap (2009), Burr & Krahmer (2012), and Sharma & Yap (2012) to provide complexity bounds for simple root isolation algorithms. This paper greatly extends the reach of continuous amortization to serve as an overarching technique which can be used to compute complexity of many root isolation techniques in a straight-forward manner. Additionally, the technique of continuous amortization is extended to higher dimensions and to the computation of the bit-complexity of algorithms. In this paper, six continuous amortization calculations are performed to compute complexity bounds (on either the size of the subdivision tree or the bit complexity) for several algorithms (including algorithms based on Sturm sequences, Descartes' rule of signs, and polynomial evaluation); in each case, continuous amortization achieves an optimal complexity bound.", "venue": "ArXiv", "authors": ["Michael A. Burr"], "year": 2013, "n_citations": 4}
{"id": 5020656, "s2_id": "65745fc510128148496671bad58e41ed6889cbba", "title": "Cylindrical algebraic decomposition using local projections", "abstract": "We present an algorithm which computes a cylindrical algebraic decomposition of a semialgebraic set using projection sets computed for each cell separately. Such local projection sets can be significantly smaller than the global projection set used by the Cylindrical Algebraic Decomposition (CAD) algorithm. This leads to reduction in the number of cells the algorithm needs to construct. We give an empirical comparison of our algorithm and the classical CAD algorithm.", "venue": "ISSAC", "authors": ["Adam W. Strzebonski"], "year": 2014, "n_citations": 3}
{"id": 5024678, "s2_id": "df0e8316d4dca2d1384246c9d503a1e2b193e81b", "title": "The VLSAT-2 Benchmark Suite", "abstract": "This report presents VLSAT-2 (an acronym for Very Large Boolean SATis ability problems ), the second part of a benchmark suite to be used in scienti c experiments and software competitions addressing SAT-solving issues. VLSAT-2 contains 100 benchmarks (50 satis able and 50 unsatis able formulas) of increasing complexity, proposed in DIMACS CNF format under a permissive Creative Commons license. 25% of these benchmarks have been used during the 2020 and 2021 editions of the International SAT Competition. Key-words: benchmark suite, Boolean satis ability problem, data set, DIMACS CNF, NestedUnit Petri Net, NUPN, Petri Net, SAT formula, SAT solving Le jeu de tests VLSAT-2 R\u00e9sum\u00e9 : VLSAT-2 (acronyme anglais de tr\u00e8s grands probl\u00e8mes de satisfaisabilit\u00e9 bool\u00e9enne ) est le second volet d'une suite de tests destin\u00e9e aux exp\u00e9rimentations scienti ques et aux comp\u00e9titions de logiciels pour la r\u00e9solution de probl\u00e8mes SAT. VLSAT-2 contient 100 tests (50 formules satisfaisables et 50 insatisfaisables) de complexit\u00e9 croissante, fournis en format DIMACS CNF sous une licence Creative Commons permissive. 25% de ces tests ont \u00e9t\u00e9 utilis\u00e9s lors des \u00e9ditions 2020 et 2021 de la comp\u00e9tition internationale sur la r\u00e9solution SAT. Mots-cl\u00e9s : DIMACS CNF, ensemble de donn\u00e9es, formule SAT, Nested-Unit Petri Net, NUPN, probl\u00e8me SAT, r\u00e9seau de Petri, satisfaisabilit\u00e9 bool\u00e9enne, suite de tests The VLSAT-2 Benchmark Suite 3 1 Benchmark Description VLSAT-2 is a collection of 100 SAT formulas. Many of these formulas are di cult to handle by current SAT solvers. One half of these formulas is satis able, while the other half is not. Each formula is provided as a separate le, expressed in Conjunctive Normal Form and encoded in the DIMACS CNF format. Each le is then compressed using bzip2 to save disk space and allow faster downloads. The 100 formulas require 5.2 gigabytes of disk space and 1.4 gigabytes when compressed using bzip2. The VLSAT-2 benchmarks are licensed under the CC-BY Creative Commons Attribution 4.0 International License. 25% of the VLSAT-2 benchmarks have been selected by the organizers of recent SAT Competitions: 7 satis able and 7 unsatis able formulas have been chosen for the SAT Competition 2020, and 5 satis able and 8 unsatis able formulas have been chosen for the SAT Competition 2021 [2].", "venue": "ArXiv", "authors": ["Pierre  Bouvier", "Hubert  Garavel"], "year": 2021, "n_citations": 1}
{"id": 5025307, "s2_id": "05a0e7bec55be267e61fd43ca978b809e05c46bf", "title": "Fast algorithms for computing isogenies between elliptic curves", "abstract": "We survey algorithms for computing isogenies between elliptic curves defined over a field of characteristic either 0 or a large prime. We introduce a new algorithm that computes an isogeny of degree l (l different from the characteristic) in time quasi-linear with respect to l. This is based in particular on fast algorithms for power series expansion of the Weierstrass \u2118-function and related functions.", "venue": "Math. Comput.", "authors": ["Alin  Bostan", "Fran\u00e7ois  Morain", "Bruno  Salvy", "\u00c9ric  Schost"], "year": 2008, "n_citations": 91}
{"id": 5028573, "s2_id": "5f8e8096c8d82e1daa7e4461616af4dfa974642b", "title": "Counting Real Roots in Polynomial-Time for Systems Supported on Circuits", "abstract": "Suppose A={a1, . . . , an+2}\u2282Z has cardinality n+2, with all the coordinates of the aj having absolute value at most d, and the aj do not all lie in the same affine hyperplane. Suppose F = (f1, . . . , fn) is an n \u00d7 n polynomial system with generic integer coefficients at most H in absolute value, and A the union of the sets of exponent vectors of the fi. We give the first algorithm that, for any fixed n, counts exactly the number of real roots of F in time polynomial in log(dH).", "venue": "ArXiv", "authors": ["J. Maurice Rojas"], "year": 2020, "n_citations": 0}
{"id": 5034191, "s2_id": "b8b6fdb6914e2d27b61ddb32260711a1315a2e4c", "title": "On Ritt's decomposition theorem in the case of finite fields", "abstract": "A classical theorem by Ritt states that all the complete decomposition chains of a univariate polynomial satisfying a certain tameness condition have the same length. In this paper we present our conclusions about the generalization of these theorem in the case of finite coefficient fields when the tameness condition is dropped.", "venue": "Finite Fields Their Appl.", "authors": ["Jaime  Gutierrez", "David  Sevilla"], "year": 2006, "n_citations": 14}
{"id": 5042523, "s2_id": "4485f4c0c8a323c12894821aab2e16808d0218a3", "title": "An Algebraic Graph Transformation Approach for RDF and SPARQL", "abstract": "We consider the recommendations of the World Wide Web Consortium (W3C) about RDF framework and its associated query language SPARQL. We propose a new formal framework based on category theory which provides clear and concise formal definitions of the main basic features of RDF and SPARQL. We define RDF graphs as well as SPARQL basic graph patterns as objects of some nested categories. This allows one to clarify, in particular, the role of blank nodes. Furthermore, we consider basic SPARQL CONSTRUCT and SELECT queries and formalize their operational semantics following a novel algebraic graph transformation approach called POIM.", "venue": "GCM@STAF", "authors": ["D.  Duval", "R.  Echahed", "F.  Prost"], "year": 2020, "n_citations": 1}
{"id": 5044013, "s2_id": "c47a0df091ef775768443576af4a746fca093064", "title": "Lemma Generation for Horn Clause Satisfiability: A Preliminary Study", "abstract": "It is known that the verification of imperative, functional, and logic programs can be reduced to the satisfiability of constrained Horn clauses (CHCs), and this satisfiability check can be performed by using CHC solvers, such as Eldarica and Z3. These solvers perform well when they act on simple constraint theories, such as Linear Integer Arithmetic and the theory of Booleans, but their efficacy is very much reduced when the clauses refer to constraints on inductively defined structures, such as lists or trees. Recently, we have presented a transformation technique for eliminating those inductively defined data structures, and hence avoiding the need for incorporating induction principles into CHC solvers. However, this technique may fail when the transformation requires the use of lemmata whose generation needs ingenuity. In this paper we show, through an example, how during the process of transforming CHCs for eliminating inductively defined structures one can introduce suitable predicates, called difference predicates, whose definitions correspond to the lemmata to be introduced. Through a second example, we show that, whenever difference predicates cannot be introduced, we can introduce, instead, auxiliary queries which also correspond to lemmata, and the proof of these lemmata can be done by showing the satisfiability of those queries.", "venue": "VPT@Programming", "authors": ["Emanuele De Angelis", "Fabio  Fioravanti", "Alberto  Pettorossi", "Maurizio  Proietti"], "year": 2019, "n_citations": 4}
{"id": 5044526, "s2_id": "688baf371b98df570995c3dc5828fc662a62b951", "title": "A probabilistic algorithm to compute the real dimension of a semi-algebraic set", "abstract": "Let $\\RR$ be a real closed field (e.g. the field of real numbers) and $\\mathscr{S} \\subset \\RR^n$ be a semi-algebraic set defined as the set of points in $\\RR^n$ satisfying a system of $s$ equalities and inequalities of multivariate polynomials in $n$ variables, of degree at most $D$, with coefficients in an ordered ring $\\ZZ$ contained in $\\RR$. We consider the problem of computing the {\\em real dimension}, $d$, of $\\mathscr{S}$. The real dimension is the first topological invariant of interest; it measures the number of degrees of freedom available to move in the set. Thus, computing the real dimension is one of the most important and fundamental problems in computational real algebraic geometry. The problem is ${\\rm NP}_{\\mathbb{R}}$-complete in the Blum-Shub-Smale model of computation. The current algorithms (probabilistic or deterministic) for computing the real dimension have complexity $(s \\, D)^{O(d(n-d))}$, that becomes $(s \\, D)^{O(n^2)}$ in the worst-case. The existence of a probabilistic or deterministic algorithm for computing the real dimension with single exponential complexity with a factor better than ${O(n^2)}$ in the exponent in the worst-case, is a longstanding open problem. We provide a positive answer to this problem by introducing a probabilistic algorithm for computing the real dimension of a semi-algebraic set with complexity $( s\\, D)^{O(n)}$.", "venue": "ArXiv", "authors": ["Mohab Safey El Din", "Elias P. Tsigaridas"], "year": 2013, "n_citations": 2}
{"id": 5045072, "s2_id": "6760bc3e7051028e63704352d5c9f9edefc8f0e7", "title": "Computing solutions of linear Mahler equations", "abstract": "Mahler equations relate evaluations of the same function $f$ at iterated $b$th powers of the variable. They arise in particular in the study of automatic sequences and in the complexity analysis of divide-and-conquer algorithms. Recently, the problem of solving Mahler equations in closed form has occurred in connection with number-theoretic questions. A difficulty in the manipulation of Mahler equations is the exponential blow-up of degrees when applying a Mahler operator to a polynomial. In this work, we present algorithms for solving linear Mahler equations for series, polynomials, and rational functions, and get polynomial-time complexity under a mild assumption. Incidentally, we develop an algorithm for computing the gcrd of a family of linear Mahler operators.", "venue": "Math. Comput.", "authors": ["Fr\u00e9d\u00e9ric  Chyzak", "Thomas  Dreyfus", "Philippe  Dumas", "Marc  Mezzarobba"], "year": 2018, "n_citations": 6}
{"id": 5050061, "s2_id": "f516ac2df81d92278837888c54426466002fe4bf", "title": "Discriminants of Complete Intersection Space Curves", "abstract": "n this paper, we develop a new approach to the discriminant of a complete intersection curve in the 3-dimensional projective space. By relying on the resultant theory, we prove a new formula that allows us to define this discriminant without ambiguity and over any commutative ring, in particular in any characteristic. This formula also provides a new method for evaluating and computing this discriminant more efficiently, without the need to introduce new variables as with the well-known Cayley trick. Then, we derive new properties and we show that this new definition of the discriminant satisfies to the expected geometric property and hence yields an effective smoothness criterion for complete intersection space curves.", "venue": "ISSAC", "authors": ["Laurent  Bus\u00e9", "Ibrahim  Nonkan\u00e9"], "year": 2017, "n_citations": 1}
{"id": 5064992, "s2_id": "42113b688203fbe1b2e570de37bdd5226fb96e7f", "title": "A fast, deterministic algorithm for computing a Hermite Normal Form of a polynomial matrix", "abstract": "Given a square, nonsingular matrix of univariate polynomials $\\mathbf{F} \\in \\mathbb{K}[x]^{n \\times n}$ over a field $\\mathbb{K}$, we give a fast, deterministic algorithm for finding the Hermite normal form of $\\mathbf{F}$ with complexity $O^{\\sim}\\left(n^{\\omega}d\\right)$ where $d$ is the degree of $\\mathbf{F}$. Here soft-$O$ notation is Big-$O$ with log factors removed and $\\omega$ is the exponent of matrix multiplication. The method relies of a fast algorithm for determining the diagonal entries of its Hermite normal form, having as cost $O^{\\sim}\\left(n^{\\omega}s\\right)$ operations with $s$ the average of the column degrees of $\\mathbf{F}$.", "venue": "ArXiv", "authors": ["George  Labahn", "Wei  Zhou"], "year": 2016, "n_citations": 2}
{"id": 5067462, "s2_id": "faf4f2e9e10e0b5b2d2cf818ee6f2c28569b5d1b", "title": "Evaluation of Multi-Sums for Large Scale Problems", "abstract": "A big class of Feynman integrals, in particular, the coefficients of their Laurent series expansion w.r.t.\\ the dimension parameter $\\ep$ can be transformed to multi-sums over hypergeometric terms and harmonic sums. In this article, we present a general summation method based on difference fields that simplifies these multi--sums by transforming them from inside to outside to representations in terms of indefinite nested sums and products. In particular, we present techniques that assist in the task to simplify huge expressions of such multi-sums in a completely automatic fashion. The ideas are illustrated on new calculations coming from 3-loop topologies of gluonic massive operator matrix elements containing two fermion lines, which contribute to the transition matrix elements in the variable flavor scheme.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "Alexander  Hasselhuhn", "Carsten  Schneider"], "year": 2012, "n_citations": 47}
{"id": 5070530, "s2_id": "027046871635732dcd8510b19c662f4f3d676826", "title": "Designing Strassen's algorithm", "abstract": "In 1969, Strassen shocked the world by showing that two n x n matrices could be multiplied in time asymptotically less than $O(n^3)$. While the recursive construction in his algorithm is very clear, the key gain was made by showing that 2 x 2 matrix multiplication could be performed with only 7 multiplications instead of 8. The latter construction was arrived at by a process of elimination and appears to come out of thin air. Here, we give the simplest and most transparent proof of Strassen's algorithm that we are aware of, using only a simple unitary 2-design and a few easy lines of calculation. Moreover, using basic facts from the representation theory of finite groups, we use 2-designs coming from group orbits to generalize our construction to all n (although the resulting algorithms aren't optimal for n at least 3).", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Joshua A. Grochow", "Cristopher  Moore"], "year": 2017, "n_citations": 4}
{"id": 5075815, "s2_id": "954b62fc55289b5b947f108406e479e51dc6a811", "title": "Improving Graph Neural Network Representations of Logical Formulae with Subgraph Pooling", "abstract": "Recent advances in the integration of deep learning with automated theorem proving have centered around the representation of logical formulae as inputs to deep learning systems. In particular, there has been a growing interest in adapting structure-aware neural methods to work with the underlying graph representations of logical expressions. While more effective than character and token-level approaches, graph-based methods have often made representational trade-offs that limited their ability to capture key structural properties of their inputs. In this work we propose a novel approach for embedding logical formulae that is designed to overcome the representational limitations of prior approaches. Our architecture works for logics of different expressivity; e.g., first-order and higher-order logic. We evaluate our approach on two standard datasets and show that the proposed architecture achieves state-of-the-art performance on both premise selection and proof step classification.", "venue": "ArXiv", "authors": ["Maxwell  Crouse", "Ibrahim  Abdelaziz", "Cristina  Cornelio", "Veronika  Thost", "Lingfei  Wu", "Kenneth  Forbus", "Achille  Fokoue"], "year": 2019, "n_citations": 13}
{"id": 5076060, "s2_id": "b7f53521d63130d4385cb82ab535db8a064134c6", "title": "A refined machinery to calculate large moments from coupled systems of linear differential equations", "abstract": "The large moment method can be used to compute a large number of moments of physical quantities that are described by coupled systems of linear differential equations. Besides these systems the algorithm requires a certain number of initial values as input, that are often hard to derive in a preprocessing step. Thus a major challenge is to keep the number of initial values as small as possible. We present the basic ideas of the underlying large moment method and present refined versions that reduce significantly the number of required initial values.", "venue": "ArXiv", "authors": ["Johannes  Bl\u00fcmlein", "Peter  Marquard", "Carsten  Schneider"], "year": 2019, "n_citations": 2}
{"id": 5076823, "s2_id": "9d893bc735a6343c192885cdd345f722a53e18c2", "title": "\"E pluribus unum\" or How to Derive Single-equation Descriptions for Output-quantities in Nonlinear Circuits using Differential Algebra", "abstract": "In this paper we describe by a number of examples how to deduce one single characterizing higher order differential equation for output quantities of an analog circuit. \nIn the linear case, we apply basic \"symbolic\" methods from linear algebra to the system of differential equations which is used to model the analog circuit. For nonlinear circuits and their corresponding nonlinear differential equations, we show how to employ computer algebra tools implemented in Maple, which are based on differential algebra.", "venue": "ArXiv", "authors": ["Eberhard H.-A. Gerbracht"], "year": 2008, "n_citations": 0}
{"id": 5077304, "s2_id": "1f4e2d1b8b723342e14ae93dbb576de77b250abc", "title": "Direct and dual laws for automata with multiplicities", "abstract": "We present here theoretical results coming from the implementation of the package called AMULT (automata with multiplicities). We show that classical formulas are optimal for the bounds. Especially they are almost everywhere optimal for the fields R and C. We characterize the dual laws preserving rationality and examine compatibility between the geometry of the K-automata andthese laws. Copyright 2001 Elsevier Science B.V.", "venue": "Theor. Comput. Sci.", "authors": ["G\u00e9rard  Duchamp", "Marianne  Flouret", "\u00c9ric  Laugerotte", "Jean-Gabriel  Luque"], "year": 2001, "n_citations": 38}
{"id": 5078604, "s2_id": "5e665c654eef78a15cda7a01c66175e268cdf417", "title": "Computable Hilbert Schemes", "abstract": "In this PhD thesis we propose an algorithmic approach to the study of the Hilbert scheme. Developing algorithmic methods, we also obtain general results about Hilbert schemes. In Chapter 1 we discuss the equations defining the Hilbert scheme as subscheme of a suitable Grassmannian and in Chapter 5 we determine a new set of equations of degree lower than the degree of equations known so far. In Chapter 2 we study the most important objects used to project algorithmic techniques, namely Borel-fixed ideals. We determine an algorithm computing all the saturated Borel-fixed ideals with Hilbert polynomial assigned and we investigate their combinatorial properties. In Chapter 3 we show a new type of flat deformations of Borel-fixed ideals which lead us to give a new proof of the connectedness of the Hilbert scheme. In Chapter 4 we construct families of ideals that generalize the notion of family of ideals sharing the same initial ideal with respect to a fixed term ordering. Some of these families correspond to open subsets of the Hilbert scheme and can be used to a local study of the Hilbert scheme. In Chapter 6 we deal with the problem of the connectedness of the Hilbert scheme of locally Cohen-Macaulay curves in the projective 3-space. We show that one of the Hilbert scheme considered a \"good\" candidate to be non-connected, is instead connected. Moreover there are three appendices that present and explain how to use the implementations of the algorithms proposed.", "venue": "ArXiv", "authors": ["Paolo  Lella"], "year": 2012, "n_citations": 1}
{"id": 5083971, "s2_id": "a151fea246c97fde52cef61ff65541886a4da6c0", "title": "Lexicographic Groebner bases of bivariate polynomials modulo a univariate one", "abstract": "Let T(x) in k[x] be a monic non-constant polynomial and write R=k[x]/(T) the quotient ring. Consider two bivariate polynomials a(x, y), b(x, y) in R[y]. In a first part, T = p^e is assumed to be the power of an irreducible polynomial p. A new algorithm that computes a minimal lexicographic Groebner basis of the ideal (a, b, p^e), is introduced. A second part extends this algorithm when T is general through the \"local/global\" principle realized by a generalization of \"dynamic evaluation\", restricted so far to a polynomial T that is squarefree. The algorithm produces splittings according to the case distinction \"invertible/nilpotent\", extending the usual \"invertible/zero\" in classic dynamic evaluation. This algorithm belongs to the Euclidean family, the core being a subresultant sequence of a and b modulo T. In particular no factorization or Groebner basis computations are necessary. The theoretical background relies on the Lazard's structural theorem for lexicographic Groebner bases in two variables. An implementation is realized in Magma, and extensive benchmarks are provided that show clearly the benefits, sometimes huge, of this approach compared to the computation of Groebner bases.", "venue": "J. Symb. Comput.", "authors": ["Xavier  Dahan"], "year": 2022, "n_citations": 0}
{"id": 5084860, "s2_id": "8e511e81521ea8c25c10a08cf830f9a7fc7cd9d1", "title": "Faster Algorithms for Rectangular Matrix Multiplication", "abstract": "Let \u03b1 be the maximal value such that the product of an n \u00d7 n<sup>\u03b1</sup> matrix by an n<sup>\u03b1</sup> \u00d7 n matrix can be computed with n<sup>2+o(1)</sup> arithmetic operations. In this paper we show that \u03b1 >; 0.30298, which improves the previous record \u03b1 >; 0.29462 by Coppersmith (Journal of Complexity, 1997). More generally, we construct a new algorithm for multiplying an n \u00d7 n<sup>k</sup> matrix by an n<sup>k</sup> \u00d7 n matrix, for any value k \u2260 1. The complexity of this algorithm is better than all known algorithms for rectangular matrix multiplication. In the case of square matrix multiplication (i.e., for k = 1), we recover exactly the complexity of the algorithm by Coppersmith and Winograd (Journal of Symbolic Computation, 1990). These new upper bounds can be used to improve the time complexity of several known algorithms that rely on rectangular matrix multiplication. For example, we directly obtain a O(n<sup>2.5302</sup>)-time algorithm for the all-pairs shortest paths problem over directed graphs with small integer weights, where n denotes the number of vertices, and also improve the time complexity of sparse square matrix multiplication.", "venue": "2012 IEEE 53rd Annual Symposium on Foundations of Computer Science", "authors": ["Fran\u00e7ois Le Gall"], "year": 2012, "n_citations": 158}
{"id": 5084868, "s2_id": "4df2058ef2841fdffa6092555d2f0dea7434e39c", "title": "A Clever Elimination Strategy for Efficient Minimal Solvers", "abstract": "We present a new insight into the systematic generation of minimal solvers in computer vision, which leads to smaller and faster solvers. Many minimal problem formulations are coupled sets of linear and polynomial equations where image measurements enter the linear equations only. We show that it is useful to solve such systems by first eliminating all the unknowns that do not appear in the linear equations and then extending solutions to the rest of unknowns. This can be generalized to fully non-linear systems by linearization via lifting. We demonstrate that this approach leads to more efficient solvers in three problems of partially calibrated relative camera pose computation with unknown focal length and/or radial distortion. Our approach also generates new interesting constraints on the fundamental matrices of partially calibrated cameras, which were not known before.", "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Zuzana  Kukelova", "Joe  Kileel", "Bernd  Sturmfels", "Tom\u00e1s  Pajdla"], "year": 2017, "n_citations": 24}
{"id": 5092489, "s2_id": "2d38aa1ab11deb37a1f4e62484e1660a90eedc59", "title": "Using a computer algebra system to simplify expressions for Titchmarsh-Weyl m-functions associated with the Hydrogen Atom on the half line", "abstract": "In this paper we give simplified formulas for certain polynomials which arise in some new Titchmarsh-Weyl m-functions for the radial part of the separated Hydrogen atom on the half line and two independent programs for generating them using the symbolic manipulator Mathematica.", "venue": "ArXiv", "authors": ["Cecilia  Knoll", "Charles  Fulton"], "year": 2008, "n_citations": 4}
{"id": 5093850, "s2_id": "11d52123449daf2fb9a8f158030db8f4a5204c9d", "title": "An introspective algorithm for the integer determinant", "abstract": "We present an algorithm computing the determinant of an integer matrix A. The algorithm is introspective in the sense that it uses several distinct algorithms that run in a concurrent manner. During the course of the algorithm partial results coming from distinct methods can be combined. Then, depending on the current running time of each method, the algorithm can emphasize a particular variant. With the use of very fast modular routines for linear algebra, our implementation is an order of magnitude faster than other existing implementations. Moreover, we prove that the expected complexity of our algorithm is only O(n^3 log^{2.5}(n ||A||) ) bit operations in the dense case and O( Omega n^{1.5} log^2(n ||A||) + n^{2.5}log^3(n||A||) ) in the sparse case, where ||A|| is the largest entry in absolute value of the matrix and Omega is the cost of matrix-vector multiplication in the case of a sparse matrix.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Anna  Urbanska"], "year": 2005, "n_citations": 5}
{"id": 5096194, "s2_id": "a57766b6043cf17f13afad4b91cb6c1f05782582", "title": "On computation of the inverse of a polynomial map over finite fields using the reduced Koopman dual linear map", "abstract": "This paper proposes a symbolic representation of non-linear maps $F$ in $\\ff^n$ in terms of linear combination of basis functions of a subspace of $(\\ff^n)^0$, the dual space of $\\ff^n$. Using this representation, it is shown that the inverse of $F$ whenever it exists can also be represented in a similar symbolic form using the same basis functions (using different coefficients). This form of representation should be of importance to solving many problems of iterations or compositions of non-linear maps using linear algebraic methods which would otherwise require solving hard computational problems due to non-linear nature of $F$.", "venue": "ArXiv", "authors": ["Ramachandran  Anantharaman", "Virendra  Sule"], "year": 2020, "n_citations": 1}
{"id": 5100552, "s2_id": "79450fb77ea71a035d2b9ea805edb31b2c40b41d", "title": "A Successive Resultant Projection for Cylindrical Algebraic Decomposition", "abstract": "This note shows the equivalence of two projection operators which both can be used in cylindrical algebraic decomposition (CAD) . One is known as Brown's Projection (C. W. Brown (2001)); the other was proposed by Lu Yang in his earlier work (L.Yang and S.~H. Xia (2000)) that is sketched as follows: given a polynomial $f$ in $x_1,\\,x_2,\\,\\cdots$, by $f_1$ denote the resultant of $f$ and its partial derivative with respect to $x_1$ (removing the multiple factors), by $f_2$ denote the resultant of $f_1$ and its partial derivative with respect to $x_2$, (removing the multiple factors), $\\cdots$, repeat this procedure successively until the last resultant becomes a univariate polynomial. Making use of an identity, the equivalence of these two projection operators is evident.", "venue": "ArXiv", "authors": ["Yong  Yao", "Jia  Xu", "Lu  Yang"], "year": 2014, "n_citations": 1}
{"id": 5113650, "s2_id": "f4a0960f52028c58b5feed89c7834213abe95e8f", "title": "Closed form solutions of linear difference equations in terms of symmetric products", "abstract": "In this paper we show how to find a closed form solution for third order difference operators in terms of solutions of second order operators. This work is an extension of previous results on finding closed form solutions of recurrence equations and a counterpart to existing results on differential equations. As motivation and application for this work, we discuss the problem of proving positivity of sequences given merely in terms of their defining recurrence relation. The main advantage of the present approach to earlier methods attacking the same problem is that our algorithm provides human-readable and verifiable, i.e., certified proofs.", "venue": "J. Symb. Comput.", "authors": ["Yongjae  Cha"], "year": 2014, "n_citations": 2}
{"id": 5114091, "s2_id": "c2a7de60d7203f875467e7dd056831c393f5a0de", "title": "Stability and Bifurcation Analysis of Coupled Fitzhugh-Nagumo Oscillators", "abstract": "Neurons are the central biological objects in understanding how the brain works. The famous Hodgkin-Huxley model, which describes how action potentials of a neuron are initiated and propagated, consists of four coupled nonlinear differential equations. Because these equations are difficult to deal with, there also exist several simplified models, of which many exhibit polynomial-like non-linearity. Examples of such models are the Fitzhugh-Nagumo (FHN) model, the Hindmarsh-Rose (HR) model, the Morris-Lecar (ML) model and the Izhikevich model. In this work, we first prescribe the biologically relevant parameter ranges for the FHN model and subsequently study the dynamical behaviour of coupled neurons on small networks of two or three nodes. To do this, we use a computational real algebraic geometry method called the Discriminant Variety (DV) method to perform the stability and bifurcation analysis of these small networks. A time series analysis of the FHN model can be found elsewhere in related work[15].", "venue": "ArXiv", "authors": ["William  Hanan", "Dhagash  Mehta", "Guillaume  Moroz", "Sepanda  Pouryahya"], "year": 2010, "n_citations": 5}
{"id": 5114407, "s2_id": "4e206fb2fac4b9637a1c1d319337319b874fea25", "title": "Multi-Source Anomaly Detection in Distributed IT Systems", "abstract": "The multi-source data generated by distributed systems, provide a holistic description of the system. Harnessing the joint distribution of the different modalities by a learning model can be beneficial for critical applications for maintenance of the distributed systems. One such important task is the task of anomaly detection where we are interested in detecting the deviation of the current behaviour of the system from the theoretically expected. In this work, we utilize the joint representation from the distributed traces and system log data for the task of anomaly detection in distributed systems. We demonstrate that the joint utilization of traces and logs produced better results compared to the single modality anomaly detection methods. Furthermore, we formalize a learning task next template prediction NTP, that is used as a generalization for anomaly detection for both logs and distributed trace. Finally, we demonstrate that this formalization allows for the learning of template embedding for both the traces and logs. The joint embeddings can be reused in other applications as good initialization for spans and logs.", "venue": "ICSOC Workshops", "authors": ["Jasmin  Bogatinovski", "Sasho  Nedelkoski"], "year": 2020, "n_citations": 2}
{"id": 5123477, "s2_id": "42393e173a6bfb7f283f405bc7c8c8e224c777e4", "title": "Bit-size estimates for triangular sets in positive dimension", "abstract": "We give bit-size estimates for the coefficients appearing in triangular sets describing positive-dimensional algebraic sets defined over Q. These estimates are worst case upper bounds; they depend only on the degree and height of the underlying algebraic sets. We illustrate the use of these results in the context of a modular algorithm. This extends the results by the first and the last author, which were confined to the case of dimension 0. Our strategy is to get back to dimension 0 by evaluation and interpolation techniques. Even though the main tool (height theory) remains the same, new difficulties arise to control the growth of the coefficients during the interpolation process.", "venue": "J. Complex.", "authors": ["Xavier  Dahan", "Abdulilah  Kadri", "\u00c9ric  Schost"], "year": 2012, "n_citations": 19}
{"id": 5134854, "s2_id": "91e87ef26929cb0ff42364d93e2527d8be6dc0d2", "title": "SPPL: probabilistic programming with fast exact symbolic inference", "abstract": "We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic programming language that automatically delivers exact solutions to a broad range of probabilistic inference queries. SPPL translates probabilistic programs into sum-product expressions, a new symbolic representation and associated semantic domain that extends standard sum-product networks to support mixed-type distributions, numeric transformations, logical formulas, and pointwise and set-valued constraints. We formalize SPPL via a novel translation strategy from probabilistic programs to sum-product expressions and give sound exact algorithms for conditioning on and computing probabilities of events. SPPL imposes a collection of restrictions on probabilistic programs to ensure they can be translated into sum-product expressions, which allow the system to leverage new techniques for improving the scalability of translation and inference by automatically exploiting probabilistic structure. We implement a prototype of SPPL with a modular architecture and evaluate it on benchmarks the system targets, showing that it obtains up to 3500x speedups over state-of-the-art symbolic systems on tasks such as verifying the fairness of decision tree classifiers, smoothing hidden Markov models, conditioning transformed random variables, and computing rare event probabilities.", "venue": "PLDI", "authors": ["Feras A. Saad", "Martin C. Rinard", "Vikash K. Mansinghka"], "year": 2021, "n_citations": 2}
{"id": 5136639, "s2_id": "0e65a66c211b16513cdb629f814a15f04a6bd008", "title": "Baby-step giant-step algorithms for the symmetric group", "abstract": "Abstract We study discrete logarithms in the setting of group actions. Suppose that G is a group that acts on a set S . When r , s \u2208 S , a solution g \u2208 G to r g = s can be thought of as a kind of logarithm. In this paper, we study the case where G = S n and develop analogs to Shanks' baby-step / giant-step procedure for ordinary discrete logarithms. Specifically, we compute two sets A , B \u2286 S n such that every permutation of S n can be written as a product ab of elements a \u2208 A and b \u2208 B . Our deterministic procedure is optimal up to constant factors, in the sense that A and B can be computed in optimal asymptotic complexity, and | A | and | B | are a small constant from n ! in size. We also analyze randomized \u201ccollision\u201d algorithms for the same problem.", "venue": "J. Symb. Comput.", "authors": ["Eric  Bach", "Bryce  Sandlund"], "year": 2018, "n_citations": 0}
{"id": 5136872, "s2_id": "19fb68e3295c8ff4fb094279167d615ff12288a8", "title": "Iterative Variable Reordering: Taming Huge System Families", "abstract": "For the verification of systems using model-checking techniques, symbolic representations based on binary decision diagrams (BDDs) often help to tackle the well-known state-space explosion problem. Symbolic BDD-based representations have been also shown to be successful for the analysis of families of systems that arise, e.g., through configurable parameters or following the feature-oriented modeling approach. The state space of such system families face an additional exponential blowup in the number of parameters or features. It is well known that the order of variables in ordered BDDs is crucial for the size of the model representation. Especially for automatically generated models from real-world systems, family models might even be not constructible due to bad variable orders. In this paper we describe a technique, called iterative variable reordering, that can enable the construction of large-scale family models. We exemplify feasibility of our approach by means of an aircraft velocity control system with redundancy mechanisms modeled in the input language of the probabilistic model checker PRISM. We show that standard reordering and dynamic reordering techniques fail to construct the family model due to memory and time constraints, respectively, while the new iterative approach succeeds to generate a symbolic family model.", "venue": "MARS@ETAPS", "authors": ["Clemens  Dubslaff", "Andrey  Morozov", "Christel  Baier", "Klaus  Janschek"], "year": 2020, "n_citations": 1}
{"id": 5142273, "s2_id": "56c716b8c51a3acf307bcc9f2c2cf445360d452a", "title": "ModelingToolkit: A Composable Graph Transformation System For Equation-Based Modeling", "abstract": "Getting good performance out of numerical equation solvers requires that the user has provided stable and efficient functions representing their model. However, users should not be trusted to write good code. In this manuscript we describe ModelingToolkit (MTK), a symbolic equationbased modeling system which allows for composable transformations to generate stable, efficient, and parallelized model implementations. MTK blurs the lines of traditional symbolic computing by acting directly on a user\u2019s numerical code. We show the ability to apply graph algorithms for automatically parallelizing and performing index reduction on code written for differential-algebraic equation (DAE) solvers, \u201cfixing\u201d the performance and stability of the model without requiring any changes to on the user\u2019s part. We demonstrate how composable model transformations can be combined with automated data-driven surrogate generation techniques, allowing machine learning methods to generate accelerated approximate models within an acausal modeling framework. These reduced models are shown to outperform the Dymola Modelica compiler on an HVAC model by 590x at 3% error. Together, this demonstrates MTK as a system for bringing the latest research in graph transformations directly to modeling applications.", "venue": "ArXiv", "authors": ["Yingbo  Ma", "Shashi  Gowda", "Ranjan  Anantharaman", "Chris  Laughman", "Viral  Shah", "Chris  Rackauckas"], "year": 2021, "n_citations": 13}
{"id": 5142927, "s2_id": "ccdd627f9b8a0fae3268ccc765890dbaa2310640", "title": "Fast Derivatives for Multilinear Polynomials", "abstract": "The article considers linear functions of many (n) variables - multilinear polynomials (MP). The three-steps evaluation is presented that uses the minimal possible number of floating point operations for non-sparse MP at each step. The minimal number of additions is achieved in the algorithm for fast MP derivatives (FMPD) calculation. The cost of evaluating all first derivatives approaches to only 1/8 of MP evaluation with a growing number of variables. The FMPD algorithm structure exhibits similarity to the Fast Fourier Transformation (FFT) algorithm.", "venue": "ArXiv", "authors": ["Valeri  Aronov"], "year": 2019, "n_citations": 0}
{"id": 5149147, "s2_id": "4e871d651df3f13c039d0fabc1181fdcc606281e", "title": "Noether's forms for the study of non-composite rational functions and their spectrum", "abstract": "In this paper, the spectrum and the decomposability of a multivariate rational function are studied by means of the effective Noether's irreducibility theorem given by Ruppert. With this approach, some new effective results are obtained. In particular, we show that the reduction modulo p of the spectrum of a given integer multivariate rational function r coincides with the spectrum of the reduction of r modulo p for p a prime integer greater or equal to an explicit bound. This bound is given in terms of the degree, the height and the number of variables of r. With the same strategy, we also study the decomposability of r modulo p. Some similar explicit results are also provided for the case of polynomials with coefficients in a polynomial ring.", "venue": "ArXiv", "authors": ["Laurent  Bus\u00e9", "Guillaume  Ch\u00e8ze", "Salah  Najib"], "year": 2009, "n_citations": 9}
{"id": 5149920, "s2_id": "0247e0f430b020ed7ae01603108c06b2ac677539", "title": "On functional decomposition of multivariate polynomials with differentiation and homogenization", "abstract": "This paper gives a theoretical analysis for the algorithms to compute functional decomposition for multivariate polynomials based on differentiation and homogenization which were proposed by Ye, Dai, and Lam (1999) and were developed by Faug\u00e8re, Perret (2006, 2008, 2009). The authors show that a degree proper functional decomposition for a set of randomly decomposable quartic homogenous polynomials can be computed using the algorithm with high probability. This solves a conjecture proposed by Ye, Dai, and Lam (1999). The authors also propose a conjecture which asserts that the decomposition for a set of polynomials can be computed from that of its homogenization and show that the conjecture is valid with high probability for quartic polynomials. Finally, the authors prove that the right decomposition factors for a set of polynomials can be computed from its right decomposition factor space.", "venue": "J. Syst. Sci. Complex.", "authors": ["Shang-Wei  Zhao", "Ruyong  Feng", "Xiao-Shan  Gao"], "year": 2010, "n_citations": 0}
{"id": 5159491, "s2_id": "204bfac7a782e5620afebe391d0d63819281b5e0", "title": "Block-Krylov techniques in the context of sparse-FGLM algorithms", "abstract": "Consider a zero-dimensional ideal $I$ in $\\mathbb{K}[X_1,\\dots,X_n]$. Inspired by Faugere and Mou's Sparse FGLM algorithm, we use Krylov sequences based on multiplication matrices of $I$ in order to compute a description of its zero set by means of univariate polynomials. \n \nSteel recently showed how to use Coppersmith's block-Wiedemann algorithm in this context; he describes an algorithm that can be easily parallelized, but only computes parts of the output in this manner. Using generating series expressions going back to work of Bostan, Salvy, and Schost, we show how to compute the entire output for a small overhead, without making any assumption on the ideal I other than it having dimension zero. We then propose a refinement of this idea that partially avoids the introduction of a generic linear form. We comment on experimental results obtained by an implementation based on the C++ libraries LinBox, Eigen and NTL.", "venue": "J. Symb. Comput.", "authors": ["Seung Gyu Hyun", "Vincent  Neiger", "Hamid  Rahkooy", "\u00c9ric  Schost"], "year": 2020, "n_citations": 4}
{"id": 5165704, "s2_id": "4f198224ef6cef8dfadd4a20b68c43f4fad23cc1", "title": "Multiplication of sparse Laurent polynomials and Poisson series on modern hardware architectures", "abstract": "In this paper we present two algorithms for the multiplication of sparse Laurent polynomials and Poisson series (the latter being algebraic structures commonly arising in Celestial Mechanics from the application of perturbation theories). Both algorithms first employ the Kronecker substitution technique to reduce multivariate multiplication to univariate multiplication, and then use the schoolbook method to perform the univariate multiplication. The first algorithm, suitable for moderately-sparse multiplication, uses the exponents of the monomials resulting from the univariate multiplication as trivial hash values in a one dimensional lookup array of coefficients. The second algorithm, suitable for highly-sparse multiplication, uses a cache-optimised hash table which stores the coefficient-exponent pairs resulting from the multiplication using the exponents as keys. Both algorithms have been implemented with attention to modern computer hardware architectures. Particular care has been devoted to the efficient exploitation of contemporary memory hierarchies through cache-blocking techniques and cache-friendly term ordering. The first algorithm has been parallelised for shared-memory multicore architectures, whereas the second algorithm is in the process of being parallelised. We present benchmarks comparing our algorithms to the routines of other computer algebra systems, both in sequential and parallel mode.", "venue": "ArXiv", "authors": ["Francesco  Biscani"], "year": 2010, "n_citations": 1}
{"id": 5165907, "s2_id": "57a06b9ae412339636a3b5b9010f3c731f58f970", "title": "Quartic curves and their bitangents", "abstract": "A smooth quartic curve in the complex projective plane has 36 inequivalent representations as a symmetric determinant of linear forms and 63 representations as a sum of three squares. These correspond to Cayley octads and Steiner complexes respectively. We present exact algorithms for computing these objects from the 28 bitangents. This expresses Vinnikov quartics as spectrahedra and positive quartics as Gram matrices. We explore the geometry of Gram spectrahedra and we find equations for the variety of Cayley octads. Interwoven is an exposition of much of the 19th century theory of plane quartics.", "venue": "J. Symb. Comput.", "authors": ["Daniel  Plaumann", "Bernd  Sturmfels", "Cynthia  Vinzant"], "year": 2011, "n_citations": 66}
{"id": 5166535, "s2_id": "438e3b6bdc0e934aaa1636a1921b1c1a2f97296d", "title": "Positive Solutions of Systems of Signed Parametric Polynomial Inequalities", "abstract": "We consider systems of strict multivariate polynomial inequalities over the reals. All polynomial coefficients are parameters ranging over the reals, where for each coefficient we prescribe its sign. We are interested in the existence of positive real solutions of our system for all choices of coefficients subject to our sign conditions. We give a decision procedure for the existence of such solutions. In the positive case our procedure yields a parametric positive solution as a rational function in the coefficients. Our framework allows to reformulate heuristic subtropical approaches for non-parametric systems of polynomial inequalities that have been recently used in qualitative biological network analysis and, independently, in satisfiability modulo theory solving. We apply our results to characterize the incompleteness of those methods.", "venue": "CASC", "authors": ["Hoon  Hong", "Thomas  Sturm"], "year": 2018, "n_citations": 1}
{"id": 5180489, "s2_id": "9c8e50089b1e2229d701dd978cbaba1181c8d626", "title": "Signature Sequence of Intersection Curve of Two Quadrics for Exact Morphological Classification", "abstract": "We present an efficient method for classifying the morphology of the intersection curve of two quadrics (QSIC) in PR3, 3D real projective space; here, the term morphology is used in a broad sense to mean the shape, topological, and algebraic properties of a QSIC, including singularity, reducibility, the number of connected components, and the degree of each irreducible component, etc. There are in total 35 different QSIC morphologies with non-degenerate quadric pencils. For each of these 35 QSIC morphologies, through a detailed study of the eigenvalue curve and the index function jump we establish a characterizing algebraic condition expressed in terms of the Segre characteristics and the signature sequence of a quadric pencil. We show how to compute a signature sequence with rational arithmetic so as to determine the morphology of the intersection curve of any two given quadrics. Two immediate applications of our results are the robust topological classification of QSIC in computing B-rep surface representation in solid modeling and the derivation of algebraic conditions for collision detection of quadric primitives.", "venue": "ArXiv", "authors": ["Changhe  Tu", "Wenping  Wang", "Bernard  Mourrain", "Jiaye  Wang"], "year": 2007, "n_citations": 12}
{"id": 5180908, "s2_id": "0635cf9201d1eb0563831ed1350179aa48b9f1e5", "title": "Frobenius Additive Fast Fourier Transform", "abstract": "In ISSAC 2017, van der Hoeven and Larrieu showed that evaluating a polynomial P \u0131n Fq [x] of degree <n at all n -th roots of unity in Fqd can essentially be computed d times faster than evaluating Q \u0131n Fqd x at all these roots, assuming Fqd contains a primitive n -th root of unity. Termed the Frobenius FFT, this discovery has a profound impact on polynomial multiplication, especially for multiplying binary polynomials, which finds ample application in coding theory and cryptography. In this paper, we show that the theory of Frobenius FFT beautifully generalizes to a class of additive FFT developed by Cantor and Gao-Mateer. Furthermore, we demonstrate the power of Frobenius additive FFT for q=2: to multiply two binary polynomials whose product is of degree <256, the new technique requires only 29,005 bit operations, while the best result previously reported was 33,397. To the best of our knowledge, this is the first time that FFT-based multiplication outperforms Karatsuba and the like at such a low degree in terms of bit-operation count.", "venue": "ISSAC", "authors": ["Wen-Ding  Li", "Ming-Shing  Chen", "Po-Chun  Kuo", "Chen-Mou  Cheng", "Bo-Yin  Yang"], "year": 2018, "n_citations": 5}
{"id": 5190630, "s2_id": "26a5f6e6f7abdc995db8136910dc2acd06c471c7", "title": "Computing the Volume of Compact Semi-Algebraic Sets", "abstract": "Let S\\subset \\bR^n be a compact basic semi-algebraic set defined as the real solution set of multivariate polynomial inequalities with rational coefficients. We design an algorithm which takes as input a polynomial system defining S and an integer p\\geq 0 and returns the n-dimensional volume of S at absolute precision 2^-p . Our algorithm relies on the relationship between volumes of semi-algebraic sets and periods of rational integrals. It makes use of algorithms computing the Picard-Fuchs differential equation of appropriate periods, properties of critical points, and high-precision numerical integration of differential equations. The algorithm runs in essentially linear time with respect to~p. This improves upon the previous exponential bounds obtained by Monte-Carlo or moment-based methods. Assuming a conjecture of Dimca, the arithmetic cost of the algebraic subroutines for computing Picard-Fuchs equations and critical points is singly exponential in n and polynomial in the maximum degree of the input.", "venue": "ISSAC", "authors": ["Pierre  Lairez", "Marc  Mezzarobba", "Mohab Safey El Din"], "year": 2019, "n_citations": 9}
{"id": 5190812, "s2_id": "6b2da13fb71ce2101657937fc852ca7e56dfe2c2", "title": "Real Root Finding for Rank Defects in Linear Hankel Matrices", "abstract": "Let H0, \u2026, H n be m x m matrices with entries in Q and Hankel structure, i.e. constant skew diagonals. We consider the linear Hankel matrix H(x) = H0+x1H_1+\u2026+xnHn and the problem of computing sample points in each connected component of the real algebraic set defined by the rank constraint rank}(H(x))\u2264 r, for a given integer r \u2264 m-1. Computing sample points in real algebraic sets defined by rank defects in linear matrices is a general problem that finds applications in many areas such as control theory, computational geometry, optimization, etc. Moreover, Hankel matrices appear in many areas of engineering sciences. Also, since Hankel matrices are symmetric, any algorithmic development for this problem can be seen as a first step towards a dedicated exact algorithm for solving semi-definite programming problems, i.e. linear matrix inequalities. Under some genericity assumptions on the input (such as smoothness of an incidence variety), we design a probabilistic algorithm for tackling this problem. It is an adaptation of the so-called critical point method that takes advantage of the special structure of the problem. Its complexity reflects this: it is essentially quadratic in specific degree bounds on an incidence variety. We report on practical experiments and analyze how the algorithm takes advantage of this special structure. A first implementation outperforms existing implementations for computing sample points in general real algebraic sets: it tackles examples that are out of reach of the state-of-the-art.", "venue": "ISSAC", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2015, "n_citations": 9}
{"id": 5193766, "s2_id": "33a945b5563439432f6bc990c96727967f9aff45", "title": "A Case Study on the Parametric Occurrence of Multiple Steady States", "abstract": "We consider the problem of determining multiple steady states for positive real values in models of biological networks. Investigating the potential for these in models of the mitogen-activated protein kinases (MAPK) network has consumed considerable effort using special insights into the structure of corresponding models. Here we apply combinations of symbolic computation methods for mixed equality/inequality systems, specifically virtual substitution, lazy real triangularization and cylindrical algebraic decomposition. We determine multistationarity of an 11-dimensional MAPK network when numeric values are known for all but potentially one parameter. More precisely, our considered model has 11 equations in 11 variables and 19 parameters, 3 of which are of interest for symbolic treatment, and furthermore positivity conditions on all variables and parameters.", "venue": "ISSAC", "authors": ["Russell J. Bradford", "James H. Davenport", "Matthew  England", "Hassan  Errami", "Vladimir P. Gerdt", "Dima  Grigoriev", "Charles Tapley Hoyt", "Marek  Kosta", "Ovidiu  Radulescu", "Thomas  Sturm", "Andreas  Weber"], "year": 2017, "n_citations": 31}
{"id": 5195640, "s2_id": "f9977d450940d8226fd0d00bf0816498872b9b2c", "title": "Synthesis of minimal-error control software", "abstract": "Software implementations of controllers for physical systems are at the core of many embedded systems. The design of controllers uses the theory of dynamical systems to construct a mathematical control law that ensures that the controlled system has certain properties, such as asymptotic convergence to an equilibrium point, and optimizes some performance criteria such as LQR-LQG. However, owing to quantization errors arising from the use of fixed-point arithmetic, the implementation of this control law can only guarantee practical stability: under the actions of the implementation, the trajectories of the controlled system converge to a bounded set around the equilibrium point, and the size of the bounded set is proportional to the error in the implementation. The problem of verifying whether a controller implementation achieves practical stability for a given bounded set has been studied before. In this paper, we change the emphasis from verification to automatic synthesis. We give a technique to synthesize embedded control software that is Pareto optimal w.r.t. both performance criteria and practical stability regions. Our technique uses static analysis to estimate quantization-related errors for specific controller implementations, and performs stochastic local search over the space of possible controllers using particle swarm optimization. The effectiveness of our technique is illustrated using several standard control system examples: in most examples, we find controllers with close-to-optimal LQR-LQG performance but with implementation errors, hence regions of practical stability, several times as small.", "venue": "EMSOFT '12", "authors": ["Rupak  Majumdar", "Indranil  Saha", "Majid  Zamani"], "year": 2012, "n_citations": 34}
{"id": 5201875, "s2_id": "143cf3eed6a5344c2b3ec513ab38d7621287c7ba", "title": "From Abstract Rewriting Systems to Abstract Proof Systems", "abstract": "Some personal recollections on the introduction of `abstract proof systems' as a framework for formulating syntax-independent, general results about rule derivability and admissibility. With a particular eye on the inspiration I owe to Roel de Vrijer: the analogy with abstract rewriting systems.", "venue": "ArXiv", "authors": ["Clemens  Grabmayer"], "year": 2009, "n_citations": 1}
{"id": 5202499, "s2_id": "24f909a177ed10e3e44703ce1f6b6c616444f332", "title": "Essentially optimal interactive certificates in linear algebra", "abstract": "Certificates to a linear algebra computation are additional data structures for each output, which can be used by a---possibly randomized---verification algorithm that proves the correctness of each output. The certificates are essentially optimal if the time (and space) complexity of verification is essentially linear in the input size <i>N</i>, meaning <i>N</i> times a factor <i>N</i><sup><i>o</i>(1)</sup>, i.e., a factor <i>N</i><sup><i>\u03b7</i>(<i>N</i>)</sup> with lim<sub><i>N</i> \u2192 \u221e</sub> \u03b7(<i>N</i>) = 0.\n We give algorithms that compute essentially optimal certificates for the positive semidefiniteness, Frobenius form, characteristic and minimal polynomial of an <i>n \u00d7 n</i> dense integer matrix <i>A</i>. Our certificates can be verified in Monte-Carlo bit complexity (<i>n</i><sup>2</sup> log ||<i>A</i>||)<sup>1+o(1)</sup>, where log ||A|| is the bit size of the integer entries, solving an open problem in [Kaltofen, Nehring, Saunders, Proc. ISSAC 2011] subject to computational hardness assumptions.\n Second, we give algorithms that compute certificates for the rank of sparse or structured <i>n \u00d7 n</i> matrices over an abstract field, whose Monte Carlo verification complexity is 2 matrix-times-vector products + <i>n</i><sup>1+o(1)</sup> arithmetic operations in the field. For example, if the <i>n \u00d7 n</i> input matrix is sparse with <i>n</i><sup>1+o(1)</sup> non-zero entries, our rank certificate can be verified in <i>n</i><sup>1+o(1)</sup> field operations. This extends also to integer matrices with only an extra log ||<i>A</i>||<sup>1+o(1)</sup> factor.\n All our certificates are based on interactive verification protocols with the interaction removed by a Fiat-Shamir identification heuristic. The validity of our verification procedure is subject to standard computational hardness assumptions from cryptography.", "venue": "ISSAC", "authors": ["Jean-Guillaume  Dumas", "Erich  Kaltofen"], "year": 2014, "n_citations": 14}
{"id": 5206114, "s2_id": "4c5c391295f0987e8de7faeef8a96b4c30def57c", "title": "Numeric certified algorithm for the topology of resultant and discriminant curves", "abstract": "Let $\\mathcal C$ be a real plane algebraic curve defined by the resultant of \n two polynomials (resp. by the discriminant of a polynomial). Geometrically \n such a curve is the projection of the intersection of the surfaces \n $P(x,y,z)=Q(x,y,z)=0$ (resp. \n $P(x,y,z)=\\frac{\\partial P}{\\partial z}(x,y,z)=0$), and generically its \n singularities are nodes (resp. nodes and ordinary cusps). State-of-the-art \n numerical algorithms compute the topology of smooth curves but usually fail to \n certify the topology of singular ones. The main challenge is to find practical \n numerical criteria that guarantee the existence and the uniqueness of a \n singularity inside a given box $B$, while ensuring that $B$ does not contain \n any closed loop of $\\mathcal{C}$. We solve this problem by first providing a \n square deflation system, based on subresultants, that can be used to certify \n numerically whether $B$ contains a unique singularity $p$ or not. Then we \n introduce a numeric adaptive separation criterion based on interval arithmetic \n to ensure that the topology of $\\mathcal C$ in $B$ is homeomorphic to the \n local topology at $p$. Our algorithms are implemented and experiments show \n their efficiency compared to state-of-the-art symbolic or homotopic methods.", "venue": "ArXiv", "authors": ["Guillaume  Moroz", "Marc  Pouget"], "year": 2014, "n_citations": 4}
{"id": 5206456, "s2_id": "05145baf2093c0ce7e814b6a6a3f130f95273904", "title": "Counting points on hyperelliptic curves with explicit real multiplication in arbitrary genus", "abstract": "We present a probabilistic Las Vegas algorithm for computing the local zeta function of a genus-$g$ hyperelliptic curve defined over $\\mathbb F_q$ with explicit real multiplication (RM) by an order $\\Z[\\eta]$ in a degree-$g$ totally real number field. \nIt is based on the approaches by Schoof and Pila in a more favorable case where we can split the $\\ell$-torsion into $g$ kernels of endomorphisms, as introduced by Gaudry, Kohel, and Smith in genus 2. To deal with these kernels in any genus, we adapt a technique that the author, Gaudry, and Spaenlehauer introduced to model the $\\ell$-torsion by structured polynomial systems. Applying this technique to the kernels, the systems we obtain are much smaller and so is the complexity of solving them. \nOur main result is that there exists a constant $c>0$ such that, for any fixed $g$, this algorithm has expected time and space complexity $O((\\log q)^{c})$ as $q$ grows and the characteristic is large enough. We prove that $c\\le 8$ and we also conjecture that the result still holds for $c=6$.", "venue": "J. Complex.", "authors": ["Simon  Abelard"], "year": 2020, "n_citations": 4}
{"id": 5207871, "s2_id": "5919083bac296911c0a2c4c79c94b67db336faff", "title": "ENIGMA Anonymous: Symbol-Independent Inference Guiding Machine (System Description)", "abstract": "We describe an implementation of gradient boosting and neural guidance of saturation-style automated theorem provers that does not depend on consistent symbol names across problems. For the gradient-boosting guidance, we manually create abstracted features by considering arity-based encodings of formulas. For the neural guidance, we use symbol-independent graph neural networks (GNNs) and their embedding of the terms and clauses. The two methods are efficiently implemented in the E prover and its ENIGMA learning-guided framework. To provide competitive real-time performance of the GNNs, we have developed a new context-based approach to evaluation of generated clauses in E. Clauses are evaluated jointly in larger batches and with respect to a large number of already selected clauses (context) by the GNN that estimates their collectively most useful subset in several rounds of message passing. This means that approximative inference rounds done by the GNN are efficiently interleaved with precise symbolic inference rounds done inside E. The methods are evaluated on the MPTP large-theory benchmark and shown to achieve comparable real-time performance to state-of-the-art symbol-based methods. The methods also show high complementarity, solving a large number of hard Mizar problems.", "venue": "IJCAR", "authors": ["Jan  Jakubuv", "Karel  Chvalovsk\u00fd", "Miroslav  Ols\u00e1k", "Bartosz  Piotrowski", "Martin  Suda", "Josef  Urban"], "year": 2020, "n_citations": 14}
{"id": 5210610, "s2_id": "33f83c2341e10118deb453b55926a159e1379fe4", "title": "Solving Rank-Constrained Semidefinite Programs in Exact Arithmetic", "abstract": "We consider the problem of minimizing a linear function over an affine section of the cone of positive semidefinite matrices, with the additional constraint that the feasible matrix has prescribed rank. When the rank constraint is active, this is a non-convex optimization problem, otherwise it is a semidefinite program. Both find numerous applications especially in systems control theory and combinatorial optimization, but even in more general contexts such as polynomial optimization or real algebra. While numerical algorithms exist for solving this problem, such as interior-point or Newton-like algorithms, in this paper we propose an approach based on symbolic computation. We design an exact algorithm for solving rank-constrained semidefinite programs, whose complexity is essentially quadratic on natural degree bounds associated to the given optimization problem: for subfamilies of the problem where the size of the feasible matrix is fixed, the complexity is polynomial in the number of variables. The algorithm works under assumptions on the input data: we prove that these assumptions are generically satisfied. We also implement it in Maple and discuss practical experiments.", "venue": "ISSAC", "authors": ["Simone  Naldi"], "year": 2016, "n_citations": 8}
{"id": 5238795, "s2_id": "880e76174184211c33df2c58a842c0a2afb5b3a5", "title": "A complete algorithm to find exact minimal polynomial by approximations", "abstract": "Based on an improved parameterized integer relation construction method, a complete algorithm is proposed for finding an exact minimal polynomial from its approximate root. It relies on a study of the error controlling for its approximation. We provide a sufficient condition on the precision of the approximation, depending only on the degree and the height of its minimal polynomial. Our result is superior to the existent error controlling on obtaining an exact rational or algebraic number from its approximation. Moreover, some applications are presented and compared with the subsistent methods.", "venue": "Int. J. Comput. Math.", "authors": ["Xiaolin  Qin", "Yong  Feng", "Jingwei  Chen", "Jingzhong  Zhang"], "year": 2012, "n_citations": 6}
{"id": 5246726, "s2_id": "65223d5303cdd108c3b4c386bdc6a10fd2ca857a", "title": "Experience with Heuristics, Benchmarks & Standards for Cylindrical Algebraic Decomposition", "abstract": "In the paper which inspired the SC-Square project, [E. Abraham, Building Bridges between Symbolic Computation and Satisfiability Checking, Proc. ISSAC '15, pp. 1-6, ACM, 2015] the author identified the use of sophisticated heuristics as a technique that the Satisfiability Checking community excels in and from which it is likely the Symbolic Computation community could learn and prosper. To start this learning process we summarise our experience with heuristic development for the computer algebra algorithm Cylindrical Algebraic Decomposition. We also propose and discuss standards and benchmarks as another area where Symbolic Computation could prosper from Satisfiability Checking expertise, noting that these have been identified as initial actions for the new SC-Square community in the CSA project, as described in [E.~Abraham et al., SC$^2$: Satisfiability Checking meets Symbolic Computation (Project Paper)}, Intelligent Computer Mathematics (LNCS 9761), pp. 28--43, Springer, 2015].", "venue": "SC\u00b2@SYNASC", "authors": ["Matthew  England", "James H. Davenport"], "year": 2016, "n_citations": 5}
{"id": 5247194, "s2_id": "41bc8ad57ae622a88de5611c4933a77a5cc5cdcc", "title": "Symbolic integration by integrating learning models with different strengths and weaknesses", "abstract": "Integration is indispensable, not only in mathematics, but also in a wide range of other fields. A deep learning method has recently been developed and shown to be capable of integrating mathematical functions that could not previously be integrated on a computer. However, that method treats integration as equivalent to natural language translation and does not reflect mathematical information. In this study, we adjusted the learning model to take mathematical information into account and developed a wide range of learning models that learn the order of numerical operations more robustly. In this way, we achieved a 98.80% correct answer rate with symbolic integration, a higher rate than that of any existing method. We judged the correctness of the integration based on whether the derivative of the primitive function was consistent with the integrand. By building an integrated model based on this strategy, we achieved a 99.79% rate of correct answers with symbolic integration.", "venue": "ArXiv", "authors": ["Hazumi  Kubota", "Yuta  Tokuoka", "Takahiro G. Yamada", "Akira  Funahashi"], "year": 2021, "n_citations": 0}
{"id": 5248114, "s2_id": "05f230b51b92cd4083dde26075da24b0cb5edbe4", "title": "Calculating three loop ladder and V-topologies for massive operator matrix elements by computer algebra", "abstract": "Abstract Three loop ladder and V -topology diagrams contributing to the massive operator matrix element A Q g are calculated. The corresponding objects can all be expressed in terms of nested sums and recurrences depending on the Mellin variable N and the dimensional parameter e . Given these representations, the desired Laurent series expansions in e can be obtained with the help of our computer algebra toolbox. Here we rely on generalized hypergeometric functions and Mellin\u2013Barnes representations, on difference ring algorithms for symbolic summation, on an optimized version of the multivariate Almkvist\u2013Zeilberger algorithm for symbolic integration, and on new methods to calculate Laurent series solutions of coupled systems of differential equations. The solutions can be computed for general coefficient matrices directly for any basis also performing the expansion in the dimensional parameter in case it is expressible in terms of indefinite nested product\u2013sum expressions. This structural result is based on new results of our difference ring theory. In the cases discussed we deal with iterative sum- and integral-solutions over general alphabets. The final results are expressed in terms of special sums, forming quasi-shuffle algebras, such as nested harmonic sums, generalized harmonic sums, and nested binomially weighted (cyclotomic) sums. Analytic continuations to complex values of N are possible through the recursion relations obeyed by these quantities and their analytic asymptotic expansions. The latter lead to a host of new constants beyond the multiple zeta values, the infinite generalized harmonic and cyclotomic sums in the case of V -topologies.", "venue": "Comput. Phys. Commun.", "authors": ["Jakob  Ablinger", "Arnd  Behring", "Johannes  Bl\u00fcmlein", "Abilio De Freitas", "A. von Manteuffel", "Carsten  Schneider"], "year": 2016, "n_citations": 94}
{"id": 5249399, "s2_id": "c80cc9a67b343f6f862496b5522230c36c5a71f0", "title": "Explicit formula for the generating series of diagonal 3D rook paths", "abstract": "Let $a_n$ denote the number of ways in which a chess rook can move from a corner cell to the opposite corner cell of an $n \\times n \\times n$ three-dimensional chessboard, assuming that the piece moves closer to the goal cell at each step. We describe the computer-driven \\emph{discovery and proof\\/} of the fact that the generating series $G(x)= \\sum_{n \\geq 0} a_n x^n$ admits the following explicit expression in terms of a Gaussian hypergeometric function: \\[ G(x) = 1 + 6 \\cdot \\int_0^x \\frac{ \\,\\pFq21{1/3}{2/3}{2} {\\frac{27 w(2-3w)}{(1-4w)^3}}}{(1-4w)(1-64w)} \\, dw. \\]", "venue": "ArXiv", "authors": ["Alin  Bostan", "Fr\u00e9d\u00e9ric  Chyzak", "Mark van Hoeij", "Lucien  Pech"], "year": 2011, "n_citations": 25}
{"id": 5250967, "s2_id": "cf8f66be9c68c8f8f32118fda7ba3346b4d8b7c2", "title": "Efficient Algorithm for the Linear Complexity of Sequences and Some Related Consequences", "abstract": "The linear complexity of a sequence s is one of the measures of its predictability. It represents the smallest degree of a linear recursion which the sequence satisfies. There are several algorithms to find the linear complexity of a periodic sequence s of length N (where N is of some given form) over a finite field ${\\mathbb{F}_q}$ in O(N) symbol field operations. The first such algorithm is The Games-Chan Algorithm which considers binary sequences of period 2n, and is known for its extreme simplicity. We generalize this algorithm and apply it efficiently for several families of binary sequences. Our algorithm is very simple, it requires \u03b2N bit operations for a small constant \u03b2, where N is the period of the sequence. We make an analysis on the number of bit operations required by the algorithm and compare it with previous algorithms. In the process, the algorithm also finds the recursion for the shortest linear feedback shift-register which generates the sequence. Some other interesting properties related to shift-register sequences, which might not be too surprising but generally unnoted, are also consequences of our exposition.", "venue": "2020 IEEE International Symposium on Information Theory (ISIT)", "authors": ["Yeow Meng Chee", "Johan  Chrisnata", "Tuvi  Etzion", "Han Mao Kiah"], "year": 2020, "n_citations": 0}
{"id": 5254053, "s2_id": "4840f05e5aaef07b9b0a2ea71d7b8dc64b1f0d33", "title": "Enhancing Linear Algebraic Computation of Logic Programs Using Sparse Representation", "abstract": "Algebraic characterization of logic programs has received increasing attention in recent years. Researchers attempt to exploit connections between linear algebraic computation and symbolic computation in order to perform logical inference in large scale knowledge bases. This paper proposes further improvement by using sparse matrices to embed logic programs in vector spaces. We show its great power of computation in reaching the fixpoint of the immediate consequence operator from the initial vector. In particular, performance for computing the least models of definite programs is dramatically improved in this way. We also apply the method to the computation of stable models of normal programs, in which the guesses are associated with initial matrices, and verify its effect when there are small numbers of negation. These results show good enhancement in terms of performance for computing consequences of programs and depict the potential power of tensorized logic programs.", "venue": "ICLP Technical Communications", "authors": ["Tuan Nguyen Quoc", "Katsumi  Inoue", "Chiaki  Sakama"], "year": 2020, "n_citations": 3}
{"id": 5254325, "s2_id": "e62439938b591f5b47072eaa946d161c8bf322ae", "title": "Advanced Computer Algebra for Determinants", "abstract": "We prove three conjectures concerning the evaluation of determinants, which are related to the counting of plane partitions and rhombus tilings. One of them was posed by George Andrews in 1980, the other two were by Guoce Xin and Christian Krattenthaler. Our proofs employ computer algebra methods, namely, the holonomic ansatz proposed by Doron Zeilberger and variations thereof. These variations make Zeilberger\u2019s original approach even more powerful and allow for addressing a wider variety of determinants. Finally, we present, as a challenge problem, a conjecture about a closed-form evaluation of Andrews\u2019s determinant.", "venue": "ArXiv", "authors": ["Christoph  Koutschan", "Thotsaporn Aek Thanatipanonda"], "year": 2011, "n_citations": 10}
{"id": 5255452, "s2_id": "57c66e150caa3d3d2ee5633c4015fe94672a0976", "title": "Towards a diagrammatic modeling of the LinBox C++ linear algebra library", "abstract": "We propose a new diagrammatic modeling language, DML. The paradigm used is that of the category theory and in particular of the pushout tool. We show that most of the object-oriented structures can be described with this tool and have many examples in C++, ranging from virtual inheritance and polymorphism to template genericity. With this powerful tool, we propose a quite simple description of the C++ LinBox library. This library has been designed for efficiency and genericity and therefore makes heavy usage of complex template and polymorphic mecanism. Be reverse engineering, we are able to describe in a simple manner the complex structure of archetypes in LinBox.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Dominique  Duval"], "year": 2005, "n_citations": 1}
{"id": 5255743, "s2_id": "097c654f7d5023a408bafa826df69b3a417d8953", "title": "Cryptanalysis of HFE", "abstract": "I transform the trapdoor problem of HFE into a linear algebra problem.", "venue": "IACR Cryptol. ePrint Arch.", "authors": ["Ilia  Toli"], "year": 2003, "n_citations": 14}
{"id": 5257481, "s2_id": "2af1d4516f4b508f0d8770505dff404a29d0458c", "title": "On the Parameterized Complexity of Associative and Commutative Unification", "abstract": "This paper studies the unification problem with associative, commutative, and associative-commutative functions. The parameterized complexity is analyzed with respect to the parameter \u201cnumber of variables\u201d. It is shown that both the associative and associative-commutative unification problems are \\(W[1]\\)-hard. For commutative unification, a polynomial-time algorithm is presented in which the number of variables is assumed to be a constant. Some related results for the string and tree edit distance problems with variables are also presented.", "venue": "IPEC", "authors": ["Tatsuya  Akutsu", "Takeyuki  Tamura", "Atsuhiro  Takasu"], "year": 2014, "n_citations": 1}
{"id": 5261555, "s2_id": "eddbf90b3e37f8a5a96d1225c4a77e2f256e3abd", "title": "A Prototype for Educational Planning Using Course Constraints to Simulate Student Populations", "abstract": "Distance learning universities usually afford their students the flexibility to advance their studies at their own pace. This can lead to a considerable fluctuation of student populations within a program's courses, possibly affecting the academic viability of a program as well as the related required resources. Providing a method that estimates this population could be of substantial help to university management and academic personnel. We describe how to use course precedence constraints to calculate alternative tuition paths and then use Markov models to estimate future populations. In doing so, we identify key issues of a large scale potential deployment.", "venue": "Int. J. Artif. Intell. Tools", "authors": ["Thanasis  Hadzilacos", "Dimitrios  Kalles", "Dimitrios  Koumanakos", "Vassilis  Mitsionis"], "year": 2009, "n_citations": 0}
{"id": 5278151, "s2_id": "30998750bc2fa5671d9b4772b3cd9febff12d7c5", "title": "Ore Polynomials in Sage", "abstract": "We present a Sage implementation of Ore algebras. The main features for the most common instances include basic arithmetic and actions; GCRD and LCLM; D-finite closure properties; natural transformations between related algebras; guessing; desingularization; solvers for polynomials, rational functions and (generalized) power series. This paper is a tutorial on how to use the package.", "venue": "Computer Algebra and Polynomials", "authors": ["Manuel  Kauers", "Maximilian  Jaroschek", "Fredrik  Johansson"], "year": 2015, "n_citations": 47}
{"id": 5281269, "s2_id": "340a114fdac65a5e84aa5282f29ee040721c7f9c", "title": "A categorical programming language", "abstract": "A theory of data types based on category theory is presented. We organize data types under a new categorical notion of F,G-dialgebras which is an extension of the notion of adjunctions as well as that of T-algebras. T-algebras are also used in domain theory, but while domain theory needs some primitive data types, like products, to start with, we do not need any. Products, coproducts and exponentiations (i.e. function spaces) are defined exactly like in category theory using adjunctions. F,G-dialgebras also enable us to define the natural number object, the object for finite lists and other familiar data types in programming. Furthermore, their symmetry allows us to have the dual of the natural number object and the object for infinite lists (or lazy lists). We also introduce a programming language in a categorical style using F,G-dialgebras as its data type declaration mechanism. We define the meaning of the language operationally and prove that any program terminates using Tait's computability method.", "venue": "ArXiv", "authors": ["Tatsuya  Hagino"], "year": 2020, "n_citations": 56}
{"id": 5283191, "s2_id": "b3d1cec974491577184da7599f1e973ccf7aa662", "title": "A linear algebra approach to the differentiation index of generic DAE systems", "abstract": "The notion of differentiation index for DAE systems of arbitrary order with generic second members is discussed by means of the study of the behavior of the ranks of certain Jacobian associated sub-matrices. As a by-product, we obtain upper bounds for the regularity of the Hilbert\u2013Kolchin function and the order of the ideal associated to the DAE systems under consideration, not depending on characteristic sets. Some quantitative and algorithmic results concerning differential transcendence bases and induced equivalent explicit ODE systems are also established.", "venue": "Applicable Algebra in Engineering, Communication and Computing", "authors": ["Lisi  D'Alfonso", "Gabriela  Jeronimo", "Pablo  Solern\u00f3"], "year": 2008, "n_citations": 5}
{"id": 5291540, "s2_id": "4dda111dc1450f7bf0629418f55187cbce8482f0", "title": "List Decoding Algorithm based on Voting in Groebner Bases for General One-Point AG Codes", "abstract": "We generalize the unique decoding algorithm for one-point AG codes over the Miura-Kamiya C a b curves proposed by Lee et al. (2012) to general one-point AG codes, without any assumption. We also extend their unique decoding algorithm to list decoding, modify it so that it can be used with the Feng-Rao improved code construction, prove equality between its error correcting capability and half the minimum distance lower bound by Andersen and Geil (2008) that has not been done in the original proposal except for one-point Hermitian codes, remove the unnecessary computational steps so that it can run faster, and analyze its computational complexity in terms of multiplications and divisions in the finite field. As a unique decoding algorithm, the proposed one is empirically and theoretically as fast as the BMS algorithm for one-point Hermitian codes. As a list decoding algorithm, extensive experiments suggest that it can be much faster for many moderate size/usual inputs than the algorithm by Beelen and Brander (2010). It should be noted that as a list decoding algorithm the proposed method seems to have exponential worst-case computational complexity while the previous proposals (Beelen and Brander, 2010; Guruswami and Sudan, 1999) have polynomial ones, and that the proposed method is expected to be slower than the previous proposals for very large/special inputs.", "venue": "J. Symb. Comput.", "authors": ["Olav  Geil", "Ryutaroh  Matsumoto", "Diego  Ruano"], "year": 2017, "n_citations": 2}
{"id": 5292986, "s2_id": "18091d4ce3e5a8b576843961e3021d3be8c2ce39", "title": "Formulas as Programs", "abstract": "We provide here a computational interpretation of first-order logic based on a constructive interpretation of satisfiability w.r.t. a fixed but arbitrary interpretation. In this approach the \\emph{formulas} themselves are \\emph{programs}. This contrasts with the so-called \\emph{formulas as types} approach in which the proofs of the formulas are typed terms that can be taken as programs. This view of computing is inspired by logic programming and constraint logic programming but differs from them in a number of crucial aspects. Formulas as programs is argued to yield a realistic approach to programming that has been realized in the implemented programming language \\almazero{} \\citeasnoun{ABPS98a} that combines the advantages of imperative and logic programming. The work here reported can also be used to reason about the correctness of non-recursive \\almazero{} programs that do not include destructive assignment.", "venue": "The Logic Programming Paradigm", "authors": ["Krzysztof R. Apt", "Marc  Bezem"], "year": 1999, "n_citations": 16}
{"id": 5293747, "s2_id": "9c66c91a027a064d91160a36f8bd6f153616aa1e", "title": "Diversification improves interpolation", "abstract": "We consider the problem of interpolating an unknown multivariate polynomial with coefficients taken from a finite field or as numerical approximations of complex numbers. Building on the recent work of Garg and Schost, we improve on the best-known algorithm for interpolation over large finite fields by presenting a Las Vegas randomized algorithm that uses fewer black box evaluations. Using related techniques, we also address numerical interpolation of sparse polynomials with complex coefficients, and provide the first provably stable algorithm (in the sense of relative error) for this problem, at the cost of modestly more evaluations. A key new technique is a randomization which makes all coefficients of the unknown polynomial distinguishable, producing what we call a diverse polynomial. Another departure from most previous approaches is that our algorithms do not rely on root finding as a subroutine. We show how these improvements affect the practical performance with trial implementations.", "venue": "ISSAC '11", "authors": ["Mark  Giesbrecht", "Daniel S. Roche"], "year": 2011, "n_citations": 31}
{"id": 5296827, "s2_id": "a90f7b123eb92d4498dc5be4639317b9d75eb80e", "title": "On the length of integers in telescopers for proper hypergeometric terms", "abstract": "We show that the number of digits in the integers of a creative telescoping relation of expected minimal order for a bivariate proper hypergeometric term has essentially cubic growth with the problem size. For telescopers of higher order but lower degree we obtain a quintic bound. Experiments suggest that these bounds are tight. As applications of our results, we give an improved bound on the maximal possible integer root of the leading coefficient of a telescoper, and the first discussion of the bit complexity of creative telescoping.", "venue": "J. Symb. Comput.", "authors": ["Manuel  Kauers", "Lily  Yen"], "year": 2015, "n_citations": 5}
{"id": 5303262, "s2_id": "f75fdd206ba5bbcc2248b2b6a6ff3f4d07624576", "title": "ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians", "abstract": "The computation of first and second-order derivatives is a staple in many computing applications, ranging from machine learning to scientific computing. We propose an algorithm to automatically differentiate algorithms written in a subset of C99 code and its efficient implementation as a Python script. We demonstrate that our algorithm enables automatic, reliable, and efficient differentiation of common algorithms used in physical simulation and geometry processing.", "venue": "ArXiv", "authors": ["Deshana  Desai", "Etai  Shuchatowitz", "Zhongshi  Jiang", "Teseo  Schneider", "Daniele  Panozzo"], "year": 2020, "n_citations": 1}
{"id": 5307453, "s2_id": "10da7c1817c3b220848ca56aeb420b338964e3b8", "title": "Computing Nearby Non-trivial Smith Forms", "abstract": "We consider the problem of computing the nearest matrix polynomial with a non-trivial Smith Normal Form. We show that computing the Smith form of a matrix polynomial is amenable to numeric computation as an optimization problem. Furthermore, we describe an effective optimization technique to find a nearby matrix polynomial with a non-trivial Smith form. The results are later generalized to include the computation of a matrix polynomial having a maximum specified number of ones in the Smith Form (i.e., with a maximum specified McCoy rank). We discuss the geometry and existence of solutions and how our results can used for a backwards error analysis. We develop an optimization-based approach and demonstrate an iterative numerical method for computing a nearby matrix polynomial with the desired spectral properties. We also describe the implementation of our algorithms and demonstrate the robustness with examples in Maple.", "venue": "ISSAC", "authors": ["Mark  Giesbrecht", "Joseph  Haraldson", "George  Labahn"], "year": 2018, "n_citations": 2}
{"id": 5316210, "s2_id": "38e38e1ff7ae8a1db6292e8db6598b41ad746e76", "title": "On the Skolem Problem for Continuous Linear Dynamical Systems", "abstract": "The Continuous Skolem Problem asks whether a real-valued function satisfying a linear differential equation has a zero in a given interval of real numbers. This is a fundamental reachability problem for continuous linear dynamical systems, such as linear hybrid automata and continuous-time Markov chains. Decidability of the problem is currently open---indeed decidability is open even for the sub-problem in which a zero is sought in a bounded interval. In this paper we show decidability of the bounded problem subject to Schanuel's Conjecture, a unifying conjecture in transcendental number theory. We furthermore analyse the unbounded problem in terms of the frequencies of the differential equation, that is, the imaginary parts of the characteristic roots. We show that the unbounded problem can be reduced to the bounded problem if there is at most one rationally linearly independent frequency, or if there are two rationally linearly independent frequencies and all characteristic roots are simple. We complete the picture by showing that decidability of the unbounded problem in the case of two (or more) rationally linearly independent frequencies would entail a major new effectiveness result in Diophantine approximation, namely computability of the Diophantine-approximation types of all real algebraic numbers.", "venue": "ICALP", "authors": ["Ventsislav  Chonev", "Jo\u00ebl  Ouaknine", "James  Worrell"], "year": 2016, "n_citations": 27}
{"id": 5323968, "s2_id": "9619bf6955ddef0114164c5142d6e34c9e923081", "title": "Computing characteristic classes of subschemes of smooth toric varieties", "abstract": "Abstract Let X \u03a3 be a smooth complete toric variety defined by a fan \u03a3 and let V = V ( I ) be a subscheme of X \u03a3 defined by an ideal I homogeneous with respect to the grading on the total coordinate ring of X \u03a3 . We show a new expression for the Segre class s ( V , X \u03a3 ) in terms of the projective degrees of a rational map specified by the generators of I when each generator corresponds to a numerically effective (nef) divisor. Restricting to the case where X \u03a3 is a smooth projective toric variety and dehomogenizing the total homogeneous coordinate ring of X \u03a3 via a dehomogenizing ideal we also give an expression for the projective degrees of this rational map in terms of the dimension of an explicit quotient ring. Under an additional technical assumption we construct what we call a general dehomogenizing ideal and apply this construction to give effective algorithms to compute the Segre class s ( V , X \u03a3 ) , the Chern\u2013Schwartz\u2013MacPherson class c S M ( V ) and the topological Euler characteristic \u03c7 ( V ) of V. These algorithms can, in particular, be used for subschemes of any product of projective spaces P n 1 \u00d7 \u22ef \u00d7 P n j or for subschemes of many other projective toric varieties. Running time bounds for several of the algorithms are given and the algorithms are tested on a variety of examples. In all applicable cases our algorithms to compute these characteristic classes are found to offer significantly increased performance over other known algorithms.", "venue": "ArXiv", "authors": ["Martin  Helmer"], "year": 2015, "n_citations": 5}
{"id": 5328688, "s2_id": "91355f8d7daa64b8dffd93aec99f03477b9aeefa", "title": "Kleene stars of the plane, polylogarithms and symmetries", "abstract": "We extend the definition and construct several bases for polylogarithms Li T , where T are some series, recognizable by a finite state (multiplicity) automaton of alphabet 4 X = {x 0 , x 1 }. The kernel of this new \"polylogarithmic map\" Li $\\bullet$ is also characterized and provides a rewriting process which terminates to a normal form. We concentrate on algebraic and analytic aspects of this extension allowing index polylogarithms at non positive multi-indices, by rational series and regularize polyzetas at non positive multi-indices.", "venue": "Theor. Comput. Sci.", "authors": ["Vincel Hoang Ngoc Minh", "Quoc Hoan Ng\u00f4", "G\u00e9rard  Duchamp", "V.  Hoang", "Ngoc  Minh", "Ngo  Quoc", "Phan Dang Luu", "Kien  An", "Hai  Phong", "Viet  Nam"], "year": 2019, "n_citations": 10}
{"id": 5331162, "s2_id": "51ddd735c4fd3177fe94ac949fa08add65b12630", "title": "Gravity, torsion, Dirac field and computer algebra using MAPLE and REDUCE", "abstract": "The article presents computer algebra procedures and routines applied to the study of the Dirac field on curved spacetimes. The main part of the procedures is devoted to the construction of Pauli and Dirac matrices algebra on an anholonomic orthonormal reference frame. Then these procedures are used to compute the Dirac equation on curved spacetimes in a sequence of special dedicated routines. A comparative review of such procedures obtained for two computer algebra platforms (REDUCE + EXCALC and MAPLE + GRTensorII) is carried out. Applications for the calculus of Dirac equation on specific examples of spacetimes with or without torsion are pointed out.", "venue": "ArXiv", "authors": ["Dumitru N. Vulcanov"], "year": 2002, "n_citations": 2}
{"id": 5334259, "s2_id": "4a9a46e2a0d64303d074a028829a8bf2749b5eca", "title": "Plane mixed discriminants and toric jacobians", "abstract": "Polynomial algebra offers a standard approach to handle several problems in geometric modeling. A key tool is the discriminant of a univariate polynomial, or of a well-constrained system of polynomial equations, which expresses the existence of a multiple root. We describe discriminants in a general context, and focus on exploiting the sparseness of polynomials via the theory of Newton polytopes and sparse (or toric) elimination. We concentrate on bivariate polynomials and establish an original formula that relates the discriminant of two bivariate Laurent polynomials with fixed support, with the sparse resultant of these polynomials and their toric Jacobian. This allows us to obtain a new proof for the bidegree formula of the discriminant as well as to establish multiplicativity formulas arising when one polynomial can be factored.", "venue": "ArXiv", "authors": ["Alicia  Dickenstein", "Ioannis Z. Emiris", "Anna  Karasoulou"], "year": 2013, "n_citations": 10}
{"id": 5337130, "s2_id": "a793ab7a8411fa5745f340065d777d26cc38fad6", "title": "Eliminating Human Insight: An Algorithmic Proof of Stembridge's TSPP Theorem", "abstract": "We present a new proof of Stembridge's theorem about the enu- meration of totally symmetric plane partitions using the methodology sug- gested in the recent Koutschan-Kauers-Zeilberger semi-rigorous proof of the Andrews-Robbins q-TSPP conjecture. Our proof makes heavy use of computer algebra and is completely automatic. We describe new methods that make the computations feasible in the first place. The tantalizing aspect of this work is that the same methods can be applied to prove the q-TSPP conjecture (that is a q-analogue of Stembridge's theorem and open for more than 25 years); the only hurdle here is still the computational complexity.", "venue": "ArXiv", "authors": ["Christoph  Koutschan"], "year": 2009, "n_citations": 6}
{"id": 5337903, "s2_id": "c415a0929d29ca507019afbf8d038f46aaceddd0", "title": "Solving rank-constrained semidefinite programs in exact arithmetic", "abstract": "Abstract We consider the problem of minimizing a linear function over an affine section of the cone of positive semidefinite matrices, with the additional constraint that the feasible matrix has prescribed rank. When the rank constraint is active, this is a non-convex optimization problem, otherwise it is a semidefinite program. Both find numerous applications especially in systems control theory and combinatorial optimization, but even in more general contexts such as polynomial optimization or real algebra. While numerical algorithms exist for solving this problem, such as interior-point or Newton-like algorithms, in this paper we propose an approach based on symbolic computation. We design an exact algorithm for solving rank-constrained semidefinite programs, whose complexity is essentially quadratic on natural degree bounds associated to the given optimization problem: for subfamilies of the problem where the size of the feasible matrix, or the dimension of the affine section, is fixed, the algorithm is polynomial time. The algorithm works under assumptions on the input data: we prove that these assumptions are generically satisfied. We implement it in Maple and discuss practical experiments.", "venue": "J. Symb. Comput.", "authors": ["Simone  Naldi"], "year": 2018, "n_citations": 6}
{"id": 5345333, "s2_id": "f1f94ff3ca8ebd04f852b78302e29918de7265e7", "title": "Random polynomials and expected complexity of bisection methods for real solving", "abstract": "Our probabilistic analysis sheds light to the following questions: Why do random polynomials seem to have few, and well separated real roots, on the average? Why do exact algorithms for real root isolation may perform comparatively well or even better than numerical ones?\n We exploit results by Kac, and by Edelman and Kostlan in order to estimate the real root separation of degree d polynomials with i.i.d. coefficients that follow two zero-mean normal distributions: for SO(2) polynomials, the i-th coefficient has variance (d/i), whereas for Weyl polynomials its variance is 1/i!. By applying results from statistical physics, we obtain the expected (bit) complexity of STURM solver, \u00d5B(rd2\u03c4), where r is the number of real roots and \u03c4 the maximum coefficient bitsize. Our bounds are two orders of magnitude tighter than the record worst case ones. We also derive an output-sensitive bound in the worst case.\n The second part of the paper shows that the expected number of real roots of a degree d polynomial in the Bernstein basis is \u221a2d \u00b1 O(1), when the coefficients are i.i.d. variables with moderate standard deviation. Our paper concludes with experimental results which corroborate our analysis.", "venue": "ISSAC", "authors": ["Ioannis Z. Emiris", "Andr\u00e9  Galligo", "Elias P. Tsigaridas"], "year": 2010, "n_citations": 28}
{"id": 5356660, "s2_id": "da118b8aa99699edd7609fbbd081d5b93bc2e87b", "title": "Automatic differentiation in machine learning: a survey", "abstract": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply \u201cauto-diff\u201d, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until \nvery recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other\u2019s results. Despite its \nrelevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names \u201cdynamic computational \ngraphs\u201d and \u201cdifferentiable programming\u201d. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main imple- \nmentation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms \u201cautodiff\u201d, \u201cautomatic differentiation\u201d, and \u201csymbolic differentiation\u201d as these are encountered more and more in machine learning settings.", "venue": "J. Mach. Learn. Res.", "authors": ["Atilim Gunes Baydin", "Barak A. Pearlmutter", "Alexey Andreyevich Radul", "Jeffrey Mark Siskind"], "year": 2017, "n_citations": 1025}
{"id": 5364345, "s2_id": "0ca12551cbebe6d42b9ac9abb2d95b819a780e9c", "title": "A Nearly Optimal Algorithm for Deciding Connectivity Queries in Smooth and Bounded Real Algebraic Sets", "abstract": "A roadmap for a semi-algebraic set S is a curve which has a non-empty and connected intersection with all connected components of S. Hence, this kind of object, introduced by Canny, can be used to answer connectivity queries (with applications, for instance, to motion planning) but has also become of central importance in effective real algebraic geometry, since it is used in higher-level algorithms. In this article, we provide a probabilistic algorithm which computes roadmaps for smooth and bounded real algebraic sets. Its output size and running time are polynomial in (nD)nlog (d), where D is the maximum of the degrees of the input polynomials, d is the dimension of the set under consideration and n is the number of variables. More precisely, the running time of the algorithm is essentially subquadratic in the output size. Even under our assumptions, it is the first roadmap algorithm with output size and running time polynomial in (nD)nlog (d).", "venue": "J. ACM", "authors": ["Mohab Safey El Din", "\u00c9ric  Schost"], "year": 2017, "n_citations": 43}
{"id": 5364696, "s2_id": "6fb0ba56bf7bb009d3555ec68264b76747fcdf48", "title": "Branch cuts in maple 17", "abstract": "Accurate and comprehensible knowledge about the position of branch cuts is essential for correctly working with multi-valued functions, such as the square root and logarithm. We discuss the new tools in Maple 17 for calculating and visualising the branch cuts of such functions, and others built up from them. The cuts are described in an intuitive and accurate form, offering substantial improvement on the descriptions previously available.", "venue": "ACCA", "authors": ["Matthew  England", "Edgardo S. Cheb-Terrab", "Russell J. Bradford", "James H. Davenport", "David J. Wilson"], "year": 2014, "n_citations": 8}
{"id": 5373013, "s2_id": "6351136ef54ef20823d650cb9e9e098e7102e964", "title": "A Factorization Algorithm for G-Algebras and Applications", "abstract": "It has been recently discovered by Bell, Heinle and Levandovskyy that a large class of algebras, including the ubiquitous G-algebras, are finite factorization domains (FFD for short). Utilizing this result, we contribute an algorithm to find all distinct factorizations of a given element f \u2208 G, where G is any G-algebra, with minor assumptions on the underlying field. Moreover, the property of being an FFD, in combination with the factorization algorithm, enables us to propose an analogous description of the factorized Gr\u00f6bner basis algorithm for G-algebras. This algorithm is useful for various applications, e.g. in analysis of solution spaces of systems of linear partial functional equations with polynomial coefficients, coming from G. Additionally, it is possible to include inequality constraints for ideals in the input.", "venue": "ISSAC", "authors": ["Albert  Heinle", "Viktor  Levandovskyy"], "year": 2016, "n_citations": 4}
{"id": 5374186, "s2_id": "f0f3a572c75b156650e2db512eebd968d472c489", "title": "Quadratic Probabilistic Algorithms for Normal Bases", "abstract": "It is well known that for any finite Galois extension field $K/F$, with Galois group $G = \\mathrm{Gal}(K/F)$, there exists an element $\\alpha \\in K$ whose orbit $G\\cdot\\alpha$ forms an $F$-basis of $K$. Such an element $\\alpha$ is called \\emph{normal} and $G\\cdot\\alpha$ is called a normal basis. In this paper we introduce a probabilistic algorithm for finding a normal element when $G$ is either a finite abelian or a metacyclic group. The algorithm is based on the fact that deciding whether a random element $\\alpha \\in K$ is normal can be reduced to deciding whether $\\sum_{\\sigma \\in G} \\sigma(\\alpha)\\sigma \\in K[G]$ is invertible. In an algebraic model, the cost of our algorithm is quadratic in the size of $G$ for metacyclic $G$ and slightly subquadratic for abelian $G$.", "venue": "ArXiv", "authors": ["Mark  Giesbrecht", "Armin  Jamshidpey", "\u00c9ric  Schost"], "year": 2019, "n_citations": 0}
{"id": 5380290, "s2_id": "566c4fe4036934e1d4374220a3db0b2bb3106ab3", "title": "A Blackbox Polynomial System Solver on Parallel Shared Memory Computers", "abstract": "A numerical irreducible decomposition for a polynomial system provides representations for the irreducible factors of all positive dimensional solution sets of the system, separated from its isolated solutions. Homotopy continuation methods are applied to compute a numerical irreducible decomposition. Load balancing and pipelining are techniques in a parallel implementation on a computer with multicore processors. The application of the parallel algorithms is illustrated on solving the cyclic $n$-roots problems, in particular for $n = 8, 9$, and~12.", "venue": "CASC", "authors": ["Jan  Verschelde"], "year": 2018, "n_citations": 1}
{"id": 5385969, "s2_id": "41f46b4d0306e4bc62d7d93856d33dca42243813", "title": "A Novel Algebraic Geometry Compiling Framework for Adiabatic Quantum Computations", "abstract": "Adiabatic Quantum Computing (AQC) is an attractive paradigm for solving hard integer polynomial optimization problems. Available hardware restricts the Hamiltonians to be of a structure that allows only pairwise interactions. This requires that the original optimization problem to be first converted -- from its polynomial form -- to a quadratic unconstrained binary optimization (QUBO) problem, which we frame as a problem in algebraic geometry. Additionally, the hardware graph where such a QUBO-Hamiltonian needs to be embedded -- assigning variables of the problem to the qubits of the physical optimizer -- is not a complete graph, but rather one with limited connectivity. This \"problem graph to hardware graph\" embedding can also be framed as a problem of computing a Groebner basis of a certain specially constructed polynomial ideal. We develop a systematic computational approach to prepare a given polynomial optimization problem for AQC in three steps. The first step reduces an input polynomial optimization problem into a QUBO through the computation of the Groebner basis of a toric ideal generated from the monomials of the input objective function. The second step computes feasible embeddings. The third step computes the spectral gap of the adiabatic Hamiltonian associated to a given embedding. These steps are applicable well beyond the integer polynomial optimization problem. Our paper provides the first general purpose computational procedure that can be used directly as a $translator$ to solve polynomial integer optimization. Alternatively, it can be used as a test-bed (with small size problems) to help design efficient heuristic quantum compilers by studying various choices of reductions and embeddings in a systematic and comprehensive manner. An added benefit of our framework is in designing Ising architectures through the study of $\\mathcal Y-$minor universal graphs.", "venue": "ArXiv", "authors": ["Raouf  Dridi", "Hedayat  Alghassi", "Sridhar R. Tayur"], "year": 2018, "n_citations": 9}
{"id": 5391201, "s2_id": "a45299a347fa5dc46e0a2f2938f4f8fd2ca0d259", "title": "FiniteFlow: multivariate functional reconstruction using finite fields and dataflow graphs", "abstract": "A bstractComplex algebraic calculations can be performed by reconstructing analytic results from numerical evaluations over finite fields. We describe FiniteFlow, a framework for defining and executing numerical algorithms over finite fields and reconstructing multivariate rational functions. The framework employs computational graphs, known as dataflow graphs, to combine basic building blocks into complex algorithms. This allows to easily implement a wide range of methods over finite fields in high-level languages and computer algebra systems, without being concerned with the low-level details of the numerical implementation. This approach sidesteps the appearance of large intermediate expressions and can be massively parallelized. We present applications to the calculation of multi-loop scattering amplitudes, including the reduction via integration-by-parts identities to master integrals or special functions, the computation of differential equations for Feynman integrals, multi-loop integrand reduction, the decomposition of amplitudes into form factors, and the derivation of integrable symbols from a known alphabet. We also release a proof-of-concept C++ implementation of this framework, with a high-level interface in Mathematica.", "venue": "Journal of High Energy Physics", "authors": ["Tiziano  Peraro"], "year": 2019, "n_citations": 58}
{"id": 5393621, "s2_id": "c31359f4a4d9d95bfa991dacee09335e1cba2b5d", "title": "Computing huge Groebner basis like cyclic10 over $\\Q$ with Giac", "abstract": "We present a short description on how to fine-tune the modular algorithm implemented in the Giac computer algebra system to reconstruct huge Groebner basis over $\\Q$. \nThe classical cyclic10 benchmark will serve as example.", "venue": "ArXiv", "authors": ["Bernard  Parisse"], "year": 2019, "n_citations": 0}
{"id": 5393944, "s2_id": "e1c793c8fa9181348fac077b2ea537c7de99f6e2", "title": "Efficient Characteristic Set Algorithms for Equation Solving in Finite Fields and Applications in Cryptanalysis", "abstract": "Efficient characteristic set methods for computing solutions of polynomial equation systems in a finite field are proposed. The concept of proper triangular sets is introduced and an explicit formula for the number of solutions of a proper and monic (or regular) triangular set is given. An improved zero decomposition algorithm which can be used to reduce the zero set of an equation system in general form to the union of zero sets of monic proper triangular sets is proposed. As a consequence, we can give an explicit formula for the number of solutions of an equation system. Bitsize complexity for the algorithm is given in the case of Boolean polynomials. We also give a multiplication free characteristic set method for Boolean polynomials, where the sizes of the polynomials are effectively controlled. The algorithms are implemented in the case of Boolean polynomials and extensive experiments show that they are quite efficient for solving certain classes of Boolean equations.", "venue": "ArXiv", "authors": ["Xiao-Shan  Gao", "Zhenyu  Huang"], "year": 2010, "n_citations": 4}
{"id": 5395152, "s2_id": "47b2de8d2fc4775465ef9f8f7b86dceea539631a", "title": "Graphical Conditions for Rate Independence in Chemical Reaction Networks", "abstract": "Chemical Reaction Networks (CRNs) provide a useful abstraction of molecular interaction networks in which molecular structures as well as mass conservation principles are abstracted away to focus on the main dynamical properties of the network structure. In their interpretation by ordinary differential equations, we say that a CRN with distinguished input and output species computes a positive real function $f : R+ \u2192 R+$, if for any initial concentration x of the input species, the concentration of the output molecular species stabilizes at concentration f (x). The Turing-completeness of that notion of chemical analog computation has been established by proving that any computable real function can be computed by a CRN over a finite set of molecular species. Rate-independent CRNs form a restricted class of CRNs of high practical value since they enjoy a form of absolute robustness in the sense that the result is completely independent of the reaction rates and depends solely on the input concentrations. The functions computed by rate-independent CRNs have been characterized mathematically as the set of piecewise linear functions from input species. However, this does not provide a mean to decide whether a given CRN is rate-independent. In this paper, we provide graphical conditions on the Petri Net structure of a CRN which entail the rate-independence property either for all species or for some output species. We show that in the curated part of the Biomodels repository, among the 590 reaction models tested, 2 reaction graphs were found to satisfy our rate-independence conditions for all species, 94 for some output species, among which 29 for some non-trivial output species. Our graphical conditions are based on a non-standard use of the Petri net notions of place-invariants and siphons which are computed by constraint programming techniques for efficiency reasons.", "venue": "CMSB", "authors": ["Elisabeth  Degrand", "Franccois  Fages", "Sylvain  Soliman"], "year": 2020, "n_citations": 1}
{"id": 5399185, "s2_id": "214fa6733ae0bdb9822e80e1f47a5adfe1be7236", "title": "Characterizing Positively Invariant Sets: Inductive and Topological Methods", "abstract": "Set positive invariance is an important concept in the theory of dynamical systems and one which also has practical applications in areas of computer science, such as formal verification, as well as in control theory. Great progress has been made in understanding positively invariant sets in continuous dynamical systems and powerful computational tools have been developed for reasoning about them; however, many of the insights from recent developments in this area have largely remained folklore and are not elaborated in existing literature. This article contributes an explicit development of modern methods for checking positively invariant sets of ordinary differential equations and describes two possible characterizations of positive invariants: one based on the real induction principle, and a novel alternative based on topological notions. The two characterizations, while in a certain sense equivalent, lead to two different decision procedures for checking whether a given semi-algebraic set is positively invariant under the flow of a system of polynomial ordinary differential equations.", "venue": "ArXiv", "authors": ["Khalil  Ghorbal", "Andrew  Sogokon"], "year": 2020, "n_citations": 0}
{"id": 5401587, "s2_id": "4803b1f9aaa435d93525a7b13d06a25f9477a407", "title": "Extensions of the AZ-algorithm and the Package MultiIntegrate", "abstract": "We extend the (continuous) multivariate Almkvist-Zeilberger algorithm in order to apply it for instance to special Feynman integrals emerging in renormalizable Quantum field Theories. We will consider multidimensional integrals over hyperexponential integrals and try to find closed form representations in terms of nested sums and products or iterated integrals. In addition, if we fail to compute a closed form solution in full generality, we may succeed in computing the first coefficients of the Laurent series expansions of such integrals in terms of indefinite nested sums and products or iterated integrals. In this article we present the corresponding methods and algorithms. Our Mathematica package MultiIntegrate, can be considered as an enhanced implementation of the (continuous) multivariate Almkvist Zeilberger algorithm to compute recurrences or differential equations for hyperexponential integrands and integrals. Together with the summation package Sigma and the package HarmonicSums our package provides methods to compute closed form representations (or coefficients of the Laurent series expansions) of multidimensional integrals over hyperexponential integrands in terms of nested sums or iterated integrals.", "venue": "Texts & Monographs in Symbolic Computation", "authors": ["Jakob  Ablinger"], "year": 2021, "n_citations": 2}
{"id": 5408009, "s2_id": "815d40b81fcc953e0e24c3e1a7f5f17b3a470f50", "title": "Independence of Hyperlogarithms over Function Fields via Algebraic Combinatorics", "abstract": "We obtain a necessary and sufficient condition for the linear independence of solutions of differential equations for hyperlogarithms. The key fact is that the multiplier (i.e. the factor M in the differential equation dS = MS) has only singularities of first order (Fuchsian-type equations) and this implies that they freely span a space which contains no primitive. We give direct applications where we extend the property of linear independence to the largest known ring of coefficients.", "venue": "CAI", "authors": ["Matthieu  Deneufch\u00e2tel", "G\u00e9rard  Duchamp", "Vincel Hoang Ngoc Minh", "Allan I. Solomon"], "year": 2011, "n_citations": 41}
{"id": 5408318, "s2_id": "f61c3fe0ff81a8097d23fb13768d6424a204af92", "title": "Segmentation of real algebraic plane curves", "abstract": "In this article we give an implementation of the standard algorithm to segment a real algebraic plane curve defined implicitly. Our implementation is efficient and simpler than previous. We use global information to count the number of half-branches at a critical point.", "venue": "ArXiv", "authors": ["C\u00e9sar  Massri", "Manuel  Dubinsky"], "year": 2016, "n_citations": 0}
{"id": 5411352, "s2_id": "ab7f3a0ca28986899f641587c686c69bd1e969c1", "title": "Quasi-optimal Multiplication of Linear Differential Operators", "abstract": "We show that linear differential operators with polynomial coefficients over a field of characteristic zero can be multiplied in quasi-optimal time. This answers an open question raised by van der Hoeven.", "venue": "2012 IEEE 53rd Annual Symposium on Foundations of Computer Science", "authors": ["Alexandre  Benoit", "Alin  Bostan", "Joris van der Hoeven"], "year": 2012, "n_citations": 9}
{"id": 5419940, "s2_id": "57fdaf09f0e62d9ffb4d0d8e3d26eb0205960d52", "title": "Generalized laplace transformations and integration of hyperbolic systems of linear partial differential equations", "abstract": "We give a new procedure for generalized factorization and construction of the complete solution of strictly hyperbolic linear partial differential equations or strictly hyperbolic systems of such equations in the plane. This procedure generalizes the classical theory of Laplace transformations of second-order equations in the plane.", "venue": "ISSAC", "authors": ["Sergey P. Tsarev"], "year": 2005, "n_citations": 61}
{"id": 5421927, "s2_id": "7cc494ce7549250bd48692df0a73ad591c0915ad", "title": "On Consensus under Polynomial Protocols", "abstract": "In this paper we explore the possibility of using computational algebraic methods to analyze a class of consensus protocols. We state some necessary conditions for convergence under consensus protocols that are polynomials.", "venue": "ArXiv", "authors": ["Joel George Manathara", "Ambedkar  Dukkipati", "Debasish  Ghose"], "year": 2011, "n_citations": 0}
{"id": 5431444, "s2_id": "91faa1c408444b86cba0577a93efb528adad63b4", "title": "qFunctions - A Mathematica package for q-series and partition theory applications", "abstract": "We describe the qFunctions Mathematica package for $q$-series and partition theory applications. This package includes both experimental and symbolic tools. The experimental set of elements includes guessers for $q$-shift equations and recurrences for given $q$-series and fitting/finding explicit expressions for sequences of polynomials. This package can symbolically handle formal manipulations on $q$-differential, $q$-shift equations and recurrences, such as switching between these forms, finding the greatest common divisor of recurrences, and formal substitutions. Here, we also extend the classical method of the weighted words approach. Moreover, qFunctions has implementations that automate the recurrence system creation of the weighted words approach as well as a scheme on cylindric partitions.", "venue": "J. Symb. Comput.", "authors": ["Jakob  Ablinger", "Ali K. Uncu"], "year": 2021, "n_citations": 7}
{"id": 5431744, "s2_id": "60dc70241fb0195f2b1082f65194424cef193345", "title": "Neuro-symbolic Architectures for Context Understanding", "abstract": "Computational context understanding refers to an agent's ability to fuse disparate sources of information for decision-making and is, therefore, generally regarded as a prerequisite for sophisticated machine reasoning capabilities, such as in artificial intelligence (AI). Data-driven and knowledge-driven methods are two classical techniques in the pursuit of such machine sense-making capability. However, while data-driven methods seek to model the statistical regularities of events by making observations in the real-world, they remain difficult to interpret and they lack mechanisms for naturally incorporating external knowledge. Conversely, knowledge-driven methods, combine structured knowledge bases, perform symbolic reasoning based on axiomatic principles, and are more interpretable in their inferential processing; however, they often lack the ability to estimate the statistical salience of an inference. To combat these issues, we propose the use of hybrid AI methodology as a general framework for combining the strengths of both approaches. Specifically, we inherit the concept of neuro-symbolism as a way of using knowledge-bases to guide the learning progress of deep neural networks. We further ground our discussion in two applications of neuro-symbolism and, in both cases, show that our systems maintain interpretability while achieving comparable performance, relative to the state-of-the-art.", "venue": "Knowledge Graphs for eXplainable Artificial Intelligence", "authors": ["Alessandro  Oltramari", "Jonathan  Francis", "Cory  Henson", "Kaixin  Ma", "Ruwan  Wickramarachchi"], "year": 2020, "n_citations": 9}
{"id": 5433045, "s2_id": "8587fe894ec4901605c13bb4fb22f28bad1a5ee3", "title": "Integral D-Finite Functions", "abstract": "We propose a differential analog of the notion of integral closure of algebraic function fields. We present an algorithm for computing the integral closure of the algebra defined by a linear differential operator. Our algorithm is a direct analog of van Hoeij's algorithm for computing integral bases of algebraic function fields.", "venue": "ISSAC", "authors": ["Manuel  Kauers", "Christoph  Koutschan"], "year": 2015, "n_citations": 9}
{"id": 5437902, "s2_id": "dde7e8b6d1e485133c4001e52b23eda915a68672", "title": "Dominance in the family of Sugeno-Weber t-norms", "abstract": "The dominance relationship between two members of the family of Sugeno-Weber t-norms is proven by using a quantifier elimination algorithm. Further it is shown that dominance is a transitive, and therefore also an order relation, on this family of t-norms.", "venue": "Fuzzy Sets Syst.", "authors": ["Manuel  Kauers", "Veronika  Pillwein", "Susanne  Saminger-Platz"], "year": 2011, "n_citations": 11}
{"id": 5443985, "s2_id": "0ec9fb2d09bac396764c85ff1832933553115de2", "title": "Generic Reductions for In-place Polynomial Multiplication", "abstract": "The polynomial multiplication problem has attracted considerable attention since the early days of computer algebra, and several algorithms have been designed to achieve the best possible time complexity. More recently, efforts have been made to improve the space complexity, developing modified versions of a few specific algorithms to use no extra space while keeping the same asymptotic running time. In this work, we broaden the scope in two regards. First, we ask whether an arbitrary multiplication algorithm can be performed in-place generically. Second, we consider two important variants which produce only part of the result (and hence have less space to work with), the so-called middle and short products, and ask whether these operations can also be performed in-place. To answer both questions in (mostly) the affirmative, we provide a series of reductions starting with any linear-space multiplication algorithm. For full and short product algorithms these reductions yield in-place versions with the same asymptotic time complexity as the out-of-place version. For the middle product, the reduction incurs an extra logarithmic factor in the time complexity only when the algorithm is quasi-linear.", "venue": "ISSAC", "authors": ["Pascal  Giorgi", "Bruno  Grenet", "Daniel S. Roche"], "year": 2019, "n_citations": 4}
{"id": 5452330, "s2_id": "5cb4874f7f382314055c320b122ae1bcde7269e7", "title": "Efficient algorithms for computing rational first integrals and Darboux polynomials of planar polynomial vector fields", "abstract": "We present fast algorithms for computing rational first integrals with bounded degree of a planar polynomial vector field. Our approach builds upon a method proposed by Ferragut and Giacomini, whose main ingredients are the calculation of a power series solution of a first order differential equation and the reconstruction of a bivariate polynomial annihilating this power series. We provide explicit bounds on the number of terms needed in the power series. This enables us to transform their method into a certified algorithm computing rational first integrals via systems of linear equations. We then significantly improve upon this first algorithm by building a probabilistic algorithm with arithmetic complexity $\\~O(N^{2 \\omega})$ and a deterministic algorithm solving the problem in at most $\\~O(d^2N^{2 \\omega+1})$ arithmetic operations, where~$N$ denotes the given bound for the degree of the rational first integral, and where $d \\leq N$ is the degree of the vector field, and $\\omega$ the exponent of linear algebra. We also provide a fast heuristic variant which computes a rational first integral, or fails, in $\\~O(N^{\\omega+2})$ arithmetic operations. By comparison, the best previous algorithm uses at least $d^{\\omega+1}\\, N^{4\\omega +4}$ arithmetic operations. We then show how to apply a similar method to the computation of Darboux polynomials. The algorithms are implemented in a Maple package RationalFirstIntegrals which is available to interested readers with examples showing its efficiency.", "venue": "Math. Comput.", "authors": ["Alin  Bostan", "Guillaume  Ch\u00e8ze", "Thomas  Cluzeau", "Jacques-Arthur  Weil"], "year": 2016, "n_citations": 17}
{"id": 5456482, "s2_id": "6798aa979280bc5046118e807b3c151e32e0a645", "title": "Entropy supplementary conservation law for non-linear systems of PDEs with non-conservative terms: application to the modelling and analysis of complex fluid flows using computer algebra", "abstract": "In the present contribution, we investigate first-order nonlinear systems of partial differential equations which are constituted of two parts: a system of conservation laws and non-conservative first order terms. Whereas the theory of first-order systems of conservation laws is well established and the conditions for the existence of supplementary conservation laws, and more specifically of an entropy supplementary conservation law for smooth solutions, well known, there exists so far no general extension to obtain such supplementary conservation laws when non-conservative terms are present. We propose a framework in order to extend the existing theory and show that the presence of non-conservative terms somewhat complexifies the problem since numerous combinations of the conservative and non-conservative terms can lead to a supplementary conservation law. We then identify a restricted framework in order to design and analyze physical models of complex fluid flows by means of computer algebra and thus obtain the entire ensemble of possible combination of conservative and non-conservative terms with the objective of obtaining specifically an entropy supplementary conservation law. The theory as well as developed computer algebra tool are then applied to a Baer-Nunziato two-phase flow model and to a multicomponent plasma fluid model. The first one is a first-order fluid model, with non-conservative terms impacting on the linearly degenerate field and requires a closure since there is no way to derive interfacial quantities from averaging principles and we need guidance in order to close the pressure and velocity of the interface and the thermodynamics of the mixture. The second one involves first order terms for the heavy species coupled to second order terms for the electrons, the non-conservative terms impact the genuinely nonlinear fields and the model can be rigorously derived from kinetic theory. We show how the theory allows to recover the whole spectrum of closures obtained so far in the literature for the two-phase flow system as well as conditions when one aims at extending the thermodynamics and also applies to the plasma case, where we recover the usual entropy supplementary equation, thus assessing the effectiveness and scope of the proposed theory.", "venue": "ArXiv", "authors": ["Pierre  Cordesse", "Marc  Massot"], "year": 2019, "n_citations": 5}
{"id": 5465155, "s2_id": "0e849cfb8f69663dd808680edea73dfaf50cc3f3", "title": "Symbolic Representation for Analog Realization of A Family of Fractional Order Controller Structures via Continued Fraction Expansion", "abstract": "This paper uses the Continued Fraction Expansion (CFE) method for analog realization of fractional order differ-integrator and few special classes of fractional order (FO) controllers viz. Fractional Order Proportional-Integral-Derivative (FOPID) controller, FO[PD] controller and FO lead-lag compensator. Contemporary researchers have given several formulations for rational approximation of fractional order elements. However, approximation of the controllers studied in this paper, due to having fractional power of a rational transfer function, is not available in analog domain; although its digital realization already exists. This motivates us for applying CFE based analog realization technique for complicated FO controller structures to get equivalent rational transfer functions in terms of the controller tuning parameters. The symbolic expressions for rationalized transfer function in terms of the controller tuning parameters are especially important as ready references, without the need of running CFE algorithm every time and also helps in the synthesis of analog circuits for such FO controllers.", "venue": "ISA transactions", "authors": ["Anindya  Pakhira", "Saptarshi  Das", "Indranil  Pan", "Shantanu  Das"], "year": 2015, "n_citations": 7}
{"id": 5465406, "s2_id": "7561d4b926a619f3957ffe922c37c94b5e984d5a", "title": "Quantifier Elimination for Reasoning in Economics", "abstract": "We consider the use of Quantifier Elimination (QE) technology for automated reasoning in economics. QE dates back to Tarski's work in the 1940s with software to perform it dating to the 1970s. There is a great body of work considering its application in science and engineering but we show here how it can also find application in the social sciences. We explain how many suggested theorems in economics could either be proven, or even have their hypotheses shown to be inconsistent, automatically; and describe the application of this in both economics education and research. We describe a bank of QE examples gathered from economics literature and note the structure of these are, on average, quite different to those occurring in the computer algebra literature. This leads us to suggest a new incremental QE approach based on result memorization of commonly occurring generic QE results.", "venue": "ArXiv", "authors": ["Casey B. Mulligan", "Russell J. Bradford", "James H. Davenport", "Matthew  England", "Zak  Tonks"], "year": 2018, "n_citations": 2}
{"id": 5468291, "s2_id": "0a065c89ccbc83b22413398b481035b715852db1", "title": "Algorithms in Real Algebraic Geometry: A Survey", "abstract": "We survey both old and new developments in the theory of algorithms in real algebraic geometry -- starting from effective quantifier elimination in the first order theory of reals due to Tarski and Seidenberg, to more recent algorithms for computing topological invariants of semi-algebraic sets. We emphasize throughout the complexity aspects of these algorithms and also discuss the computational hardness of the underlying problems. We also describe some recent results linking the computational hardness of decision problems in the first order theory of the reals, with that of computing certain topological invariants of semi-algebraic sets. Even though we mostly concentrate on exact algorithms, we also discuss some numerical approaches involving semi-definite programming that have gained popularity in recent times.", "venue": "ArXiv", "authors": ["Saugata  Basu"], "year": 2014, "n_citations": 34}
{"id": 5468390, "s2_id": "c78b69cb40d749f0011fbe47f3a0cdf2fcc56592", "title": "Divide-And-Conquer Computation of Cylindrical Algebraic Decomposition", "abstract": "We present a divide-and-conquer version of the Cylindrical Algebraic Decomposition (CAD) algorithm. The algorithm represents the input as a Boolean combination of subformulas, computes cylindrical algebraic decompositions of solution sets of the subformulas, and combines the results. We propose a graph-based heuristic to find a suitable partitioning of the input and present empirical comparison with direct CAD computation.", "venue": "ArXiv", "authors": ["Adam W. Strzebonski"], "year": 2014, "n_citations": 2}
{"id": 5471134, "s2_id": "50dacd271febdb31e72f99e18440b4d004efb573", "title": "Algebraic and algorithmic aspects of radical parametrizations", "abstract": "In this article algebraic constructions are introduced in order to study the variety defined by a radical parametrization (a tuple of functions involving complex numbers, $n$ variables, the four field operations and radical extractions). We provide algorithms to implicitize radical parametrizations and to check whether a radical parametrization can be reparametrized into a rational parametrization.", "venue": "Comput. Aided Geom. Des.", "authors": ["J. Rafael Sendra", "David  Sevilla", "Carlos  Villarino"], "year": 2017, "n_citations": 8}
{"id": 5473128, "s2_id": "98c1ed5c8973ab1ef12bcbd79aa7255769e7a860", "title": "Computing and Using Minimal Polynomials", "abstract": "Given a zero-dimensional ideal I in a polynomial ring, many computations start by finding univariate polynomials in I. Searching for a univariate polynomial in I is a particular case of considering the minimal polynomial of an element in P/I. It is well known that minimal polynomials may be computed via elimination, therefore this is considered to be a \"resolved problem\". But being the key of so many computations, it is worth investigating its meaning, its optimization, its applications (e.g. testing if a zero-dimensional ideal is radical, primary or maximal). We present efficient algorithms for computing the minimal polynomial of an element of P/I. For the specific case where the coefficients are in Q, we show how to use modular methods to obtain a guaranteed result. We also present some applications of minimal polynomials, namely algorithms for computing radicals and primary decompositions of zero-dimensional ideals, and also for testing radicality and maximality.", "venue": "J. Symb. Comput.", "authors": ["John  Abbott", "Anna Maria Bigatti", "Elisa  Palezzato", "Lorenzo  Robbiano"], "year": 2020, "n_citations": 6}
{"id": 5476907, "s2_id": "37b883a575b7e7fb6c98395faaf427071090dbe0", "title": "Free quasi-symmetric functions, product actions and quantum field theory of partitions", "abstract": "We examine two associative products over the ring of symmetric functions related to the intransitive and Cartesian products of permutation groups. As an application, we give an enumeration of some Feynman type diagrams arising in Bender's QFT of partitions. We end by exploring possibilities to construct noncommutative analogues.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Jean-Gabriel  Luque", "Karol A. Penson", "Christophe  Tollu"], "year": 2004, "n_citations": 4}
{"id": 5489787, "s2_id": "3df51d4529400e9f77abc621050106eea95757b6", "title": "Fast computation of Smith forms of sparse matrices over local rings", "abstract": "We present algorithms to compute the Smith Normal Form of matrices over two families of local rings. The algorithms use the <i>black-box</i> model which is suitable for sparse and structured matrices. The algorithms depend on a number of tools, such as matrix rank computation over finite fields, for which the best-known time- and memory-efficient algorithms are probabilistic.\n For an <i>n</i> x <i>n</i> matrix <i>A</i> over the ring F[<i>z</i>]/(<i>f</i><sup><i>e</i></sup>), where <i>f</i><sup><i>e</i></sup> is a power of an irreducible polynomial <i>f</i> \u2208 F[<i>z</i>] of degree <i>d</i>, our algorithm requires O(\u03b7<i>de</i><sup>2</sup><i>n</i>) operations in F, where our black-box is assumed to require O(\u03b7) operations in F to compute a matrix-vector product by a vector over F[<i>z</i>]/(<i>f</i><sup><i>e</i></sup>) (and \u03b7 is assumed greater than <i>nde</i>). The algorithm only requires additional storage for O(<i>nde</i>) elements of F. In particular, if \u03b7 = O(<i>nde</i>), then our algorithm requires only O(<i>n</i><sup>2</sup><i>d</i><sup>2</sup><i>e</i><sup>3</sup>) operations in F, which is an improvement on known dense methods for small <i>d</i> and <i>e</i>.\n For the ring Z/<i>p</i><sup><i>e</i></sup>Z, where <i>p</i> is a prime, we give an algorithm which is time- and memory-efficient when the number of nontrivial invariant factors is small. We describe a method for dimension reduction while preserving the invariant factors. The time complexity is essentially linear in \u03bc<i>nre</i> log <i>p</i>, where \u03bc is the number of operations in Z/<i>p</i>Z to evaluate the black-box (assumed greater than <i>n</i>) and <i>r</i> is the total number of non-zero invariant factors. To avoid the practical cost of conditioning, we give a Monte Carlo certificate, which at low cost, provides either a high probability of success or a proof of failure. The quest for a time- and memory-efficient solution without restrictions on the number of nontrivial invariant factors remains open. We offer a conjecture which may contribute toward that end.", "venue": "ISSAC", "authors": ["Mustafa  Elsheikh", "Mark  Giesbrecht", "Andrew  Novocin", "B. David Saunders"], "year": 2012, "n_citations": 8}
{"id": 5498876, "s2_id": "89ba215563cfdb71e629614792acdb9d7b641f35", "title": "Differentiable Set Operations for Algebraic Expressions", "abstract": "Basic principles of set theory have been applied in the context of probability and binary computation. Applying the same principles on inequalities is less common but can be extremely beneficial in a variety of fields. This paper formulates a novel approach to directly apply set operations on inequalities to produce resultant inequalities with differentiable boundaries. The suggested approach uses inequalities of the form Ei: fi(x1,x2,..,xn) and an expression of set operations in terms of Ei like, (E1 and E2) or E3, or can be in any standard form like the Conjunctive Normal Form (CNF) to produce an inequality F(x1,x2,..,xn)<=1 which represents the resulting bounded region from the expressions and has a differentiable boundary. To ensure differentiability of the solution, a trade-off between representation accuracy and curvature at borders (especially corners) is made. A set of parameters is introduced which can be fine-tuned to improve the accuracy of this approach. The various applications of the suggested approach have also been discussed which range from computer graphics to modern machine learning systems to fascinating demonstrations for educational purposes (current use). A python script to parse such expressions is also provided.", "venue": "ArXiv", "authors": ["Jasdeep Singh Grover"], "year": 2019, "n_citations": 1}
{"id": 5499365, "s2_id": "1df26745c4076249a30b56cb6b1fdc3bb89049f0", "title": "Convolutions of Liouvillian Sequences", "abstract": "While Liouvillian sequences are closed under many operations, simple examples show that they are not closed under convolution, and the same goes for d'Alembertian sequences. Nevertheless, we show that d'Alembertian sequences are closed under convolution with rationally d'Alembertian sequences, and that Liouvillian sequences are closed under convolution with rationally Liouvillian sequences.", "venue": "J. Symb. Comput.", "authors": ["Sergei A. Abramov", "Marko  Petkovsek", "Helena  Zakrajsek"], "year": 2020, "n_citations": 1}
{"id": 5500471, "s2_id": "62c8ca1700138331a49dab894721662eda79d0c1", "title": "Tensor computations in computer algebra systems", "abstract": "This paper considers three types of tensor computations. On their basis, we attempt to formulate criteria that must be satisfied by a computer algebra system dealing with tensors. We briefly overview the current state of tensor computations in different computer algebra systems. The tensor computations are illustrated with appropriate examples implemented in specific systems: Cadabra and Maxima.", "venue": "Programming and Computer Software", "authors": ["Anna V. Korolkova", "Dmitry S. Kulyabov", "Leonid A. Sevastyanov"], "year": 2013, "n_citations": 14}
{"id": 5507688, "s2_id": "31c2ed623fc32715231505d3bf76435d227d3334", "title": "Faster inversion and other black box matrix computations using efficient block projections", "abstract": "Efficient block projections of non-singular matrices have recently been used by the authors in [10] to obtain an efficient algorithm to find rational solutions for sparse systems of linear equations. In particular a bound ofO~(n2.5) machine operations is presented for this computation assuming that the input matrix can be multiplied by a vector with constant-sized entries using O~(n) machine operations. Somewhat more general bounds for black-box matrix computations are also derived. Unfortunately, the correctness of this algorithm depends on the existence of efficient block projections of non-singular matrices, and this was only conjectured.\n In this paper we establish the correctness of the algorithm from [10] by proving the existence of efficient block projections for arbitrary non-singular matrices over sufficiently large fields. We further demonstrate the usefulness of these projections by incorporating them into existing black-box matrix algorithms to derive improved bounds for the cost of several matrix problems. We consider, in particular, matrices that can be multiplied by a vector using O~(n) field operations: We show how to compute the inverse of any such non-singular matrix over any field using an expected number of O~(n2.27) operations in that field. A basis for the null space of such a matrix, and a certification of its rank, are obtained at the same cost. An application of this technique to Kaltofen and Villard's Baby-Steps/Giant-Steps algorithms for the determinant and Smith Form of an integer matrix is also sketched, yielding algorithms requiring O~(n2.66) machine operations. More general bounds involving the number of black-box matrix operations to be used are also obtained.\n The derived algorithms are all probabilistic of the Las Vegas type. They are assumed to be able to generate random elements - bits or field elements - at unit cost, and always output the correct answer in the expected time given.", "venue": "ISSAC '07", "authors": ["Wayne  Eberly", "Mark  Giesbrecht", "Pascal  Giorgi", "Arne  Storjohann", "Gilles  Villard"], "year": 2007, "n_citations": 33}
{"id": 5508605, "s2_id": "65ae424b5549d02d4f650b27f971815e77abb437", "title": "Algorithms for the solution of systems of linear equations in commutative ring", "abstract": "Solution methods for linear equation systems in a commutative ring are discussed. Four methods are compared, in the setting of several different rings: Dodgson\u2019s method [1], Bareiss\u2019s method [2] and two methods of the author method by forward and back-up procedures [3] and a one-pass method [4]. We show that for the number of coefficient operations, or for the number of operations in the finite rings, or for modular computation in the polynomial rings the one-pass method [4] is the best. The method of forward and back-up procedures [3] is the best for the polynomial rings when we make use of classical algorithms for polynomial operations.", "venue": "ArXiv", "authors": ["Gennadi I. Malaschonok"], "year": 2017, "n_citations": 1}
{"id": 5516263, "s2_id": "88b13be83f9dbb03856d29345fdb4c2a9199e999", "title": "Robust Numerical Tracking of One Path of a Polynomial Homotopy on Parallel Shared Memory Computers", "abstract": "We consider the problem of tracking one solution path defined by a polynomial homotopy on a parallel shared memory computer. Our robust path tracker applies Newton's method on power series to locate the closest singular parameter value. On top of that, it computes singular values of the Hessians of the polynomials in the homotopy to estimate the distance to the nearest different path. Together, these estimates are used to compute an appropriate adaptive stepsize. For n-dimensional problems, the cost overhead of our robust path tracker is O(n), compared to the commonly used predictor-corrector methods. This cost overhead can be reduced by a multithreaded program on a parallel shared memory computer.", "venue": "CASC", "authors": ["Simon  Telen", "Marc Van Barel", "Jan  Verschelde"], "year": 2020, "n_citations": 3}
{"id": 5525335, "s2_id": "72c9ef08b7606220255d00209bd893aefe208c1a", "title": "Experiments in Model-Checking Optimistic Replication Algorithms", "abstract": "This paper describes a series of model-checking experiments to verify optimistic replication algorithms based on Operational Transformation (OT) approach used for supporting collaborative edition. We formally define, using tool UPPAAL, the behavior and the main consistency requirement (i.e. convergence property) of the collaborative editing systems, as well as the abstract behavior of the environment where these systems are supposed to operate. Due to data replication and the unpredictable nature of user interactions, such systems have infinitely many states. So, we show how to exploit some features of the UPPAAL specification language to attenuate the severe state explosion problem. Two models are proposed. The first one, called concrete model, is very close to the system implementation but runs up against a severe explosion of states. The second model, called symbolic model, aims to overcome the limitation of the concrete model by delaying the effective selection and execution of editing operations until the construction of symbolic execution traces of all sites is completed. Experimental results have shown that the symbolic model allows a significant gain in both space and time. Using the symbolic model, we have been able to show that if the number of sites exceeds $2$ then the convergence property is not satisfied for all OT algorithms considered here. A counterexample is provided for every algorithm.", "venue": "ArXiv", "authors": ["Hanifa  Boucheneb", "Abdessamad  Imine"], "year": 2008, "n_citations": 2}
{"id": 5526856, "s2_id": "4fde55259b61f640cbdec5d9095759483fb4c7dd", "title": "Benchmark Problems for Constraint Solving", "abstract": "Constraint Programming is roughly a new software technology introduced by Jaffar and Lassez in 1987 for description and effective solving of large, particularly combinatorial, problems especially in areas of planning and scheduling. In the following we define three problems for constraint solving from the domain of electrical networks; based on them we define 43 related problems. For the defined set of problems we benchmarked five systems: ILOG OPL, AMPL, GAMS, Mathematica and UniCalc. As expected some of the systems performed very well for some problems while others performed very well on others.", "venue": "ArXiv", "authors": ["Alin  Suciu", "Rodica  Potolea", "Tudor  Muresan"], "year": 2006, "n_citations": 0}
{"id": 5533788, "s2_id": "824b886c95310804656959614db4a08852f1b302", "title": "Logspace computations for Garside groups of spindle type", "abstract": "M. Picantin introduced the notion of Garside groups of spindle type, generalizing the 3-strand braid group. We show that, for linear Garside groups of spindle type, a normal form and a solution to the conjugacy problem are logspace computable. For linear Garside groups of spindle type with homogenous presentation we compute a geodesic normal form in logspace.", "venue": "ArXiv", "authors": ["Murray  Elder", "Arkadius G. Kalka"], "year": 2013, "n_citations": 1}
{"id": 5539365, "s2_id": "8088f41d172e977ff49b7b28ccb7c34612c0694f", "title": "A fast algorithm for computing the Smith normal form with multipliers for a nonsingular integer matrix", "abstract": "A Las Vegas randomized algorithm is given to compute the Smith multipliers for a nonsingular integer matrix A, that is, unimodular matrices U and V such that AV = US , with S the Smith normal form of A. The expected running time of the algorithm is about the same as required to multiply together two matrices of the same dimension and size of entries as A. Explicit bounds are given for the size of the entries in both unimodular multipliers. The main tool used by the algorithm is the Smith massager, a relaxed version of V , the unimodular matrix specifying the column operations of the Smith computation. From the perspective of efficiency, the main tools used are fast linear solving and partial linearization of integer matrices. As an application of the Smith with multipliers algorithm, a fast algorithm is given to find the fractional part of the inverse of the input matrix.", "venue": "ArXiv", "authors": ["Stavros  Birmpilis", "George  Labahn", "Arne  Storjohann"], "year": 2021, "n_citations": 0}
{"id": 5545247, "s2_id": "06880444848b3f97f5f8ae7d592024f61910fed1", "title": "Efficient polynomial time algorithms computing industrial-strength primitive roots", "abstract": "E. Bach, following an idea of T. Itoh, has shown how to build a small set of numbers modulo a prime p such that at least one element of this set is a generator of Z/pZ. E. Bach suggests also that at least half of his set should be generators. We show here that a slight variant of this set can indeed be made to contain a ratio of primitive roots as close to 1 as necessary. In particular we present an asymptotically O\u02dc(\u221a1/elog(p)+log2(p)) algorithm providing primitive roots of p with probability of correctness greater than 1-e and several O(log\u03b1(p)), \u03b1\u22645.23, algorithms computing \"Industrial-strength\" primitive roots.", "venue": "Inf. Process. Lett.", "authors": ["Jacques  Dubrois", "Jean-Guillaume  Dumas"], "year": 2006, "n_citations": 13}
{"id": 5554102, "s2_id": "6f5825f51979b26838c578c255af01b6239b9255", "title": "Block SOS Decomposition", "abstract": "A widely used method for solving SOS (Sum Of Squares) decomposition problem is to reduce it to the problem of semi-definite programs (SDPs) which can be efficiently solved in theory. In practice, although many SDP solvers can work out some problems of big scale, the efficiency and reliability of such method decrease greatly while the input size increases. Recently, by exploiting the sparsity of the input SOS decomposition problem, some preprocessing algorithms were proposed [5,17], which first divide the input problem satisfying special definitions or properties into smaller SDP problems and then pass the smaller ones to SDP solvers to obtain reliable results efficiently. A natural question is that to what extent the above mentioned preprocessing algorithms work. That is, how many polynomials satisfying those definitions or properties are there in the SOS polynomials? In this paper, we define a concept of block SOS decomposable polynomials which is a generalization of those special classes in [5] and [17]. Roughly speaking, it is a class of polynomials whose SOS decomposition problem can be transformed into smaller ones (in other words, the corresponding SDP matrices can be block-diagnolized) by considering their supports only (coefficients are not considered). Then we prove that the set of block SOS decomposable polynomials has measure zero in the set of SOS polynomials. That means if we only consider supports (not with coefficients) of polynomials, such algorithms decreasing the size of SDPs for those SDP-based SOS solvers can only work on very few polynomials. As a result, this shows that the SOS decomposition problems that can be optimized by the above mentioned preprocessing algorithms are very few.", "venue": "ArXiv", "authors": ["Haokun  Li", "Bican  Xia"], "year": 2018, "n_citations": 0}
{"id": 5557646, "s2_id": "a271478b2f01d40456bc45596d299a97d0b277b3", "title": "The Multivariate Schwartz-Zippel Lemma", "abstract": "We show that, except for a special family of polynomials -that we call $\\lambda$-reducible-, a natural multivariate generalization of Schwartz-Zippel-DeMillo-Lipton lemma holds. Moreover, we develop a symbolic algorithm to detect $\\lambda$-reducibility. Our work is motivated by and has applications in combinatorial geometry. Along the way we also present a multivariate generalization of Combinatorial Nullstellensatz, which might be of independent interest.", "venue": "ArXiv", "authors": ["M. Levent Dogan", "Alperen A. Erg\u00fcr", "Jake D. Mundo", "Elias  Tsigaridas"], "year": 2019, "n_citations": 0}
{"id": 5558344, "s2_id": "8dd54d29ef5f9396824d30dd335131bd56d5ef71", "title": "Symbolic-numeric integration of rational functions", "abstract": "We consider the problem of symbolic-numeric integration of symbolic functions, focusing on rational functions. Using a hybrid method allows the reliable yet efficient computation of symbolic antiderivatives while avoiding issues of ill-conditioning to which numerical methods are susceptible. We propose two alternative methods for exact input that compute the rational part of the integral using Hermite reduction and then compute the transcendental part two different ways using a combination of exact integration and efficient numerical computation of roots. The symbolic computation is done within bpas , or Basic Polynomial Algebra Subprograms, which is a highly optimized environment for polynomial computation on parallel architectures, while the numerical computation is done using the highly optimized multiprecision rootfinding package MPSolve . We provide for both algorithms computable expressions for the first-order term of a structured forward and backward error and show how, away from singularities, tolerance proportionality is achieved by adjusting the precision of the rootfinding tasks.", "venue": "Numerical Algorithms", "authors": ["Robert H. C. Moir", "Robert M. Corless", "Marc Moreno Maza", "Ning  Xie"], "year": 2019, "n_citations": 4}
{"id": 5561087, "s2_id": "92d1b468a295a70c5044bec50f120819c2651707", "title": "SimpleTensor - a user-friendly Mathematica package for elementary tensor and differential-geometric calculations", "abstract": "In this paper we present a short overview of the new Wolfram Mathematica package intended for elementary \u201din-basis\u201d tensor and differential-geometric calculations. In contrast to alternatives our package is designed to be easy-to-use, short, all-purpose, and hackable. It supports tensor contractions using Einstein notation, transformations between different bases, tensor derivative operator, expansion in basis vectors and forms, exterior derivative, and interior product.", "venue": "ArXiv", "authors": ["D. O. Rybalka"], "year": 2021, "n_citations": 0}
{"id": 5562364, "s2_id": "fd577a059af091b00bd179e6c307dc3df0b2a33d", "title": "A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra Computation", "abstract": "We propose a functional implementation of Multivariate Tower Automatic Differentiation. Our implementation is intended to be used in implementing C\u221e-structure computation of an arbitrary Weil algebra, which we discussed in [5].", "venue": "ArXiv", "authors": ["Hiromi  Ishii"], "year": 2021, "n_citations": 1}
{"id": 5564588, "s2_id": "8b7fa447794e20366f25de09edc5ac43dce47f76", "title": "On the uniqueness of simultaneous rational function reconstruction", "abstract": "This paper focuses on the problem of reconstructing a vector of rational functions given some evaluations, or more generally given their remainders modulo different polynomials. The special case of rational functions sharing the same denominator, a.k.a. Simultaneous Rational Function Reconstruction (SRFR), has many applications from linear system solving to coding theory, provided that SRFR has a unique solution. The number of unknowns in SRFR is smaller than for a general vector of rational function. This allows one to reduce the number of evaluation points needed to guarantee the existence of a solution, possibly losing its uniqueness. In this work, we prove that uniqueness is guaranteed for a generic instance.", "venue": "ISSAC", "authors": ["Eleonora  Guerrini", "Romain  Lebreton", "Ilaria  Zappatore"], "year": 2020, "n_citations": 2}
{"id": 5565694, "s2_id": "fe81420c45eaaae0587a02e1b85f810af27eac0d", "title": "Large Galois groups with applications to Zariski density", "abstract": "We introduce the first provably efficient algorithm to check if a finitely generated subgroup of an almost simple semi-simple group over the rationals is Zariski-dense. We reduce this question to one of computing Galois groups, and to this end we describe efficient algorithms to check if the Galois group of a polynomial $p$ with integer coefficients is \"generic\" (which, for arbitrary polynomials of degree $n$ means the full symmetric group $S_n,$ while for reciprocal polynomials of degree $2n$ it means the hyperoctahedral group $C_2 \\wr S_n.$). We give efficient algorithms to verify that a polynomial has Galois group $S_n,$ and that a reciprocal polynomial has Galois group $C_2 \\wr S_n.$ We show how these algorithms give efficient algorithms to check if a set of matrices $\\mathcal{G}$ in $\\mathop{SL}(n, \\mathbb{Z})$ or $\\mathop{Sp}(2n, \\mathbb{Z})$ generate a \\emph{Zariski dense} subgroup. \nThe complexity of doing this in$\\mathop{SL}(n, \\mathbb{Z})$ is of order $O(n^4 \\log n \\log \\|\\mathcal{G}\\|)\\log \\epsilon$ and in $\\mathop{Sp}(2n, \\mathbb{Z})$ the complexity is of order $O(n^8 \\log n\\log \\|\\mathcal{G}\\|)\\log \\epsilon$ In general semisimple groups we show that Zariski density can be confirmed or denied in time of order $O(n^14 \\log \\|\\mathcal{G}\\|\\log \\epsilon),$ where $\\epsilon$ is the probability of a wrong \"NO\" answer, while $\\|\\mathcal{G}\\|$ is the measure of complexity of the input (the maximum of the Frobenius norms of the generating matrices). The algorithms work essentially without change over algebraic number fields, and in other semi-simple groups. However, we restrict to the case of the special linear and symplectic groups and rational coefficients in the interest of clarity.", "venue": "ArXiv", "authors": ["Igor  Rivin"], "year": 2013, "n_citations": 8}
{"id": 5566672, "s2_id": "cea99aeaf3fc4f30eb3eafe17f938a841ee87e67", "title": "Some Open Problems in Combinatorial Physics", "abstract": "We point out four problems which have arisen during the recent research in the domain of Combinatorial Physics.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "H.  Cheballah"], "year": 2009, "n_citations": 3}
{"id": 5567622, "s2_id": "b3f50d56f5e1cacda2960e4ad0af049074f34b76", "title": "Similarity detection of rational space curves", "abstract": "We provide an algorithm to check whether two rational space curves are related by a similarity. The algorithm exploits the relationship between the curvatures and torsions of two similar curves, which is formulated in a computer algebra setting. Helical curves, where curvature and torsion are proportional, need to be distinguished as a special case. The algorithm is easy to implement, as it involves only standard computer algebra techniques, such as greatest common divisors and resultants, and Gr\\\"obner basis for the special case of helical curves. Details on the implementation and experimentation carried out using the computer algebra system Maple 18 are provided.", "venue": "J. Symb. Comput.", "authors": ["Juan Gerardo Alc\u00e1zar", "Carlos  Hermoso", "Georg  Muntingh"], "year": 2018, "n_citations": 10}
{"id": 5574782, "s2_id": "75b612af9adcc2d62bbfbe960d6f0cfde41b07f0", "title": "On Differentially Algebraic Generating Series for Walks in the Quarter Plane", "abstract": "We refine necessary and sufficient conditions for the generating series of a weighted model of a quarter plane walk to be differentially algebraic. In addition, we give algorithms based on the theory of Mordell-Weil lattices, that, for each weighted model, yield polynomial conditions on the weights determining this property of the associated generating series.", "venue": "Selecta Mathematica", "authors": ["CHARLOTTE  HARDOUIN", "MICHAEL F. SINGER"], "year": 2021, "n_citations": 4}
{"id": 5581274, "s2_id": "8d4d85b3abdab5e7f7cc8a505b622d27478fd7c3", "title": "On Computing Fixpoints in Well-Structured Regular Model Checking, with Applications to Lossy Channel Systems", "abstract": "We prove a general finite convergence theorem for \u201cupward-guarded\" fixpoint expressions over a well-quasi-ordered set. This has immediate applications in regular model checking of well-structured systems, where a main issue is the eventual convergence of fixpoint computations. In particular, we are able to directly obtain several new decidability results on lossy channel systems.", "venue": "LPAR", "authors": ["Christel  Baier", "Nathalie  Bertrand", "Philippe  Schnoebelen"], "year": 2006, "n_citations": 30}
{"id": 5583282, "s2_id": "63e3a6b659a74f27d96c692827883f243ee58118", "title": "New bounds and efficient algorithm for sparse difference resultant", "abstract": "Let $\\mathbb{P}=\\{\\mathbb{P}_0,\\mathbb{P}_1,\\dots,\\mathbb{P}_n\\}$ be a generic Laurent transformally essential system and $\\mathbb{P}_{\\mathbb{T}}=\\{\\mathbb{P}_0,\\mathbb{P}_1,\\dots,\\mathbb{P}_m\\} (m\\leq n)$ be its super essential system. We show that the sparse difference resultant of a simplified system of $\\mathbb{P}_{\\mathbb{T}}$ by setting the selected $n-m$ variables to one is the same to the one of $\\mathbb{P}$. Moreover, new order bounds of sparse difference resultant are obtained. Then we propose an efficient algorithm to compute sparse difference resultant which is the quotient of two determinants whose elements are the coefficients of the polynomials in the strong essential system. We analyze complexity of the algorithm. Experimental results show the efficiency of the algorithm.", "venue": "J. Symb. Comput.", "authors": ["Chun-Ming  Yuan", "Zhi-Yong  Zhang"], "year": 2021, "n_citations": 1}
{"id": 5583924, "s2_id": "b78210f6b3bb90282daf02a7cdafe4371739847e", "title": "Lattice Green's Functions of the Higher-Dimensional Face-Centered Cubic Lattices", "abstract": "We study the face-centered cubic (fcc) lattice in up to six dimensions. In particular, we are concerned with lattice Green functions (LGFs) and return probabilities. Computer algebra techniques, such as the method of creative telescoping, are used for deriving an ODE for a given LGF. For the four- and five-dimensional fcc lattices, we give rigorous proofs of the ODEs that were conjectured by Guttmann and Broadhurst. Additionally, we find the ODE of the LGF of the six-dimensional fcc lattice, a result that was not believed to be achievable with current computer hardware.", "venue": "ArXiv", "authors": ["Christoph  Koutschan"], "year": 2011, "n_citations": 25}
{"id": 5586835, "s2_id": "1cbad174ba54f9891d7e0d9eeebb3e65c5c56dcc", "title": "Multigraded Sylvester forms, Duality and Elimination Matrices", "abstract": "In this paper we study the equations of the elimination ideal associated with n+1 generic multihomogeneous polynomials defined over a product of projective spaces of dimension n. We first prove a duality property and then make this duality explicit by introducing multigraded Sylvester forms. These results provide a partial generalization of similar properties that are known in the setting of homogeneous polynomial systems defined over a single projective space. As an important consequence, we derive a new family of elimination matrices that can be used for solving zero-dimensional multiprojective polynomial systems by means of linear algebra methods.", "venue": "ArXiv", "authors": ["Laurent  Bus'e", "Marc  Chardin", "Navid  Nemati"], "year": 2021, "n_citations": 1}
{"id": 5600356, "s2_id": "ceb8e93390370c8612252a717b4ccf17c3396a62", "title": "Desingularization explains order-degree curves for ore operators", "abstract": "Desingularization is the problem of finding a left multiple of a given Ore operator in which some factor of the leading coefficient of the original operator is removed. An order-degree curve for a given Ore operator is a curve in the (r,d)-plane such that for all points (r,d) above this curve, there exists a left multiple of order r and degree d of the given operator. We give a new proof of a desingularization result by Abramov and van Hoeij for the shift case, and show how desingularization implies order-degree curves which are extremely accurate in examples.", "venue": "ISSAC '13", "authors": ["Shaoshi  Chen", "Maximilian  Jaroschek", "Manuel  Kauers", "Michael F. Singer"], "year": 2013, "n_citations": 27}
{"id": 5621786, "s2_id": "9d033ffb1b06b0ed1f352087dda8c2c06f16eb17", "title": "Matrix factoring by fraction-free reduction", "abstract": "We consider exact matrix decomposition by Gauss-Bareiss reduction. We investigate two aspects of the process: common row and column factors and the influence of pivoting strategies. We identify two types of common factors: systematic and statistical. Systematic factors depend on the process, while statistical factors depend on the specific data. We show that existing fraction-free QR (Gram-Schmidt) algorithms create a common factor in the last column of Q. We relate the existence of row factors in LU decomposition to factors appearing in the Smith normal form of the matrix. For statistical factors, we identify mechanisms and give estimates of the frequency. Our conclusions are tested by experimental data. For pivoting strategies, we compare the sizes of output factors obtained by different strategies. We also comment on timing differences.", "venue": "ArXiv", "authors": ["Johannes  Middeke", "David J. Jeffrey"], "year": 2016, "n_citations": 0}
{"id": 5624211, "s2_id": "89efe5dea38a3ba49657c5a697a6976febe233df", "title": "Computing the first few Betti numbers of semi-algebraic sets in single exponential time", "abstract": "Abstract In this paper we describe an algorithm that takes as input a description of a semi-algebraic set S \u2282 R k , defined by a Boolean formula with atoms of the form P > 0 , P 0 , P = 0 for P \u2208 P \u2282 R [ X 1 , \u2026 , X k ] , and outputs the first l + 1 Betti numbers of S , b 0 ( S ) , \u2026 , b l ( S ) . The complexity of the algorithm is ( s d ) k O ( l ) , where s = # ( P ) and d = max P \u2208 P deg ( P ) , which is singly exponential in k for l any fixed constant. Previously, singly exponential time algorithms were known only for computing the Euler\u2013Poincare characteristic, the zeroth and the first Betti numbers.", "venue": "J. Symb. Comput.", "authors": ["Saugata  Basu"], "year": 2006, "n_citations": 46}
{"id": 5624432, "s2_id": "a268a971c42d077809023547164d1d43a47915f9", "title": "Computer Algebra meets Finite Elements: an Efficient Implementation for Maxwell's Equations", "abstract": "We consider the numerical discretization of the time-domain Maxwell\u2019s equations with an energy-conserving discontinuous Galerkin finite element formulation. This particular formulation allows for higher order approximations of the electric and magnetic field. Special emphasis is placed on an efficient implementation which is achieved by taking advantage of recurrence properties and the tensor-product structure of the chosen shape functions. These recurrences have been derived symbolically with computer algebra methods reminiscent of the holonomic systems approach.", "venue": "ArXiv", "authors": ["Christoph  Koutschan", "Christoph  Lehrenfeld", "Joachim  Sch\u00f6berl"], "year": 2011, "n_citations": 14}
{"id": 5626315, "s2_id": "9e73e34438921df363e7fa11ae308d880753bd37", "title": "Solving the Forward Position Problem of an In-Parallel Planar Manipulator in the Gauss Plane", "abstract": "We study determining the posture of an in-parallel planar manipulator, which has three connectors composed of revolute, prismatic and revolute joints, from specified active joint variables. We construct an ideal in the field of complex numbers,\nand we introduce self inversive polynomials. We provide results for an in-parallel planar manipulator, which has a base and moving platform in right triangular shape. Using Sage computer algebra system, we compute its Groebner bases. We illustrate that the single variable polynomials obtained from the Groebner bases are self reciprocal.", "venue": "ArXiv", "authors": ["Sureyya  Sahin"], "year": 2015, "n_citations": 0}
{"id": 5628603, "s2_id": "6269d4295556f4f4d348ca9fb4f3a740db44fb6b", "title": "On the complexity of computing with zero-dimensional triangular sets", "abstract": "We study the complexity of some fundamental operations for triangular sets in dimension zero. Using Las Vegas algorithms, we prove that one can perform such operations as change of order, equiprojectable decomposition, or quasi-inverse computation with a cost that is essentially that of modular composition. Over an abstract field, this leads to a subquadratic cost (with respect to the degree of the underlying algebraic set). Over a finite field, in a boolean RAM model, we obtain a quasi-linear running time using Kedlaya and [email\u00a0protected]? algorithm for modular composition. Conversely, we also show how to reduce the problem of modular composition to change of order for triangular sets, so that all these problems are essentially equivalent. Our algorithms are implemented in Maple; we present some experimental results.", "venue": "J. Symb. Comput.", "authors": ["Adrien  Poteaux", "\u00c9ric  Schost"], "year": 2013, "n_citations": 26}
{"id": 5632893, "s2_id": "f0c07b46fd7e3df74a9960f30665e17d62b32b52", "title": "Towards an Intelligent Tutor for Mathematical Proofs", "abstract": "Computer-supported learning is an increasingly important form of study since it allows for independent learning and individualized instruction. In this paper, we discuss a novel approach to developing an intelligent tutoring system for teaching textbook-style mathematical proofs. We characterize the particularities of the domain and discuss common ITS design models. Our approach is motivated by phenomena found in a corpus of tutorial dialogs that were collected in a Wizard-of-Oz experiment. We show how an intelligent tutor for textbook-style mathematical proofs can be built on top of an adapted assertion-level proof assistant by reusing representations and proof search strategies originally developed for automated and interactive theorem proving. The resulting prototype was successfully evaluated on a corpus of tutorial dialogs and yields good results.", "venue": "ThEdu", "authors": ["Serge  Autexier", "Dominik  Dietrich", "Marvin R. G. Schiller"], "year": 2011, "n_citations": 6}
{"id": 5634288, "s2_id": "aa6daec87a839d421a42ad8f0968f67a8a22fbf7", "title": "Towards identification of explicit solutions to overdetermined systems of differential equations", "abstract": "The authors proposed a general way to find particular solutions for overdetermined systems of PDEs previously, where the number of equations is greater than the number of unknown functions. In this paper, we propose an algorithm for finding solutions for overdetermined PDE systems, where we use a method for finding an explicit solution for overdetermined algebraic (polynomial) equations. Using this algorithm, the solution of some overdetermined PDE systems can be obtained in explicit form. The main difficulty of this algorithm is the huge number of polynomial equations that arise, which need to be investigated and solved numerically or explicitly. For example, the overdetermined hydrodynamic equations obtained earlier by the authors give a minimum of 10 million such equations. However, if they are solved explicitly, then we can write out the solution of the hydrodynamic equations in a general form, which is of great scientific interest.", "venue": "ArXiv", "authors": ["Maxim  Zaytsev", "V'yacheslav  Akkerman"], "year": 2019, "n_citations": 0}
{"id": 5638689, "s2_id": "48a04268b08911b0dbe6165298d6a5c176b1f583", "title": "An in-place truncated fourier transform and applications to polynomial multiplication", "abstract": "The truncated Fourier transform (TFT) was introduced by van der Hoeven in 2004 as a means of smoothing the \"jumps\" in running time of the ordinary FFT algorithm that occur at power-of-two input sizes. However, the TFT still introduces these jumps in memory usage. We describe in-place variants of the forward and inverse TFT algorithms, achieving time complexity O(n log n) with only O(1) auxiliary space. As an application, we extend the second author's results on space-restricted FFT-based polynomial multiplication to polynomials of arbitrary degree.", "venue": "ISSAC", "authors": ["David  Harvey", "Daniel S. Roche"], "year": 2010, "n_citations": 27}
{"id": 5641848, "s2_id": "0c4a3e8e34aac63650c750d24a9b5161e10a7b5b", "title": "Computing hypergeometric solutions of second order linear differential equations using quotients of formal solutions and integral bases", "abstract": "We present two algorithms for computing hypergeometric solutions of second order linear differential operators with rational function coefficients. Our first algorithm searches for solutions of the form \\[ \\exp(\\int r \\, dx)\\cdot{_{2}F_1}(a_1,a_2;b_1;f) \\] where $r,f \\in \\overline{\\mathbb{Q}(x)}$, and $a_1,a_2,b_1 \\in \\mathbb{Q}$. It uses modular reduction and Hensel lifting. Our second algorithm tries to find solutions in the form \\[ \\exp(\\int r \\, dx)\\cdot \\left( r_0 \\cdot{_{2}F_1}(a_1,a_2;b_1;f) + r_1 \\cdot{_{2}F_1}'(a_1,a_2;b_1;f) \\right) \\] where $r_0, r_1 \\in \\overline{\\mathbb{Q}(x)}$, as follows: It tries to transform the input equation to another equation with solutions of the first type, and then uses the first algorithm.", "venue": "J. Symb. Comput.", "authors": ["Erdal  Imamoglu", "Mark van Hoeij"], "year": 2017, "n_citations": 24}
{"id": 5641849, "s2_id": "c3414e1e4f2058b79d3e805cd362f0f4df3fa1ac", "title": "Method for estimating hidden structures determined by unidentifiable state-space models and time-series data based on the Groebner basis", "abstract": "In this study, we propose a method for extracting the hidden algebraic structures of model parameters that are uniquely determined by observed time-series data and unidentifiable state-space models, explicitly and exhaustively. State-space models are often constructed based on the domain, for example, physical or biological. Such models include parameters that are assigned specific meanings in relation to the system under consideration, which is examined by estimating the parameters using the corresponding data. As the parameters of unidentifiable models cannot be uniquely determined from the given data, it is difficult to examine the systems described by such models. To overcome this difficulty, multiple possible sets of parameters are estimated and analysed in the exiting approaches; however, in general, all the possible parameters cannot be explored; therefore, considerations on the system using the estimated parameters become insufficient. In this study, focusing on certain structures determined by the observed data and models uniquely, even if they are unidentifiable, we introduce the concept of parameter variety. This is newly defined and proven to form algebraic varieties, in general. A computational algebraic method that relies on the Gr\u00f6bner basis for deriving the explicit representation of the varieties is presented along with the supporting theory. Furthermore, its application in the analysis of a model that describes virus dynamics is presented. With this, new insight on the dynamics overlooked by the conventional approach are discovered, confirming the applicability of our idea and the proposed method.", "venue": "ArXiv", "authors": ["Mizuka  Komatsu", "Takaharu  Yaguchi"], "year": 2020, "n_citations": 0}
{"id": 5645930, "s2_id": "deb5eeb2e4c527955ff56986ecc2fda0d2b73d9d", "title": "SqFreeEVAL: An (almost) optimal real-root isolation algorithm", "abstract": "Let f be a univariate polynomial with real coefficients, f@?R[X]. Subdivision algorithms based on algebraic techniques (e.g., Sturm or Descartes methods) are widely used for isolating the real roots of f in a given interval. In this paper, we consider a simple subdivision algorithm whose primitives are purely numerical (e.g., function evaluation). The complexity of this algorithm is adaptive because the algorithm makes decisions based on local data. The complexity analysis of adaptive algorithms (and this algorithm in particular) is a new challenge for computer science. In this paper, we compute the size of the subdivision tree for the SqFreeEVAL algorithm. The SqFreeEVAL algorithm is an evaluation-based numerical algorithm which is well-known in several communities. The algorithm itself is simple, but prior attempts to compute its complexity have proven to be quite technical and have yielded sub-optimal results. Our main result is a simple O(d(L+lnd)) bound on the size of the subdivision tree for the SqFreeEVAL algorithm on the benchmark problem of isolating all real roots of an integer polynomial f of degree d and whose coefficients can be written with at most L bits. Our proof uses two amortization-based techniques: first, we use the algebraic amortization technique of the standard Mahler-Davenport root bounds to interpret the integral in terms of d and L. Second, we use a continuous amortization technique based on an integral to bound the size of the subdivision tree. This paper is the first to use the novel analysis technique of continuous amortization to derive state of the art complexity bounds.", "venue": "J. Symb. Comput.", "authors": ["Michael A. Burr", "Felix  Krahmer"], "year": 2012, "n_citations": 27}
{"id": 5645932, "s2_id": "64c763b0f9565f77b06f8da9f8673085085e24ce", "title": "Symbolic Tensor Calculus - Functional and Dynamic Approach", "abstract": "In this paper, we briefly discuss the dynamic and functional approach to computer symbolic tensor analysis. The ccgrg package for Wolfram Language/Mathematica is used to illustrate this approach. Some examples of applications are attached.", "venue": "ArXiv", "authors": ["Andrzej  Woszczyna", "P.  Plaszczyk", "Wojciech  Czaja", "Zdzislaw A. Golda"], "year": 2016, "n_citations": 4}
{"id": 5652458, "s2_id": "31bb1d3791f9bae9fb0e0dfaf8470d1af57f0e88", "title": "An Illustrated Introduction to the Truncated Fourier Transform", "abstract": "The Truncated Fourier Transform (tft) is a variation of the Discrete Fourier Transform (dft/fft) that allows for input vectors that do not have length 2 n for n a positive integer. We present the univariate version of the tft, originally due to Joris van der Hoeven, heavily illustrating the presentation in order to make these methods accessible to a broader audience.", "venue": "ArXiv", "authors": ["Paul  Vrbik"], "year": 2016, "n_citations": 0}
{"id": 5661805, "s2_id": "b62cfd6dc299a5311eafbc61e4d2ebc7b9b5b9a0", "title": "Generic design of Chinese remaindering schemes", "abstract": "We propose a generic design for Chinese remainder algorithms. A Chinese remainder computation consists in reconstructing an integer value from its residues modulo coprime integers. We also propose an efficient linear data structure, a radix ladder, for the intermediate storage and computations. Our design is structured into three main modules: a black box residue computation in charge of computing each residue; a Chinese remaindering controller in charge of launching the computation and of the termination decision; an integer builder in charge of the reconstruction computation. We show that this design enables many different forms of Chinese remaindering (for example deterministic, early terminated, distributed, etc.); easy comparisons between these forms and user-transparent parallelism at different parallel grains.", "venue": "PASCO", "authors": ["Jean-Guillaume  Dumas", "Thierry  Gautier", "Jean-Louis  Roch"], "year": 2010, "n_citations": 5}
{"id": 5662967, "s2_id": "72247b2163cf200d26352ffee71ed61c896e59a5", "title": "Parallel Computation of Echelon Forms", "abstract": "We propose efficient parallel algorithms and implementations on shared memory architectures of LU factorization over a finite field. Compared to the corresponding numerical routines, we have identified three main specifities of linear algebra over finite fields. First, the arithmetic complexity could be dominated by modular reductions. Therefore, it is mandatory to delay as much as possible these reductions while mixing fine-grain parallelizations of tiled iterative and recursive algorithms. Second, fast linear algebra variants, e.g., using Strassen-Winograd algorithm, never suffer from instability and can thus be widely used in cascade with the classical algorithms. There, trade-offs are to be made between size of blocks well suited to those fast variants or to load and communication balancing. Third, many applications over finite fields require the rank profile of the matrix (quite often rank deficient) rather than the solution to a linear system. It is thus important to design parallel algorithms that preserve and compute this rank profile. Moreover, as the rank profile is only discovered during the algorithm, block size has then to be dynamic. We propose and compare several block decompositions: tile iterative with left-looking, right-looking and Crout variants, slab and tile recursive. Experiments demonstrate that the tile recursive variant performs better and matches the performance of reference numerical software when no rank deficiency occurs. Furthermore, even in the most heterogeneous case, namely when all pivot blocks are rank deficient, we show that it is possbile to maintain a high efficiency.", "venue": "Euro-Par", "authors": ["Jean-Guillaume  Dumas", "Thierry  Gautier", "Cl\u00e9ment  Pernet", "Ziad  Sultan"], "year": 2014, "n_citations": 12}
{"id": 5664993, "s2_id": "45258acbe863c47de43aeda55ae0d21896c31f9a", "title": "Spectral approach to verifying non-linear arithmetic circuits", "abstract": "This paper presents a fast and effective computer algebraic method for analyzing and verifying non-linear integer arithmetic circuits using a novel algebraic spectral model. It introduces a concept of algebraic spectrum, a numerical form of polynomial expression; it uses the distribution of coefficients of the monomials to determine the type of arithmetic function under verification. In contrast to previous works, the proof of functional correctness is achieved by computing an algebraic spectrum combined with local rewriting of word-level polynomials. The speedup is achieved by propagating coefficients through the circuit using And-Inverter Graph (AIG) datastructure. The effectiveness of the method is demonstrated with experiments including standard and Booth multipliers, and other synthesized non-linear arithmetic circuits up to 1024 bits containing over 12 million gates.", "venue": "ASP-DAC", "authors": ["Cunxi  Yu", "Tiankai  Su", "Atif  Yasin", "Maciej J. Ciesielski"], "year": 2019, "n_citations": 4}
{"id": 5676462, "s2_id": "0a575e2f2cbc14e704bc9002ef19d664503847f2", "title": "Computing strong regular characteristic pairs with Groebner bases", "abstract": "The W-characteristic set of a polynomial ideal is the minimal triangular set contained in the reduced lexicographical Groebner basis of the ideal. A pair (G,C) of polynomial sets is a strong regular characteristic pair if G is a reduced lexicographical Groebner basis, C is the W-characteristic set of the ideal , the saturated ideal sat(C) of C is equal to , and C is regular. In this paper, we show that for any polynomial ideal I with given generators one can either detect that I is unit, or construct a strong regular characteristic pair (G,C) by computing Groebner bases such that I$\\subseteq$sat(C)= and sat(C) divides I, so the ideal I can be split into the saturated ideal sat(C) and the quotient ideal I:sat(C). Based on this strategy of splitting by means of quotient and with Groebner basis and ideal computations, we devise a simple algorithm to decompose an arbitrary polynomial set F into finitely many strong regular characteristic pairs, from which two representations for the zeros of F are obtained: one in terms of strong regular Groebner bases and the other in terms of regular triangular sets. We present some properties about strong regular characteristic pairs and characteristic decomposition and illustrate the proposed algorithm and its performance by examples and experimental results.", "venue": "J. Symb. Comput.", "authors": ["Rina  Dong", "Dongming  Wang"], "year": 2021, "n_citations": 1}
{"id": 5677386, "s2_id": "7199e13ea4b9dec5f2548ba9bc99f18bf985bffb", "title": "p-Adic Stability In Linear Algebra", "abstract": "Using the differential precision methods developed previously by the same authors, we study the p-adic stability of standard operations on matrices and vector spaces. We demonstrate that lattice-based methods surpass naive methods in many applications, such as matrix multiplication and sums and intersections of subspaces. We also analyze determinants, characteristic polynomials and LU factorization using these differential methods. We supplement our observations with numerical experiments.", "venue": "ISSAC", "authors": ["Xavier  Caruso", "David  Roe", "Tristan  Vaccon"], "year": 2015, "n_citations": 15}
{"id": 5678601, "s2_id": "d32387e3a3936d1d365d8d2b25a08d349db2546b", "title": "On the existence of telescopers for mixed hypergeometric terms", "abstract": "We present a criterion for the existence of telescopers for mixed hypergeometric terms, which is based on additive and multiplicative decompositions. The criterion enables us to determine the termination of Zeilberger's algorithms for mixed hypergeometric inputs, and to verify that certain indefinite sums do not satisfy any polynomial differential equation.", "venue": "J. Symb. Comput.", "authors": ["Shaoshi  Chen", "Fr\u00e9d\u00e9ric  Chyzak", "Ruyong  Feng", "Guofeng  Fu", "Ziming  Li"], "year": 2015, "n_citations": 20}
{"id": 5679109, "s2_id": "01a6b8b734b1d4fd7a29cb6d852d68588ea9fbb2", "title": "Existence Problem of Telescopers: Beyond the Bivariate Case", "abstract": "In this paper, we solve the existence problem of telescopers for rational functions in three discrete variables. We reduce the problem to that of deciding the summability of bivariate rational functions, a problem which has recently been solved. This existence criteria is used, for example, for detecting the termination of Zeilberger's algorithm to the function classes studied in this paper.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Qing-Hu  Hou", "George  Labahn", "Rong-Hua  Wang"], "year": 2016, "n_citations": 8}
{"id": 5680392, "s2_id": "43b788b4e1e919d19a38f062483735adcda0cf29", "title": "Moderate Growth Time Series for Dynamic Combinatorics Modelisation", "abstract": "Here, we present a family of time series with a simple growth constraint. This family can be the basis of a model to apply to emerging computation in business and micro-economy where global functions can be expressed from local rules. We explicit a double statistics on these series which allows to establish a one-to-one correspondence between three other ballot-like strunctures.", "venue": "ArXiv", "authors": ["Lua\u00ef  Jaff", "G\u00e9rard  Duchamp", "Hatem Hadj Kacem", "Cyrille  Bertelle"], "year": 2007, "n_citations": 1}
{"id": 5684377, "s2_id": "6f086cf616a495fa68599dfb0e83a0c6a62292fd", "title": "An Algorithm for Deciding the Summability of Bivariate Rational Functions", "abstract": "Let \u0394 x f ( x , y ) = f ( x + 1 , y ) - f ( x , y ) and \u0394 y f ( x , y ) = f ( x , y + 1 ) - f ( x , y ) be the difference operators with respect to x and y. A rational function f ( x , y ) is called summable if there exist rational functions g ( x , y ) and h ( x , y ) such that f ( x , y ) = \u0394 x g ( x , y ) + \u0394 y h ( x , y ) . Recently, Chen and Singer presented a method for deciding whether a rational function is summable. To implement their method in the sense of algorithms, we need to solve two problems. The first is to determine the shift equivalence of two bivariate polynomials. We solve this problem by presenting an algorithm for computing the dispersion sets of any two bivariate polynomials. The second is to solve a univariate difference equation in an algebraically closed field. By considering the irreducible factorization of the denominator of f ( x , y ) in a general field, we present a new criterion which requires only finding a rational solution of a bivariate difference equation. We give a new estimation of the universal denominators based on the m-fold Gosper representation and transform the bivariate difference equation to a system of linear difference equations in one variable. Combining these algorithms, we can decide the summability of a bivariate rational function.", "venue": "Adv. Appl. Math.", "authors": ["Qing-Hu  Hou", "Rong-Hua  Wang"], "year": 2015, "n_citations": 9}
{"id": 5694851, "s2_id": "55d82b6d4fc1ad7c45beb1d2fbcf82fafc5d7f4d", "title": "Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and Symbolic Logic Rules", "abstract": "One of the challenges faced by conversational agents is their inability to identify unstated presumptions of their users\u2019 commands, a task trivial for humans due to their common sense. In this paper, we propose a zeroshot commonsense reasoning system for conversational agents in an attempt to achieve this. Our reasoner uncovers unstated presumptions from user commands satisfying a general template of if-(state ), then-(action ), because-(goal ). Our reasoner uses a state-ofthe-art transformer-based generative commonsense knowledge base (KB) as its source of background knowledge for reasoning. We propose a novel and iterative knowledge query mechanism to extract multi-hop reasoning chains from the neural KB which uses symbolic logic rules to significantly reduce the search space. Similar to any KBs gathered to date, our commonsense KB is prone to missing knowledge. Therefore, we propose to conversationally elicit the missing knowledge from human users with our novel dynamic question generation strategy, which generates and presents contextualized queries to human users. We evaluate the model with a user study with human users that achieves a 35% higher success rate compared to SOTA.", "venue": "EMNLP", "authors": ["Forough  Arabshahi", "Jennifer  Lee", "Antoine  Bosselut", "Yejin  Choi", "Tom  Mitchell"], "year": 2021, "n_citations": 1}
{"id": 5698586, "s2_id": "f05cb2c780bd6e575af13ad6ff5fa31ef74c9240", "title": "A fast algorithm for computing the characteristic polynomial of the p-curvature", "abstract": "We discuss theoretical and algorithmic questions related to the <i>p</i>-curvature of differential operators in characteristic <i>p</i>. Given such an operator <i>L</i>, and denoting by \u039e(<i>L</i>) the characteristic polynomial of its <i>p</i>-curvature, we first prove a new, alternative, description of \u039e(<i>L</i>). This description turns out to be particularly well suited to the fast computation of \u039e(<i>L</i>) when <i>p</i> is large: based on it, we design a new algorithm for computing \u039e(<i>L</i>), whose cost with respect to <i>p</i> is <i>\u00d5</i>(<i>p</i><sup>0.5</sup>) operations in the ground field. This is remarkable since, prior to this work, the fastest algorithms for this task, and even for the subtask of deciding nilpotency of the <i>p</i>-curvature, had merely slightly subquadratic complexity <i>\u00d5</i>(<i>p</i><sup>1.79</sup>).", "venue": "ISSAC", "authors": ["Alin  Bostan", "Xavier  Caruso", "\u00c9ric  Schost"], "year": 2014, "n_citations": 11}
{"id": 5704825, "s2_id": "a38d25b23a927c84828f2156545f19ac66839e0a", "title": "Generic regular decompositions for parametric polynomial systems", "abstract": "This paper presents a generalization of the authors\u2019 earlier work. In this paper, the two concepts, generic regular decomposition (GRD) and regular-decomposition-unstable (RDU) variety introduced in the authors\u2019 previous work for generic zero-dimensional systems, are extended to the case where the parametric systems are not necessarily zero-dimensional. An algorithm is provided to compute GRDs and the associated RDU varieties of parametric systems simultaneously on the basis of the algorithm for generic zero-dimensional systems proposed in the authors\u2019 previous work. Then the solutions of any parametric system can be represented by the solutions of finitely many regular systems and the decomposition is stable at any parameter value in the complement of the associated RDU variety of the parameter space. The related definitions and the results presented in the authors\u2019 previous work are also generalized and a further discussion on RDU varieties is given from an experimental point of view. The new algorithm has been implemented on the basis of DISCOVERER with Maple 16 and experimented with a number of benchmarks from the literature.", "venue": "J. Syst. Sci. Complex.", "authors": ["Zhenghong  Chen", "Xiaoxian  Tang", "Bican  Xia"], "year": 2015, "n_citations": 3}
{"id": 5706709, "s2_id": "4fb031df1ad7cc7c9b92f54d11113fbba3895ed5", "title": "Open Weak CAD and Its Applications", "abstract": "Abstract The concept of open weak CAD is introduced. Every open CAD is an open weak CAD. On the contrary, an open weak CAD is not necessarily an open CAD. An algorithm for computing projection polynomials of open weak CADs is proposed. The key idea is to compute the intersection of projection factor sets produced by different projection orders. The resulting open weak CAD often has smaller number of sample points than open CADs. The algorithm can be used for computing sample points for all open connected components of f \u2260 0 for a given polynomial f. It can also be used for many other applications, such as testing semi-definiteness of polynomials and copositive problems. In fact, we solved several difficult semi-definiteness problems efficiently by using the algorithm. Furthermore, applying the algorithm to copositive problems, we find an explicit expression of the polynomials producing open weak CADs under some conditions, which significantly improves the efficiency of solving copositive problems.", "venue": "J. Symb. Comput.", "authors": ["Liyun  Dai", "Jingjun  Han", "Hoon  Hong", "Bican  Xia"], "year": 2017, "n_citations": 4}
{"id": 5706985, "s2_id": "f6fdab6651d835b1dd4be1226782b826fa9062a3", "title": "Generating and Searching Families of FFT Algorithms", "abstract": "A fundamental question of longstanding theoretical interest is to prove the lowest exact count of real additions and multiplications required to compute a power-of-two discrete Fourier transform (DFT). For 35 years the split-radix algorithm held the record by requiring just 4n log n - 6n + 8 arithmetic operations on real numbers for a size-n DFT, and was widely believed to be the best possible. Recent work by Van Buskirk et al. demonstrated improvements to the split-radix operation count by using multiplier coefficients or \"twiddle factors\" that are not n-th roots of unity for a size-n DFT. This paper presents a Boolean Satisfiability-based proof of the lowest operation count for certain classes of DFT algorithms. First, we present a novel way to choose new yet valid twiddle factors for the nodes in flowgraphs generated by common power-of-two fast Fourier transform algorithms, FFTs. With this new technique, we can generate a large family of FFTs realizable by a fixed flowgraph. This solution space of FFTs is cast as a Boolean Satisfiability problem, and a modern Satisfiability Modulo Theory solver is applied to search for FFTs requiring the fewest arithmetic operations. Surprisingly, we find that there are FFTs requiring fewer operations than the split-radix even when all twiddle factors are n-th roots of unity.", "venue": "J. Satisf. Boolean Model. Comput.", "authors": ["Steve  Haynal", "Heidi  Haynal"], "year": 2011, "n_citations": 6}
{"id": 5713825, "s2_id": "10a07a2b7bcd469debd69791dfc702b2a5269462", "title": "Numerical Hilbert functions for Macaulay2", "abstract": "The NumericalHilbert package for Macaulay2 includes algorithms for computing local dual spaces of polynomial ideals, and related local combinatorial data about its scheme structure. These techniques are numerically stable, and can be used with floating point arithmetic over the complex numbers. They provide a viable alternative in this setting to purely symbolic methods such as standard bases. In particular, these methods can be used to compute initial ideals, local Hilbert functions and Hilbert regularity.", "venue": "ArXiv", "authors": ["Robert  Krone"], "year": 2014, "n_citations": 2}
{"id": 5716898, "s2_id": "db4e62c0f49b757dce2493a893946824cec76fca", "title": "Computing real roots of real polynomials", "abstract": "Computing the roots of a univariate polynomial is a fundamental and long-studied problem of computational algebra with applications in mathematics, engineering, computer science, and the natural sciences. For isolating as well as for approximating all complex roots, the best algorithm known is based on an almost optimal method for approximate polynomial factorization, introduced by Pan in 2002. Pan's factorization algorithm goes back to the splitting circle method from Schonhage in 1982. The main drawbacks of Pan's method are that it is quite involved22In Victor Pan's own words: \"Our algorithms are quite involved, and their implementation would require a non-trivial work, incorporating numerous known implementation techniques and tricks\". In fact, we are not aware of any implementation of Pan's method. and that all roots have to be computed at the same time. For the important special case, where only the real roots have to be computed, much simpler methods are used in practice; however, they considerably lag behind Pan's method with respect to complexity.In this paper, we resolve this discrepancy by introducing a hybrid of the Descartes method and Newton iteration, denoted ANewDsc, which is simpler than Pan's method, but achieves a run-time comparable to it. Our algorithm computes isolating intervals for the real roots of any real square-free polynomial, given by an oracle that provides arbitrary good approximations of the polynomial's coefficients. ANewDsc can also be used to only isolate the roots in a given interval and to refine the isolating intervals to an arbitrary small size; it achieves near optimal complexity for the latter task.", "venue": "J. Symb. Comput.", "authors": ["Michael  Sagraloff", "Kurt  Mehlhorn"], "year": 2016, "n_citations": 68}
{"id": 5717230, "s2_id": "c22d212aae1d9a4e4c11b07f8069ad2734a61307", "title": "A random walk through experimental mathematics", "abstract": "We describe our adventures in creating a new first-year course in Experimental Mathematics that uses active learning. We used a state-of-the-art facility, called The Western Active Learning Space, and got the students to \"drive the spaceship\" (at least a little bit). This paper describes some of our techniques for pedagogy, some of the vignettes of experimental mathematics that we used, and some of the outcomes. EYSC was a student in the simultaneously-taught senior sister course \"Open Problems in Experimental Mathematics\" the first time it was taught and an unofficial co-instructor the second time. Jon Borwein attended the Project Presentation Day (the second time) and gave thoughtful feedback to each student. This paper is dedicated to his memory.", "venue": "ArXiv", "authors": ["Eunice Y. S. Chan", "Robert M. Corless"], "year": 2018, "n_citations": 4}
{"id": 5719281, "s2_id": "867ebb5728a523d53f7a4d9341b5539b1663a00a", "title": "A polynomial time algorithm for computing the HNF of a module over the integers of a number field", "abstract": "We present a variation of the modular algorithm for computing the Hermite Normal Form of an OK-module presented by Cohen [4], where OK is the ring of integers of a number field K. An approach presented in [4] based on reductions modulo ideals was conjectured to run in polynomial time by Cohen, but so far, no such proof was available in the literature. In this paper, we present a modification of the approach of [4] to prevent the coefficient swell and we rigorously assess its complexity with respect to the size of the input and the invariants of the field K.", "venue": "ISSAC", "authors": ["Jean-Fran\u00e7ois  Biasse", "Claus  Fieker"], "year": 2012, "n_citations": 8}
{"id": 5720888, "s2_id": "57763e8b30a3dcf731bc008ad80bc3832ae58cd7", "title": "The SAT+CAS method for combinatorial search with applications to best matrices", "abstract": "In this paper, we provide an overview of the SAT+CAS method that combines satisfiability checkers (SAT solvers) and computer algebra systems (CAS) to resolve combinatorial conjectures, and present new results vis-\u00e0-vis best matrices. The SAT+CAS method is a variant of the Davis\u2013Putnam\u2013Logemann\u2013Loveland DPLL(T) architecture, where the T solver is replaced by a CAS. We describe how the SAT+CAS method has been previously used to resolve many open problems from graph theory, combinatorial design theory, and number theory, showing that the method has broad applications across a variety of fields. Additionally, we apply the method to construct the largest best matrices yet known and present new skew Hadamard matrices constructed from best matrices. We show the best matrix conjecture (that best matrices exist in all orders of the form r2 + r +\u20091) which was previously known to hold for r \u2264\u20096 also holds for r =\u20097. We also confirmed the results of the exhaustive searches that have been previously completed for r \u2264\u20096.", "venue": "Annals of Mathematics and Artificial Intelligence", "authors": ["Curtis  Bright", "Dragomir Z. Dokovic", "Ilias  Kotsireas", "Vijay  Ganesh"], "year": 2019, "n_citations": 3}
{"id": 5731020, "s2_id": "d8ea94bf8ac7d2fcf655b198b4efa461930cd9a0", "title": "Stationary or static space-times and Young tableaux", "abstract": "Algebraic curvature tensors possess generators which can be formed from symmetric or alternating tensors S, A or tensors \u03b8 with an irreducible (2 1)-symmetry. In differential geometry examples of curvature formulas are known which contain generators on the basis of S or A realized by differentiable tensor fields in a natural way. We show that certain curvature formulas for stationary or static space-times contain such differentiable realizations of generators based on \u03b8. The tensor \u03b8 is connected with the timelike Killing vector field of the space-time. \u03b8 lies in a special symmetry class from the in.nite family of irreducible (2 1)- symmetry classes. We determine characteristics of this class. In particular, this class allows a maximal reduction of the length of the curvature formulas. We use a projection formalism by Vladimirov, Young symmetrizers and Littlewood-Richardson products. Computer calculations were carried out by means of the packages Ricci and PERMS.", "venue": "ArXiv", "authors": ["Bernd  Fiedler"], "year": 2005, "n_citations": 0}
{"id": 5732461, "s2_id": "13df057e59f5328f73e67a4128d677f87ead59af", "title": "A triangular decomposition algorithm for differential polynomial systems with elementary computation complexity", "abstract": "In this paper, a new triangular decomposition algorithm is proposed for ordinary differential polynomial systems, which has triple exponential computational complexity. The key idea is to eliminate one algebraic variable from a set of polynomials in one step using the theory of multivariate resultant. This seems to be the first differential triangular decomposition algorithm with elementary computation complexity.", "venue": "J. Syst. Sci. Complex.", "authors": ["Wei  Zhu", "Xiao-Shan  Gao"], "year": 2017, "n_citations": 2}
{"id": 5736189, "s2_id": "d8b0456b84ca49a739c62630aa8026406b6245b7", "title": "PPT: New Low Complexity Deterministic Primality Tests Leveraging Explicit and Implicit Non-Residues. A Set of Three Companion Manuscripts", "abstract": "In this set of three companion manuscripts/articles, we unveil our new results on primality testing and reveal new primality testing algorithms enabled by those results. The results have been classified (and referred to) as lemmas/corollaries/claims whenever we have complete analytic proof(s); otherwise the results are introduced as conjectures. \nIn Part/Article 1, we start with the Baseline Primality Conjecture~(PBPC) which enables deterministic primality detection with a low complexity = O((log N)^2) ; when an explicit value of a Quadratic Non Residue (QNR) modulo-N is available (which happens to be the case for an overwhelming majority = 11/12 = 91.67% of all odd integers). We then demonstrate Primality Lemma PL-1, which reveals close connections between the state-of-the-art Miller-Rabin method and the renowned Euler-Criterion. This Lemma, together with the Baseline Primality Conjecture enables a synergistic fusion of Miller-Rabin iterations and our method(s), resulting in hybrid algorithms that are substantially better than their components. Next, we illustrate how the requirement of an explicit value of a QNR can be circumvented by using relations of the form: Polynomial(x) mod N = 0 ; whose solutions implicitly specify Non Residues modulo-N. We then develop a method to derive low-degree canonical polynomials that together guarantee implicit Non Residues modulo-N ; which along with the Generalized Primality Conjectures enable algorithms that achieve a worst case deterministic polynomial complexity = O( (log N)^3 polylog(log N)) ; unconditionally ; for any/all values of N. \nIn Part/Article 2 , we present substantial experimental data that corroborate all the conjectures. No counter example has been found. \nFinally in Part/Article 3, we present analytic proof(s) of the Baseline Primality Conjecture that we have been able to complete for some special cases.", "venue": "ArXiv", "authors": ["Dhananjay  Phatak", "Alan T. Sherman", "Steven D. Houston", "Andrew  Henry"], "year": 2019, "n_citations": 1}
{"id": 5745217, "s2_id": "abbf9a75ef05b7cf97584f5ccd0c261ac75edf5a", "title": "Symbolic computation of weighted Moore-Penrose inverse using partitioning method", "abstract": "Abstract We propose a method and algorithm for computing the weighted Moore\u2013Penrose inverse of one-variable rational matrices. Continuing this idea, we develop an algorithm for computing the weighted Moore\u2013Penrose inverse of one-variable polynomial matrix. These methods and algorithms are generalizations of the method for computing the weighted Moore\u2013Penrose inverse for constant matrices, originated in Wang and Chen [G.R. Wang, Y.L. Chen, A recursive algorithm for computing the weighted Moore\u2013Penrose inverse A MN \u2020 , J. Comput. Math. 4 (1986) 74\u201385], and the partitioning method for computing the Moore\u2013Penrose inverse of rational and polynomial matrices introduced in Stanimirovic and Tasic [P.S. Stanimirovic, M.B. Tasic, Partitioning method for rational and polynomial matrices, Appl. Math. Comput. 155 (2004) 137\u2013163]. Algorithms are implemented in the symbolic computational package MATHEMATICA .", "venue": "Appl. Math. Comput.", "authors": ["Milan B.  Tasi\u0107", "Predrag S.  Stanimirovi\u0107", "Marko D.  Petkovi\u0107"], "year": 2007, "n_citations": 27}
{"id": 5746242, "s2_id": "a9ade41f76d02545e24f93feaacbdd1148706c6a", "title": "Characterizing 1-dof Henneberg-I graphs with efficient configuration spaces", "abstract": "We define and study exact, efficient representations of realization spaces of a natural class of underconstrained 2D Euclidean Distance constraint systems (Linkages or Frameworks) based on 1-dof Henneberg-I graphs. Each representation corresponds to a choice of parameters and yields a different parametrized configuration space. Our notion of efficiency is based on the algebraic complexities of sampling the configuration space and of obtaining a realization from the sample (parametrized) configuration. Significantly, we give purely combinatorial characterizations that capture (i) the class of graphs that have efficient configuration spaces and (ii) the possible choices of representation parameters that yield efficient configuration spaces for a given graph. Our results automatically yield an efficient algorithm for sampling realizations, without missing extreme or boundary realizations. In addition, our results formally show that our definition of efficient configuration space is robust and that our characterizations are tight. We choose the class of 1-dof Henneberg-I graphs in order to take the next step in a systematic and graded program of combinatorial characterizations of efficient configuration spaces. In particular, the results presented here are the first characterizations that go beyond graphs that have connected and convex configuration spaces.", "venue": "SAC '09", "authors": ["Heping  Gao", "Meera  Sitharam"], "year": 2009, "n_citations": 12}
{"id": 5747986, "s2_id": "0e03ddac43510af2fd71ef5a72773ec3901961f4", "title": "Bounds for D-finite closure properties", "abstract": "We provide bounds on the size of operators obtained by algorithms for executing D-finite closure properties. For operators of small order, we give bounds on the degree and on the height (bit-size). For higher order operators, we give degree bounds that are parameterized with respect to the order and reflect the phenomenon that higher order operators may have lower degrees (order-degree curves).", "venue": "ISSAC", "authors": ["Manuel  Kauers"], "year": 2014, "n_citations": 4}
{"id": 5754208, "s2_id": "b063f0f74ce5b4f9bc11f8b939b89cfed22ee566", "title": "Decomposition of polynomial sets into characteristic pairs", "abstract": "A characteristic pair is a pair (G,C) of polynomial sets in which G is a reduced lexicographic Groebner basis, C is the minimal triangular set contained in G, and C is normal. In this paper, we show that any finite polynomial set P can be decomposed algorithmically into finitely many characteristic pairs with associated zero relations, which provide representations for the zero set of P in terms of those of Groebner bases and those of triangular sets. The algorithm we propose for the decomposition makes use of the inherent connection between Ritt characteristic sets and lexicographic Groebner bases and is based essentially on the structural properties and the computation of lexicographic Groebner bases. Several nice properties about the decomposition and the resulting characteristic pairs, in particular relationships between the Groebner basis and the triangular set in each pair, are established. Examples are given to illustrate the algorithm and some of the properties.", "venue": "Math. Comput.", "authors": ["Dongming  Wang", "Rina  Dong", "Chenqi  Mou"], "year": 2020, "n_citations": 5}
{"id": 5769836, "s2_id": "2542e882a8fb5dcf086ee64e4827df0a2b959ce8", "title": "Globally Optimal Solution to Inverse Kinematics of 7DOF Serial Manipulator", "abstract": "The Inverse Kinematics (IK) problem is to nd robot control parameters to bring it into the desired position under the kinematics and collision constraints. We present a global solution to the optimal IK problem for a general serial 7DOF manipulator with revolute joints and a quadratic polynomial objective function. We show that the kinematic constraints due to rotations can all be generated by second-degree polynomials. This is important since it signicantly simplies further step where we nd the optimal solution by Lasserre relaxations of non-convex polynomial systems. We demonstrate that the second relaxation is sucient to solve the 7DOF IK problem. Our approach is certiably globally optimal. We demonstrate the method on the 7DOF KUKA LBR IIWA manipulator and show that we are able to compute the optimal IK or certify in-feasibility in 99 % tested poses.", "venue": "ArXiv", "authors": ["Pavel  Trutman", "Mohab Safey El Din", "Didier  Henrion", "Tom\u00e1s  Pajdla"], "year": 2020, "n_citations": 1}
{"id": 5783099, "s2_id": "f278df9803ae95315485d33e5e535164118984b5", "title": "Entropy of tropical holonomic sequences", "abstract": "We introduce tropical holonomic sequences of a given order and calculate their entropy in case of the second order.", "venue": "J. Symb. Comput.", "authors": ["Dima  Grigoriev"], "year": 2020, "n_citations": 1}
{"id": 5783229, "s2_id": "a697f0d387b2c33a389fd6746d2374505e8648ef", "title": "ATENSOR - REDUCE program for tensor simplification", "abstract": "The paper presents a REDUCE program for the simplification of tensor expressions that are considered as formal indexed objects. The proposed algorithm is based on the consideration of tensor expressions as vectors in some linear space. This linear space is formed by all the elements of the group algebra of the corresponding tensor expression. Such approach permits us to simplify the tensor expressions possessing symmetry properties, summation (dummy) indices and multiterm identities by unify manner. The canonical element for the tensor expression is defined in terms of the basic vectors of this linear space. The main restriction of the algorithm is the dimension of the linear space that is equal to N!, where N is a number of indices of the tensor expression. The program uses REDUCE as user interface.", "venue": "ArXiv", "authors": ["Viatcheslav A. Ilyin", "Alexander  Kryukov"], "year": 2018, "n_citations": 11}
{"id": 5788121, "s2_id": "c62a00ee404d32ca7078f65ed460657abfdd29f5", "title": "Automated Synthesis of Safe Digital Controllers for Sampled-Data Stochastic Nonlinear Systems", "abstract": "We present a new method for the automated synthesis of digital controllers with formal safety guarantees for systems with nonlinear dynamics, noisy output measurements, and stochastic disturbances. Our method derives digital controllers such that the corresponding closed-loop system, modeled as a sampled-data stochastic control system, satisfies a safety specification with probability above a given threshold. Our technique uses a fast solver and an optimization method to search for candidate controllers, which are then formally evaluated in closed-loop with the system in question by a verified solver. Unstable candidate controllers are discarded by efficiently checking a sufficient condition for Lyapunov stability of sampled-data nonlinear systems. We evaluate our technique on three case studies: an artificial pancreas model, a powertrain control model, and a quadruple-tank process.", "venue": "IEEE Access", "authors": ["Fedor  Shmarov", "Sadegh  Soudjani", "Nicola  Paoletti", "Ezio  Bartocci", "Shan  Lin", "Scott A. Smolka", "Paolo  Zuliani"], "year": 2020, "n_citations": 7}
{"id": 5796437, "s2_id": "10d2c31ddad671410d43ed06c05082768950cde2", "title": "How to integrate a polynomial over a simplex", "abstract": "This paper starts by settling the computational complexity of the problem of integrating a polynomial function f over a rational simplex. We prove that the problem is NP-hard for arbitrary polynomials via a generalization of a theorem of Motzkin and Straus. On the other hand, if the polynomial depends only on a fixed number of variables, while its degree and the dimension of the simplex are allowed to vary, we prove that integration can be done in polynomial time. As a consequence, for polynomials of fixed total degree, there is a polynomial time algorithm as well. We explore our algorithms with some experiments. We conclude the article with extensions to other polytopes and discussion of other available methods. 1.", "venue": "Math. Comput.", "authors": ["Velleda  Baldoni", "Nicole  Berline", "Jes\u00fas A. De Loera", "Matthias  K\u00f6ppe", "Mich\u00e8le  Vergne"], "year": 2011, "n_citations": 85}
{"id": 5796946, "s2_id": "c9af30358358b15d05ce72a86ec5f0ce883afdc6", "title": "Augmenting Policy Learning with Routines Discovered from a Single Demonstration", "abstract": "Humans can abstract prior knowledge from very little data and use it to boost skill learning. In this paper, we propose routineaugmented policy learning (RAPL), which discovers routines composed of primitive actions from a single demonstration and uses discovered routines to augment policy learning. To discover routines from the demonstration, we first abstract routine candidates by identifying grammar over the demonstrated action trajectory. Then, the best routines measured by length and frequency are selected to form a routine library. We propose to learn policy simultaneously at primitive-level and routine-level with discovered routines, leveraging the temporal structure of routines. Our approach enables imitating expert behavior at multiple temporal scales for imitation learning and promotes reinforcement learning exploration. Extensive experiments on Atari games demonstrate that RAPL improves the state-of-the-art imitation learning method SQIL and reinforcement learning method A2C. Further, we show that discovered routines can generalize to unseen levels and difficulties on the", "venue": "AAAI", "authors": ["Zelin  Zhao", "Chuang  Gan", "Jiajun  Wu", "Xiaoxiao  Guo", "Joshua B. Tenenbaum"], "year": 2021, "n_citations": 0}
{"id": 5797793, "s2_id": "0f7918f4b40e29724e026d607bdca788702e659f", "title": "Integrating multiple sources to answer questions in algebraic topology", "abstract": "We present in this paper an evolution of a tool from a user interface for a concrete Computer Algebra system for Algebraic Topology (the Kenzo system), to a front-end allowing the interoperability among different sources for computation and deduction. The architecture allows the system not only to interface several systems, but also to make them cooperate in shared calculations.", "venue": "AISC'10/MKM'10/Calculemus'10", "authors": ["J\u00f3nathan  Heras", "Vico  Pascual", "Ana  Romero", "Julio  Rubio"], "year": 2010, "n_citations": 3}
{"id": 5815409, "s2_id": "ed05832c9e6adf956d356e30118945fc47825f04", "title": "Deciding Nonnegativity of Polynomials by MAPLE", "abstract": "There have been some effective tools for solving (constant/parametric) semi-algebraic systems in Maple's library RegularChains since Maple 13. By using the functions of the library, e.g., RealRootClassfication, one can prove and discover polynomial inequalities. This paper is more or less a user guide on using RealRootClassfication to prove the nonnegativity of polynomials. We show by examples how to use this powerful tool to prove a polynomial is nonnegative under some polynomial inequality and/or equation constraints. Some tricks for using the tool are also provided.", "venue": "ArXiv", "authors": ["Lu  Yang", "Bican  Xia"], "year": 2013, "n_citations": 2}
{"id": 5815933, "s2_id": "c1ce807edc3643e9767d4060c376b44e5fb9e4da", "title": "Groebner Bases Applied to Systems of Linear Difference Equations", "abstract": "In this paper we consider systems of partial (multidimensional) linear difference equations. Specifically, such systems arise in scientific computing under discretization of linear partial differential equations and in computational high energy physics as recurrence relations for multiloop Feynman integrals. The most universal algorithmic tool for investigation of linear difference systems is based on their transformation into an equivalent Groebner basis form. We present an algorithm for this transformation implemented in Maple. The algorithm and its implementation can be applied to automatic generation of difference schemes for linear partial differential equations and to reduction of Feynman integrals. Some illustrative examples are given.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt"], "year": 2006, "n_citations": 0}
{"id": 5817020, "s2_id": "c1aa2c3b73f5787bac7f1d0e883284c33123ab4a", "title": "Local Search for Fast Matrix Multiplication", "abstract": "Laderman discovered a scheme for computing the product of two 3x3 matrices using only 23 multiplications in 1976. Since then, some more such schemes were proposed, but it remains open how many there are and whether there exist schemes with fewer than 23 multiplications. In this paper we present two independent SAT-based methods for finding new schemes. Both methods allow computing a few hundred new schemes individually, and many thousands when combined. Local search SAT solvers outperform CDCL solvers consistently in this application.", "venue": "SAT", "authors": ["Marijn  Heule", "Manuel  Kauers", "Martina  Seidl"], "year": 2019, "n_citations": 6}
{"id": 5829971, "s2_id": "dc22c3d555af57dd2dfb03db76df7efdfac65aff", "title": "Spherical Distribution of 5 Points with Maximal Distance Sum", "abstract": "In this paper, we consider the problem of spherical distribution of 5 points, that is, how to configure 5 points on the unit sphere such that the mutual distance sum is maximal. It is conjectured that the sum of distances is maximal if the 5 points form a bipyramid distribution with two points positioned at opposite poles of the sphere and the other three positioned uniformly on the equator. We study this problem using interval methods and related techniques, and give a computer-assisted proof.", "venue": "Discret. Comput. Geom.", "authors": ["Xiaorong  Hou", "Junwei  Shao"], "year": 2011, "n_citations": 19}
{"id": 5832165, "s2_id": "a8f6f1345c7516c3e485ca7f13f4016d9ab4ffb2", "title": "SONC Optimization and Exact Nonnegativity Certificates via Second-Order Cone Programming", "abstract": "The second-order cone (SOC) is a class of simple convex cones and optimizing over them can be done more efficiently than with semidefinite programming. It is interesting both in theory and in practice to investigate which convex cones admit a representation using SOCs, given that they have a strong expressive ability. In this paper, we prove constructively that the cone of sums of nonnegative circuits (SONC) admits an SOC representation. Based on this, we give a new algorithm for unconstrained polynomial optimization via SOC programming. We also provide a hybrid numeric-symbolic scheme which combines the numerical procedure with a rounding-projection algorithm to obtain exact nonnegativity certificates. Numerical experiments demonstrate the efficiency of our algorithm for polynomials with fairly large degree and number of variables.", "venue": "ArXiv", "authors": ["Victor  Magron", "Jie  Wang"], "year": 2020, "n_citations": 2}
{"id": 5835695, "s2_id": "8a777e8410aaf3aecb40d9dbeca1cc8c3b32a6d8", "title": "Computing the decomposition group of a zero-dimensional ideal by elimination method", "abstract": "In this note, we show that the decomposition group $Dec(I)$ of a zero-dimensional radical ideal $I$ in ${\\bf K}[x_1,\\ldots,x_n]$ can be represented as the direct sum of several symmetric groups of polynomials based upon using Gr\\\"{o}bner bases. The new method makes a theoretical contribution to discuss the decomposition group of $I$ by using Computer Algebra without considering the complexity. As one application, we also present an approach to yield new triangular sets in computing triangular decomposition of polynomial sets ${\\mathbb P}$ if $Dec( )$ is known.", "venue": "ArXiv", "authors": ["Yongbin  Li"], "year": 2016, "n_citations": 0}
{"id": 5837216, "s2_id": "beb325a509ca9fce6fa98c0cb78a1e3df0b86cfd", "title": "The Method of Gauss-Newton to Compute Power Series Solutions of Polynomial Homotopies", "abstract": "Abstract We consider the extension of the method of Gauss\u2013Newton from complex floating-point arithmetic to the field of truncated power series with complex floating-point coefficients. With linearization we formulate a linear system where the coefficient matrix is a series with matrix coefficients, and provide a characterization for when the matrix series is regular based on the algebraic variety of an augmented system. The structure of the linear system leads to a block triangular system. In the regular case, solving the linear system is equivalent to solving a Hermite interpolation problem. We show that this solution has cost cubic in the problem size. In general, at singular points, we rely on methods of tropical algebraic geometry to compute Puiseux series. With a few illustrative examples, we demonstrate the application to polynomial homotopy continuation.", "venue": "ArXiv", "authors": ["Nathan  Bliss", "Jan  Verschelde"], "year": 2016, "n_citations": 5}
{"id": 5839555, "s2_id": "33f2742f803f4de0a5c33ca75975c62386f320a1", "title": "Programming Realization of Symbolic Computations for Non-linear Commutator Superalgebras over the Heisenberg-Weyl Superalgebra: Data Structures and Processing Methods", "abstract": "We suggest a programming realization of an algorithm for verifying a given set of algebraic relations in the form of a supercommutator multiplication table for the Verma module, which is constructed according to a generalized Cartan procedure for a quadratic superalgebra and whose elements are realized as a formal power series with respect to non-commuting elements. To this end, we propose an algebraic procedure of Verma module construction and its realization in terms of non-commuting creation and annihilation operators of a given Heisenberg--Weyl superalgebra. In doing so, we set up a problem which naturally arises within a Lagrangian description of higher-spin fields in anti-de-Sitter (AdS) spaces: to verify the fact that the resulting Verma module elements obey the given commutator multiplication for the original non-linear superalgebra. The problem setting is based on a restricted principle of mathematical induction, in powers of inverse squared radius of the AdS-space. For a construction of an algorithm resolving this problem, we use a two-level data model within the object-oriented approach, which is realized on a basis of the programming language C#. The program allows one to consider objects (of a less general nature than non-linear commutator superalgebras) that fall under the class of so-called $GR$-algebras, for whose treatment one widely uses the module \\emph{Plural} of the system \\emph{Singular} of symbolic computations for polynomials.", "venue": "ArXiv", "authors": ["Andrei  Kuleshov", "Alexander A. Reshetnyak"], "year": 2009, "n_citations": 5}
{"id": 5839755, "s2_id": "5e709153c72083aa1ecce88789c8a27858dbefc3", "title": "Deciding the Consistency of Non-Linear Real Arithmetic Constraints with a Conflict Driven Search Using Cylindrical Algebraic Coverings", "abstract": "We present a new algorithm for determining the satisfiability of conjunctions of non-linear polynomial constraints over the reals, which can be used as a theory solver for satisfiability modulo theory (SMT) solving for non-linear real arithmetic. The algorithm is a variant of Cylindrical Algebraic Decomposition (CAD) adapted for satisfiability, where solution candidates (sample points) are constructed incrementally, either until a satisfying sample is found or sufficient samples have been sampled to conclude unsatisfiability. The choice of samples is guided by the input constraints and previous conflicts. \nThe key idea behind our new approach is to start with a partial sample; demonstrate that it cannot be extended to a full sample; and from the reasons for that rule out a larger space around the partial sample, which build up incrementally into a cylindrical algebraic covering of the space. There are similarities with the incremental variant of CAD, the NLSAT method of Jovanovic and de~Moura, and the NuCAD algorithm of Brown; but we present worked examples and experimental results on a preliminary implementation to demonstrate the differences to these, and the benefits of the new approach.", "venue": "J. Log. Algebraic Methods Program.", "authors": ["Erika  'Abrah'am", "James H. Davenport", "Matthew  England", "Gereon  Kremer"], "year": 2021, "n_citations": 4}
{"id": 5846502, "s2_id": "22fe5247c8a41d6bf6f289efb592fc114d36139e", "title": "The strong approximation theorem and computing with linear groups", "abstract": "Abstract We obtain a computational realization of the strong approximation theorem. That is, we develop algorithms to compute all congruence quotients modulo rational primes of a finitely generated Zariski dense group H \u2264 SL ( n , Z ) for n \u2265 2 . More generally, we are able to compute all congruence quotients of a finitely generated Zariski dense subgroup of SL ( n , Q ) for n > 2 .", "venue": "Journal of Algebra", "authors": ["Alla  Detinko", "Dane  Flannery", "Alexander  Hulpke"], "year": 2019, "n_citations": 4}
{"id": 5849045, "s2_id": "b41323c11bde3cfb6e32d83d361cb9eb84bc73f8", "title": "Balanced presentations of the trivial group on two generators and the Andrews-Curtis conjecture", "abstract": "The Andrews-Curtis conjecture states that every balanced presentation of the trivial group can be reduced to the standard one by a sequence of the elementary Nielsen transformations and conjugations. In this paper we describe all balanced presentations of the trivial group on two generators and with the total length of relators <= 12. We show that all these presentations satisfy the Andrews-Curtis conjecture.", "venue": "ArXiv", "authors": ["Alexei D. Miasnikov", "Alexei G. Myasnikov"], "year": 2003, "n_citations": 22}
{"id": 5853856, "s2_id": "467a471dc687c50830c04b5d5bd9983a198e4a11", "title": "Proof Theory at Work: Complexity Analysis of Term Rewrite Systems", "abstract": "This thesis is concerned with investigations into the \"complexity of term rewriting systems\". Moreover the majority of the presented work deals with the \"automation\" of such a complexity analysis. The aim of this introduction is to present the main ideas in an easily accessible fashion to make the result presented accessible to the general public. Necessarily some technical points are stated in an over-simplified way.", "venue": "ArXiv", "authors": ["Georg  Moser"], "year": 2009, "n_citations": 16}
{"id": 5860513, "s2_id": "654ce294a79225ddf1dbb362ad445d703eafcedd", "title": "Efficient Higher Order Derivatives of Objective Functions Composed of Matrix Operations", "abstract": "This paper is concerned with the efficient evaluation of higher-order derivatives of functions $f$ that are composed of matrix operations. I.e., we want to compute the $D$-th derivative tensor $\\nabla^D f(X) \\in \\mathbb R^{N^D}$, where $f:\\mathbb R^{N} \\to \\mathbb R$ is given as an algorithm that consists of many matrix operations. We propose a method that is a combination of two well-known techniques from Algorithmic Differentiation (AD): univariate Taylor propagation on scalars (UTPS) and first-order forward and reverse on matrices. The combination leads to a technique that we would like to call univariate Taylor propagation on matrices (UTPM). The method inherits many desirable properties: It is easy to implement, it is very efficient and it returns not only $\\nabla^D f$ but yields in the process also the derivatives $\\nabla^d f$ for $d \\leq D$. As performance test we compute the gradient $\\nabla f(X)$ % and the Hessian $\\nabla_A^2 f(A)$ by a combination of forward and reverse mode of $f(X) = \\trace (X^{-1})$ in the reverse mode of AD for $X \\in \\mathbb R^{n \\times n}$. We observe a speedup of about 100 compared to UTPS. Due to the nature of the method, the memory footprint is also small and therefore can be used to differentiate functions that are not accessible by standard methods due to limited physical memory.", "venue": "ArXiv", "authors": ["Sebastian F. Walter"], "year": 2009, "n_citations": 0}
{"id": 5861378, "s2_id": "ad6d438eb03122203a3e0702ead011092ed7e43e", "title": "Chordal networks of polynomial ideals", "abstract": "We introduce a novel representation of structured polynomial ideals, which we refer to as chordal networks. The sparsity structure of a polynomial system is often described by a graph that captures the interactions among the variables. Chordal networks provide a computationally convenient decomposition into simpler (triangular) polynomial sets, while preserving the underlying graphical structure. We show that many interesting families of polynomial ideals admit compact chordal network representations (of size linear in the number of variables), even though the number of components is exponentially large. Chordal networks can be computed for arbitrary polynomial systems using a refinement of the chordal elimination algorithm from [Cifuentes-Parrilo-2016]. Furthermore, they can be effectively used to obtain several properties of the variety, such as its dimension, cardinality, and equidimensional components, as well as an efficient probabilistic test for radical ideal membership. We apply our methods to examples from algebraic statistics and vector addition systems; for these instances, algorithms based on chordal networks outperform existing techniques by orders of magnitude.", "venue": "SIAM J. Appl. Algebra Geom.", "authors": ["Diego  Cifuentes", "Pablo A. Parrilo"], "year": 2017, "n_citations": 12}
{"id": 5863145, "s2_id": "f8a718aeb0cbd098c29b80ce5f04e2595df7e2f4", "title": "Adjoint Differentiation for generic matrix functions", "abstract": "We derive a formula for the adjoint A of a square-matrix operation of the form C = f(A), where f is holomorphic in the neighborhood of each eigenvalue. We then apply the formula to derive closed-form expressions in particular cases of interest such as the case when we have a spectral decomposition A = UDU, the spectrum cut-off C = A+ and the Nearest Correlation Matrix routine. Finally, we explain how to simplify the computation of adjoints for regularized linear regression coefficients.", "venue": "ArXiv", "authors": ["Andrei  Goloubentsev", "Dmitri  Goloubentsev", "Evgeny  Lakshtanov"], "year": 2021, "n_citations": 0}
{"id": 5868535, "s2_id": "d4b61b49c3b0c16d8d5c103802b77135fb9bf650", "title": "What underlies rapid learning and systematic generalization in humans", "abstract": "Despite the groundbreaking successes of neural networks, contemporary models require extensive training with massive datasets and exhibit poor out-of-sample generalization. One proposed solution is to build systematicity and domain-specific constraints into the model, echoing the tenets of classical, symbolic cognitive architectures. In this paper, we consider the limitations of this approach by examining human adults\u2019 ability to learn an abstract reasoning task from a brief instructional tutorial and explanatory feedback for incorrect responses, demonstrating that human learning dynamics and ability to generalize outside the range of the training examples differ drastically from those of a representative neural network model, and that the model is brittle to changes in features not anticipated by its authors. We present further evidence from human data that the ability to consistently solve the puzzles was associated with education, particularly basic mathematics education, and with the ability to provide a reliably identifiable, valid description of the strategy used. We propose that rapid learning and systematic generalization in humans may depend on a gradual, experience-dependent process of learningto-learn using instructions and explanations to guide the construction of explicit abstract rules that support generalizable inferences.", "venue": "ArXiv", "authors": ["Andrew Joohun Nam", "James L. McClelland"], "year": 2021, "n_citations": 1}
{"id": 5870198, "s2_id": "430aa3ae303eeb350262037cfdfd273620a8e295", "title": "New Remarks on the Factorization and Equivalence Problems for a Class of Multivariate Polynomial Matrices", "abstract": "This paper is concerned with the factorization and equivalence problems of multivariate polynomial matrices. We present some new criteria for the existence of matrix factorizations for a class of multivariate polynomial matrices, and obtain a necessary and sufficient condition for the equivalence of a square polynomial matrix and a diagonal matrix. Based on the constructive proof of the new criteria, we give a factorization algorithm and prove the uniqueness of the factorization. We implement the algorithm on Maple, and two illustrative examples are given to show the effectiveness of the algorithm.", "venue": "ArXiv", "authors": ["Dong  Lu", "Dingkang  Wang", "Fanghui  Xiao"], "year": 2020, "n_citations": 0}
{"id": 5871475, "s2_id": "f800ec5057565016488eb9c8621696393051fe29", "title": "Symbolic Versus Numerical Computation and Visualization of Parameter Regions for Multistationarity of Biological Networks", "abstract": "We investigate models of the mitogenactivated protein kinases (MAPK) network, with the aim of determining where in parameter space there exist multiple positive steady states. We build on recent progress which combines various symbolic computation methods for mixed systems of equalities and inequalities. We demonstrate that those techniques benefit tremendously from a newly implemented graph theoretical symbolic preprocessing method. We compare computation times and quality of results of numerical continuation methods with our symbolic approach before and after the application of our preprocessing.", "venue": "CASC", "authors": ["Matthew  England", "Hassan  Errami", "Dima  Grigoriev", "Ovidiu  Radulescu", "Thomas  Sturm", "Andreas  Weber"], "year": 2017, "n_citations": 20}
{"id": 5873329, "s2_id": "1a15a62e1ba9ccafec0aeff0debb77c24ebc454d", "title": "Lie algebra conjugacy", "abstract": "We study the problem of matrix Lie algebra conjugacy. Lie algebras arise centrally in areas as diverse as differential equations, particle physics, group theory, and the Mulmuley--Sohoni Geometric Complexity Theory program. A matrix Lie algebra is a set L of matrices such that $A, B\\in L$ implies $AB - BA \\in L$. Two matrix Lie algebras are conjugate if there is an invertible matrix $M$ such that $L_1 = M L_2 M^{-1}$. \nWe show that certain cases of Lie algebra conjugacy are equivalent to graph isomorphism. On the other hand, we give polynomial-time algorithms for other cases of Lie algebra conjugacy, which allow us to essentially derandomize a recent result of Kayal on affine equivalence of polynomials. Affine equivalence is related to many complexity problems such as factoring integers, graph isomorphism, matrix multiplication, and permanent versus determinant. \nSpecifically, we show: \nAbelian Lie algebra conjugacy is equivalent to the code equivalence problem, and hence is as hard as graph isomorphism. \nAbelian Lie algebra conjugacy of $n \\times n$ matrices can be solved in poly(n) time when the Lie algebras have dimension O(1). \nSemisimple Lie algebra conjugacy is equivalent to graph isomorphism. A Lie algebra is semisimple if it is a direct sum of simple Lie algebras. \nSemisimple Lie algebra conjugacy of $n \\times n$ matrices can be solved in polynomial time when the Lie algebras consist of only $O(\\log n)$ simple direct summands. \nConjugacy of completely reducible Lie algebras---that is, a direct sum of an abelian and a semisimple Lie algebra---can be solved in polynomial time when the abelian part has dimension O(1) and the semisimple part has $O(\\log n)$ simple direct summands.", "venue": "Electron. Colloquium Comput. Complex.", "authors": ["Joshua A. Grochow"], "year": 2011, "n_citations": 3}
{"id": 5890356, "s2_id": "f3896ecc7eac20503cac08fdff8fc4005b044f83", "title": "Tropicalization of Classical Moduli Spaces", "abstract": "The image of the complement of a hyperplane arrangement under a monomial map can be tropicalized combinatorially using matroid theory. We apply this to classical moduli spaces that are associated with complex reflection arrangements. Starting from modular curves, we visit the Segre cubic, the Igusa quartic, and moduli of marked del Pezzo surfaces of degrees 2 and 3. Our primary example is the Burkhardt quartic, whose tropicalization is a 3-dimensional fan in 39-dimensional space. This effectuates a synthesis of concrete and abstract approaches to tropical moduli of genus 2 curves.", "venue": "Math. Comput. Sci.", "authors": ["Qingchun  Ren", "Steven V. Sam", "Bernd  Sturmfels"], "year": 2014, "n_citations": 27}
{"id": 5898274, "s2_id": "2f8bc46178691019d03b8ab7f52471e8537435f5", "title": "A refined denominator bounding algorithm for multivariate linear difference equations", "abstract": "We continue to investigate which polynomials can possibly occur as factors in the denominators of rational solutions of a given partial linear difference equation. In an earlier article we have introduced the distinction between periodic and aperiodic factors in the denominator, and we have given an algorithm for predicting the aperiodic ones. Now we extend this technique towards the periodic case and present a refined algorithm which also finds most of the periodic factors.", "venue": "ISSAC '11", "authors": ["Manuel  Kauers", "Carsten  Schneider"], "year": 2011, "n_citations": 4}
{"id": 5903411, "s2_id": "d775a832ed4f599939010027e14c421d42901121", "title": "Computation of Differential Chow Forms for Prime Differential Ideals", "abstract": "In this paper, we propose algorithms to compute differential Chow forms for prime differential ideals which are given by their characteristic sets. The main algorithm is based on an optimal bound for the order of a prime differential ideal in terms of its characteristic set under an arbitrary ranking, which shows the Jacobi bound conjecture holds in this case. Apart from the order bound, we also give a degree bound for the differential Chow form. In addition, for prime differential ideals given by their characteristic sets under an orderly ranking, a much more simpler algorithm is given to compute its differential Chow form. The computational complexity of both is single exponential in terms of the Jacobi number, the maximal degree of the differential polynomials in the characteristic set and the number of variables.", "venue": "ArXiv", "authors": ["Wei  Li", "Yinghong  Li"], "year": 2015, "n_citations": 1}
{"id": 5905161, "s2_id": "4be8d612cf65ced5e25ea1087cb3a4c2c4141b7b", "title": "Methods in Mathematica for Solving Ordinary Differential Equations", "abstract": "An overview of the solution methods for ordinary differential equations in the Mathematica function DSolve is presented.", "venue": "ArXiv", "authors": ["\u00dcnal  G\u00f6ktas", "Devendra  Kapadia"], "year": 2011, "n_citations": 1}
{"id": 5907931, "s2_id": "2818314933aa22f312b7421387f01667e8b8b885", "title": "Computing GCRDs of approximate differential polynomials", "abstract": "Differential (Ore) type polynomials with approximate polynomial coefficients are introduced. These provide a useful representation of approximate differential operators with a strong algebraic structure, which has been used successfully in the exact, symbolic, setting. We then present an algorithm for the approximate Greatest Common Right Divisor (GCRD) of two approximate differential polynomials, which intuitively is the differential operator whose solutions are those common to the two inputs operators. More formally, given approximate differential polynomials f and g, we show how to find \"nearby\" polynomials f and g which have a non-trivial GCRD. Here \"nearby\" is under a suitably defined norm. The algorithm is a generalization of the SVD-based method of Corless et al. (1995) for the approximate GCD of regular polynomials. We work on an appropriately \"linearized\" differential Sylvester matrix, to which we apply a block SVD. The algorithm has been implemented in Maple and a demonstration of its robustness is presented.", "venue": "SNC", "authors": ["Mark  Giesbrecht", "Joseph  Haraldson"], "year": 2014, "n_citations": 4}
{"id": 5916700, "s2_id": "aa255ce6c716374c9543dcc41ad6fbb6ab783fe5", "title": "A Flawed Dataset for Symbolic Equation Verification", "abstract": "Arabshahi, Singh, and Anandkumar (2018) propose a method for creating a dataset of symbolic mathematical equations for the tasks of symbolic equation verification and equation completion. Unfortunately, a dataset constructed using the method they propose will suffer from two serious flaws. First, the class of true equations that the procedure can generate will be very limited. Second, because true and false equations are generated in completely different ways, there are likely to be artifactual features that allow easy discrimination. Moreover, over the class of equations they consider, there is an extremely simple probabilistic procedure that solves the problem of equation verification with extremely high reliability. The usefulness of this problem in general as a testbed for AI systems is therefore doubtful.", "venue": "ArXiv", "authors": ["Ernest  Davis"], "year": 2021, "n_citations": 1}
{"id": 5918325, "s2_id": "0c387d6bc885c0f26815af61d704aca97ed6adb2", "title": "The PSLQ Algorithm for Empirical Data", "abstract": "The celebrated integer relation finding algorithm PSLQ has been successfully used in many applications. PSLQ was only analyzed theoretically for exact input data, however, when the input data are irrational numbers, they must be approximate ones due to the finite precision of the computer. When the algorithm takes empirical data (inexact data with error bounded) instead of exact real numbers as its input, how do we theoretically ensure the output of the algorithm to be an exact integer relation? \nIn this paper, we investigate the PSLQ algorithm for empirical data as its input. Firstly, we give a termination condition for this case. Secondly, we analyze a perturbation on the hyperplane matrix constructed from the input data and hence disclose a relationship between the accuracy of the input data and the output quality (an upper bound on the absolute value of the inner product of the exact data and the computed integer relation), which naturally leads to an error control strategy for PSLQ. Further, we analyze the complexity bound of the PSLQ algorithm for empirical data. Examples on transcendental numbers and algebraic numbers show the meaningfulness of our error control strategy.", "venue": "Math. Comput.", "authors": ["Yong  Feng", "Jingwei  Chen", "Wenyuan  Wu"], "year": 2019, "n_citations": 6}
{"id": 5920700, "s2_id": "fbdbf32eef3655eb6c39e3eb0959c590a6c61e95", "title": "Linear equations for unordered data vectors", "abstract": "Following a recently considered generalisation of linear equations to unordereddata vectors and to ordered-data vectors, we perform a further generalisation to k-elementsets-of-unordered-data vectors. These generalised equations naturally appear in the analysis of vector addition systems (or Petri nets) extended so that each token carries a set of unordered data. We show that nonnegative-integer solvability of linear equations is in nondeterministic-exponential-time while integer solvability is in polynomial-time.", "venue": "ArXiv", "authors": ["Piotr  Hofman", "Jakub  R'o.zycki"], "year": 2021, "n_citations": 0}
{"id": 5928074, "s2_id": "53fbcf7092c732b9221f744d1d8eb5931821047a", "title": "Resolving Zero Divisors Using Hensel Lifting", "abstract": "Algorithms which compute modulo triangular sets must respect zero divisors. We present Hensel lifting as a tool for resolving them. We give an application: a modular algorithm for computing gcds of univariate polynomials with coefficients modulo a radical triangular set over the rational numbers. We have implemented our algorithm using Maple's RECDEN package. We compare our implementation with the procedure RegularGcd in the RegularChains package.", "venue": "2017 19th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)", "authors": ["John  Kluesner", "Michael B. Monagan"], "year": 2017, "n_citations": 0}
{"id": 5928091, "s2_id": "11cf35e425a42b4b68cfe5936024bbcf93bcaed8", "title": "Understanding Branch Cuts of Expressions", "abstract": "We assume some standard choices for the branch cuts of a group of functions and consider the problem of then calculating the branch cuts of expressions involving those functions. Typical examples include the addition formulae for inverse trigonometric functions. Understanding these cuts is essential for working with the single-valued counterparts, the common approach to encoding multi-valued functions in computer algebra systems. While the defining choices are usually simple (typically portions of either the real or imaginary axes) the cuts induced by the expression may be surprisingly complicated. We have made explicit and implemented techniques for calculating the cuts in the computer algebra programme Maple. We discuss the issues raised, classifying the different cuts produced. The techniques have been gathered in the BranchCuts package, along with tools for visualising the cuts. The package is included in Maple 17 as part of the FunctionAdvisor tool.", "venue": "MKM/Calculemus/DML", "authors": ["Matthew  England", "Russell J. Bradford", "James H. Davenport", "David J. Wilson"], "year": 2013, "n_citations": 16}
{"id": 5930114, "s2_id": "5f1ef9119537c9b9f0b93329723a8bc3392b8552", "title": "Reduction-Based Creative Telescoping for Algebraic Functions", "abstract": "Continuing a series of articles in the past few years on creative telescoping using reductions, we develop a new algorithm to construct minimal telescopers for algebraic functions. This algorithm is based on Trager's Hermite reduction and on polynomial reduction, which was originally designed for hyperexponential functions and extended to the algebraic case in this paper.", "venue": "ISSAC", "authors": ["Shaoshi  Chen", "Manuel  Kauers", "Christoph  Koutschan"], "year": 2016, "n_citations": 26}
{"id": 5931504, "s2_id": "a9e0f6a08ef152f6fe02c5e56582b62e6de78b1d", "title": "How to Refine Polynomial Functions", "abstract": "Research on refinable functions in wavelet theory is mostly focused to localized functions. However it is known, that polynomial functions are refinable, too. In our paper we investigate on conversions between refinement masks and polynomials and their uniqueness.", "venue": "Int. J. Wavelets Multiresolution Inf. Process.", "authors": ["Henning  Thielemann"], "year": 2012, "n_citations": 1}
{"id": 5939035, "s2_id": "a7365f9a19dacc094f761cae2559bf42d7a5f426", "title": "Some Algebraic Properties of a Subclass of Finite Normal Form Games", "abstract": "We study the problem of computing all Nash equilibria of a subclass of finite normal form games. With algebraic characterization of the games, we present a method for computing all its Nash equilibria. Further, we present a method for deciding membership to the class of games with its related results. An appendix, containing an example to show working of each of the presented methods, concludes the work.", "venue": "ArXiv", "authors": ["Samaresh  Chatterji", "Ratnik  Gandhi"], "year": 2010, "n_citations": 2}
{"id": 5944472, "s2_id": "6b570069f14c7588e066f7138e1f21af59d62e61", "title": "Theano: A Python framework for fast computation of mathematical expressions", "abstract": "Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. \nThe present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.", "venue": "ArXiv", "authors": ["Rami  Al-Rfou'", "Guillaume  Alain", "Amjad  Almahairi", "Christof  Angerm\u00fcller", "Dzmitry  Bahdanau", "Nicolas  Ballas", "Fr\u00e9d\u00e9ric  Bastien", "Justin  Bayer", "Anatoly  Belikov", "Alexander  Belopolsky", "Yoshua  Bengio", "Arnaud  Bergeron", "James  Bergstra", "Valentin  Bisson", "Josh Bleecher Snyder", "Nicolas  Bouchard", "Nicolas  Boulanger-Lewandowski", "Xavier  Bouthillier", "Alexandre de Br\u00e9bisson", "Olivier  Breuleux", "Pierre Luc Carrier", "Kyunghyun  Cho", "Jan  Chorowski", "Paul F. Christiano", "Tim  Cooijmans", "Marc-Alexandre  C\u00f4t\u00e9", "Myriam  C\u00f4t\u00e9", "Aaron C. Courville", "Yann  Dauphin", "Olivier  Delalleau", "Julien  Demouth", "Guillaume  Desjardins", "Sander  Dieleman", "Laurent  Dinh", "Melanie  Ducoffe", "Vincent  Dumoulin", "Samira Ebrahimi Kahou", "Dumitru  Erhan", "Ziye  Fan", "Orhan  Firat", "Mathieu  Germain", "Xavier  Glorot", "Ian J. Goodfellow", "Matthew  Graham", "\u00c7aglar  G\u00fcl\u00e7ehre", "Philippe  Hamel", "Iban  Harlouchet", "Jean-Philippe  Heng", "Bal\u00e1zs  Hidasi", "Sina  Honari", "Arjun  Jain", "S\u00e9bastien  Jean", "Kai  Jia", "Mikhail  Korobov", "Vivek  Kulkarni", "Alex  Lamb", "Pascal  Lamblin", "Eric  Larsen", "C\u00e9sar  Laurent", "Sean  Lee", "Simon  Lefran\u00e7ois", "Simon  Lemieux", "Nicholas  L\u00e9onard", "Zhouhan  Lin", "Jesse A. Livezey", "Cory  Lorenz", "Jeremiah  Lowin", "Qianli  Ma", "Pierre-Antoine  Manzagol", "Olivier  Mastropietro", "Robert  McGibbon", "Roland  Memisevic", "Bart van Merrienboer", "Vincent  Michalski", "Mehdi  Mirza", "Alberto  Orlandi", "Christopher Joseph Pal", "Razvan  Pascanu", "Mohammad  Pezeshki", "Colin  Raffel", "Daniel  Renshaw", "Matthew  Rocklin", "Adriana  Romero", "Markus  Roth", "Peter  Sadowski", "John  Salvatier", "Fran\u00e7ois  Savard", "Jan  Schl\u00fcter", "John  Schulman", "Gabriel  Schwartz", "Iulian  Serban", "Dmitriy  Serdyuk", "Samira  Shabanian", "\u00c9tienne  Simon", "Sigurd  Spieckermann", "S. Ramana Subramanyam", "Jakub  Sygnowski", "J\u00e9r\u00e9mie  Tanguay", "Gijs van Tulder", "Joseph P. Turian", "Sebastian  Urban", "Pascal  Vincent", "Francesco  Visin", "Harm de Vries", "David  Warde-Farley", "Dustin J. Webb", "Matthew  Willson", "Kelvin  Xu", "Lijun  Xue", "Li  Yao", "Saizheng  Zhang", "Ying  Zhang"], "year": 2016, "n_citations": 2033}
{"id": 5948170, "s2_id": "eca1649cacc283442e354ec7acc4783996c9ed1f", "title": "Some open problems related to creative telescoping", "abstract": "Creative telescoping is the method of choice for obtaining information about definite sums or integrals. It has been intensively studied since the early 1990s, and can now be considered as a classical technique in computer algebra. At the same time, it is still a subject of ongoing research. This paper presents a selection of open problems in this context. The authors would be curious to hear about any substantial progress on any of these problems.", "venue": "J. Syst. Sci. Complex.", "authors": ["Shaoshi  Chen", "Manuel  Kauers"], "year": 2017, "n_citations": 16}
{"id": 5953010, "s2_id": "a3a4f5144e2a3955884a2231f4485efc8201fdfb", "title": "Fast in-place algorithms for polynomial operations: division, evaluation, interpolation", "abstract": "We consider space-saving versions of several important operations on univariate polynomials, namely power series inversion and division, division with remainder, multi-point evaluation, and interpolation. Now-classical results show that such problems can be solved in (nearly) the same asymptotic time as fast polynomial multiplication. However, these reductions, even when applied to an in-place variant of fast polynomial multiplication, yield algorithms which require at least a linear amount of extra space for intermediate results. We demonstrate new in-place algorithms for the aforementioned polynomial computations which require only constant extra space and achieve the same asymptotic running time as their out-of-place counterparts. We also provide a precise complexity analysis so that all constants are made explicit, parameterized by the space usage of the underlying multiplication algorithms.", "venue": "ISSAC", "authors": ["Pascal  Giorgi", "Bruno  Grenet", "Daniel S. Roche"], "year": 2020, "n_citations": 3}
{"id": 5960741, "s2_id": "1da7de9c14455b64592cdef4e8a17eef022b9437", "title": "Abstract predicate entailment over points-to heaplets is syntax recognition", "abstract": "Abstract predicates are considered in this paper as abstraction technique for heap-separated configurations, and as genuine Prolog predicates which are translated straight into a corresponding formal language grammar used as validation scheme for intermediate heap states. The approach presented is rule-based because the abstract predicates are rule-based, the parsing technique can be interpreted as an automated fold/unfold of the corresponding heap graph.", "venue": "2016 18th Conference of Open Innovations Association and Seminar on Information Security and Protection of Information Technology (FRUCT-ISPIT)", "authors": ["Ren\u00e9  Haberland", "Kirill  Krinkin", "Sergey  Ivanovskiy"], "year": 2016, "n_citations": 0}
{"id": 5964175, "s2_id": "a5059e3d85058ba76cbaa349ad3e22dea8e1f5e7", "title": "Relative parametrization of linear multidimensional systems", "abstract": "In the last chapter of his book \u201cThe Algebraic Theory of Modular Systems\u201d published in 1916, F. S. Macaulay developped specific techniques for dealing with \u201cunmixed polynomial ideals\u201d by introducing what he called \u201cinverse systems\u201d. The purpose of this paper is to extend such a point of view to differential modules defined by linear multidimensional systems, that is by linear systems of ordinary differential or partial differential equations of any order, with any number of independent variables, any number of unknowns and even with variable coefficients. The first and main idea is to replace unmixed polynomial ideals by pure differential modules. The second idea is to notice that a module is $$0$$0-pure if and only if it is torsion-free and thus if and only if it admits an \u201cabsolute parametrization\u201d by means of arbitrary potential like functions, or, equivalently, if it can be embedded into a free module by means of an \u201cabsolute localization\u201d. The third idea is to refer to a difficult theorem of algebraic analysis saying that an $$r$$r-pure module can be embedded into a module of projective dimension $$r$$r, that is a module admitting a projective resolution with exactly $$r$$r operators. The fourth and final idea is to establish a link between the use of extension modules for such a purpose and specific formal properties of the underlying multidimensional system through the use of \u201cinvolution\u201d and a \u2018relative localization\u201d leading to a \u201crelative parametrization\u201d. The paper is written in a rather effective self-contained way and we provide many explicit examples that should become test examples for a future use of computer algebra.", "venue": "Multidimens. Syst. Signal Process.", "authors": ["Jean-Fran\u00e7ois  Pommaret"], "year": 2015, "n_citations": 20}
{"id": 5965828, "s2_id": "ec95b6b5b443d3cb3f08e50ba863b1cb4fbeb961", "title": "A Special Homotopy Continuation Method for a Class of Polynomial Systems", "abstract": "A special homotopy continuation method, as a combination of the polyhedral homotopy and the linear product homotopy, is proposed for computing all the isolated solutions to a special class of polynomial systems. The root number bound of this method is between the total degree bound and the mixed volume bound and can be easily computed. The new algorithm has been implemented as a program called LPH using C++. Our experiments show its efficiency compared to the polyhedral or other homotopies on such systems. As an application, the algorithm can be used to find witness points on each connected component of a real variety.", "venue": "CASC", "authors": ["Yu  Wang", "Wenyuan  Wu", "Bican  Xia"], "year": 2017, "n_citations": 4}
{"id": 5970483, "s2_id": "3798066995303ec09b8f938d623a179f45603315", "title": "Algebraic diagonals and walks: Algorithms, bounds, complexity", "abstract": "The diagonal of a multivariate power series F is the univariate power series Diag(F) generated by the diagonal terms of F. Diagonals form an important class of power series; they occur frequently in number theory, theoretical physics and enumerative combinatorics. We study algorithmic questions related to diagonals in the case where F is the Taylor expansion of a bivariate rational function. It is classical that in this case Diag(F) is an algebraic function. We propose an algorithm that computes an annihilating polynomial for Diag(F). We give a precise bound on the size of this polynomial and show that generically, this polynomial is the minimal polynomial and that its size reaches the bound. The algorithm runs in time quasi-linear in this bound, which grows exponentially with the degree of the input rational function. We then address the related problem of enumerating directed lattice walks. The insight given by our study leads to a new method for expanding the generating power series of bridges, excursions and meanders. We show that their first N terms can be computed in quasi-linear complexity in N, without first computing a very large polynomial equation.", "venue": "J. Symb. Comput.", "authors": ["Alin  Bostan", "Louis  Dumont", "Bruno  Salvy"], "year": 2017, "n_citations": 8}
{"id": 5970763, "s2_id": "64147a64e4ba7a47578b3151a3feef5b5e385b61", "title": "Special algorithm for stability analysis of multistable biological regulatory systems", "abstract": "We consider the problem of counting (stable) equilibriums of an important family of algebraic differential equations modeling multistable biological regulatory systems. The problem can be solved, in principle, using real quantifier elimination algorithms, in particular real root classification algorithms. However, it is well known that they can handle only very small cases due to the enormous computing time requirements. In this paper, we present a special algorithm which is much more efficient than the general methods. Its efficiency comes from the exploitation of certain interesting structures of the family of differential equations.", "venue": "J. Symb. Comput.", "authors": ["Hoon  Hong", "Xiaoxian  Tang", "Bican  Xia"], "year": 2015, "n_citations": 10}
{"id": 5973330, "s2_id": "8fcd171f6fc9a5d311fe0884db46a7451344f374", "title": "Testing Zero-Dimensionality of Varieties at a Point", "abstract": "Effective methods are introduced for testing zero-dimensionality of varieties at a point. The motivation of this paper is to compute and analyze deformations of isolated hypersurface singularities. As an application, methods for computing local dimensions are also described. For the case where a given ideal contains parameters, the proposed algorithms can output in particular a decomposition of a parameter space into strata according to the local dimension at a point of the associated varieties. The key of the proposed algorithms is the use of the notion of comprehensive Gr\u00f6bner systems.", "venue": "Math. Comput. Sci.", "authors": ["Katsusuke  Nabeshima", "Shinichi  Tajima"], "year": 2021, "n_citations": 5}
{"id": 5976453, "s2_id": "e053618dd04f25b8c1ab827b39f6040288f4032f", "title": "On Factor Left Prime Factorization Problems for Multivariate Polynomial Matrices", "abstract": "This paper is concerned with factor left prime factorization problems for multivariate polynomial matrices without full row rank. We propose a necessary and sufficient condition for the existence of factor left prime factorizations of a class of multivariate polynomial matrices, and then design an algorithm to compute all factor left prime factorizations if they exist. We implement the algorithm on the computer algebra system Maple, and two examples are given to illustrate the effectiveness of the algorithm. The results presented in this paper are also true for the existence of factor right prime factorizations of multivariate polynomial matrices without full column rank.", "venue": "Multidimens. Syst. Signal Process.", "authors": ["Dong  Lu", "Dingkang  Wang", "Fanghui  Xiao"], "year": 2021, "n_citations": 0}
{"id": 5986215, "s2_id": "7a943fbdfc3d0d0d70afd465283d8d6f9d12a4c2", "title": "Introduction to the Symbolic Integration System", "abstract": "Symbolic integration is an important module of a typical Computer Algebra System. As for now, Mathematica, Matlab, Maple and Sage are all mainstream CAS. They share the same framework for symbolic integration at some points. In this book first we review the state of the art in the field of CAS. Then we focus on typical frameworks of the current symbolic integration systems and summarize the main mathematical theories behind these frameworks. Based on the open-source computer algebra system maTHmU developed by our team in our university, we propose a potential framework to improve the performance of the current symbolic integration system.", "venue": "ArXiv", "authors": ["Weiguang  Mao"], "year": 2013, "n_citations": 0}
{"id": 5987551, "s2_id": "73aad01ee623de63ad54f1d4de59453198bb3f30", "title": "The Piranha algebraic manipulator", "abstract": "In this paper we present a specialised algebraic manipulation package devoted to Celestial Mechanics. The system, called Piranha, is built on top of a generic and extensible framework, which allows to treat efficiently and in a unified way the algebraic structures most commonly encountered in Celestial Mechanics (such as multivariate polynomials and Poisson series). In this contribution we explain the architecture of the software, with special focus on the implementation of series arithmetics, show its current capabilities, and present benchmarks indicating that Piranha is competitive, performance-wise, with other specialised manipulators.", "venue": "ArXiv", "authors": ["Francesco  Biscani"], "year": 2009, "n_citations": 7}
{"id": 5995043, "s2_id": "ccc22c435a121092c093faa538d9f5d0e329e5d0", "title": "Solving Polynomial Systems with phcpy", "abstract": "The solutions of a system of polynomials in several variables are often needed, e.g.: in the design of mechanical systems, and in phase-space analyses of nonlinear biological dynamics. Reliable, accurate, and comprehensive numerical solutions are available through PHCpack, a FOSS package for solving polynomial systems with homotopy continuation. This paper explores new developments in phcpy, a scripting interface for PHCpack, over the past five years. For instance, phcpy is now available online through a JupyterHub server featuring Python2, Python3, and SageMath kernels. As small systems are solved in real-time by phcpy, they are suitable for interactive exploration through the notebook interface. Meanwhile, phcpy supports GPU parallelization, improving the speed and quality of solutions to much larger polynomial systems. From various model design and analysis problems in STEM, certain classes of polynomial system frequently arise, to which phcpy is well-suited.", "venue": "Proceedings of the 18th Python in Science Conference", "authors": ["Jasmine  Otto", "Angus  Forbes", "Jan  Verschelde"], "year": 2019, "n_citations": 2}
{"id": 5996083, "s2_id": "d1b450d3b5b95711c7ee33020de528253ebaddc1", "title": "Univariate real root isolation in an extension field", "abstract": "We present algorithmic, complexity and implementation results for the problem of isolating the real roots of a univariate polynomial in <i>B</i><sub>\u03b1</sub> \u2208 <i>L</i>[<i>y</i>], where <i>L</i>=<i>Q</i>\u03b1 is a simple algebraic extension of the rational numbers. We revisit two approaches for the problem. In the first approach, using resultant computations, we perform a reduction to a polynomial with integer coefficients and we deduce a bound of <i>O</i><sub><i>B</i></sub>(<i>N</i><sup>10</sup>) for isolating the real roots of <i>B</i><sub>\u03b1</sub>, where <i>N</i> is an upper bound on all the quantities (degree and bitsize) of the input polynomials. In the second approach we isolate the real roots working directly on the polynomial of the input. We compute improved separation bounds for the roots and we prove that they are optimal, under mild assumptions. For isolating the real roots we consider a modified Sturm algorithm, and a modified version of Descartes' algorithm introduced by Sagraloff. For the former we prove a complexity bound of <i>O</i><sub>B</sub>(<i>N</i><sup>8</sup>) and for the latter a bound of <i>O</i><sub>B</sub>(<i>N</i><sup>7</sup>). We implemented the algorithms in C as part of the core library of Mathematica and we illustrate their efficiency over various data sets. Finally, we present complexity results for the general case of the first approach, where the coefficients belong to multiple extensions.", "venue": "ISSAC '11", "authors": ["Adam W. Strzebonski", "Elias P. Tsigaridas"], "year": 2011, "n_citations": 19}
{"id": 6003398, "s2_id": "5f39b48af8b70555e0378e93b80827ccf94b6aa4", "title": "Computing the Characteristic Polynomial of Generic Toeplitz-like and Hankel-like Matrices", "abstract": "New algorithms are presented for computing annihilating polynomials of Toeplitz, Hankel, and more generally Toeplitz+Hankel-like matrices over a field. Our approach follows works on Coppersmith's block Wiedemann method with structured projections, which have been recently successfully applied for computing the bivariate resultant. A first baby steps/giant steps approach --directly derived using known techniques on structured matrices-- gives a randomized Monte Carlo algorithm for the minimal polynomial of an (n x n) Toeplitz or Hankel-like matrix of displacement rank \u03b1 using(\u00d5nw-c(w) \u00d5 c(w)) arithmetic operations, where (w) is the exponent of matrix multiplication and (c(2.373) = 0.523) for the best known value of (w). For generic Toeplitz+Hankel-like matrices a second algorithm computes the characteristic polynomial; in particular, when the displacement rank is considered constant, its cost is (\u00d5n2-1/w). Previous algorithms required (O(n2) operations while the exponents presented here are respectively less than 1.86 and 1.58 with the best known estimate for (w).", "venue": "ISSAC", "authors": ["Cl'ement  Pernet", "Hippolyte  Signargout", "Pierre  Karpman", "Gilles  Villard"], "year": 2021, "n_citations": 0}
{"id": 6006715, "s2_id": "f449adc556e1d0a914fbf300a0c77c1f6151942e", "title": "On the shape of curves that are rational in polar coordinates", "abstract": "In this paper we provide a computational approach to the shape of curves which are rational in polar coordinates, i.e. which are defined by means of a parametrization (r(t),@q(t)) where both r(t), @q(t) are rational functions. Our study includes theoretical aspects on the shape of these curves, and algorithmic results which eventually lead to an algorithm for plotting the ''interesting parts'' of the curve, i.e. the parts showing the main geometrical features.", "venue": "Comput. Aided Geom. Des.", "authors": ["Juan Gerardo Alc\u00e1zar", "Gema Mar\u00eda D\u00edaz-Toca"], "year": 2012, "n_citations": 0}
{"id": 6010153, "s2_id": "132cde4b6f6a0d84d17a4a1ef8a896d747250427", "title": "Computing Hypergeometric Functions Rigorously", "abstract": "We present an efficient implementation of hypergeometric functions in arbitrary-precision interval arithmetic. The functions 0F1, 1F1, 2F1, and 2F0 (or the Kummer U-function) are supported for unrestricted complex parameters and argument, and, by extension, we cover exponential and trigonometric integrals, error functions, Fresnel integrals, incomplete gamma and beta functions, Bessel functions, Airy functions, Legendre functions, Jacobi polynomials, complete elliptic integrals, and other special functions. The output can be used directly for interval computations or to generate provably correct floating-point approximations in any format. Performance is competitive with earlier arbitrary-precision software and sometimes orders of magnitude faster. We also partially cover the generalized hypergeometric function pFq and computation of high-order parameter derivatives.", "venue": "ACM Trans. Math. Softw.", "authors": ["Fredrik  Johansson"], "year": 2019, "n_citations": 28}
{"id": 6016090, "s2_id": "062d26c8981f85cb84908cc060c3a72ee98cfe7c", "title": "Computation of Difference Groebner Bases", "abstract": "To compute difference Groebner bases of ideals generated by linear polynomials we adopt to difference polynomial rings the involutive algorithm based on Janet-like division. The algorithm has been implemented in Maple in the form of the package LDA (Linear Difference Algebra) and we describe the main features of the package. Its applications are illustrated by generation of finite difference approximations to linear partial differential equations and by reduction of Feynman integrals. We also present the algorithm for an ideal generated by a finite set of nonlinear difference polynomials. If the algorithm terminates, then it constructs a Groebner basis of the ideal.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt", "Daniel  Robertz"], "year": 2012, "n_citations": 9}
{"id": 6019503, "s2_id": "f5529bef847ac2b46798e4454e2c5ce33f66285f", "title": "Macaulay bases of modules", "abstract": "We define Macaulay bases of modules, which are a common generalization of Groebner bases and Macaulay H-bases to suitably graded modules over a commutative graded k-algebra, where the index sets of the two gradings may differ. This includes Groebner bases of modules as a special case, in contrast to previous work on Macaulay bases of modules. We show that the standard results on Groebner bases and Macaulay H-bases generalize in fields of arbitrary characteristic to Macaulay bases, including the reduction algorithm and Buchberger\u2019s criterion and algorithm. A key result is that Macaulay bases, in contrast to Groebner bases, respect symmetries when there is a group G acting homogeneously on a graded module, in which case the reduction algorithm is G-equivariant and the k-span of a Macaulay basis is G-invariant. We also show that some of the standard applications of Groebner bases can be generalized to Macaulay bases, including elimination and computation of syzygy modules, which require the generalization to modules that was not present in previous work.", "venue": "ArXiv", "authors": ["Sujit  Rao"], "year": 2021, "n_citations": 0}
{"id": 6025594, "s2_id": "e67fcba492b468057160024c0560fcc18b234934", "title": "Extensional Higher-Order Paramodulation in Leo-III", "abstract": "Leo-III is an automated theorem prover for extensional type theory with Henkin semantics and choice. Reasoning with primitive equality is enabled by adapting paramodulation-based proof search to higher-order logic. The prover may cooperate with multiple external specialist reasoning systems such as first-order provers and SMT solvers. Leo-III is compatible with the TPTP/TSTP framework for input formats, reporting results and proofs, and standardized communication between reasoning systems, enabling e.g. proof reconstruction from within proof assistants such as Isabelle/HOL. Leo-III supports reasoning in polymorphic first-order and higher-order logic, in all normal quantified modal logics, as well as in different deontic logics. Its development had initiated the ongoing extension of the TPTP infrastructure to reasoning within non-classical logics.", "venue": "J. Autom. Reason.", "authors": ["Alexander  Steen", "Christoph  Benzm\u00fcller"], "year": 2021, "n_citations": 4}
{"id": 6030869, "s2_id": "c83abb15a36cc560c7179f6000d55ebf94e25b98", "title": "Computing multiplicative order and primitive root in finite cyclic group", "abstract": "Multiplicative order of an element a of Group g is the least positive integer n such that an = e, where e is the identity element of G. If the order of an element is equal to |G|, it is called generator or primitive root. This paper describes the algorithms for computing multiplicative order and primitive root in \u2124p*, we also present a logarithmic improvement over classical algorithms.", "venue": "2014 Seventh International Conference on Contemporary Computing (IC3)", "authors": ["Shri Prakash Dwivedi"], "year": 2014, "n_citations": 0}
{"id": 6032260, "s2_id": "9f89248ecfb8914fdd137363fbf4402d4777d350", "title": "Dependency Pairs and Polynomial Path Orders", "abstract": "We show how polynomial path orders can be employed efficiently in conjunction with weak innermost dependency pairs to automatically certify polynomial runtime complexity of term rewrite systems and the polytime computability of the functions computed. The established techniques have been implemented and we provide ample experimental data to assess the new method.", "venue": "RTA", "authors": ["Martin  Avanzini", "Georg  Moser"], "year": 2009, "n_citations": 22}
{"id": 6040252, "s2_id": "6d1e1757a9fc33b93a0a789d0eb7079439c30726", "title": "Prover Efficient Public Verification of Dense or Sparse/Structured Matrix-Vector Multiplication", "abstract": "With the emergence of cloud computing services, computationally weak devices (Clients) can delegate expensive tasks to more powerful entities (Servers). This raises the question of verifying a result at a lower cost than that of recomputing it. This verification can be private, between the Client and the Server, or public, when the result can be verified by any third party. We here present protocols for the verification of matrix-vector multiplications, that are secure against malicious Servers. The obtained algorithms are essentially optimal in the amortized model: the overhead for the Server is limited to a very small constant factor, even in the sparse or structured matrix case; and the computational time for the public Verifier is linear in the dimension. Our protocols combine probabilistic checks and cryptographic operations, but minimize the latter to preserve practical efficiency. Therefore our protocols are overall more than two orders of magnitude faster than existing ones.", "venue": "ACISP", "authors": ["Jean-Guillaume  Dumas", "Vincent  Zucca"], "year": 2017, "n_citations": 3}
{"id": 6047476, "s2_id": "617e2588a04cad4fc7e5c5db24910650fe2d12ab", "title": "Simplification of tensor expressions in computer algebra", "abstract": "Computer algebra is widely used in various fields of mathematics, physics and other sciences. The simplification of tensor expressions is an important special case of computer algebra. In this paper, we consider the reduction of tensor polynomials to canonical form, taking into account the properties of symmetry under permutations of indices, the symmetries associated with the renaming of summation indices, and also linear relations between tensors of a general form. We give a definition of the canonical representation for polynomial (multiplicative) expressions of variables with abstract indices, which is the result of averaging of the original expression by the action of some finite group (the signature stabilizer). In practice, the proposed algorithms demonstrate high efficiency for expressions made of Riemann curvature tensors.", "venue": "Journal of Physics: Conference Series", "authors": ["Alexander  Kryukov", "G.  Shpiz"], "year": 2019, "n_citations": 0}
{"id": 6057437, "s2_id": "cda0b715b322fdd4f93d5a19be7430d3b1b1d2cb", "title": "Bisimilar Conversion of Multi-valued Networks to Boolean Networks", "abstract": "Discrete modelling frameworks of Biological networks can be divided in two distinct categories: Boolean and Multi-valued. Although Multi-valued networks are more expressive for qualifying the regulatory behaviours modelled by more than two values, the ability to automatically convert them to Boolean network with an equivalent behaviour breaks down the fundamental borders between the two approaches. Theoretically investigating the conversion process provides relevant insights into bridging the gap between them. Basically, the conversion aims at finding a Boolean network bisimulating a Multi-valued one. In this article, we investigate the bisimilar conversion where the Boolean integer coding is a parameter that can be freely modified. Based on this analysis, we define a computational method automatically inferring a bisimilar Boolean network from a given Multi-valued one.", "venue": "ArXiv", "authors": ["Franck  Delaplace", "Sergiu  Ivanov"], "year": 2020, "n_citations": 0}
{"id": 6063028, "s2_id": "1eeceb34039f2d1c62ec8e4edd2678049ac56086", "title": "Probabilistic analysis of Wiedemann's algorithm for minimal polynomial computation", "abstract": "Blackbox algorithms for linear algebra problems start with projection of the sequence of powers of a matrix to a sequence of vectors (Lanczos), a sequence of scalars (Wiedemann) or a sequence of smaller matrices (block methods). Such algorithms usually depend on the minimal polynomial of the resulting sequence being that of the given matrix. Here exact formulas are given for the probability that this occurs. They are based on the generalized Jordan normal form (direct sum of companion matrices of the elementary divisors) of the matrix. Sharp bounds follow from this for matrices of unknown elementary divisors. The bounds are valid for all finite field sizes and show that a small blocking factor can give high probability of success for all cardinalities and matrix dimensions.", "venue": "J. Symb. Comput.", "authors": ["Gavin  Harrison", "Jeremy R. Johnson", "B. David Saunders"], "year": 2016, "n_citations": 0}
{"id": 6063089, "s2_id": "dbabacb582595054d81ada348b15938523a92d50", "title": "Minimizing polynomial functions on quantum computers", "abstract": "This expository paper reviews some of the recent uses of computational algebraic geometry in classical and quantum optimization. The paper assumes an elementary background in algebraic geometry and adiabatic quantum computing (AQC), and concentrates on presenting concrete examples (with Python codes tested on a quantum computer) of applying algebraic geometry constructs: solving binary optimization, factoring, and compiling. Reversing the direction, we also briefly describe a novel use of quantum computers to compute Groebner bases for toric ideals. We also show how Groebner bases play a role in studying AQC at a fundamental level within a Morse theory framework. We close by placing our work in perspective, by situating this leg of the journey, as part of a marvelous intellectual expedition that began with our ancients over 4000 years ago.", "venue": "ArXiv", "authors": ["Raouf  Dridi", "Hedayat  Alghassi", "Sridhar R. Tayur"], "year": 2019, "n_citations": 3}
{"id": 6063777, "s2_id": "749f375ff67d3efe2aebfef136c87e82565bbc63", "title": "Defining and computing persistent Z-homology in the general case", "abstract": "By general case we mean methods able to process simplicial sets and chain complexes not of finite type. A filtration of the object to be studied is the heart of both subjects persistent homology and spectral sequences. In this paper we present the complete relation between them, both from theoretical and computational points of view. One of the main contributions of this paper is the observation that a slight modification of our previous programs computing spectral sequences is enough to compute also persistent homology. By inheritance from our spectral sequence programs, we obtain for free persistent homology programs applicable to spaces not of finite type (provided they are spaces with effective homology) and with Z-coefficients (significantly generalizing the usual presentation of persistent homology over a field). As an illustration, we compute some persistent homology groups (and the corresponding integer barcodes) in the case of a Postnikov tower.", "venue": "ArXiv", "authors": ["Ana  Romero", "J\u00f3nathan  Heras", "Julio  Rubio", "Francis  Sergeraert"], "year": 2014, "n_citations": 12}
{"id": 6069171, "s2_id": "1ec8b91c74d7b0640cb3ffd7060a2a124ec08749", "title": "Modeling Hierarchical System with Operads", "abstract": "This paper applies operads and functorial semantics to address the problem of failure diagnosis in complex systems. We start with a concrete example, developing a hierarchical interaction model for the Length Scale Interferometer, a high-precision measurement system operated by the US National Institute of Standards and Technology. The model is expressed in terms of combinatorial/diagrammatic structures called port-graphs, and we explain how to extract an operad LSI from a collection of these diagrams. Next we show how functors to the operad of probabilities organize and constrain the relative probabilities of component failure in the system. Finally, we show how to extend the analysis from general component failure to specific failure modes.", "venue": "ACT", "authors": ["Spencer  Breiner", "Blake  Pollard", "Eswaran  Subrahmanian", "Olivier  Marie-Rose"], "year": 2019, "n_citations": 5}
{"id": 6074044, "s2_id": "b2e03315484f523639fa31fa30e0989609495ee8", "title": "Finding binomials in polynomial ideals", "abstract": "We describe an algorithm which finds binomials in a given ideal $$I\\subset \\mathbb {Q}[x_1,\\dots ,x_n]$$I\u2282Q[x1,\u22ef,xn] and in particular decides whether binomials exist in I at all. Binomials in polynomial ideals can be well hidden. For example, the lowest degree of a binomial cannot be bounded as a function of the number of indeterminates, the degree of the generators, or the Castelnuovo\u2013Mumford regularity. We approach the detection problem by reduction to the Artinian case using tropical geometry. The Artinian case is solved with algorithms from computational number theory.", "venue": "ArXiv", "authors": ["Anders  Jensen", "Thomas  Kahle", "Lukas  Katth\u00e4n"], "year": 2016, "n_citations": 12}
{"id": 6082204, "s2_id": "59d11bfb791e8ef63be3e5e31e7680cc104187e0", "title": "Computing nearby non-trivial Smith forms", "abstract": "Abstract We consider the problem of computing the nearest matrix polynomial with a non-trivial Smith Normal Form. We show that computing the Smith form of a matrix polynomial is amenable to numeric computation as an optimization problem. Furthermore, we describe an effective optimization technique to find a nearby matrix polynomial with a non-trivial Smith form. The results are then generalized to include the computation of a matrix polynomial having a maximum specified number of ones in the Smith Form (i.e., with a maximum specified McCoy rank). We discuss the geometry and existence of solutions and how our results can be used for an error analysis. We develop an optimization-based approach and demonstrate an iterative numerical method for computing a nearby matrix polynomial with the desired spectral properties. We also describe an implementation of our algorithms and demonstrate the robustness with examples in Maple .", "venue": "J. Symb. Comput.", "authors": ["Mark  Giesbrecht", "Joseph  Haraldson", "George  Labahn"], "year": 2021, "n_citations": 1}
{"id": 6082828, "s2_id": "3594c5f64f30c09fa89a928543e5540754c6d1d9", "title": "An Evidential Path Logic for Multi-Relational Networks", "abstract": "Multi-relational networks are used extensively to structure knowledge. Perhaps the most popular instance, due to the widespread adoption of the Semantic Web, is the Resource Description Framework (RDF). One of the primary purposes of a knowledge network is to reason; that is, to alter the topology of the network according to an algorithm that uses the existing topological structure as its input. There exist many such reasoning algorithms. With respect to the Semantic Web, the bivalent, axiomatic reasoners of the RDF Schema (RDFS) and the Web Ontology Language (OWL) are the most prevalent. However, nothing prevents other forms of reasoning from existing in the Semantic Web. This article presents a non-bivalent, non-axiomatic, evidential logic and reasoner that is an algebraic ring over a multi-relational network and two binary operations that can be composed to perform various forms of inference. Given its multi-relational grounding, it is possible to use the presented evidential framework as another method for structuring knowledge and reasoning in the Semantic Web. The benefits of this framework are that it works with arbitrary, partial, and contradictory knowledge while, at the same time, supporting a tractable approximate reasoning process.", "venue": "AAAI Spring Symposium: Technosocial Predictive Analytics", "authors": ["Marko A. Rodriguez", "Joe  Geldart"], "year": 2009, "n_citations": 2}
{"id": 6083044, "s2_id": "64730b0fbd6be3bcb61372bac4d91a7ca9abb358", "title": "A Graph Analysis of the Linked Data Cloud", "abstract": "The Linked Data community is focused on integrating Resource Description Framework (RDF) data sets into a single unified representation known as the Web of Data. The Web of Data can be traversed by both man and machine and shows promise as the \\textit{de facto} standard for integrating data world wide much like the World Wide Web is the \\textit{de facto} standard for integrating documents. On February 27$^\\text{th}$ of 2009, an updated Linked Data cloud visualization was made publicly available. This visualization represents the various RDF data sets currently in the Linked Data cloud and their interlinking relationships. For the purposes of this article, this visual representation was manually transformed into a directed graph and analyzed.", "venue": "ArXiv", "authors": ["Marko A. Rodriguez"], "year": 2009, "n_citations": 20}
{"id": 6085388, "s2_id": "96f762f8fcecc8ae5aab71ebb8b20de81a0be0c7", "title": "A Computer Program for the Numerical Analysis of Economic Cycles Within the Framework of the Dubovsky Generalized Model", "abstract": "Abstract. The article proposes a computer program for calculating economic crises according to the generalized mathematical model of S.V. Dubovsky. This model is represented by a system of ordinary nonlinear differential equations with fractional derivatives in the sense of Gerasimov-Caputo with initial conditions. Furthermore, according to a numerical algorithm based on an explicit nonlocal finite-difference scheme, oscillograms and phase trajectories were constructed. It is shown that changing the orders of fractional derivatives in the model can give rise to various modes, for example, damped modes with a steady-state amplitude. It is concluded that the orders of fractional derivatives are responsible for the intensity of the process.", "venue": "ArXiv", "authors": ["Danil  Makarov", "Roman  Parovik"], "year": 2021, "n_citations": 0}
{"id": 6095254, "s2_id": "306510f3e899d212329f7e5fb71d7da1b08cbfd5", "title": "OGRe: An Object-Oriented General Relativity Package for Mathematica", "abstract": "OGRe is a modern Mathematica package for differential geometry and tensor calculus. It can be used in a variety of contexts where tensor calculations are needed, in both mathematics and physics, but it is especially suitable for general relativity \u2014 the field of physics where tensors are most commonly and ubiquitously used. Whether the user is doing cutting-edge research in general relativity or just making first steps in learning the theory, the ability to manipulate tensors and perform tensor calculations quickly, easily, and intuitively will greatly simplify and accelerate their work.", "venue": "Journal of Open Source Software", "authors": ["Barak  Shoshany"], "year": 2021, "n_citations": 0}
{"id": 6095649, "s2_id": "64b66375bd713a1fa7281c851a39f3fab184b8ed", "title": "Competition Report: CHC-COMP-21", "abstract": "CHC-COMP-211 is the fourth competition of solvers for Constrained Horn Clauses. In this year, 7 solvers participated at the competition, and were evaluated in 7 separate tracks on problems in linear integer arithmetic, linear real arithmetic, arrays, and algebraic data-types. The competition was run in March 2021 using the StarExec computing cluster. This report gives an overview of the competition design, explains the organisation of the competition, and presents the competition results.", "venue": "Electronic Proceedings in Theoretical Computer Science", "authors": ["Grigory  Fedyukovich", "Philipp  R\u00fcmmer"], "year": 2021, "n_citations": 0}
{"id": 6097315, "s2_id": "d33a853e6fed42336087d2d86e1f143fb7ac6494", "title": "Generalization of Risch's Algorithm to Special Functions", "abstract": "Symbolic integration deals with the evaluation of integrals in closed form. We present an overview of Risch\u2019s algorithm including recent developments. The algorithms discussed are suited for both indefinite and definite integration. They can also be used to compute linear relations among integrals and to find identities for special functions given by parameter integrals. The aim of this presentation is twofold: to introduce the reader to some basic ideas of differential algebra in the context of integration and to raise awareness in the physics community of computer algebra algorithms for indefinite and definite integration.", "venue": "ArXiv", "authors": ["C. G. Raab"], "year": 2013, "n_citations": 4}
{"id": 6101376, "s2_id": "02b3d68aab662c911c45e9ed7c84ccb2dd32a62d", "title": "Cyclotomic Identity Testing and Applications", "abstract": "We consider the cyclotomic identity testing (CIT) problem: given a polynomial f(x1,\u2026,xk), decide whether f(\u03b6ne1, \u2026,\u03b6nek) is zero, where \u03b6n = e2\u03c0 i/n is a primitive complex n-th root of unity and e1,\u2026,ek are integers, represented in binary. When f is given by an algebraic circuit, we give a randomized polynomial-time algorithm for CIT assuming the generalised Riemann hypothesis (GRH), and show that the problem is in NP unconditionally. When f is given by a circuit of polynomially bounded degree, we give a randomized NC algorithm. In case f is a linear form we show that the problem lies in NC. Towards understanding when CIT can be solved in deterministic polynomial-time, we consider so-called diagonal depth-3 circuits, i.e., polynomials f \u2211mi=1 g+idi, where gi is a linear form and di a positive integer given in unary. We observe that a polynomial-time algorithm for CIT on this class would yield a sub-exponential-time algorithm for polynomial identity testing. However, assuming GRH, we show that if the linear forms gi are all identical then CIT can be solved in polynomial time. Finally, we use our results to give a new proof that equality of compressed strings, i.e., strings presented using context-free grammars, can be decided in randomized NC.", "venue": "ISSAC", "authors": ["Nikhil  Balaji", "Sylvain  Perifel", "Mahsa  Shirmohammadi", "James  Worrell"], "year": 2021, "n_citations": 0}
{"id": 6102084, "s2_id": "16f64eff2c5f0a87b5f4265b1454ccf592e5aba7", "title": "Satisfiability Checking meets Symbolic Computation (Project Paper)", "abstract": "Symbolic Computation and Satisfiability Checking are two research areas, both having their individual scientific focus but sharing also common interests in the development, implementation and application of decision procedures for arithmetic theories. Despite their commonalities, the two communities are rather weakly connected. The aim of our newly accepted SC project (H2020-FETOPEN-CSA) is to strengthen the connection between these communities by creating common platforms, initiating interaction and exchange, identifying common challenges, and developing a common roadmap from theory along the way to tools and (industrial) applications. In this paper we report on the aims and on the first activities of this project, and formalise some relevant challenges for the unified SC community.", "venue": "ArXiv", "authors": ["Erika  \u00c1brah\u00e1m", "John  Abbott", "Bernd  Becker", "Anna Maria Bigatti", "Martin  Brain", "Bruno  Buchberger", "Alessandro  Cimatti", "James H. Davenport", "Matthew  England", "Pascal  Fontaine", "Stephen  Forrest", "Alberto  Griggio", "Daniel  Kroening", "Werner M. Seiler", "Thomas  Sturm"], "year": 2016, "n_citations": 1}
{"id": 6108905, "s2_id": "fdc8b5809f341820a40c1a74861f8fe4dbdd6e18", "title": "Improved algorithms for left factorial residues", "abstract": "We present improved algorithms for computing the left factorial residues $!p=0!+1!+\\dots+(p-1)! \\!\\mod p$. We use these algorithms for the calculation of the residues $!p\\!\\mod p$, for all primes $p$ up to $2^{40}$. Our results confirm that Kurepa's left factorial conjecture is still an open problem, as they show that there are no odd primes $p<2^{40}$ such that $p$ divides $!p$. Additionally, we confirm that there are no socialist primes $p$ with $5", "venue": "Inf. Process. Lett.", "authors": ["Vladica  Andrejic", "Alin  Bostan", "Milos  Tatarevic"], "year": 2021, "n_citations": 0}
{"id": 6113361, "s2_id": "7cd6f79ad9e3197bd5fb0d7e09a09796a101e7da", "title": "Module Border Bases", "abstract": "In this paper, we generalize the notion of border bases of zero-dimensional polynomial ideals to the module setting. To this end, we introduce order modules as a generalization of order ideals and module border bases of submodules with finite codimension in a free module as a generalization of border bases of zero-dimensional ideals in the first part of this paper. In particular, we extend the division algorithm for border bases to the module setting, show the existence and uniqueness of module border bases, and characterize module border bases analogously like border bases via the special generation property, border form modules, rewrite rules, commuting matrices, and liftings of border syzygies. Furthermore, we deduce Buchberger's Criterion for Module Border Bases and give an algorithm for the computation of module border bases that uses linear algebra techniques. In the second part, we further generalize the notion of module border bases to quotient modules. We then show the connection between quotient module border bases and special module border bases and deduce characterizations similar to the ones for module border bases. Moreover, we give an algorithm for the computation of quotient module border bases using linear algebra techniques, again. At last, we prove that subideal border bases are isomorphic to special quotient module border bases. This isomorphy immediately yields characterizations and an algorithm for the computation of subideal border bases.", "venue": "ArXiv", "authors": ["Markus  Kriegl"], "year": 2013, "n_citations": 0}
{"id": 6117440, "s2_id": "a98daf0c36156ec328b5173169df3eb2b6dee58f", "title": "Exact Safety Verification of Hybrid Systems Based on Bilinear SOS Representation", "abstract": "In this article, we address the problem of safety verification of nonlinear hybrid systems. A hybrid symbolic-numeric method is presented to compute exact inequality invariants of hybrid systems efficiently. Some numerical invariants of a hybrid system can be obtained by solving a bilinear SOS programming via the PENBMI solver or iterative method, then the modified Newton refinement and rational vector recovery techniques are applied to obtain exact polynomial invariants with rational coefficients, which exactly satisfy the conditions of invariants. Experiments on some benchmarks are given to illustrate the efficiency of our algorithm.", "venue": "ACM Trans. Embed. Comput. Syst.", "authors": ["Zhengfeng  Yang", "Wang  Lin", "Min  Wu"], "year": 2015, "n_citations": 27}
{"id": 6117516, "s2_id": "26e02fc5572fcf1e55496a2846aaa77b9b45b14d", "title": "Powers of tensors and fast matrix multiplication", "abstract": "This paper presents a method to analyze the powers of a given trilinear form (a special kind of algebraic construction also called a tensor) and obtain upper bounds on the asymptotic complexity of matrix multiplication. Compared with existing approaches, this method is based on convex optimization, and thus has polynomial-time complexity. As an application, we use this method to study powers of the construction given by Coppersmith and Winograd [Journal of Symbolic Computation, 1990] and obtain the upper bound \u03c9 < 2.3728639 on the exponent of square matrix multiplication, which slightly improves the best known upper bound.", "venue": "ISSAC", "authors": ["Fran\u00e7ois Le Gall"], "year": 2014, "n_citations": 993}
{"id": 6120919, "s2_id": "91ecc9265555bc603f1b5f58a6f9fcfc29e0c2fa", "title": "The package HarmonicSums: Computer Algebra and Analytic aspects of Nested Sums", "abstract": "This paper summarizes the essential functionality of the computer algebra package HarmonicSums. On the one hand HarmonicSums can work with nested sums such as harmonic sums and their generalizations and on the other hand it can treat iterated integrals of the Poincare and Chen-type, such as harmonic polylogarithms and their generalizations. The interplay of these representations and the analytic aspects are illustrated by concrete examples.", "venue": "ArXiv", "authors": ["Jakob  Ablinger"], "year": 2014, "n_citations": 51}
{"id": 6123573, "s2_id": "d49520fe761130e28cce8d9b9fc662bd34b02e83", "title": "Parallel versions of the symbolic manipulation system FORM", "abstract": "The symbolic manipulation program FORM is specialized to handle very large algebraic expressions. Some specific features of its internal structure make FORM very well suited for parallelization. \nWe have now two parallel versions of FORM, one is based on POSIX threads and is optimal for modern multicore computers while another one uses MPI and can be used to parallelize FORM on clusters and Massive Parallel Processing systems. Most existing FORM programs will be able to take advantage of the parallel execution without the need for modifications.", "venue": "ArXiv", "authors": ["M.  Tentyukov", "J. A. M. Vermaseren", "J.  Vollinga"], "year": 2010, "n_citations": 1}
{"id": 6124030, "s2_id": "1ea93a52896aa99f672b05a3a072d35da01c535b", "title": "Computational aspects of finding a solution asymptotics for a singularly perturbed system of differential equations", "abstract": "We analyze the spatial structure of asymptotics of a solution to a singularly perturbed system of mass transfer equations. The leading term of the asymptotics is described by a parabolic equation with possibly degenerate spatial part. We prove a theorem that establishes a relationship between the degree of degeneracy and the numbers of equations in the system and spatial variables in some particular cases. The work hardly depends on the calculation of the eigenvalues of matrices that determine the spatial structure of the asymptotics by the means of computer algebra system Wolfram Mathematica. We put forward a hypothesis on the existence of the found connection for an arbitrary number of equations and spatial variables.", "venue": "ArXiv", "authors": ["Vitaly A. Krasikov", "Andrey V. Nesterov"], "year": 2021, "n_citations": 0}
{"id": 6124837, "s2_id": "7a617b48832b1ae55ce17508c6deab07d33c22d3", "title": "ASF+ --- eine ASF-aehnliche Spezifikationssprache", "abstract": "Ohne auf wesentliche Aspekte der in [Bergstraa im zweiten Fall mus er eine Kopie des Moduls importieren. Schlieslicherlaubt ASF + semantische Bedingungen an Parameter und die Angabe von Beweiszielen.", "venue": "ArXiv", "authors": ["R\u00fcdiger  Lunde", "Claus-Peter  Wirth"], "year": 2009, "n_citations": 1}
{"id": 6125686, "s2_id": "4765bccca432a8c156d7b1f25b342c1c50661612", "title": "Proof of George Andrews\u2019s and David Robbins\u2019s q-TSPP conjecture", "abstract": "The conjecture that the orbit-counting generating function for totally symmetric plane partitions can be written as an explicit product formula has been stated independently by George Andrews and David Robbins around 1983. We present a proof of this long-standing conjecture.", "venue": "Proceedings of the National Academy of Sciences", "authors": ["Christoph  Koutschan", "Manuel  Kauers", "Doron  Zeilberger"], "year": 2011, "n_citations": 32}
{"id": 6137192, "s2_id": "374d8792543a0a3c9c3802eb023e7fcb21c29cd7", "title": "A canonical form for the continuous piecewise polynomial functions", "abstract": "We present in this paper a canonical form for the elements in the ring of continuous piecewise polynomial functions. This new representation is based on the use of a particular class of functions { C i ( P ) : P ? Q x , i = 0 , ? , deg ( P ) } defined by C i ( P ) ( x ) = { 0 if? x ? \u03b1 P ( x ) if? x ? \u03b1 where \u03b1 is the i th real root of the polynomial P . These functions will allow us to represent and manipulate easily every continuous piecewise polynomial function through the use of the corresponding canonical form.It will be also shown how to produce a \"rational\" representation of each function C i ( P ) allowing its evaluation by performing only operations in Q and avoiding the use of any real algebraic number.", "venue": "J. Comput. Appl. Math.", "authors": ["Jorge  Caravantes", "Maria de los Angeles Gomez-Molleda", "Laureano  Gonz\u00e1lez-Vega"], "year": 2015, "n_citations": 1}
{"id": 6149018, "s2_id": "f02899c06dfe228795d11d6aef6470d3ef4fd965", "title": "Laderman matrix multiplication algorithm can be constructed using Strassen algorithm and related tensor's isotropies", "abstract": "In 1969, V. Strassen improves the classical~2x2 matrix multiplication algorithm. The current upper bound for 3x3 matrix multiplication was reached by J.B. Laderman in 1976. This note presents a geometric relationship between Strassen and Laderman algorithms. By doing so, we retrieve a geometric formulation of results very similar to those presented by O. Sykora in 1977.", "venue": "ArXiv", "authors": ["Alexandre  Sedoglavic"], "year": 2017, "n_citations": 5}
{"id": 6153348, "s2_id": "494660b4afec6ffd2387ad04c801bd5b6a079a18", "title": "Multiplicity-preserving triangular set decomposition of two polynomials", "abstract": "In this paper, a multiplicity-preserving triangular set decomposition algorithm is proposed for a system of two polynomials, which involves only computing the primitive polynomial remainder sequence of two polynomials once and certain GCD computations. The algorithm decomposes the unmixed variety defined by two polynomials into square free and disjoint (for non-vertical components, see Definition 4) algebraic cycles represented by triangular sets, which may have negative multiplicities. Thus, the authors can count the multiplicities of the non-vertical components. In the bivariate case, the authors give a complete algorithm to decompose the system into zeros represented by triangular sets with multiplicities. The authors also analyze the complexity of the algorithm in the bivariate case. The authors implement the algorithm and show the effectiveness of the method with extensive experiments.", "venue": "J. Syst. Sci. Complex.", "authors": ["Jin-San  Cheng", "Xiao-Shan  Gao"], "year": 2014, "n_citations": 12}
{"id": 6153787, "s2_id": "240b64e35c8713c20b3730ee16dbfd55bd95fcd1", "title": "Upper Hessenberg and Toeplitz Bohemians", "abstract": "We look at Bohemians, specifically those with population $\\{-1, 0, {+1}\\}$ and sometimes $\\{0,1,i,-1,-i\\}$. More, we specialize the matrices to be upper Hessenberg Bohemian. From there, focusing on only those matrices whose characteristic polynomials have maximal height allows us to explicitly identify these polynomials and give useful bounds on their height, and conjecture an accurate asymptotic formula. The lower bound for the maximal characteristic height is exponential in the order of the matrix; in contrast, the height of the matrices remains constant. We give theorems about the numbers of normal matrices and the numbers of stable matrices in these families.", "venue": "ArXiv", "authors": ["Eunice Y. S. Chan", "Robert M. Corless", "Laureano  Gonz\u00e1lez-Vega", "J. Rafael Sendra", "Juana  Sendra"], "year": 2019, "n_citations": 7}
{"id": 6153816, "s2_id": "b67f9150ffef2251829d189c8a17ec6aa0b416f1", "title": "Faster Polynomial Multiplication over Finite Fields", "abstract": "Polynomials over finite fields play a central role in algorithms for cryptography, error correcting codes, and computer algebra. The complexity of multiplying such polynomials is still a major open problem. Let p be a prime, and let Mp(n) denote the bit complexity of multiplying two polynomials in Fp[X] of degree less than n. For n large compared to p, we establish the bound Mp(n) = O(n log n 8log* n log p), where log* n = min{k \u03f5 N: log \u2026k\u00d7\u2026 log n \u2264 1} stands for the iterated logarithm. This improves on the previously best known bound Mp(n) = O(n log n log log n log p), which essentially goes back to the 1970s.", "venue": "J. ACM", "authors": ["David  Harvey", "Joris van der Hoeven", "Gr\u00e9goire  Lecerf"], "year": 2017, "n_citations": 58}
{"id": 6181764, "s2_id": "1df63b38058b8a373f2436dd91434bc496030f0f", "title": "Solving degree, last fall degree, and related invariants", "abstract": "In this paper we study and relate several invariants connected to the solving degree of a polynomial system. This provides a rigorous framework for estimating the complexity of solving a system of polynomial equations via Gr\u00f6bner bases methods. Our main results include a connection between the solving degree and the last fall degree and one between the degree of regularity and the Castelnuovo\u2013Mumford regularity.", "venue": "ArXiv", "authors": ["Alessio  Caminata", "Elisa  Gorla"], "year": 2021, "n_citations": 0}
{"id": 6186886, "s2_id": "cf1dd15cdee595f5b09ad259acdb248b1b7126b7", "title": "Faster sparse multivariate polynomial interpolation of straight-line programs", "abstract": "Given a straight-line program whose output is a polynomial function of the inputs, we present a new algorithm to compute a concise representation of that unknown function. Our algorithm can handle any case where the unknown function is a multivariate polynomial, with coefficients in an arbitrary finite field, and with a reasonable number of nonzero terms but possibly very large degree. It is competitive with previously known sparse interpolation algorithms that work over an arbitrary finite field, and provides an improvement when there are a large number of variables.", "venue": "J. Symb. Comput.", "authors": ["Andrew  Arnold", "Mark  Giesbrecht", "Daniel S. Roche"], "year": 2016, "n_citations": 30}
{"id": 6186999, "s2_id": "fd037504025cbe88c8279deb6855f83baefdaad4", "title": "Chunky and equal-spaced polynomial multiplication", "abstract": "Finding the product of two polynomials is an essential and basic problem in computer algebra. While most previous results have focused on the worst-case complexity, we instead employ the technique of adaptive analysis to give an improvement in many ''easy'' cases. We present two adaptive measures and methods for polynomial multiplication, and also show how to effectively combine them to gain both advantages. One useful feature of these algorithms is that they essentially provide a gradient between existing ''sparse'' and ''dense'' methods. We prove that these approaches provide significant improvements in many cases but in the worst case are still comparable to the fastest existing algorithms.", "venue": "J. Symb. Comput.", "authors": ["Daniel S. Roche"], "year": 2011, "n_citations": 17}
{"id": 6192412, "s2_id": "caeadadfbe44d73742b75a7ab28d780bd51d1ab5", "title": "Abstraction and Refinement in Static Model-Checking", "abstract": "interpretation is a general methodology for building static analyses of programs. It was introduced by P. and R. Cousot in \\cite{cc}. We present, in this paper, an application of a generic abstract interpretation to domain of model-checking. Dynamic checking are usually easier to use, because the concept are establishe d and wide well know. But they are usually limited to systems whose states space is finite. In an other part, certain faults cannot be detected dynamically, even by keeping track of the history of the states space.Indeed, the classical problem of finding the right test cases is far from trivial and limit the abilities of dynamic checkers further. Static checking have the advantage that they work on a more abstract level than dynamic checker and can verify system properties for all inputs. Problem, it is hard to guarantee that a violation of a modeled property corresponds to a fault in the concrete system. We propose an approach, in which we generate counter-examples dynamically using the abstract interpretation techniques.", "venue": "ArXiv", "authors": ["Kaninda  Musumbu"], "year": 2009, "n_citations": 0}
{"id": 6199324, "s2_id": "b7479992d18704e263532716611bc8fbe8419c5b", "title": "Numerical Coverage Estimation for the Symbolic Simulation of Real-Time Systems", "abstract": "Three numerical coverage metrics for the symbolic simulation of dense-time systems and their estimation methods are presented. Special techniques to derive numerical estimations of dense-time state-spaces have also been developed. Properties of the metrics are also discussed with respect to four criteria. Implementation and experiments are then reported.", "venue": "FORTE", "authors": ["Farn  Wang", "Geng-Dian  Hwang", "Fang  Yu"], "year": 2003, "n_citations": 13}
{"id": 6203135, "s2_id": "fb7514029328f0f087fce5824eac09a2e4de8049", "title": "Predicate Abstraction via Symbolic Decision Procedures", "abstract": "We present a new approach for performing predicate abstraction based on\nsymbolic decision procedures. Intuitively, a symbolic decision procedure for a\ntheory takes a set of predicates in the theory and symbolically executes a\ndecision procedure on all the subsets over the set of predicates. The result of\nthe symbolic decision procedure is a shared expression (represented by a\ndirected acyclic graph) that implicitly represents the answer to a predicate\nabstraction query.\n We present symbolic decision procedures for the logic of Equality and\nUninterpreted Functions (EUF) and Difference logic (DIFF) and show that these\nprocedures run in pseudo-polynomial (rather than exponential) time. We then\nprovide a method to construct symbolic decision procedures for simple mixed\ntheories (including the two theories mentioned above) using an extension of the\nNelson-Oppen combination method. We present preliminary evaluation of our\nProcedure on predicate abstraction benchmarks from device driver verification\nin SLAM.", "venue": "Log. Methods Comput. Sci.", "authors": ["Shuvendu K. Lahiri", "Thomas  Ball", "Byron  Cook"], "year": 2007, "n_citations": 45}
{"id": 6209826, "s2_id": "005295094674ad0caa8256f1d58d52d990199036", "title": "Computing periods of rational integrals", "abstract": "A period of a rational integral is the result of integrating, with respect to one or several variables, a rational function over a closed path. This work focuses particularly on periods depending on a parameter: in this case the period under consideration satisfies a linear differential equation, the Picard-Fuchs equation. I give a reduction algorithm that extends the Griffiths-Dwork reduction and apply it to the computation of Picard-Fuchs equations. The resulting algorithm is elementary and has been successfully applied to problems that were previously out of reach.", "venue": "Math. Comput.", "authors": ["Pierre  Lairez"], "year": 2016, "n_citations": 50}
{"id": 6213094, "s2_id": "becbba6fe8abfbc6f5f467e851a142bd198f0069", "title": "Comparing machine learning models to choose the variable ordering for cylindrical algebraic decomposition", "abstract": "There has been recent interest in the use of machine learning (ML) approaches within mathematical software to make choices that impact on the computing performance without affecting the mathematical correctness of the result. We address the problem of selecting the variable ordering for cylindrical algebraic decomposition (CAD), an important algorithm in Symbolic Computation. Prior work to apply ML on this problem implemented a Support Vector Machine (SVM) to select between three existing human-made heuristics, which did better than anyone heuristic alone. Here we extend this result by training ML models to select the variable ordering directly, and by trying out a wider variety of ML techniques.", "venue": "CICM", "authors": ["Matthew  England", "Dorian  Florescu"], "year": 2019, "n_citations": 12}
{"id": 6215104, "s2_id": "81d4ce0cc4593a394fc277496e839fa4f390f8c2", "title": "Effective bounds for P-recursive sequences", "abstract": "We describe an algorithm that takes as input a complex sequence (u\"n) given by a linear recurrence relation with polynomial coefficients along with initial values, and outputs a simple explicit upper bound (v\"n) such that |u\"n|@?v\"n for all n. Generically, the bound is tight, in the sense that its asymptotic behaviour matches that of u\"n. We discuss applications to the evaluation of power series with guaranteed precision.", "venue": "J. Symb. Comput.", "authors": ["Marc  Mezzarobba", "Bruno  Salvy"], "year": 2010, "n_citations": 41}
{"id": 6222221, "s2_id": "4d54a42d4596a7a412ac41d3e9506e77e36a30ae", "title": "Symbolic-numeric methods for improving structural analysis of differential-algebraic equation systems", "abstract": "Systems of differential-algebraic equations (DAEs) are generated routinely by simulation and modeling environments, such as MapleSim and those based on the Modelica language. Before a simulation starts and a numerical method is applied, some kind of structural analysis is performed to determine which equations to be differentiated, and how many times. Both Pantelides\u2019s algorithm and Pryce\u2019s \u03a3-method are equivalent in the sense that, if one method succeeds in finding the correct index and producing a nonsingular Jacobian for a numerical solution procedure, then the other does also. Such a success occurs on many problems of interest, but these structural analysis methods can fail on simple, solvable DAEs and give incorrect structural information including the index. This article investigates \u03a3-method\u2019s failures and presents two symbolic-numeric conversion methods for fixing them. Both methods convert a DAE on which the \u03a3-method fails to a DAE on which this SA may succeed.", "venue": "ArXiv", "authors": ["Guangning  Tan", "Nedialko S. Nedialkov", "John D. Pryce"], "year": 2015, "n_citations": 6}
{"id": 6228962, "s2_id": "eb5859d0d60d6ddc4acddb9693974f51ab08073c", "title": "Recursive Polynomial Remainder Sequence and the Nested Subresultants", "abstract": "We give two new expressions of subresultants, nested subresultant and reduced nested subresultant, for the recursive polynomial remainder sequence (PRS) which has been introduced by the author. The reduced nested subresultant reduces the size of the subresultant matrix drastically compared with the recursive subresultant proposed by the authors before, hence it is much more useful for investigation of the recursive PRS. Finally, we discuss usage of the reduced nested subresultant in approximate algebraic computation, which motivates the present work.", "venue": "CASC", "authors": ["Akira  Terui"], "year": 2005, "n_citations": 1}
{"id": 6242351, "s2_id": "5e44e4c61d592fcef0fe3bd5bc425e3a084a832a", "title": "Formulas for Continued Fractions: An Automated Guess and Prove Approach", "abstract": "We describe a simple method that produces automatically closed forms for the coefficients of continued fractions expansions of a large number of special functions. The function is specified by a non-linear differential equation and initial conditions. This is used to generate the first few coefficients and from there a conjectured formula. This formula is then proved automatically thanks to a linear recurrence satisfied by some remainder terms. Extensive experiments show that this simple approach and its straightforward generalization to difference and q-difference equations capture a large part of the formulas in the literature on continued fractions.", "venue": "ISSAC", "authors": ["S\u00e9bastien  Maulat", "Bruno  Salvy"], "year": 2015, "n_citations": 2}
{"id": 6245766, "s2_id": "aeb1be92d2a40112b645058800afebb3ab1730b7", "title": "The Complexity of Factors of Multivariate Polynomials", "abstract": "Abstract\nThe existence of string functions, which are not polynomial time \ncomputable, but whose graph is checkable in polynomial time, is a basic \nassumption in cryptography. \nWe prove that in the framework of algebraic complexity, there are no such \nfamilies of polynomial functions of polynomially bounded degree over \nfields of characteristic zero.\nThe proof relies on a polynomial upper bound on the approximative complexity of \na factor g of a polynomial f in terms of the (approximative) complexity of f\nand the degree of the factor g. This extends a result by Kaltofen. \nThe concept of approximative complexity allows us to cope with the case that a factor has \nan exponential multiplicity, by using a perturbation argument. \nOur result extends to randomized (two-sided error) decision complexity. \n\n", "venue": "Found. Comput. Math.", "authors": ["Peter  B\u00fcrgisser"], "year": 2004, "n_citations": 36}
{"id": 6254607, "s2_id": "e66d56d61919de63f8ea3294bd9ffc660dc3193f", "title": "Faster algorithms for the square root and reciprocal of power series", "abstract": "We give new algorithms for the computation of square roots and reciprocals of power series in C[x]. If M(n) denotes the cost of multiplying polynomials of degree n, the square root to order n costs (1.333...+o(1))M(n) and the reciprocal costs (1.444... +o(1))M(n). These improve on the previous best results, (1.8333... + o(1))M(n) and (1.5 + o(1))M(n), respectively.", "venue": "Math. Comput.", "authors": ["David  Harvey"], "year": 2011, "n_citations": 17}
{"id": 6262049, "s2_id": "db1dba4f8669e9ecece44ab6bc0260c2f2930317", "title": "On mu-Symmetric Polynomials", "abstract": "In this paper, we study functions of the roots of a univariate polynomial in which the roots have a given multiplicity structure $\\mu$. Traditionally, root functions are studied via the theory of symmetric polynomials; we extend this theory to $\\mu$-symmetric polynomials. We were motivated by a conjecture from Becker et al.~(ISSAC 2016) about the $\\mu$-symmetry of a particular root function $D^+(\\mu)$, called D-plus. To investigate this conjecture, it was desirable to have fast algorithms for checking if a given root function is $\\mu$-symmetric. We designed three such algorithms: one based on Grobner bases, another based on preprocessing and reduction, and the third based on solving linear equations. We implemented them in Maple and experiments show that the latter two algorithms are significantly faster than the first.", "venue": "ArXiv", "authors": ["Jing  Yang", "Chee K. Yap"], "year": 2020, "n_citations": 1}
{"id": 6263931, "s2_id": "03074163dc6f74c3ff4381f524a8b112d7f26f86", "title": "Combinatorial Differential Algebra of xp", "abstract": "We link n -jets of the affine monomial scheme defined by x to the stable set polytope of some perfect graph. We prove that, as p varies, the dimension of the coordinate ring of the scheme of n -jets as a C -vector space is a polynomial of degree n+1, namely the Erhart polynomial of the stable set polytope of that graph. One main ingredient for our proof is a result of Zobnin who determined a differential Gr\u00f6bner basis of the differential ideal generated by x. We generalize Zobnin\u2019s result to the bivariate case. We study (m,n) -jets, a higher-dimensional analog of jets, and relate them to regular unimodular triangulations of the m\u00d7 n -rectangle.", "venue": "ArXiv", "authors": ["Rida Ait El Manssour", "Anna-Laura  Sattelberger"], "year": 2021, "n_citations": 1}
{"id": 6271468, "s2_id": "8af4ad9e7b7b569ed61c7fbed961058a3f11c2d0", "title": "Factoring bivariate lacunary polynomials without heights", "abstract": "We present an algorithm which computes the multilinear factors of bivariate lacunary polynomials. It is based on a new Gap theorem which allows to test whether <i>P(X)</i>=\u2211<sup><i>k</i></sup><sub><i>j</i>=1</sub> \u03b1<sub><i>j</i></sub><i>X</i><sup>\u03b1<i>j</i></sup>(1+<i>X</i>)<sup><i>\u03b2j</i></sup>is identically zero in polynomial time. The algorithm we obtain is more elementary than the one by Kaltofen and Koiran (ISSAC'05) since it relies on the valuation of polynomials of the previous form instead of the height of the coefficients. As a result, it can be used to find some linear factors of bivariate lacunary polynomials over a field of large finite characteristic in probabilistic polynomial time.", "venue": "ISSAC '13", "authors": ["Arkadev  Chattopadhyay", "Bruno  Grenet", "Pascal  Koiran", "Natacha  Portier", "Yann  Strozecki"], "year": 2013, "n_citations": 12}
{"id": 6277126, "s2_id": "7c6266c6f49cd4d19413cf90d14dbd6e1d53b5a6", "title": "Towards a Theory of Domains for Harmonic Functions and its Symbolic Counterpart", "abstract": "In this paper, we begin by reviewing the calculus induced by the framework of [10]. In there, we extended Polylogarithm functions over a subalgebra of noncommutative rational power series, recognizable by finite state (multiplicity) automata over the alphabet X = {x0,x1}. The stability of this calculus under shuffle products relies on the nuclearity of the target space [31]. We also concentrated on algebraic and analytic aspects of this extension allowing to index polylogarithms, at non positive multi-indices, by rational series and also allowing to regularize divergent polyzetas, at non positive multi-indices [10]. As a continuation of works in [10] and in order to understand the bridge between the extension of this \u201cpolylogarithmic calculus\u201d and the world of harmonic sums, we propose a local theory, adapted to a full calculus on indices of Harmonic Sums based on the Taylor expansions, around zero, of polylogarithms with index x1 on the rightmost end. This theory is not only compatible with Stuffle products but also with the Analytic Model. In this respect, it provides a stable and fully algorithmic model for Harmonic calculus. Examples by computer are also provided .", "venue": "ArXiv", "authors": ["van Chien Bui", "G'erard  Duchamp", "Quoc Hoan Ngo", "Vincel Hoang Ngoc Minh", "Vu Nguyen Dinh"], "year": 2021, "n_citations": 0}
{"id": 6278815, "s2_id": "2cfd6e5aca04b5f4d089a951b33e45a6a132523b", "title": "Sparse FGLM algorithms", "abstract": "Given a zero-dimensional ideal $I \\subset \\kx$ of degree $D$, the transformation of the ordering of its \\grobner basis from DRL to LEX is a key step in polynomial system solving and turns out to be the bottleneck of the whole solving process. Thus it is of crucial importance to design efficient algorithms to perform the change of ordering. The main contributions of this paper are several efficient methods for the change of ordering which take advantage of the sparsity of multiplication matrices in the classical {\\sf FGLM} algorithm. Combing all these methods, we propose a deterministic top-level algorithm that automatically detects which method to use depending on the input. As a by-product, we have a fast implementation that is able to handle ideals of degree over $40000$. Such an implementation outperforms the {\\sf Magma} and {\\sf Singular} ones, as shown by our experiments. First for the shape position case, two methods are designed based on the Wiedemann algorithm: the first is probabilistic and its complexity to complete the change of ordering is $O(D(N_1+n\\log (D)))$, where $N_1$ is the number of nonzero entries of a multiplication matrix; the other is deterministic and computes the LEX \\grobner basis of $\\sqrt{I}$ via Chinese Remainder Theorem. Then for the general case, the designed method is characterized by the Berlekamp--Massey--Sakata algorithm from Coding Theory to handle the multi-dimensional linearly recurring relations. Complexity analyses of all proposed methods are also provided. Furthermore, for generic polynomial systems, we present an explicit formula for the estimation of the sparsity of one main multiplication matrix, and prove its construction is free. With the asymptotic analysis of such sparsity, we are able to show for generic systems the complexity above becomes $O(\\sqrt{6/n \\pi} D^{2+\\frac{n-1}{n}})$.", "venue": "J. Symb. Comput.", "authors": ["Jean-Charles  Faug\u00e8re", "Chenqi  Mou"], "year": 2017, "n_citations": 36}
{"id": 6279663, "s2_id": "84e9033825c580d72142d3b604ac3287f985c2f2", "title": "Demand analysis with partial predicates", "abstract": "Abstract To alleviate the inefficiencies caused by the interaction of the logic and functional sides, integrated languages may take advantage of demand information, i.e. knowing in advance which computations are needed and, to which extent, in a particular context. This work studies demand analysis \u2013 which is closely related to backwards strictness analysis \u2013 in a semantic framework of partial predicates, which in turn are constructive realizations of ideals in a domain. This will allow us to give a concise, unified presentation of demand analysis, to relate it to other analyses based on abstract interpretation or strictness logics, some hints for the implementation, and, more important, to prove the soundness of our analysis based on demand equations. There are also some innovative results. One of them is that a set constraint-based analysis has been derived in a stepwise manner using ideas taken from the area of program transformation. The other one is the possibility of using program transformation itself to perform the analysis, specially in those domains of properties where algorithms based on constraint solving are too weak.", "venue": "Theory and Practice of Logic Programming", "authors": ["Julio  Mari\u00f1o-Carballo", "\u00c1ngel  Herranz-Nieva", "Juan Jos\u00e9 Moreno-Navarro"], "year": 2007, "n_citations": 0}
{"id": 6280611, "s2_id": "f528c847fa68626476aa49de82889ceb3017fa0b", "title": "Computer algebra tools for Feynman integrals and related multi-sums", "abstract": "In perturbative calculations, e.g., in the setting of Quantum Chromodynamics (QCD) one aims at the evaluation of Feynman integrals. Here one is often faced with the problem to simplify multiple nested integrals or sums to expressions in terms of indefinite nested integrals or sums. Furthermore, one seeks for solutions of coupled systems of linear differential equations, that can be represented in terms of indefinite nested sums (or integrals). In this article we elaborate the main tools and the corresponding packages, that we have developed and intensively used within the last 10 years in the course of our QCD-calculations.", "venue": "Proceedings of Loops and Legs in Quantum Field Theory \u2014 PoS(LL2018)", "authors": ["Johannes  Bl\u00fcmlein", "Carsten  Schneider"], "year": 2018, "n_citations": 1}
{"id": 6282053, "s2_id": "d757ad78eaceda73f6ac7ce8986b1a8b2b53d5fb", "title": "Good pivots for small sparse matrices", "abstract": "For sparse matrices up to size $8 \\times 8$, we determine optimal choices for pivot selection in Gaussian elimination. It turns out that they are slightly better than the pivots chosen by a popular pivot selection strategy, so there is some room for improvement. We then create a pivot selection strategy using machine learning and find that it indeed leads to a small improvement compared to the classical strategy.", "venue": "CASC", "authors": ["Manuel  Kauers", "Jakob  Moosbauer"], "year": 2020, "n_citations": 0}
{"id": 6288934, "s2_id": "f4c502289c0987fe07c08d0dc0fe8dd48e98e335", "title": "Closed form solutions of linear difference equations in terms of symmetric products", "abstract": "In this paper we show how to find a closed form solution for third order difference operators in terms of solutions of second order operators. This work is an extension of previous results on finding closed form solutions of recurrence equations and a counterpart to existing results on differential equations. As motivation and application for this work, we discuss the problem of proving positivity of sequences given merely in terms of their defining recurrence relation. The main advantage of the present approach to earlier methods attacking the same problem is that our algorithm provides human-readable and verifiable, i.e., certified proofs.", "venue": "ACCA", "authors": ["Yongjae  Cha"], "year": 2013, "n_citations": 1}
{"id": 6290214, "s2_id": "1f0083955141885b7dc45b3f3c87805094a5c81d", "title": "Ideal Membership Problem for Boolean Minority", "abstract": "The Ideal Membership Problem (IMP) tests if an input polynomial $f\\in \\mathbb{F}[x_1,\\dots,x_n]$ with coefficients from a field $\\mathbb{F}$ belongs to a given ideal $I \\subseteq \\mathbb{F}[x_1,\\dots,x_n]$. It is a well-known fundamental problem with many important applications, though notoriously intractable in the general case. In this paper we consider the IMP for polynomial ideals encoding combinatorial problems and where the input polynomial $f$ has degree at most $d=O(1)$ (we call this problem IMP$_d$). A dichotomy result between ``hard'' (NP-hard) and ``easy'' (polynomial time) IMPs was recently achieved for Constraint Satisfaction Problems over finite domains [Bulatov FOCS'17, Zhuk FOCS'17] (this is equivalent to IMP$_0$) and IMP$_d$ for the Boolean domain [Mastrolilli SODA'19], both based on the classification of the IMP through functions called polymorphisms. The complexity of the IMP$_d$ for five polymorphisms has been solved in [Mastrolilli SODA'19] whereas for the ternary minority polymorphism it was incorrectly declared to have been resolved by a previous result. As a matter of fact the complexity of the IMP$_d$ for the ternary minority polymorphism is open. In this paper we provide the missing link by proving that the IMP$_d$ for Boolean combinatorial ideals whose constraints are closed under the minority polymorphism can be solved in polynomial time. This result, along with the results in [Mastrolilli SODA'19], completes the identification of the precise borderline of tractability for the IMP$_d$ for constrained problems over the Boolean domain. This paper is motivated by the pursuit of understanding the issue of bit complexity of Sum-of-Squares proofs raised by O'Donnell [ITCS'17]. Raghavendra and Weitz [ICALP'17] show how the IMP$_d$ tractability for combinatorial ideals implies bounded coefficients in Sum-of-Squares proofs.", "venue": "ArXiv", "authors": ["Arpitha P. Bharathi", "Monaldo  Mastrolilli"], "year": 2020, "n_citations": 2}
{"id": 6294614, "s2_id": "094ccd6fef39e15d593602f2b7b0eca3c93618e9", "title": "On the Chordality of Polynomial Sets in Triangular Decomposition in Top-Down Style", "abstract": "In this paper the chordal graph structures of polynomial sets appearing in triangular decomposition in top-down style are studied when the input polynomial set has a chordal associated graph. We prove that the associated graph of one specific triangular set computed in any algorithm for triangular decomposition in top-down style is a subgraph of the chordal graph of the input polynomial set and that all the polynomial sets, including all the computed triangular sets, appearing in one specific algorithm for triangular decomposition in top-down style (Wang's method) have associated graphs which are subgraphs of the chordal graph of the input polynomial set.", "venue": "ISSAC", "authors": ["Chenqi  Mou", "Yang  Bai"], "year": 2018, "n_citations": 8}
{"id": 6303594, "s2_id": "e7c041d2c97fb27e79a55efd111ca8e507d8e159", "title": "On the complexity of solving quadratic Boolean systems", "abstract": "A fundamental problem in computer science is that of finding all the common zeros of m quadratic polynomials in n unknowns over F\"2. The cryptanalysis of several modern ciphers reduces to this problem. Up to now, the best complexity bound was reached by an exhaustive search in 4log\"2n2^n operations. We give an algorithm that reduces the problem to a combination of exhaustive search and sparse linear algebra. This algorithm has several variants depending on the method used for the linear algebra step. We show that, under precise algebraic assumptions on the input system, the deterministic variant of our algorithm has complexity bounded by O(2^0^.^8^4^1^n) when m=n, while a probabilistic variant of the Las Vegas type has expected complexity O(2^0^.^7^9^2^n). Experiments on random systems show that the algebraic assumptions are satisfied with probability very close to 1. We also give a rough estimate for the actual threshold between our method and exhaustive search, which is as low as 200, and thus very relevant for cryptographic applications.", "venue": "J. Complex.", "authors": ["Magali  Bardet", "Jean-Charles  Faug\u00e8re", "Bruno  Salvy", "Pierre-Jean  Spaenlehauer"], "year": 2013, "n_citations": 77}
{"id": 6307771, "s2_id": "567067f24e1352306765474897252fa37663dbc3", "title": "An Algorithm for Computing the Limit Points of the Quasi-component of a Regular Chain", "abstract": "For a regular chain $R$, we propose an algorithm which computes the (non-trivial) limit points of the quasi-component of $R$, that is, the set $\\bar{W(R)} \\setminus W(R)$. Our procedure relies on Puiseux series expansions and does not require to compute a system of generators of the saturated ideal of $R$. We focus on the case where this saturated ideal has dimension one and we discuss extensions of this work in higher dimensions. We provide experimental results illustrating the benefits of our algorithms.", "venue": "ArXiv", "authors": ["Parisa  Alvandi", "Changbo  Chen", "Marc Moreno Maza"], "year": 2013, "n_citations": 0}
{"id": 6308060, "s2_id": "9c33b4370860b935f9f019851689a5c5ea581966", "title": "Detecting similarity of rational plane curves", "abstract": "A novel and deterministic algorithm is presented to detect whether two given rational plane curves are related by means of a similarity, which is a central question in Pattern Recognition. As a by-product it finds all such similarities, and the particular case of equal curves yields all symmetries. A complete theoretical description of the method is provided, and the method has been implemented and tested in the Sage system for curves of moderate degrees.", "venue": "J. Comput. Appl. Math.", "authors": ["Juan Gerardo Alc\u00e1zar", "Carlos  Hermoso", "Georg  Muntingh"], "year": 2014, "n_citations": 30}
{"id": 6308468, "s2_id": "eceeb9856725865cf45b9325c934ca69447b4e9d", "title": "A Variant of Gerdt's Algorithm for Computing Involutive Bases", "abstract": "Ihe first author presented an efficient algorithm for computing involutive (and reduced Groebner) bases. In this paper, we consider a modification of this algorithm which simplifies matters to understand it and to implement. We prove correctness and termination of the modified algorithm and also correctness of the used criteria. The proposed algorithm has been implemented in Maple. We present experimental comparison, via some examples, of performance of the modified algorithm with its original form which has been implemented in Maple too. In doing so, we have taken care to provide uniform implementation details for the both algorithms.", "venue": "ArXiv", "authors": ["Vladimir P. Gerdt", "Amir  Hashemi", "Benyamin  M.-Alizadeh"], "year": 2011, "n_citations": 4}
{"id": 6312125, "s2_id": "56de1deef7802df540398e7963d81936ce82796e", "title": "Polynomial-division-based algorithms for computing linear recurrence relations", "abstract": "Sparse polynomial interpolation, sparse linear system solving or modular rational reconstruction are fundamental problems in Computer Algebra. They come down to computing linear recurrence relations of a sequence with the Berlekamp-Massey algorithm. Likewise, sparse multivariate polynomial interpolation and multidimensional cyclic code decoding require guessing linear recurrence relations of a multivariate sequence. \nSeveral algorithms solve this problem. The so-called Berlekamp-Massey-Sakata algorithm (1988) uses polynomial additions and shifts by a monomial. The Scalar-FGLM algorithm (2015) relies on linear algebra operations on a multi-Hankel matrix, a multivariate generalization of a Hankel matrix. The Artinian Gorenstein border basis algorithm (2017) uses a Gram-Schmidt process. \nWe propose a new algorithm for computing the Grobner basis of the ideal of relations of a sequence based solely on multivariate polynomial arithmetic. This algorithm allows us to both revisit the Berlekamp-Massey-Sakata algorithm through the use of polynomial divisions and to completely revise the Scalar-FGLM algorithm without linear algebra operations. \nA key observation in the design of this algorithm is to work on the mirror of the truncated generating series allowing us to use polynomial arithmetic modulo a monomial ideal. It appears to have some similarities with Pade approximants of this mirror polynomial. \nAs an addition from the paper published at the ISSAC conferance, we give an adaptive variant of this algorithm taking into account the shape of the final Grobner basis gradually as it is discovered. The main advantage of this algorithm is that its complexity in terms of operations and sequence queries only depends on the output Grobner basis. \nAll these algorithms have been implemented in Maple and we report on our comparisons.", "venue": "J. Symb. Comput.", "authors": ["J\u00e9r\u00e9my  Berthomieu", "Jean-Charles  Faug\u00e8re"], "year": 2021, "n_citations": 0}
{"id": 6314608, "s2_id": "c6b926532524fb7f6e3611dd1fbe1930b7637950", "title": "Some fast algorithms multiplying a matrix by its adjoint", "abstract": "We present a non-commutative algorithm for the multiplication of a 2\u00d7 2 block-matrix by its adjoint, defined by a matrix ring anti-homomorphism. This algorithm uses 5 block products (3 recursive calls and 2 general products)over C or in positive characteristic. The resulting algorithm for arbitrary dimensions is a reduction of multiplication of a matrix by its adjoint to general matrix product, improving by a constant factor previously known reductions. We prove also that there is no algorithm derived from bilinear forms using only four products and the adjoint of one of them. Second we give novel dedicated algorithms for the complex field and the quaternions to alternatively compute the multiplication taking advantage of the structure of the matrix-polynomial arithmetic involved. We then analyze the respective ranges of predominance of the two strategies. Finally we propose schedules with low memory footprint that support a fast and memory efficient practical implementation over a prime field.", "venue": "ArXiv", "authors": ["Jean-Guillaume  Dumas", "Cl'ement  Pernet", "Alexandre  Sedoglavic"], "year": 2021, "n_citations": 0}
{"id": 6320642, "s2_id": "cc1c88ce7b41ae5651c1aa132b1e77bff5d3e9bb", "title": "Feynman graphs and related Hopf algebras", "abstract": "In a recent series of communications we have shown that the reordering problem of bosons leads to certain combinatorial structures. These structures may be associated with a certain graphical description. In this paper, we show that there is a Hopf Algebra structure associated with this problem which is, in a certain sense, unique.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "Pawel  Blasiak", "Andrzej  Horzela", "Karol A. Penson", "Allan I. Solomon"], "year": 2005, "n_citations": 9}
{"id": 6322863, "s2_id": "dbc13717882be1143b0c19a35e94ad2d863ca89b", "title": "On modular computation of Groebner bases with integer coefficients", "abstract": "Let $I_1\\subset I_2\\subset\\dots$ be an increasing sequence of ideals of the ring $\\Bbb Z[X]$, $X=(x_1,\\dots,x_n)$ and let $I$ be their union. We propose an algorithm to compute the Gr\\\"obner base of $I$ under the assumption that the Gr\\\"obner bases of the ideal $\\Bbb Q I$ of the ring $\\Bbb Q[X]$ and the the ideals $I\\otimes(\\Bbb Z/m\\Bbb Z)$ of the rings $(\\Bbb Z/m\\Bbb Z)[X]$ are known. \nSuch an algorithmic problem arises, for example, in the construction of Markov and semi-Markov traces on cubic Hecke algebras.", "venue": "ArXiv", "authors": ["S. Yu. Orevkov"], "year": 2013, "n_citations": 0}
{"id": 6323024, "s2_id": "6021bc2b97771f08b236365d8d64457a1ac963f4", "title": "Minimal Representations and Algebraic Relations for Single Nested Products", "abstract": "Abstract Recently, it has been shown constructively how a finite set of hypergeometric products, multibasic hypergeometric products or their mixed versions can be modeled properly in the setting of formal difference rings. Here special emphasis is put on robust constructions: whenever further products have to be considered, one can reuse \u2013up to some mild modifications \u2013 the already existing difference ring. In this article we relax this robustness criteria and seek for another form of optimality. We will elaborate a general framework to represent a finite set of products in a formal difference ring where the number of transcendental product generators is minimal. As a bonus we are able to describe explicitly all relations among the given input products.", "venue": "Programming and Computer Software", "authors": ["Carsten  Schneider"], "year": 2020, "n_citations": 5}
{"id": 6325484, "s2_id": "f2abfcf16160b49e309dd3e76dd80c9a5e7081a0", "title": "Computer Algebra Methods in Control Systems", "abstract": "As dynamic and control systems become more complex, relying purely on numerical computations for systems analysis and design might become extremely expensive or totally infeasible. Computer algebra can act as an enabler for analysis and design of such complex systems. It also provides means for characterization of all solutions and studying them before realizing a particular solution. This note provides a brief survey on some of the applications of symbolic computations in control systems analysis and design.", "venue": "ArXiv", "authors": ["Masoud  Abbaszadeh"], "year": 2017, "n_citations": 0}
{"id": 6345307, "s2_id": "ab64fff0c60c5e43f33f5ec85dbc327e3064271a", "title": "On Two Signature Variants of Buchberger's Algorithm over Principal Ideal Domains", "abstract": "Signature-based algorithms have brought large improvements in the performances of Gr\u00f6bner bases algorithms for polynomial systems over fields. Furthermore, they yield additional data which can be used, for example, to compute the module of syzygies of an ideal or to compute coefficients in terms of the input generators. In this paper, we examine two variants of Buchberger's algorithm to compute Gr\u00f6bner bases over principal ideal domains, with the addition of signatures. The first one is adapted from Kandri-Rody and Kapur's algorithm [17], whereas the second one uses the ideas developed in the algorithms by L. Pan [25] and D. Lichtblau [18]. The differences in constructions between the algorithms entail differences in the operations which are compatible with the signatures, and in the criteria which can be used to discard elements. We prove that both algorithms are correct and discuss their relative performances in a prototype implementation in Magma.", "venue": "ISSAC", "authors": ["Maria  Francis", "Thibaut  Verron"], "year": 2021, "n_citations": 0}
{"id": 6348467, "s2_id": "0f1eff0442ac9bf4cb63516fe6853a8004ff4e90", "title": "Power series composition and change of basis", "abstract": "Efficient algorithms are known for many operations on truncated power series (multiplication, powering, exponential, ...). Composition is a more complex task. We isolate a large class of power series for which composition can be performed efficiently. We deduce fast algorithms for converting polynomials between various bases, including Euler, Bernoulli, Fibonacci, and the orthogonal Laguerre, Hermite, Jacobi, Krawtchouk, Meixner and Meixner-Pollaczek.", "venue": "ISSAC '08", "authors": ["Alin  Bostan", "Bruno  Salvy", "\u00c9ric  Schost"], "year": 2008, "n_citations": 22}
{"id": 6353195, "s2_id": "0dfd1969c30e6f0333878edb2286e47bc68d8706", "title": "Automatic congruences for diagonals of rational functions", "abstract": "In this paper we use the framework of automatic sequences to study combinatorial sequences modulo prime powers. Given a sequence whose generating function is the diagonal of a rational power series, we provide a method, based on work of Denef and Lipshitz, for computing a finite automaton for the sequence modulo $p^\\alpha$, for all but finitely many primes $p$. This method gives completely automatic proofs of known results, establishes a number of new theorems for well-known sequences, and allows us to resolve some conjectures regarding the Ap\\'ery numbers. We also give a second method, which applies to an algebraic sequence modulo $p^\\alpha$ for all primes $p$, but is significantly slower. Finally, we show that a broad range of multidimensional sequences possess Lucas products modulo $p$.", "venue": "ArXiv", "authors": ["Eric S. Rowland", "Reem  Yassawi"], "year": 2013, "n_citations": 43}
{"id": 6353674, "s2_id": "5698b3c51723d37c28b27a96cc737674c5363db5", "title": "Higher-order reverse automatic differentiation with emphasis on the third-order", "abstract": "It is commonly assumed that calculating third order information is too expensive for most applications. But we show that the directional derivative of the Hessian ($$D^3 f(x)\\cdot d$$D3f(x)\u00b7d) can be calculated at a cost proportional to that of a state-of-the-art method for calculating the Hessian matrix. We do this by first presenting a simple procedure for designing high order reverse methods and applying it to deduce several methods including a reverse method that calculates $$D^3f(x)\\cdot d$$D3f(x)\u00b7d. We have implemented this method taking into account symmetry and sparsity, and successfully calculated this derivative for functions with a million variables. These results indicate that the use of third order information in a general nonlinear solver, such as Halley\u2013Chebyshev methods, could be a practical alternative to Newton\u2019s method. Furthermore, high-order sensitivity information is used in methods for robust aerodynamic design. An efficient high-order differentiation tool could facilitate the use of similar methods in the design of other mechanical structures.", "venue": "Math. Program.", "authors": ["Robert Mansel Gower", "Artur L. Gower"], "year": 2016, "n_citations": 6}
{"id": 6355210, "s2_id": "e9c0ea227d97e039392348034335debfbbd983d3", "title": "Computing isomorphisms and embeddings of finite fields", "abstract": "Let $\\mathbb{F}_q$ be a finite field. Given two irreducible polynomials $f,g$ over $\\mathbb{F}_q$, with $\\mathrm{deg} f$ dividing $\\mathrm{deg} g$, the finite field embedding problem asks to compute an explicit description of a field embedding of $\\mathbb{F}_q[X]/f(X)$ into $\\mathbb{F}_q[Y]/g(Y)$. When $\\mathrm{deg} f = \\mathrm{deg} g$, this is also known as the isomorphism problem. \nThis problem, a special instance of polynomial factorization, plays a central role in computer algebra software. We review previous algorithms, due to Lenstra, Allombert, Rains, and Narayanan, and propose improvements and generalizations. Our detailed complexity analysis shows that our newly proposed variants are at least as efficient as previously known algorithms, and in many cases significantly better. \nWe also implement most of the presented algorithms, compare them with the state of the art computer algebra software, and make the code available as open source. Our experiments show that our new variants consistently outperform available software.", "venue": "Math. Comput.", "authors": ["Ludovic  Brieulle", "Luca De Feo", "Javad  Doliskani", "Jean-Pierre  Flori", "\u00c9ric  Schost"], "year": 2019, "n_citations": 7}
{"id": 6356050, "s2_id": "394725bd056cdc977c8ced7986fd6bcc0b9b6f5d", "title": "Tame decompositions and collisions", "abstract": "A univariate polynomial <i>f</i> over a field is decomposable if <i>f</i> = <i>g</i> o <i>h</i> = <i>g</i>(<i>h</i>) for nonlinear polynomials <i>g</i> and <i>h</i>. It is intuitively clear that the decomposable polynomials form a small minority among all polynomials over a finite field. The tame case, where the characteristic of F<sub><i>q</i></sub> does not divide <i>n</i> = deg <i>f</i>, is fairly well-understood, and we have reasonable bounds on the number of decomposables of degree <i>n</i>. Nevertheless, no exact formula is known if <i>n</i> has more than two prime factors. In order to count the decomposables, one wants to know, under a suitable normalization, the number of collisions, where essentially different components (<i>g, h</i>) yield the same <i>f</i>. In the tame case, Ritt's Second Theorem classifies all collisions of two such pairs.\n We present a normal form for collisions of any number of decompositions with any number of components and describe exactly the (non)uniqueness of the parameters in the tame case. This yields an exact formula for the number of such collisions over a finite field. We conclude with a fast algorithm for the exact number of decomposable polynomials of degree <i>n</i> over a finite field F<i>q</i> of characteristic coprime to <i>n</i>.", "venue": "ISSAC", "authors": ["Konstantin  Ziegler"], "year": 2014, "n_citations": 4}
{"id": 6357076, "s2_id": "c691e527b9675a8e2e5770f5c1576f37857cf7f0", "title": "Solving Linear Difference Equations with Coefficients in Rings with Idempotent Representations", "abstract": "We introduce a general reduction strategy that enables one to search for solutions of parameterized linear difference equations in difference rings. Here we assume that the ring itself can be decomposed by a direct sum of integral domains (using idempotent elements) that enjoys certain technical features and that the coefficients of the difference equation are not degenerated. Using this mechanism we can reduce the problem to find solutions in a ring (with zero-divisors) to search solutions in several copies of integral domains. Utilizing existing solvers in this integral domain setting, we obtain a general solver where the components of the linear difference equations and the solutions can be taken from difference rings that are built e.g., by R\u03a0\u03a3-extensions over \u03a0\u03a3-fields. This class of difference rings contains, e.g., nested sums and products, products over roots of unity and nested sums defined over such objects.", "venue": "ISSAC", "authors": ["Jakob  Ablinger", "Carsten  Schneider"], "year": 2021, "n_citations": 1}
{"id": 6357306, "s2_id": "cdc3d2ab759c2abc52e495c1bfabeaf04a48d9a7", "title": "Middle-Solving F4 to Compute Grobner bases for Cryptanalysis over GF(2)", "abstract": "Algebraic cryptanalysis usually requires to recover the secret key by solving polynomial equations. Faugere's F4 is a well-known Grobner bases algorithm to solve this problem. However, a serious drawback exists in the Grobner bases based algebraic attacks, namely, any information won't be got if we couldn't work out the Grobner bases of the polynomial equations system. In this paper, we in-depth research the F4 algorithm over GF(2). By using S-polynomials to replace critical pairs and computing the normal form of the productions with respect to the field equations in certain steps, many \"redundant\" reductors are avoided during the computation process of the F4 algorithm. By slightly modifying the logic of F4 algorithm, we solve the univariate polynomials appeared in the algorithm and then back-substitute the values of the solved variables at each iteration of the algorithm. We call our improvements Middle-Solving F4. The heuristic strategy of Middle-Solving overcomes the drawback of algebraic attacks and well suits algebraic attacks. It has never been applied to the Grobner bases algorithm before. Experiments to some Hidden Field Equation instances and some classical benchmarks (Cyclic 6, Gonnet83) show that Middle-Solving F4 is faster and uses less memory than Faugere's F4.", "venue": "ArXiv", "authors": ["Heliang  Huang", "Wansu  Bao"], "year": 2013, "n_citations": 2}
{"id": 6357473, "s2_id": "07170b30d56c5ee609af61a11b8c59b0f8fccf35", "title": "Near optimal subdivision algorithms for real root isolation", "abstract": "Abstract Isolating real roots of a square-free polynomial in a given interval is a fundamental problem in computational algebra. Subdivision based algorithms are a standard approach to solve this problem. For instance, Sturm's method, or various algorithms based on the Descartes's rule of signs. For the benchmark problem of isolating all the real roots of a polynomial of degree n and root separation \u03c3, the size of the subdivision tree of most of these algorithms is bounded by O ( log \u2061 1 / \u03c3 ) (assume \u03c3 1 ). Moreover, it is known that this is optimal for subdivision algorithms that perform uniform subdivision, i.e., the width of the interval decreases by some constant. Recently Sagraloff (2012) and Sagraloff\u2013Mehlhorn (2016) have developed algorithms for real root isolation that combine subdivision with Newton iteration to reduce the size of the subdivision tree to O ( n ( log \u2061 ( n log \u2061 1 / \u03c3 ) ) ) . We describe a subroutine that reduces the size of the subdivision tree of any subdivision algorithm for real root isolation. The subdivision tree size of our algorithm using predicates based on either the Descartes's rule of signs or Sturm sequences is bounded by O ( n log \u2061 n ) , which is close to the optimal value of O ( n ) . The corresponding bound for the algorithm EVAL , which uses certain interval-arithmetic based predicates, is O ( n 2 log \u2061 n ) . Our analysis differs in two key aspects from earlier approaches. First, we use the general technique of continuous amortization from Burr\u2013Krahmer\u2013Yap (2009) , and extend it to handle non-uniform subdivisions; second, we use the geometry of clusters of roots instead of root bounds. The latter aspect enables us to derive a bound on the subdivision tree that is independent of the root separation \u03c3. The number of Newton iterations is bounded by O ( n log \u2061 log \u2061 ( 1 / \u03c3 ) ) .", "venue": "J. Symb. Comput.", "authors": ["Prashant  Batra", "Vikram  Sharma"], "year": 2017, "n_citations": 1}
{"id": 6361680, "s2_id": "f5e44a020701d2c2f8568fc3ea8addcf3cccabdb", "title": "Solving p-adic polynomial systems via iterative eigenvector algorithms", "abstract": "In this article, we describe an implementation of a polynomial system solver to compute the approximate solutions of a 0-dimensional polynomial system with finite precision p-adic arithmetic. We also describe an improvement to an algorithm of Caruso, Roe, and Vaccon for calculating the eigenvalues and eigenvectors of a p-adic matrix.", "venue": "ArXiv", "authors": ["Avinash  Kulkarni"], "year": 2019, "n_citations": 2}
{"id": 6365524, "s2_id": "51785e8e484858c1bd5d946fd9ae9002b69a5918", "title": "On the computation of matrices of traces and radicals of ideals", "abstract": "Let f\"1,...,f\"[email\u00a0protected]?K[x\"1,...,x\"m] be a system of polynomials generating a zero-dimensional ideal I, where K is an arbitrary algebraically closed field. We study the computation of ''matrices of traces'' for the factor algebra [email\u00a0protected]?K[x\"1,...,x\"m]/I, i.e. matrices with entries which are trace functions of the roots of I. Such matrices of traces in turn allow us to compute a system of multiplication matrices {M\"x\"\"\"i|i=1,...,m} of the radical I. We first propose a method using Macaulay type resultant matrices of f\"1,...,f\"s and a polynomial J to compute moment matrices, and in particular matrices of traces for A. Here J is a polynomial generalizing the Jacobian. We prove bounds on the degrees needed for the Macaulay matrix in the case when I has finitely many projective roots in P\"K^m. We also extend previous results which work only for the case where A is Gorenstein to the non-Gorenstein case. The second proposed method uses Bezoutian matrices to compute matrices of traces of A. Here we need the assumption that s=m and f\"1,...,f\"m define an affine complete intersection. This second method also works if we have higher-dimensional components at infinity. A new explicit description of the generators of I are given in terms of Bezoutians.", "venue": "J. Symb. Comput.", "authors": ["Itnuit  Janovitz-Freireich", "Bernard  Mourrain", "Lajos  R\u00f3nyai", "\u00c1gnes  Sz\u00e1nt\u00f3"], "year": 2012, "n_citations": 5}
{"id": 6372079, "s2_id": "e9b4656d5473e726e92934788de27210aafa3888", "title": "Exact Algorithms for Semidefinite Programs with Degenerate Feasible Set", "abstract": "Let A0, ..., An be m x m symmetric matrices with entries in Q, and let A(x) be the linear pencil A0+x1 A1 + \u00b7\u00b7\u00b7 + xn An, where x=(x1,...,xn) are unknowns. The linear matrix inequality (LMI) A(x) \u2265 0 defines the subset of Rn, called spectrahedron, containing all points x such that A(x) has non-negative eigenvalues. The minimization of linear functions over spectrahedra is called semidefinite programming (SDP). Such problems appear frequently in control theory and real algebra, especially in the context of nonnegativity certificates for multivariate polynomials based on sums of squares. Numerical software for solving SDP are mostly based on the interior point method, assuming some non-degeneracy properties such as the existence of interior points in the admissible set. In this paper, we design an exact algorithm based on symbolic homotopy for solving semidefinite programs without assumptions on the feasible set, and we analyze its complexity. Because of the exactness of the output, it cannot compete with numerical routines in practice but we prove that solving such problems can be done in polynomial time if either n or m is fixed.", "venue": "ISSAC", "authors": ["Didier  Henrion", "Simone  Naldi", "Mohab Safey El Din"], "year": 2018, "n_citations": 7}
{"id": 6372522, "s2_id": "9e2e3ae69ac0b2e86ac23005d4e47ced2c21dcee", "title": "Design of Low-Artifact Interpolation Kernels by Means of Computer Algebra", "abstract": "We present a number of new piecewise-polynomial kernels for image interpolation. The kernels are constructed by optimizing a measure of interpolation quality based on the magnitude of anisotropic artifacts. The kernel design process is performed symbolically using Mathematica computer algebra system. Experimental evaluation involving 14 image quality assessment methods demonstrates that our results compare favorably with the existing linear interpolators.", "venue": "ArXiv", "authors": ["Peter  Karpov"], "year": 2021, "n_citations": 0}
{"id": 6379017, "s2_id": "24cbd3da51101cc32ba0960e8c23b06af74e0296", "title": "Formulating problems for real algebraic geometry", "abstract": "We discuss issues of problem formulation for algorithms in real algebraic geometry, focussing on quantifier elimination by cylindrical algebraic decomposition. We recall how the variable ordering used can have a profound effect on both performance and output and summarise what may be done to assist with this choice. We then survey other questions of problem formulation and algorithm optimisation that have become pertinent following advances in CAD theory, including both work that is already published and work that is currently underway. With implementations now in reach of real world applications and new theory meaning algorithms are far more sensitive to the input, our thesis is that intelligently formulating problems for algorithms, and indeed choosing the correct algorithm variant for a problem, is key to improving the practical use of both quantifier elimination and symbolic real algebraic geometry in general.", "venue": "ArXiv", "authors": ["Matthew  England"], "year": 2014, "n_citations": 0}
{"id": 6380131, "s2_id": "1a68e2fe67017c2001527b5e74956fb3e7d959da", "title": "Decomposition of a Quantum System Into Subsystems in Finite Quantum Mechanics", "abstract": "Any Hilbert space with composite dimension can be factorized into a tensor product of smaller Hilbert spaces. This allows to decompose a quantum system into subsystems. We propose a simple tractable model for a constructive study of decompositions of quantum systems.", "venue": "ArXiv", "authors": ["Vladimir V. Kornyak"], "year": 2021, "n_citations": 0}
{"id": 6380970, "s2_id": "09f885a971283ab7564da76f82c0e15560c74a8d", "title": "Reduction of Algebraic Parametric Systems by Rectification of Their Affine Expanded Lie Symmetries", "abstract": "Lie group theory states that knowledge of a m-parameters solvable group of symmetries of a system of ordinary differential equations allows to reduce by m the number of equations. We apply this principle by finding some affine derivations that induces expanded Lie point symmetries of considered system. By rewriting original problem in an invariant coordinates set for these symmetries, we reduce the number of involved parameters. We present an algorithm based on this standpoint whose arithmetic complexity is quasi-polynomial in input's size.", "venue": "AB", "authors": ["Alexandre  Sedoglavic"], "year": 2007, "n_citations": 18}
{"id": 6384607, "s2_id": "197ad6b008bb5399ef256e777c7b55efe624ea2d", "title": "An Additive Decomposition in S-Primitive Towers", "abstract": "We consider the additive decomposition problem in primitive towers and present an algorithm to decompose a function in an S-primitive tower as a sum of a derivative in the tower and a remainder which is minimal in some sense. Special instances of S-primitive towers include differential fields generated by finitely many logarithmic functions and logarithmic integrals. A function in an S-primitive tower is integrable in the tower if and only if the remainder is equal to zero. The additive decomposition is achieved by viewing our towers not as a traditional chain of extension fields, but rather as a direct sum of certain subrings. Furthermore, we can determine whether or not a function in an S-primitive tower has an elementary integral without solving any differential equations. We also show that a kind of S-primitive towers, known as logarithmic towers, can be embedded into a particular extension where we can obtain a finer remainder.", "venue": "ArXiv", "authors": ["Hao  Du", "Jing  Guo", "Ziming  Li", "Elaine  Wong"], "year": 2020, "n_citations": 0}
{"id": 6388634, "s2_id": "01c8f02b49e82de6e56bcd289bc1d02054e03e22", "title": "Subtotal ordering -- a pedagogically advantageous algorithm for computing total degree reverse lexicographic order", "abstract": "Total degree reverse lexicographic order is currently generally regarded as most often fastest for computing Grobner bases. This article describes an alternate less mysterious algorithm for computing this order using exponent subtotals and describes why it should be very nearly the same speed the traditional algorithm, all other things being equal. However, experimental evidence suggests that subtotal order is actually slightly faster for the Mathematica R Grobner basis implementation more often than not. This is probably because the weight vectors associated with the natural subtotal weight matrix and with the usual total degree reverse lexicographic weight matrix are different, and Mathematica also uses those the corresponding weight vectors to help select successive S polynomials and divisor polynomials: Those selection heuristics appear to work slightly better more often with subtotal weight vectors. However, the most important advantage of exponent subtotals is pedagogical. It is easier to understand than the total degree reverse lexicographic algorithm, and it is more evident why the resulting order is often the fastest known order for computing Grobner bases.", "venue": "ArXiv", "authors": ["David R. Stoutemyer"], "year": 2012, "n_citations": 0}
{"id": 6392277, "s2_id": "d04dc4bfd7ddb279974153b73080f20b8b2ed12c", "title": "Stream/block ciphers, difference equations and algebraic attacks", "abstract": "In this paper we introduce a general class of stream and block ciphers that are defined by means of systems of (ordinary) explicit difference equations over a finite field. We call this class \"difference ciphers\". Many important ciphers such as systems of LFSRs, Trivium/Bivium and Keeloq are difference ciphers. To the purpose of studying their underlying explicit difference systems, we introduce key notions as state transition endomorphisms and show conditions for their invertibility. Reducible and periodic systems are also considered. We then propose general algebraic attacks to difference ciphers which are experimented by means of Bivium and Keeloq.", "venue": "J. Symb. Comput.", "authors": ["Roberto La Scala", "Sharwan K. Tiwari"], "year": 2022, "n_citations": 0}
{"id": 6393274, "s2_id": "a41a31ecd4ab1e48374a050ec000ed4e663e61bf", "title": "Evaluating parametric holonomic sequences using rectangular splitting", "abstract": "We adapt the rectangular splitting technique of Paterson and Stockmeyer to the problem of evaluating terms in holonomic sequences that depend on a parameter. This approach allows computing the n-th term in a recurrent sequence of suitable type using O(n1/2) \"expensive\" operations at the cost of an increased number of \"cheap\" operations.\n Rectangular splitting has little overhead and can perform better than either naive evaluation or asymptotically faster algorithms for ranges of n encountered in applications. As an example, fast numerical evaluation of the gamma function is investigated. Our work generalizes two previous algorithms of Smith.", "venue": "ISSAC", "authors": ["Fredrik  Johansson"], "year": 2014, "n_citations": 8}
{"id": 6408374, "s2_id": "fd510b8209383001d6bfb55226595633d8ba4d64", "title": "An Elimination Method to Solve Interval Polynomial Systems", "abstract": "There are several efficient methods to solve linear interval polynomial systems in the context of interval computations, however, the general case of interval polynomial systems is not yet covered as well. In this paper we introduce a new elimination method to solve and analyse interval polynomial systems, in general case. This method is based on computational algebraic geometry concepts such as polynomial ideals and Groebner basis computation. Specially, we use the comprehensive Groebner system concept to keep the dependencies between interval coefficients. At the end of paper, we will state some applications of our method to evaluate its performance.", "venue": "ArXiv", "authors": ["Sajjad  Rahmany", "Abdolali  Basiri", "Benyamin  M.-Alizadeh"], "year": 2015, "n_citations": 0}
{"id": 6415498, "s2_id": "30bfec22a8fd87aa7505c0442260242fd74fefcf", "title": "FunGrim: A Symbolic Library for Special Functions", "abstract": "We present the Mathematical Functions Grimoire (FunGrim), a website and database of formulas and theorems for special functions. We also discuss the symbolic computation library used as the backend and main development tool for FunGrim, and the Grim formula language used in these projects to represent mathematical content semantically.", "venue": "ICMS", "authors": ["Fredrik  Johansson"], "year": 2020, "n_citations": 1}
{"id": 6417356, "s2_id": "5a8a8f38da2cbb81c8a5c3f38ee8b12ff86c88eb", "title": "Arrangement computation for planar algebraic curves", "abstract": "We present a new certified and complete algorithm to compute arrangements of real planar algebraic curves. Our algorithm provides a geometric-topological analysis of the decomposition of the plane induced by a finite number of algebraic curves in terms of a cylindrical algebraic decomposition of the plane. Compared to previous approaches, we improve in two main aspects: Firstly, we significantly limit the types of involved exact operations, that is, our algorithms only use resultant and gcd computations as purely symbolic operations. Secondly, we introduce a new hybrid method in the lifting step of our algorithm which combines the use of a certified numerical complex root solver and information derived from the resultant computation. Additionally, we never consider any coordinate transformation and the output is also given with respect to the initial coordinate system.\n We implemented our algorithm as a prototypical package of the C++-library Cgal. Our implementation exploits graphics hardware to expedite the resultant and gcd computation. We also compared our implementation with the current reference implementation, that is, Cgal's curve analysis and arrangement for algebraic curves. For various series of challenging instances, our experiments show that the new implementation outperforms the existing one.", "venue": "SNC '11", "authors": ["Eric  Berberich", "Pavel  Emeliyanenko", "Alexander  Kobel", "Michael  Sagraloff"], "year": 2012, "n_citations": 17}
{"id": 6431133, "s2_id": "871f2c02e52c2920850a33ee806c93a523f2316d", "title": "Degeneracy Loci and Polynomial Equation Solving", "abstract": "Let $$V$$V be a smooth, equidimensional, quasi-affine variety of dimension $$r$$r over $$\\mathbb {C}$$C, and let $$F$$F be a $$(p\\times s)$$(p\u00d7s) matrix of coordinate functions of $$\\mathbb {C}[V]$$C[V], where $$s\\ge p+r$$s\u2265p+r. The pair $$(V,F)$$(V,F) determines a vector bundle $$E$$E of rank $$s-p$$s-p over $$W:=\\{x\\in V \\mid \\mathrm{rk }F(x)=p\\}$$W:={x\u2208V\u2223rkF(x)=p}. We associate with $$(V,F)$$(V,F) a descending chain of degeneracy loci of $$E$$E (the generic polar varieties of $$V$$V represent a typical example of this situation). The maximal degree of these degeneracy loci constitutes the essential ingredient for the uniform, bounded-error probabilistic pseudo-polynomial-time algorithm that we will design and that solves a series of computational elimination problems that can be formulated in this framework. We describe applications to polynomial equation solving over the reals and to the computation of a generic fiber of a dominant endomorphism of an affine space.", "venue": "Found. Comput. Math.", "authors": ["Bernd  Bank", "Marc  Giusti", "Joos  Heintz", "Gr\u00e9goire  Lecerf", "Guillermo  Matera", "Pablo  Solern\u00f3"], "year": 2015, "n_citations": 14}
{"id": 6438026, "s2_id": "b39eed03d345f5c244eac12fd1315d26eba77d62", "title": "Deep Learning for Symbolic Mathematics", "abstract": "Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing these mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.", "venue": "ICLR", "authors": ["Guillaume  Lample", "Franccois  Charton"], "year": 2020, "n_citations": 135}
{"id": 6444990, "s2_id": "00234bdec6ae3b3ecf9fa87ba7caadbd49aecdc2", "title": "Affine solution sets of sparse polynomial systems", "abstract": "This paper focuses on the equidimensional decomposition of affine varieties defined by sparse polynomial systems. For generic systems with fixed supports, we give combinatorial conditions for the existence of positive dimensional components which characterize the equidimensional decomposition of the associated affine variety. This result is applied to design an equidimensional decomposition algorithm for generic sparse systems. For arbitrary sparse systems of n polynomials in n variables with fixed supports, we obtain an upper bound for the degree of the affine variety defined and we present an algorithm which computes finite sets of points representing its equidimensional components.", "venue": "J. Symb. Comput.", "authors": ["Mar\u00eda Isabel Herrero", "Gabriela  Jeronimo", "Juan  Sabia"], "year": 2013, "n_citations": 17}
{"id": 6451172, "s2_id": "b47f116a76882a697fe92abc0e9ed5516130a628", "title": "NumGfun: a package for numerical and analytic computation with D-finite functions", "abstract": "This article describes the implementation in the software package NumGfun of classical algorithms that operate on solutions of linear differential equations or recurrence relations with polynomial coefficients, including what seems to be the first general implementation of the fast high-precision numerical evaluation algorithms of Chudnovsky & Chudnovsky. In some cases, our descriptions contain improvements over existing algorithms. We also provide references to relevant ideas not currently used in NumGfun.", "venue": "ISSAC", "authors": ["Marc  Mezzarobba"], "year": 2010, "n_citations": 40}
{"id": 6457527, "s2_id": "83e2c3a5a8a417ed83a411ca5eeff68d9e79b8ea", "title": "On Kahan's Rules for Determining Branch Cuts", "abstract": "In computer algebra there are different ways of approaching the mathematical concept of functions, one of which is by defining them as solutions of differential equations. We compare different such approaches and discuss the occurring problems. The main focus is on the question of determining possible branch cuts. We explore the extent to which the treatment of branch cuts can be rendered (more) algorithmic, by adapting Kahan's rules to the differential equation setting.", "venue": "2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing", "authors": ["Fr\u00e9d\u00e9ric  Chyzak", "James H. Davenport", "Christoph  Koutschan", "Bruno  Salvy"], "year": 2011, "n_citations": 0}
{"id": 6466140, "s2_id": "27e1caff568315abcb36b4949011be040ada6168", "title": "Series misdemeanors", "abstract": "Puiseux series are power series in which the exponents can be fractional and/or negative rational numbers. Several computer algebra systems have one or more built-in or loadable functions for computing truncated Puiseux series -- perhaps generalized to allow coefficients containing functions of the series variable that are dominated by any power of that variable, such as logarithms and nested logarithms of the series variable. Some computer-algebra systems also offer functions that can compute more-general truncated recursive hierarchical series. However, for all of these kinds of truncated series there are important implementation details that haven't been addressed before in the published literature and in current implementations.\n For implementers this article contains ideas for designing more convenient, correct, and efficient implementations or improving existing ones. For users, this article is a warning about some of these limitations. More specifically, this article discusses issues such as avoiding unnecessary restrictions such as prohibiting negative or fractional requested orders, the pros and cons of displaying results with explicit infectious error terms of the form o (...), O (...), and/or \u03b8(...), efficient data structures, and algorithms that efficiently give users exactly the order or number of nonzero terms they request..\n Most of the ideas in this article have been implemented in the computer-algebra within the TI-Nspire calculator, Windows and Macintosh products.", "venue": "ACCA", "authors": ["David R. Stoutemyer"], "year": 2013, "n_citations": 1}
{"id": 6471391, "s2_id": "83a5eaa629b6e4d959dde4723a5db40c36580e1f", "title": "Some properties of finite meadows", "abstract": "The aim of this note is to describe the structure of finite meadows. We will show that the class of finite meadows is the closure of the class of finite fields under finite products. As a corollary, we obtain a unique representation of minimal meadows in terms of prime fields.", "venue": "ArXiv", "authors": ["Inge  Bethke", "Pieter Hendrik Rodenburg"], "year": 2007, "n_citations": 8}
{"id": 6474397, "s2_id": "756d841c0a276f8c873d13cd365f854729a57c79", "title": "A nearly optimal algorithm to decompose binary forms", "abstract": "Symmetric tensor decomposition is an important problem with applications in several areas for example signal processing, statistics, data analysis and computational neuroscience. It is equivalent to Waring's problem for homogeneous polynomials, that is to write a homogeneous polynomial in n variables of degree D as a sum of D-th powers of linear forms, using the minimal number of summands. This minimal number is called the rank of the polynomial/tensor. We focus on decomposing binary forms, a problem that corresponds to the decomposition of symmetric tensors of dimension 2 and order D. Under this formulation, the problem finds its roots in invariant theory where the decompositions are known as canonical forms. In this context many different algorithms were proposed. We introduce a superfast algorithm that improves the previous approaches with results from structured linear algebra. It achieves a softly linear arithmetic complexity bound. To the best of our knowledge, the previously known algorithms have at least quadratic complexity bounds. Our algorithm computes a symbolic decomposition in $O(M(D) log(D))$ arithmetic operations, where $M(D)$ is the complexity of multiplying two polynomials of degree D. It is deterministic when the decomposition is unique. When the decomposition is not unique, our algorithm is randomized. We present a Monte Carlo version of it and we show how to modify it to a Las Vegas one, within the same complexity. From the symbolic decomposition, we approximate the terms of the decomposition with an error of $2^{--$\\epsilon$}$ , in $O(D log^2(D) (log^2(D) + log($\\epsilon$)))$ arithmetic operations. We use results from Kaltofen and Yagati (1989) to bound the size of the representation of the coefficients involved in the decomposition and we bound the algebraic degree of the problem by min(rank, D -- rank + 1). We show that this bound can be tight. When the input polynomial has integer coefficients, our algorithm performs, up to poly-logarithmic factors, $O\\_{bit} (D{\\ell} + D^4 + D^3 $\\tau$)$ bit operations, where $$\\tau$$ is the maximum bitsize of the coefficients and $2^{--{\\ell}}$ is the relative error of the terms in the decomposition.", "venue": "J. Symb. Comput.", "authors": ["Mat\u00edas R. Bender", "Jean-Charles  Faug\u00e8re", "Ludovic  Perret", "Elias P. Tsigaridas"], "year": 2021, "n_citations": 2}
{"id": 6478572, "s2_id": "2d818eae70584e49a03c14f80bd6548646202017", "title": "An Oracle-Based, output-Sensitive Algorithm for Projections of Resultant Polytopes", "abstract": "We design an algorithm to compute the Newton polytope of the resultant, known as resultant polytope, or its orthogonal projection along a given direction. The resultant is fundamental in algebraic elimination, optimization, and geometric modeling. Our algorithm exactly computes vertex- and halfspace-representations of the polytope using an oracle producing resultant vertices in a given direction, thus avoiding walking on the polytope whose dimension is alpha-n-1, where the input consists of alpha points in Z^n. Our approach is output-sensitive as it makes one oracle call per vertex and facet. It extends to any polytope whose oracle-based definition is advantageous, such as the secondary and discriminant polytopes. Our publicly available implementation uses the experimental CGAL package triangulation. Our method computes 5-, 6- and 7-dimensional polytopes with 35K, 23K and 500 vertices, respectively, within 2hrs, and the Newton polytopes of many important surface equations encountered in geometric modeling in <1sec, whereas the corresponding secondary polytopes are intractable. It is faster than tropical geometry software up to dimension 5 or 6. Hashing determinantal predicates accelerates execution up to 100 times. One variant computes inner and outer approximations with, respectively, 90% and 105% of the true volume, up to 25 times faster.", "venue": "Int. J. Comput. Geom. Appl.", "authors": ["Ioannis Z. Emiris", "Vissarion  Fisikopoulos", "Christos  Konaxis", "Luis Mariano Pe\u00f1aranda"], "year": 2013, "n_citations": 17}
{"id": 6487422, "s2_id": "705e2f79d89ae6b165099688cfd7a109ae9b62d3", "title": "Accelerated approximation of the complex roots and factors of a univariate polynomial", "abstract": "The algorithms of Pan (1995) and(2002) approximate the roots of a complex univariate polynomial in nearly optimal arithmetic and Boolean time but require precision of computing that exceeds the degree of the polynomial. This causes numerical stability problems when the degree is large. We observe, however, that such a difficulty disappears at the initial stage of the algorithms, and in our present paper we extend this stage to root-finding within a nearly optimal arithmetic and Boolean complexity bounds provided that some mild initial isolation of the roots of the input polynomial has been ensured. Furthermore our algorithm is nearly optimal for the approximation of the roots isolated in a fixed disc, square or another region on the complex plane rather than all complex roots of a polynomial. Moreover the algorithm can be applied to a polynomial given by a black box for its evaluation (even if its coefficients are not known); it promises to be of practical value for polynomial root-finding and factorization, the latter task being of interest on its own right. We also provide a new support for a winding number algorithm, which enables extension of our progress to obtaining mild initial approximations to the roots. We conclude with summarizing our algorithms and their extension to the approximation of isolated multiple roots and root clusters.", "venue": "Theor. Comput. Sci.", "authors": ["Victor Y. Pan", "Elias P. Tsigaridas"], "year": 2017, "n_citations": 9}
{"id": 6488861, "s2_id": "1233b2ad91ecd4000261206fcba773eb9a616e22", "title": "Parallel Symbolic Computation of Curvature Invariants in General Relativity", "abstract": "We present a practical application of parallel symbolic computation in General Relativity: the calculation of curvature invariants for large dimension. We discuss the structure of the calculations, an implementation of the technique and scaling of the computation with spacetime dimension for various invariants.", "venue": "ArXiv", "authors": ["Kenneth R. Koehler"], "year": 2006, "n_citations": 1}
{"id": 6490954, "s2_id": "3bd41e11232395fcc9f460681c4e8d87341ef3d3", "title": "Tropical recurrent sequences", "abstract": "Tropical recurrent sequences are introduced satisfying a given vector (being a tropical counterpart of classical linear recurrent sequences). We consider the case when Newton polygon of the vector has a single (bounded) edge. In this case there are periodic tropical recurrent sequences which are similar to classical linear recurrent sequences. A question is studied when there exists a non-periodic tropical recurrent sequence satisfying a given vector, and partial answers are provided to this question. Also an algorithm is designed which tests existence of non-periodic tropical recurrent sequences satisfying a given vector with integer coordinates. Finally, we introduce a tropical entropy of a vector and provide some bounds on it.", "venue": "Adv. Appl. Math.", "authors": ["Dima  Grigoriev"], "year": 2020, "n_citations": 4}
{"id": 6492298, "s2_id": "3e20e89c2dc544c4f4e05dc6e51e78cebf41e296", "title": "The Alternative Operad Is Not Koszul", "abstract": "Using computer calculations, we prove the statement in the title.", "venue": "Exp. Math.", "authors": ["Askar  Dzhumadil'daev", "Pasha  Zusmanovich"], "year": 2011, "n_citations": 8}
{"id": 6493910, "s2_id": "dc2bf932e9eaaa2b1aa693f2d613df59402ecb69", "title": "Applications of the Gauss-Jordan algorithm, done right", "abstract": "Computer Algebra systems are widely spread because of some of their remarkable features such as their ease of use and performance. Nonetheless, this focus on performance sometimes leads to unwanted consequences: algorithms and computations are implemented and carried out in a way which is sometimes not transparent to the users, and that can lead to unexpected failures. In this paper we present a formalisation in a proof assistant system of a naive version of the Gauss-Jordan algorithm, with explicit proofs of some of its applications, and additionally a process to obtain versions of this algorithm in two different functional languages (SML and Haskell) by means of code generation techniques from the verified algorithm. The obtained programs are then applied to test cases, which, despite the simplicity of the original algorithm, have shown remarkable features in comparison to some Computer Algebra systems, such as Mathematica R (where some of these computations are even incorrect), or Sage (in comparison to which the generated programs show a compelling performance). The aim of the paper is to show that, with the current technology in Theorem Proving, formalising Linear Algebra procedures is a challenging but rewarding task, which provides programs that can be compared in some aspects to state of the art procedures in Computer Algebra systems, and whose correctness is formally proved.", "venue": "ArXiv", "authors": ["Jes\u00fas  Aransay", "Jose  Divas\u00f3n"], "year": 2014, "n_citations": 0}
{"id": 6497871, "s2_id": "abb41b9db4bd216e6420cd1034ecbfe0b0cd4e2a", "title": "Invariant Generation for Multi-Path Loops with Polynomial Assignments", "abstract": "Program analysis requires the generation of program properties expressing conditions to hold at intermediate program locations. When it comes to programs with loops, these properties are typically expressed as loop invariants. In this paper we study a class of multi-path program loops with numeric variables, in particular nested loops with conditionals, where assignments to program variables are polynomial expressions over program variables. We call this class of loops extended P-solvable and introduce an algorithm for generating all polynomial invariants of such loops. By an iterative procedure employing Gr\\\"obner basis computation, our approach computes the polynomial ideal of the polynomial invariants of each program path and combines these ideals sequentially until a fixed point is reached. This fixed point represents the polynomial ideal of all polynomial invariants of the given extended P-solvable loop. We prove termination of our method and show that the maximal number of iterations for reaching the fixed point depends linearly on the number of program variables and the number of inner loops. In particular, for a loop with m program variables and r conditional branches we prove an upper bound of m*r iterations. We implemented our approach in the Aligator software package. Furthermore, we evaluated it on 18 programs with polynomial arithmetic and compared it to existing methods in invariant generation. The results show the efficiency of our approach.", "venue": "VMCAI", "authors": ["Andreas  Humenberger", "Maximilian  Jaroschek", "Laura  Kov\u00e1cs"], "year": 2018, "n_citations": 15}
{"id": 6499969, "s2_id": "9d9a4331b1f70d7cf538cc7d98b6ac356a1b6cf2", "title": "The complete Generating Function for Gessel Walks is Algebraic", "abstract": "Gessel walks are lattice walks in the quarter plane $\\set N^2$ which start at the origin $(0,0)\\in\\set N^2$ and consist only of steps chosen from the set $\\{\\leftarrow,\\swarrow,\\nearrow,\\to\\}$. We prove that if $g(n;i,j)$ denotes the number of Gessel walks of length $n$ which end at the point $(i,j)\\in\\set N^2$, then the trivariate generating series $G(t;x,y)=\\sum_{n,i,j\\geq 0} g(n;i,j)x^i y^j t^n$ is an algebraic function.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Manuel  Kauers"], "year": 2009, "n_citations": 110}
{"id": 6502532, "s2_id": "0d580c5ccad991bbcdd3a093ae5c9e34c7de7a53", "title": "Digital Collections of Examples in Mathematical Sciences", "abstract": "Some aspects of Computer Algebra (notably Computation Group Theory and Computational Number Theory) have some good databases of examples, typically of the form \u201call the X up to size n\u201d. But most of the others, especially on the polynomial side, are lacking such, despite the utility they have demonstrated in the related fields of SAT and SMT solving. We claim that the field would be enhanced by such community-maintained databases, rather than each author hand-selecting a few, which are often too large or error-prone to print, and therefore difficult for subsequent authors to reproduce.", "venue": "ArXiv", "authors": ["James Harold Davenport"], "year": 2021, "n_citations": 0}
{"id": 6502759, "s2_id": "4e216f78cdb041170856d9b4d4b9b0f7de329c0a", "title": "Exact symbolic-numeric computation of planar algebraic curves", "abstract": "We present a certified and complete algorithm to compute arrangements of real planar algebraic curves. It computes the decomposition of the plane induced by a finite number of algebraic curves in terms of a cylindrical algebraic decomposition. From a high-level perspective, the overall method splits into two main subroutines, namely an algorithm denoted Bisolve to isolate the real solutions of a zero-dimensional bivariate system, and an algorithm denoted GeoTop to compute the topology of a single algebraic curve. \n \nCompared to existing approaches based on elimination techniques, we considerably improve the corresponding lifting steps in both subroutines. As a result, generic position of the input system is never assumed, and thus our algorithm never demands for any change of coordinates. In addition, we significantly limit the types of symbolic operations involved, that is, we only use resultant and gcd computations as purely symbolic operations. The latter results are achieved by combining techniques from different fields such as (modular) symbolic computation, numerical analysis and algebraic geometry. \n \nWe have implemented our algorithms as prototypical contributions to the C++-project Cgal. We exploit graphics hardware to expedite the remaining symbolic computations. We have also compared our implementation with the current reference implementations, that is, Lgp and Maple\u2019s Isolate for polynomial system solving, and Cgal\u2019s bivariate algebraic kernel for analyses and arrangement computations of algebraic curves. For various series of challenging instances, our exhaustive experiments show that the new implementations outperform the existing ones.", "venue": "Theor. Comput. Sci.", "authors": ["Eric  Berberich", "Pavel  Emeliyanenko", "Alexander  Kobel", "Michael  Sagraloff"], "year": 2013, "n_citations": 21}
{"id": 6503978, "s2_id": "2416565f162d775d4b2976be7d783ee883d10ef9", "title": "Definite Sums as Solutions of Linear Recurrences With Polynomial Coefficients", "abstract": "We present an algorithm which, given a linear recurrence operator $L$ with polynomial coefficients, $m \\in \\mathbb{N}\\setminus\\{0\\}$, $a_1,a_2,\\ldots,a_m \\in \\mathbb{N}\\setminus\\{0\\}$ and $b_1,b_2,\\ldots,b_m \\in \\mathbb{K}$, returns a linear recurrence operator $L'$ with rational coefficients such that for every sequence $h$, \\[ L\\left(\\sum_{k=0}^\\infty \\prod_{i=1}^m \\binom{a_i n + b_i}{k} h_k\\right) = 0 \\] if and only if $L' h = 0$.", "venue": "ArXiv", "authors": ["Marko  Petkovsek"], "year": 2018, "n_citations": 1}
{"id": 6504293, "s2_id": "4d0c84d90ad51c46f9797f5ed5154cf6270f7016", "title": "An Algorithmic Approach to Limit Cycles of Nonlinear Differential Systems: The Averaging Method Revisited", "abstract": "This paper introduces an algorithmic approach to the analysis of bifurcation of limit cycles from the centers of nonlinear continuous differential systems via the averaging method. We develop three algorithms to implement the averaging method. The first algorithm allows to transform the considered differential systems to the normal formal of averaging. Here, we restricted the unperturbed term of the normal form of averaging to be identically zero. The second algorithm is used to derive the computational formulae of the averaged functions at any order. The third algorithm is based on the first two algorithms that determines the exact expressions of the averaged functions for the considered differential systems. The proposed approach is implemented in Maple and its effectiveness is shown by several examples. Moreover, we report some incorrect results in published papers on the averaging method.", "venue": "ISSAC", "authors": ["Bo  Huang", "Chee  Yap"], "year": 2019, "n_citations": 4}
{"id": 6506356, "s2_id": "3158edf19df5e4ad7b9a7ebd47d920069728db99", "title": "Border Basis Computation with Gradient-Weighted Norm", "abstract": "Normalization of polynomials plays an essential role in the approximate basis computation of vanishing ideals. In computer algebra, coefficient normalization, which normalizes a polynomial by its coefficient norm, is the most common method. In this study, we propose gradientweighted normalization for the approximate border basis computation of vanishing ideals, inspired by the recent results in machine learning. The data-dependent nature of gradient-weighted normalization leads to powerful properties such as better stability against the perturbation and a sort of consistency in the scaling of input points, which cannot be attained by the conventional coefficient normalization. With a slight modification, the analysis of algorithms with coefficient normalization still works with gradient-weighted normalization and the time complexity does not change. We also provide an upper bound of the coefficient norm with respect to the gradient-weighted norm, which allows us to discuss the approximate border bases with gradient-weighted normalization from the perspective of the coefficient norm.", "venue": "ArXiv", "authors": ["Hiroshi  Kera"], "year": 2021, "n_citations": 1}
{"id": 6507884, "s2_id": "5b8b404cdca66157c5fcdef56a0d0d2d7405a4f1", "title": "Parallel Computation of tropical varieties, their positive part, and tropical Grassmannians", "abstract": "In this article, we present a massively parallel framework for computing tropicalizations of algebraic varieties which can make use of finite symmetries. We compute the tropical Grassmannian TGr$_0(3,8)$, and show that it refines the $15$-dimensional skeleton of the Dressian Dr$(3,8)$ with the exception of $23$ special cones for which we construct explicit obstructions to the realizability of their tropical linear spaces. Moreover, we propose algorithms for identifying maximal-dimensional tropical cones which belong to the positive tropicalization. These algorithms exploit symmetries of the tropical variety even though the positive tropicalization need not be symmetric. We compute the maximal-dimensional cones of the positive Grassmannian TGr$^+(3,8)$ and compare them to the cluster complex of the classical Grassmannian Gr$(3,8)$.", "venue": "ArXiv", "authors": ["Dominik  Bendle", "Janko  B\u00f6hm", "Yue  Ren", "Benjamin  Schr\u00f6ter"], "year": 2020, "n_citations": 3}
{"id": 6509662, "s2_id": "cf34256f59c461ef42b52aa573cc6f8bbe714478", "title": "Solving Detachability Problem for the Polynomial Ring by Signature-based Groebner Basis Algorithms", "abstract": "Signature-based algorithms are a popular kind of algorithms for computing Groebner basis, including the famous F5 algorithm, F5C, extended F5, G2V and the GVW algorithm. In this paper, an efficient method is proposed to solve the detachability problem. The new method only uses the outputs of signature-based algorithms, and no extra Groebner basis computations are needed. When a Groebner basis is obtained by signature-based algorithms, the detachability problem can be settled in polynomial time.", "venue": "ArXiv", "authors": ["Yao  Sun", "Dingkang  Wang"], "year": 2011, "n_citations": 7}
{"id": 6511870, "s2_id": "5a1689f72153fe760aa79a144f3398840e643bfd", "title": "HYPERgeometric functions DIfferential REduction: Mathematica-based packages for the differential reduction of generalizedhypergeometric functions: Fc hypergeometric function of three variables", "abstract": "We present a further development of the HYPERDIRE project: a set of Mathematica-based program packages for manipulations with Horn-type hypergeometric functions on the basis of differential equations. Specifically, we present the implementation of differential reduction for the Lauricella function F C of three variables. Nature of the problem: reduction of Fc hypergeometric function of three variables to a set of basis functions by differential reduction method Method of solution: differential reduction Restriction on the complexity of the problem: none Typical running time: depending on the complexity of the problem 2", "venue": "ArXiv", "authors": ["Vladimir V. Bytev", "Bernd A. Kniehl"], "year": 2016, "n_citations": 2}
{"id": 6517875, "s2_id": "7500e8c44e7c7d9d06359c656d49cf1616c838ca", "title": "Symbolic multibody methods for real-time simulation of railway vehicles", "abstract": "In this work, recently developed state-of-the-art symbolic multibody methods are tested to accurately model a complex railway vehicle. The model is generated using a symbolic implementation of the principle of virtual power. Creep forces are modeled using a direct symbolic implementation of the standard linear Kalker model. No simplifications, such as base parameter reduction, partial-linearization or lookup tables for contact kinematics, are used. An Implicit\u2013Explicit integration scheme is proposed to efficiently deal with the stiff creep dynamics. Real-time performance is achieved: the CPU time required for a very robust 1ms$1~\\text{ms}$ integration time step is 203\u00a0\u03bcs.", "venue": "ArXiv", "authors": ["Javier  Ros", "Aitor  Plaza", "Xabier  Iriarte", "Jes\u00fas Mar\u00eda Pintor"], "year": 2017, "n_citations": 5}
{"id": 6520249, "s2_id": "5945c017b7abe56686795d3ed030e042b5c823a9", "title": "Triangular decomposition of semi-algebraic systems", "abstract": "Regular chains and triangular decompositions are fundamental and well-developed tools for describing the complex solutions of polynomial systems. This paper proposes adaptations of these tools focusing on solutions of the real analogue: semi-algebraic systems.\n We show that any such system can be decomposed into finitely many regular semi-algebraic systems. We propose two specifications of such a decomposition and present corresponding algorithms. Under some assumptions, one type of decomposition can be computed in singly exponential time w.r.t. the number of variables. We implement our algorithms and the experimental results illustrate their effectiveness.", "venue": "ISSAC", "authors": ["Changbo  Chen", "James H. Davenport", "John P. May", "Marc Moreno Maza", "Bican  Xia", "Rong  Xiao"], "year": 2010, "n_citations": 11}
{"id": 6521214, "s2_id": "0f23b9f6d2753bd078c156d71e6e33504719dc63", "title": "On Jacobian group arithmetic for typical divisors on curves", "abstract": "In a previous joint article with Abu Salem, we gave efficient algorithms for Jacobian group arithmetic of \u201ctypical\u201d divisor classes on $$C_{3,4}$$C3,4 curves, improving on similar results by other authors. At that time, we could only state that a general divisor was typical, and hence unlikely to be encountered if one implemented these algorithms over a very large finite field. This article pins down an explicit characterization of these typical divisors, for an arbitrary smooth projective curve of genus $$g \\ge 1$$g\u22651 having at least one rational point. We give general algorithms for Jacobian group arithmetic with these typical divisors, and prove not only that the algorithms are correct if various divisors are typical, but also that the success of our algorithms provides a guarantee that the resulting output is correct and that the resulting input and/or output divisors are also typical. These results apply in particular to our earlier algorithms for $$C_{3,4}$$C3,4 curves. As a byproduct, we obtain a further speedup of approximately 15% on our previous algorithms for $$C_{3,4}$$C3,4 curves.", "venue": "ArXiv", "authors": ["Kamal  Khuri-Makdisi"], "year": 2013, "n_citations": 4}
{"id": 6524069, "s2_id": "4e684d4f91bde5d60cf6661b2c79aca3129b5986", "title": "Sparse Interpolation in Terms of Multivariate Chebyshev Polynomials", "abstract": "Sparse interpolation refers to the exact recovery of a function as a short linear combination of basis functions from a limited number of evaluations. For multivariate functions, the case of the monomial basis is well studied, as is now the basis of exponential functions. Beyond the multivariate Chebyshev polynomial obtained as tensor products of univariate Chebyshev polynomials, the theory of root systems allows to define a variety of generalized multivariate Chebyshev polynomials that have connections to topics such as Fourier analysis and representations of Lie algebras. We present a deterministic algorithm to recover a function that is the linear combination of at most r such polynomials from the knowledge of r and an explicitly bounded number of evaluations of this function.", "venue": "Foundations of Computational Mathematics", "authors": ["Evelyne  Hubert", "Michael F. Singer"], "year": 2021, "n_citations": 1}
{"id": 6530793, "s2_id": "51e7f02c368053bbf40c4364f4ae4bca224fda29", "title": "The Differential Dimension Polynomial for Characterizable Differential Ideals", "abstract": "We generalize the notion of a differential dimension polynomial of a prime differential ideal to that of a characterizable differential ideal. Its computation is algorithmic, its degree and leading coefficient remain differential birational invariants, and it decides equality of characterizable differential ideals contained in each other.", "venue": "ArXiv", "authors": ["Markus  Lange-Hegermann"], "year": 2014, "n_citations": 9}
{"id": 6532643, "s2_id": "9cd109c806e49eba4c067daecc3878ee7c5c58cb", "title": "Machine learning the real discriminant locus", "abstract": "Parameterized systems of polynomial equations arise in many applications in science and engineering with the real solutions describing, for example, equilibria of a dynamical system, linkages satisfying design constraints, and scene reconstruction in computer vision. Since different parameter values can have a different number of real solutions, the parameter space is decomposed into regions whose boundary forms the real discriminant locus. This article views locating the real discriminant locus as a supervised classification problem in machine learning where the goal is to determine classification boundaries over the parameter space, with the classes being the number of real solutions. For multidimensional parameter spaces, this article presents a novel sampling method which carefully samples the parameter space. At each sample point, homotopy continuation is used to obtain the number of real solutions to the corresponding polynomial system. Machine learning techniques including nearest neighbor and deep learning are used to efficiently approximate the real discriminant locus. One application of having learned the real discriminant locus is to develop a real homotopy method that only tracks the real solution paths unlike traditional methods which track all~complex~solution~paths. Examples show that the proposed approach can efficiently approximate complicated solution boundaries such as those arising from the equilibria of the Kuramoto model.", "venue": "ArXiv", "authors": ["Edgar A. Bernal", "Jonathan D. Hauenstein", "Dhagash  Mehta", "Margaret H. Regan", "Tingting  Tang"], "year": 2020, "n_citations": 4}
{"id": 6535288, "s2_id": "b94980caebb82159bc7d4f4dbf4f8d622dd9ae74", "title": "Rational univariate representations of bivariate systems and applications", "abstract": "We address the problem of solving systems of two bivariate polynomials of total degree at most <i>d</i> with integer coefficients of maximum bitsize \u03c4 We suppose known a linear separating form (that is a linear combination of the variables that takes different values at distinct solutions of the system) and focus on the computation of a Rational Univariate Representation (RUR). \n We present an algorithm for computing a RUR with worst-case bit complexity in \u00d5<sub>B</sub>(d<sup>7</sup>+d<sup>6</sup>\u03c4) and bound the bitsize of its coefficients by \u00d5(d<sup>2</sup>+d\u03c4) (where \u00d5<sub>B</sub> refers to bit complexities and \u00d5 to complexities where polylogarithmic factors are omitted). We show in addition that isolating boxes of the solutions of the system can be computed from the RUR with \u00d5<sub>B</sub>(d<sup>8</sup>+d<sup>7</sup>\u03c4) bit operations. Finally, we show how a RUR can be used to evaluate the sign of a bivariate polynomial (of degree at most <i>d</i> and bitsize at most \u03c4) at one real solution of the system in \u00d5<sub>B</sub>(d<sup>8</sup>+d<sup>7</sup>\u03c4) bit operations and at all the \u03f4(d<sup>2</sup>) solutions in only <i>O</i>(<i>d</i>) times that for one solution.", "venue": "ISSAC '13", "authors": ["Yacine  Bouzidi", "Sylvain  Lazard", "Marc  Pouget", "Fabrice  Rouillier"], "year": 2013, "n_citations": 20}
{"id": 6537643, "s2_id": "b7a4be81d927ac88dd5b61dcc2962f604ca30926", "title": "How to hunt wild constants", "abstract": "There are now several comprehensive web applications, stand-alone computer programs and computer algebra functions that, given a floating point number such as 6.518670730718491, can return concise nonfloat constants such as 3 arctan 2 + ln 9 + 1 that closely approximate the float. Examples include AskConstants, Inverse Symbolic Calculator, the Maple identify function, MESearch, OEIS, RIES, and WolframAlpha. Usefully often such a result is the exact limit as the float is computed with increasing precision. Therefore these program results are candidates for proving an exact result that you could not derive or conjecture without the program. Moreover, candidates that are not the exact limit can be provable bounds, or convey qualitative insight, or suggest series that they truncate, or provide sufficiently close efficient approximations for subsequent computation. This article describes some of these programs, how they work, and how best to use each of them. Almost everyone who uses or should use mathematical software can benefit from acquaintance with several such programs, because these programs differ in the sets of constants that they can return.", "venue": "ArXiv", "authors": ["David R. Stoutemyer"], "year": 2021, "n_citations": 0}
{"id": 6542257, "s2_id": "579fd05e8027c0ec93621845e7cd3d9cade66555", "title": "Implementing an Automatic Differentiator in ACL2", "abstract": "The foundational theory of differentiation was developed as part of the original release of ACL2(r). In work reported at the last ACL2 Workshop, we presented theorems justifying the usual differentiation rules, including the chain rule and the derivative of inverse functions. However, the process of applying these theorems to formalize the derivative of a particular function is completely manual. More recently, we developed a macro and supporting functions that can automate this process. This macro uses the ACL2 table facility to keep track of functions and their derivatives, and it also interacts with the macro that introduces inverse functions in ACL2(r), so that their derivatives can also be automated. In this paper, we present the implementation of this macro and related functions.", "venue": "ACL2", "authors": ["Peter  Reid", "Ruben  Gamboa"], "year": 2011, "n_citations": 1}
{"id": 6543902, "s2_id": "a25fac1ae3333239f848c7415ffef38d3be938fb", "title": "Separating variables in bivariate polynomial ideals", "abstract": "We present an algorithm which for any given ideal I \u2286 K[x, y] finds all elements of I that have the form f(x) - g(y), i.e., all elements in which no monomial is a multiple of xy.", "venue": "ISSAC", "authors": ["Manfred  Buchacher", "Manuel  Kauers", "Gleb  Pogudin"], "year": 2020, "n_citations": 1}
{"id": 6547209, "s2_id": "1323754af26f51e393182b0d559fa3276ca79dfb", "title": "Symbolically Solving Partial Differential Equations using Deep Learning", "abstract": "We describe a neural-based method for generating exact or approximate solutions to differential equations in the form of mathematical expressions. Unlike other neural methods, our system returns symbolic expressions that can be interpreted directly. Our method uses a neural architecture for learning mathematical expressions to optimize a customizable objective, and is scalable, compact, and easily adaptable for a variety of tasks and configurations. The system has been shown to effectively find exact or approximate symbolic solutions to various differential equations with applications in natural sciences. In this work, we highlight how our method applies to partial differential equations over multiple variables and more complex boundary and initial value conditions.", "venue": "ArXiv", "authors": ["Maysum  Panju", "Kourosh  Parand", "Ali  Ghodsi"], "year": 2020, "n_citations": 0}
{"id": 6547870, "s2_id": "7753fdb20983d25441f4973159f08a9479a4fe59", "title": "Trading order for degree in creative telescoping", "abstract": "We analyze the differential equations produced by the method of creative telescoping applied to a hyperexponential term in two variables. We show that equations of low order have high degree, and that higher order equations have lower degree. More precisely, we derive degree bounding formulas which allow to estimate the degree of the output equations from creative telescoping as a function of the order. As an application, we show how the knowledge of these formulas can be used to improve, at least in principle, the performance of creative telescoping implementations, and we deduce bounds on the asymptotic complexity of creative telescoping for hyperexponential terms.", "venue": "J. Symb. Comput.", "authors": ["Shaoshi  Chen", "Manuel  Kauers"], "year": 2012, "n_citations": 31}
{"id": 6548738, "s2_id": "f5852b87cc8376906eaaeafe83aace49cfd5c6b0", "title": "Fast, deterministic computation of the Hermite normal form and determinant of a polynomial matrix", "abstract": "Given a nonsingular $n \\times n$ matrix of univariate polynomials over a field $\\mathbb{K}$, we give fast and deterministic algorithms to compute its determinant and its Hermite normal form. Our algorithms use $\\widetilde{\\mathcal{O}}(n^\\omega \\lceil s \\rceil)$ operations in $\\mathbb{K}$, where $s$ is bounded from above by both the average of the degrees of the rows and that of the columns of the matrix and $\\omega$ is the exponent of matrix multiplication. The soft-$O$ notation indicates that logarithmic factors in the big-$O$ are omitted while the ceiling function indicates that the cost is $\\widetilde{\\mathcal{O}}(n^\\omega)$ when $s = o(1)$. Our algorithms are based on a fast and deterministic triangularization method for computing the diagonal entries of the Hermite form of a nonsingular matrix.", "venue": "J. Complex.", "authors": ["George  Labahn", "Vincent  Neiger", "Wei  Zhou"], "year": 2017, "n_citations": 19}
{"id": 6551174, "s2_id": "f3d325c21a6788a68fa7f77b5e76631930919496", "title": "On some combinatorial sequences associated to invariant theory", "abstract": "We study the enumerative and analytic properties of some sequences constructed using tensor invariant theory. The octant sequences are constructed from the exceptional Lie group G2 and the quadrant sequences from the special linear group SL(3). In each case we show that the corresponding sequences are related by binomial transforms. The first three octant sequences and the first four quadrant sequences are listed in the On-Line Encyclopedia of Integer Sequences (OEIS). These sequences all have interpretations as enumerating two-dimensional lattice walks but for the octant sequences the boundary conditions are unconventional. These sequences are all P-recursive and we give the corresponding recurrence relations. In all cases the associated differential operators are of third order and have the remarkable property that they can be solved to give closed formulae for the ordinary generating functions in terms of classical Gaussian hypergeometric functions. Moreover, we show that the octant sequences and the quadrant sequences are related by the branching rules for the inclusion of SL(3) in G2.", "venue": "ArXiv", "authors": ["Alin  Bostan", "Jordan  Tirrell", "Bruce W. Westbury", "Yi  Zhang"], "year": 2021, "n_citations": 0}
{"id": 6552480, "s2_id": "2943af429f0918e12f0a96ca21a6bb95c4d47628", "title": "On Minor Left Prime Factorization Problem for Multivariate Polynomial Matrices", "abstract": "A new necessary and sufficient condition for the existence of minor left prime factorizations of multivariate polynomial matrices without full row rank is presented. The key idea is to establish a relationship between a matrix and its full row rank submatrix. Based on the new result, we propose an algorithm for factorizing matrices and have implemented it on the computer algebra system Maple. Two examples are given to illustrate the effectiveness of the algorithm, and experimental data shows that the algorithm is efficient.", "venue": "ArXiv", "authors": ["Dong  Lu", "Dingkang  Wang", "Fanghui  Xiao"], "year": 2020, "n_citations": 0}
{"id": 6565418, "s2_id": "7f7e5de5c3a517e04f12de45f5a33dcc90711276", "title": "Involutive bases algorithm incorporating F5 criterion", "abstract": "Faugere's F5 algorithm is the fastest known algorithm to compute Groebner bases. It has a signature-based and an incremental structure that allow to apply the F5 criterion for deletion of unnecessary reductions. In this paper, we present an involutive completion algorithm which outputs a minimal involutive basis. Our completion algorithm has a nonincremental structure and in addition to the involutive form of Buchberger's criteria it applies the F5 criterion whenever this criterion is applicable in the course of completion to involution. In doing so, we use the G2V form of the F5 criterion developed by Gao, Guan and Volny IV. To compare the proposed algorithm, via a set of benchmarks, with the Gerdt-Blinkov involutive algorithm (which does not apply the F5 criterion) we use implementations of both algorithms done on the same platform in Maple.", "venue": "J. Symb. Comput.", "authors": ["Vladimir P. Gerdt", "Amir  Hashemi", "Benyamin  M.-Alizadeh"], "year": 2013, "n_citations": 15}
{"id": 6566753, "s2_id": "d85534c8a34999c71184e33dc6fd2461d2114a93", "title": "On the k-synchronizability of Systems", "abstract": "We study k-synchronizability: a system is k-synchronizable if any of its executions, up to reordering causally independent actions, can be divided into a succession of k-bounded interaction phases. We show two results (both for mailbox and peer-to-peer automata): first, the reachability problem is decidable for k-synchronizable systems; second, the membership problem (whether a given system is k-synchronizable) is decidable as well. Our proofs fix several important issues in previous attempts to prove these two results for mailbox automata.", "venue": "FoSSaCS", "authors": ["Cinzia Di Giusto", "Laetitia  Laversa", "Etienne  Lozes"], "year": 2020, "n_citations": 5}
{"id": 6570515, "s2_id": "3cc2bb50710697f5640613212da02d34592556c6", "title": "Not another computer algebra system: Highlighting wxMaxima in calculus", "abstract": "This article introduces and explains a computer algebra system (CAS) wxMaxima for Calculus teaching and learning at the tertiary level. The didactic reasoning behind this approach is the need to implement an element of technology into classrooms to enhance students\u2019 understanding of Calculus concepts. For many mathematics educators who have been using CAS, this material is of great interest, particularly for secondary teachers and university instructors who plan to introduce an alternative CAS into their classrooms. By highlighting both the strengths and limitations of the software, we hope that it will stimulate further debate not only among mathematics educators and software users but also also among symbolic computation and software developers.", "venue": "Mathematics", "authors": ["Natanael  Karjanto", "Husty Serviana Husain"], "year": 2021, "n_citations": 1}
{"id": 6571763, "s2_id": "84b19adee434083aabe6ca6b4ebd8f88fa930cbd", "title": "Term Algebras, Canonical Representations and Difference Ring Theory for Symbolic Summation", "abstract": "A general overview of the existing difference ring theory for symbolic summation is given. Special emphasis is put on the user interface: the translation and back translation of the corresponding representations within the term algebra and the formal difference ring setting. In particular, canonical (unique) representations and their refinements in the introduced term algebra are explored by utilizing the available difference ring theory. Based on that, precise input-output specifications of the available tools of the summation package Sigma are provided.", "venue": "Texts & Monographs in Symbolic Computation", "authors": ["Carsten  Schneider"], "year": 2021, "n_citations": 2}
{"id": 6575113, "s2_id": "d7bc647200e935c011d4631382fa0aa8b79b4d4e", "title": "An Application of Rubi: Series Expansion of the Quark Mass Renormalization Group Equation", "abstract": "We highlight how Rule-based Integration (Rubi) is an enhanced method of symbolic integration which allows for the integration of many difficult integrals not accomplished by other computer algebra systems. Using Rubi, many integration techniques become tractable. Integrals are approached using step-wise simplification, hence distilling an integral (if the solution is unknown) into composite integrals which highlight yet undiscovered integration rules. The motivating example we use is the derivation of the updated series expansion of the quark mass renormalization group equation (RGE) to five-loop order. This series provides the relation between a light quark mass in the modified minimal subtraction ($\\overline{\\text{MS}}$) scheme defined at some given scale, e.g. at the tau-lepton mass scale, and another chosen energy scale, $s$. This relation explicitly depicts the renormalization scheme dependence of the running quark mass on the scale parameter, $s$, and is important in accurately determining a light quark mass at a chosen scale. The five-loop QCD $\\beta(a_s)$ and $\\gamma(a_s)$ functions are used in this determination.", "venue": "ArXiv", "authors": ["Alexes  Mes", "Jed  Stephens"], "year": 2018, "n_citations": 1}
{"id": 6584809, "s2_id": "a7c55a27053a00c44e7174992bfa79515ca66020", "title": "Computing modular correspondences for abelian varieties", "abstract": "The aim of this paper is to give a higher dimensional equivalent of the classical modular polynomials $\\Phi_\\ell(X,Y)$. If $j$ is the $j$-invariant associated to an elliptic curve $E_k$ over a field $k$ then the roots of $\\Phi_\\ell(j,X)$ correspond to the $j$-invariants of the curves which are $\\ell$-isogeneous to $E_k$. Denote by $X_0(N)$ the modular curve which parametrizes the set of elliptic curves together with a $N$-torsion subgroup. It is possible to interpret $\\Phi_\\ell(X,Y)$ as an equation cutting out the image of a certain modular correspondence $X_0(\\ell) \\rightarrow X_0(1) \\times X_0(1)$ in the product $X_0(1) \\times X_0(1)$. Let $g$ be a positive integer and $\\overn \\in \\N^g$. We are interested in the moduli space that we denote by $\\Mn$ of abelian varieties of dimension $g$ over a field $k$ together with an ample symmetric line bundle $\\pol$ and a symmetric theta structure of type $\\overn$. If $\\ell$ is a prime and let $\\overl=(\\ell, \\ldots , \\ell)$, there exists a modular correspondence $\\Mln \\rightarrow \\Mn \\times \\Mn$. We give a system of algebraic equations defining the image of this modular correspondence. We describe an algorithm to solve this system of algebraic equations which is much more efficient than a general purpose Gr\u00a8obner basis algorithm. As an application, we explain how this algorithm can be used to speed up the initialisation phase of a point counting algorithm.", "venue": "ArXiv", "authors": ["Jean-Charles  Faug\u00e8re", "David  Lubicz", "Damien  Robert"], "year": 2009, "n_citations": 21}
{"id": 6593945, "s2_id": "aef72ff2c5422fda589ba853f7d6ff7424786622", "title": "Graph Neural Reasoning May Fail in Certifying Boolean Unsatisfiability", "abstract": "It is feasible and practically-valuable to bridge the characteristics between graph neural networks (GNNs) and logical reasoning. Despite considerable efforts and successes witnessed to solve Boolean satisfiability (SAT), it remains a mystery of GNN-based solvers for more complex predicate logic formulae. In this work, we conjectures with some evidences, that generally-defined GNNs present several limitations to certify the unsatisfiability (UNSAT) in Boolean formulae. It implies that GNNs may probably fail in learning the logical reasoning tasks if they contain proving UNSAT as the sub-problem included by most predicate logic formulae.", "venue": "ArXiv", "authors": ["Ziliang  Chen", "Zhanfu  Yang"], "year": 2019, "n_citations": 5}
{"id": 6596577, "s2_id": "01f65c183417ef145b2240d8a0f7b5765dca426e", "title": "Input-output equations and identifiability of linear ODE models", "abstract": "Structural identifiability is a property of a differential model with parameters that allows for the parameters to be determined from the model equations in the absence of noise. The method of input-output equations is one method for verifying structural identifiability. This method stands out in its importance because the additional insights it provides can be used to analyze and improve models. However, its complete theoretical grounds and applicability are still to be established. A subtlety and key for this method to work is knowing if the coefficients of these equations are identifiable. \nIn this paper, to address this, we prove identifiability of the coefficients of input-output equations for types of differential models that often appear in practice, such as linear models with one output and linear compartment models in which, from each compartment, one can reach either a leak or an input. This shows that checking identifiability via input-output equations for these models is legitimate and, as we prove, that the field of identifiable functions is generated by the coefficients of the input-output equations. Finally, we show that, for a linear compartment model with an input and strongly connected graph, the field of all identifiable functions is generated by the coefficients of the equations obtained from the model just using Cramer's rule.", "venue": "ArXiv", "authors": ["Alexey  Ovchinnikov", "Gleb  Pogudin", "Peter  Thompson"], "year": 2019, "n_citations": 12}
{"id": 6602807, "s2_id": "04bdb1978fbc0ba1b0ea9591c35b0945ebe90313", "title": "A general framework for Noetherian well ordered polynomial reductions", "abstract": "Polynomial reduction is one of the main tools in computational algebra with innumerable applications in many areas, both pure and applied. Since many years both the theory and an efficient design of the related algorithm have been solidly established. \nThis paper presents a general definition of polynomial reduction structure, studies its features and highlights the aspects needed in order to grant and to efficiently test the main properties (noetherianity, confluence, ideal membership). \nThe most significant aspect of this analysis is a negative reappraisal of the role of the notion of term order which is usually considered a central and crucial tool in the theory. In fact, as it was already established in the computer science context in relation with termination of algorithms, most of the properties can be obtained simply considering a well-founded ordering, while the classical requirement that it be preserved by multiplication is irrelevant. \nThe last part of the paper shows how the polynomial basis concepts present in literature are interpreted in our language and their properties are consequences of the general results established in the first part of the paper.", "venue": "J. Symb. Comput.", "authors": ["Michela  Ceria", "Teo  Mora", "Margherita  Roggero"], "year": 2019, "n_citations": 3}
{"id": 6604601, "s2_id": "e3e48c9d9101c120f07f0eb41ccb7bb55804478f", "title": "A Fast Algorithm for the Inversion of Quasiseparable Vandermonde-like Matrices", "abstract": "The results on Vandermonde-like matrices were introduced as a generalization of polynomial Vandermonde matrices, and the displacement structure of these matrices was used to derive an inversion formula. In this paper we first present a fast Gaussian elimination algorithm for the polynomial Vandermonde-like matrices. Later we use the said algorithm to derive fast inversion algorithms for quasiseparable, semiseparable and well-free Vandermonde-like matrices having $\\mathcal{O}(n^2)$ complexity. To do so we identify structures of displacement operators in terms of generators and the recurrence relations(2-term and 3-term) between the columns of the basis transformation matrices for quasiseparable, semiseparable and well-free polynomials. Finally we present an $\\mathcal{O}(n^2)$ algorithm to compute the inversion of quasiseparable Vandermonde-like matrices.", "venue": "ArXiv", "authors": ["Sirani M. Perera", "Grigory  Bonik", "Vadim  Olshevsky"], "year": 2014, "n_citations": 0}
{"id": 6609044, "s2_id": "b95b98282509b64d956492279b752e61053ebe48", "title": "Rings: an efficient Java/Scala library for polynomial rings", "abstract": "Abstract In this paper we briefly discuss Rings \u2014\u00a0an efficient lightweight library for commutative algebra. Polynomial arithmetic, GCDs, polynomial factorization and Grobner bases are implemented with the use of modern asymptotically fast algorithms. Rings can be easily interacted or embedded in applications in high-energy physics and other research areas via a simple API with fully typed hierarchy of algebraic structures and algorithms for commutative algebra. The use of the Scala language brings a quite novel powerful, strongly typed functional programming model allowing to write short, expressive, and fast code for applications. At the same time Rings shows one of the best performances among existing software for algebraic calculations. Program summary Program Title: Rings Program Files doi: http://dx.doi.org/10.17632/2k79hftjy9.1 Licensing provisions: Apache 2.0 Programming language: Java, Scala Nature of problem: Fast methods for rational function arithmetic, simplification of polynomial expressions, Grobner bases and other related computer algebra methods naturally arising in physical applications Solution method: Efficient implementation of modern asymptotically fast algorithms in Java language External routines: Java 8 and higher, Scala 2.11 or 2.12 Additional comments: project page: https://github.com/PoslavskySV/rings , \u00a0documentation: http://rings.readthedocs.io/en/latest/", "venue": "Comput. Phys. Commun.", "authors": ["Stanislav  Poslavsky"], "year": 2019, "n_citations": 6}
{"id": 6611574, "s2_id": "c7e80dae990cbe173fef0aca5c0b5a5caf6409fc", "title": "Efficient Rational Creative Telescoping", "abstract": "We present a new algorithm to compute minimal telescopers for rational functions in two discrete variables. As with recent reduction-based approach, our algorithm has the nice feature that the computation of a telescoper is independent of its certificate. Moreover, our algorithm uses a sparse representation of the certificate, which allows it to be easily manipulated and analyzed without knowing the precise expanded form. This representation hides potential expression swell until the final (and optional) expansion, which can be accomplished in time polynomial in the size of the expanded certificate. A complexity analysis, along with a Maple implementation, suggests that our algorithm has better theoretical and practical performance than the reduction-based approach in the rational case.", "venue": "J. Symb. Comput.", "authors": ["Mark  Giesbrecht", "Hui  Huang", "George  Labahn", "Eugene  Zima"], "year": 2019, "n_citations": 1}
{"id": 6613724, "s2_id": "3afb344f945fb4f8e63a4a6f2f6b716d807a25bd", "title": "Fast and deterministic computation of the determinant of a polynomial matrix", "abstract": "Given a square, nonsingular matrix of univariate polynomials $\\mathbf{F}\\in\\mathbb{K}[x]^{n\\times n}$ over a field $\\mathbb{K}$, we give a deterministic algorithm for finding the determinant of $\\mathbf{F}$. The complexity of the algorithm is $\\bigO \\left(n^{\\omega}s\\right)$ field operations where $s$ is the average column degree or the average row degree of $\\mathbf{F}$. Here $\\bigO$ notation is Big-$O$ with log factors omitted and $\\omega$ is the exponent of matrix multiplication.", "venue": "ArXiv", "authors": ["Wei  Zhou", "George  Labahn"], "year": 2014, "n_citations": 1}
{"id": 6614700, "s2_id": "dfb65ea2130d0e58ea09d7adc45d71700cebe6fc", "title": "EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: the MonuMAI cultural heritage use case", "abstract": "The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols \u2013such as knowledge graphs\u2013 are easier to explain. However, they present lower generalisation and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process so it serves as a sound basis for explainability. In particular, X-NeSyL methodology involves the concrete use of two notions of explanation, both at inference and training time respectively: 1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional convolutional neural network that makes use of symbolic representations, and 2) SHAP-Backprop, an explainable AI-informed training procedure that corrects and guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that our approach improves not only explainability of DL models but also performance.", "venue": "Inf. Fusion", "authors": ["Natalia  D'iaz-Rodr'iguez", "Alberto  Lamas", "Jules  Sanchez", "Gianni  Franchi", "Ivan  Donadello", "Siham  Tabik", "David  Filliat", "Policarpo  Cruz", "Rosana  Montes", "Francisco  Herrera"], "year": 2022, "n_citations": 3}
{"id": 6630606, "s2_id": "23a68930cfe7f6c51818aef4a35c019086fb7e90", "title": "The complexity of MinRank", "abstract": "In this note, we leverage some of our results from arXiv:1706.06319 to produce a concise and rigorous proof for the complexity of the generalized MinRank Problem in the under-defined and well-defined case. Our main theorem recovers and extends previous results by Faugere, Safey El Din, Spaenlehauer (arXiv:1112.4411).", "venue": "IACR Cryptol. ePrint Arch.", "authors": ["Alessio  Caminata", "Elisa  Gorla"], "year": 2019, "n_citations": 2}
{"id": 6631349, "s2_id": "9e9adcbde0ac20b7f6c4577ae1ba5911ce14a1c1", "title": "Relativistic Coulomb Integrals and Zeilberger's Holonomic Systems Approach II", "abstract": "We derive the recurrence relations for relativistic Coulomb integrals directly from the integral representations with the help of computer algebra methods. In order to manage the computational complexity of this problem, we employ holonomic closure properties in a sophisticated way.", "venue": "AADIOS", "authors": ["Christoph  Koutschan", "Peter  Paule", "Sergei K. Suslov"], "year": 2012, "n_citations": 7}
{"id": 6634711, "s2_id": "56ddb476b744b44d32cce54fce3949f381d66aeb", "title": "Homotopy techniques for solving sparse column support determinantal polynomial systems", "abstract": "Let K be a field of characteristic zero with K its algebraic closure. Given a sequence of polynomials g = (g_1 ,. .. , g_s) \u2208 K[x_1 , ... , x_n ] s and a polynomial matrix F = [f_{i,j} ] \u2208 K[x_1 , ... , x_n ] p\u00d7q , with p \u2264 q, we are interested in determining the isolated points of V_p (F , g), the algebraic set of points in K at which all polynomials in g and all p-minors of F vanish, under the assumption n = q \u2212 p + s + 1. Such polynomial systems arise in a variety of applications including for example polynomial optimization and computational geometry. We design a randomized sparse homotopy algorithm for computing the isolated points in V_p (F , g) which takes advantage of the determinantal structure of the system defining V_p (F , g). Its complexity is polynomial in the maximum number of isolated solutions to such systems sharing the same sparsity pattern and in some combinatorial quantities attached to the structure of such systems. It is the first algorithm which takes advantage both on the determinantal structure and sparsity of input polynomials. We also derive complexity bounds for the particular but important case where g and the columns of F satisfy weighted degree constraints. Such systems arise naturally in the computation of critical points of maps restricted to algebraic sets when both are invariant by the action of the symmetric group.", "venue": "J. Complex.", "authors": ["George  Labahn", "Mohab Safey El Din", "\u00c9ric  Schost", "Thi Xuan Vu"], "year": 2021, "n_citations": 1}
{"id": 6635638, "s2_id": "03ed5b63b924bd1b58853e8d0c3c619efb981f4c", "title": "Monomial-agnostic computation of vanishing ideals", "abstract": "In recent years, the approximate basis computation of vanishing ideals has been studied extensively and adopted both in computer algebra and data-driven applications such as machine learning. However, symbolic computation and the dependency on monomial ordering remain as essential gaps between the two abovementioned fields. In this paper, we propose the first efficient monomial-agnostic approximate basis computation of vanishing ideals, where polynomials are manipulated without any information of monomials; this can be implemented in a fully numerical manner and is thus desirable for data-driven applications. In particular, we propose gradient normalization, which achieves not only the first efficient and monomial-agnostic normalization of polynomials but also provides significant advantages such as consistency in translation and scaling of data points, which cannot be realized by existing basis computation algorithms. During the basis computation, the gradients of polynomials at the given points are proven to be efficiently and exactly obtained without performing differentiation. By exploiting the gradient information, we further propose a basis reduction method to remove redundant polynomials in a monomial-agnostic manner. Finally, we also propose a regularization method using gradients to avoiding overfitting of the basis for the given perturbed points.", "venue": "ArXiv", "authors": ["Hiroshi  Kera", "Yoshihiko  Hasegawa"], "year": 2021, "n_citations": 1}
{"id": 6652447, "s2_id": "27fbcab0c0103711ca3c8c77304ec26e852f5ad8", "title": "Symbolic Computations of First Integrals for Polynomial Vector Fields", "abstract": "In this article we show how to generalize to the Darbouxian, Liouvillian and Riccati case the extactic curve introduced by J. Pereira. With this approach, we get new algorithms for computing, if it exists, a rational, Darbouxian, Liouvillian or Riccati first integral with bounded degree of a polynomial planar vector field. We give probabilistic and deterministic algorithms. The arithmetic complexity of our probabilistic algorithm is in $\\tilde{\\mathcal{O}}(N^{\\omega+1})$, where $N$ is the bound on the degree of a representation of the first integral and $\\omega \\in [2;3]$ is the exponent of linear algebra. This result improves previous algorithms. Our algorithms have been implemented in Maple and are available on authors' websites. In the last section, we give some examples showing the efficiency of these algorithms.", "venue": "Found. Comput. Math.", "authors": ["Guillaume  Ch\u00e8ze", "Thierry  Combot"], "year": 2020, "n_citations": 3}
{"id": 6655395, "s2_id": "d18a52c0d21319641c50438706ca5dadb3b1896f", "title": "Differential elimination by differential specialization of Sylvester style matrices", "abstract": "Differential resultant formulas are defined, for a system P of n ordinary Laurent differential polynomials in n\u22121 differential variables. These are determinants of coefficient matrices of an extended system of polynomials obtained from P through derivations and multiplications by Laurent monomials. To start, through derivations, a system ps(P) of L polynomials in L\u2212 1 algebraic variables is obtained, which is non sparse in the order of derivation. This enables the use of existing formulas for the computation of algebraic resultants, of the multivariate sparse algebraic polynomials in ps(P), to obtain polynomials in the differential elimination ideal generated by P. The formulas obtained are multiples of the sparse differential resultant defined by Li, Yuan and Gao, and provide order and degree bounds in terms of mixed volumes in the generic case.", "venue": "ACCA", "authors": ["Sonia L. Rueda"], "year": 2015, "n_citations": 0}
{"id": 6662834, "s2_id": "db4ded9429243a3ce1d8d565ab41f16eb3f4028a", "title": "Fast arithmetics in artin-schreier towers over finite fields", "abstract": "An Artin-Schreier tower over the finite field <b>F</b><sub><i>p</i></sub> is a tower of field extensions generated by polynomials of the form <i>X<sup>p</sup></i>-<i>X</i>-\u03b1. Following Cantor and Couveignes, we give algorithms with quasi-linear time complexity for arithmetic operations in such towers. As an application, we present an implementation of Couveignes' algorithm for computing isogenies between elliptic curves using the <i>p</i>-torsion.", "venue": "ISSAC '09", "authors": ["Luca De Feo", "\u00c9ric  Schost"], "year": 2009, "n_citations": 16}
{"id": 6667995, "s2_id": "53bfea9299fed0d4da30c22aa48c359099761898", "title": "Space Efficient Representations of Finite Groups", "abstract": "The Cayley table representation of a group uses $\\mathcal{O}(n^2)$ words for a group of order $n$ and answers multiplication queries in time $\\mathcal{O}(1)$. It is interesting to ask if there is a $o(n^2)$ space representation of groups that still has $\\mathcal{O}(1)$ query-time. We show that for any $\\delta$, $\\frac{1}{\\log n} \\le \\delta \\le 1$, there is an $\\mathcal{O}(\\frac{n^{1 +\\delta}}{\\delta})$ space representation for groups of order $n$ with $\\mathcal{O}(\\frac{1}{\\delta})$ query-time. \nWe also show that for Z-groups, simple groups and several group classes defined in terms of semidirect product, there are linear space representations with at most logarithmic query-time. \nFarzan and Munro (ISSAC'06) defined a model for group representation and gave a succinct data structure for abelian groups with constant query-time. They asked if their result can be extended to categorically larger group classes. We construct data structures in their model for Hamiltonian groups and some other classes of groups with constant query-time.", "venue": "J. Comput. Syst. Sci.", "authors": ["Bireswar  Das", "Shivdutt  Sharma", "P. R. Vaidyanathan"], "year": 2020, "n_citations": 0}
{"id": 6668240, "s2_id": "98b611be0fdd74d96a1b28a6fdcb00cd71f21114", "title": "Algorithmic averaging for studying periodic orbits of planar differential systems", "abstract": "One of the main open problems in the qualitative theory of real planar differential systems is the study of limit cycles. In this article, we present an algorithmic approach for detecting how many limit cycles can bifurcate from the periodic orbits of a given polynomial differential center when it is perturbed inside a class of polynomial differential systems via the averaging method. We propose four symbolic algorithms to implement the averaging method. The first algorithm is based on the change of polar coordinates that allows one to transform a considered differential system to the normal form of averaging. The second algorithm is used to derive the solutions of certain differential systems associated to the unperturbed term of the normal of averaging. The third algorithm exploits the partial Bell polynomials and allows one to compute the integral formula of the averaged functions at any order. The last algorithm is based on the aforementioned algorithms and determines the exact expressions of the averaged functions for the considered differential systems. The implementation of our algorithms is discussed and evaluated using several examples. The experimental results have extended the existing relevant results for certain classes of differential systems.", "venue": "ISSAC", "authors": ["Bo  Huang"], "year": 2020, "n_citations": 1}
{"id": 6670836, "s2_id": "adb434fa569065289e63f25bbf9fca3337e62125", "title": "New techniques for computing the ideal class group and a system of fundamental units in number fields", "abstract": "We describe a new algorithm for computing the ideal class group, the regulator and a system of fundamental units in number fields under the generalized Riemann hypothesis. We use sieving techniques adapted from the number field sieve algorithm to derive relations between elements of the ideal class group, and p-adic approximations to manage the loss of precision during the computation of units. This new algorithm is particularily efficient for number fields of small degree for which a speed-up of an order of magnitude is achieved with respect to the standard methods.", "venue": "ArXiv", "authors": ["Jean-Fran\u00e7ois  Biasse", "Claus  Fieker"], "year": 2012, "n_citations": 17}
{"id": 6672150, "s2_id": "97fc7f6fc3586947740f16484c44da59fcb3d67b", "title": "Extending the scalars of minimizations", "abstract": "In the classical theory of formal languages, finite state automata allow to recognize the words of a rational subset of $\\Sigma^*$ where $\\Sigma$ is a set of symbols (or the alphabet). Now, given a semiring $(\\K,+,.)$, one can construct $\\K$-subsets of $\\Sigma^*$ in the sense of Eilenberg, that are alternatively called noncommutative formal power series for which a framework very similar to language theory has been constructed Particular noncommutative formal power series, which are called rational series, are the behaviour of a family of weighted automata (or $\\K$-automata). In order to get an efficient encoding, it may be interesting to point out one of them with the smallest number of states. Minimization processes of $\\K$-automata already exist for $\\K$ being: {\\bf a)} a field, {\\bf b)} a noncommutative field, {\\bf c)} a PID . When $\\K$ is the bolean semiring, such a minimization process (with isomorphisms of minimal objects) is known within the category of deterministic automata. Minimal automata have been proved to be isomorphic in cases {\\bf (a)} and {\\bf (b)}. But the proof given for (b) is not constructive. In fact, it lays on the existence of a basis for a submodule of $\\K^n$. Here we give an independent algorithm which reproves this fact and an example of a pair of nonisomorphic minimal automata. Moreover, we examine the possibility of extending {\\bf (c)}. To this end, we provide an {\\em Effective Minimization Process} (or {\\em EMP}) which can be used for more general sets of coefficients.", "venue": "ArXiv", "authors": ["G\u00e9rard  Duchamp", "\u00c9ric  Laugerotte", "Jean-Gabriel  Luque"], "year": 2006, "n_citations": 0}
{"id": 6676714, "s2_id": "482c6685daa31858161bf5ec840236477c3e0372", "title": "Twisting q-holonomic sequences by complex roots of unity", "abstract": "A sequence <i>f</i><sub><i>n</i></sub>(<i>q</i>) is <i>q</i>-holonomic if it satisfies a nontrivial linear recurrence with coefficients polynomials in <i>q</i> and <i>q</i><sup><i>n</i></sup>. Our main theorems state that <i>q</i>-holonomicity is preserved under twisting, i.e., replacing <i>q</i> by \u03c9<i>q</i> where \u03c9 is a complex root of unity, and under the substitution <i>q</i> \u2192 <i>q</i><sup>\u03b1</sup> where \u03b1 is a rational number. Our proofs are constructive, work in the multivariate setting of \u2202-finite sequences and are implemented in the Mathematica package HolonomicFunctions. Our results are illustrated by twisting natural <i>q</i>-holonomic sequences which appear in quantum topology, namely the colored Jones polynomial of pretzel knots and twist knots. The recurrence of the twisted colored Jones polynomial can be used to compute the asymptotics of the Kashaev invariant of a knot at an arbitrary complex root of unity.", "venue": "ISSAC", "authors": ["Stavros  Garoufalidis", "Christoph  Koutschan"], "year": 2012, "n_citations": 5}
{"id": 6680485, "s2_id": "c5fbbfbbcfd72a0d065390e3f96d5f5e9f3c69c1", "title": "Maple+GrTensorII libraries for cosmology", "abstract": "The article mainly presents some results in using MAPLE platform for computer algebra (CA) and GrTensorII package in doing calculations for theoretical and numerical cosmology. AMS Subject Classification: 68W30, 83C05, 85A40", "venue": "ArXiv", "authors": ["Dumitru N. Vulcanov", "Valentina D. Vulcanov"], "year": 2004, "n_citations": 0}
{"id": 6681533, "s2_id": "f92e685a031853c66336154908a7749d1ffe0b74", "title": "Computing cylindrical algebraic decomposition via triangular decomposition", "abstract": "Cylindrical algebraic decomposition is one of the most important tools for computing with semi-algebraic sets, while triangular decomposition is among the most important approaches for manipulating constructible sets. In this paper, for an arbitrary finite set <i>F</i> \u2282 [<i>y<sub>1</sub></i>,...,<i>y<sub>n</sub></i>] we apply comprehensive triangular decomposition in order to obtain an <i>F</i>-invariant cylindrical decomposition of the <i>n</i>-dimensional complex space, from which we extract an <i>F</i>-invariant cylindrical algebraic decomposition of the <i>n</i>-dimensional real space. We report on an implementation of this new approach for constructing cylindrical algebraic decompositions.", "venue": "ISSAC '09", "authors": ["Changbo  Chen", "Marc Moreno Maza", "Bican  Xia", "Lu  Yang"], "year": 2009, "n_citations": 98}
{"id": 6690723, "s2_id": "873a85f30f45c0a2cf05205e8e3560f2a640f583", "title": "Predicate Abstraction via Symbolic Decision Procedures", "abstract": "We present a new approach for performing predicate abstraction based on symbolic decision procedures. A symbolic decision procedure for a theory T (SDPT) takes sets of predicates G and E and symbolically executes a decision procedure for T on G\u2032 \u222a {\u2013 e | e \u2208 E}, for all the subsets G\u2032 of G. The result of SDPT is a shared expression (represented by a directed acyclic graph) that implicitly represents the answer to a predicate abstraction query. \n \nWe present symbolic decision procedures for the logic of Equality and Uninterpreted Functions(EUF) and Difference logic (DIF) and show that these procedures run in pseudo-polynomial (rather than exponential) time. We then provide a method to construct SDP's for simple mixed theories (including EUF + DIF) using an extension of the Nelson-Oppen combination method. We present preliminary evaluation of our procedure on predicate abstraction benchmarks from device driver verification in SLAM.", "venue": "CAV", "authors": ["Shuvendu K. Lahiri", "Thomas  Ball", "Byron  Cook"], "year": 2005, "n_citations": 3}
{"id": 6693209, "s2_id": "14c0fd0970b30bd2f1780f5e5e862baa28704857", "title": "Multi-agent Safety Verification Using Symmetry Transformations", "abstract": "We show that symmetry transformations and caching can enable scalable, and possibly unbounded, verification of multi-agent systems. Symmetry transformations map any solution of the system to another solution. We show that this property can be used to transform cached reachsets to compute new reachsets, for hybrid and multi-agent models. We develop a notion of a virtual system which defines symmetry transformations for a broad class of agent models that visit waypoint sequences. Using this notion of a virtual system, we present a prototype tool CacheReach that builds a cache of reachsets, in a way that is agnostic of the representation of the reachsets and the reachability analysis method used. Our experimental evaluation of CacheReach shows up to 64% savings in safety verification computation time on multi-agent systems with 3-dimensional linear and 4-dimensional nonlinear fixed-wing aircraft models following sequences of waypoints. These savings and our theoretical results illustrate the potential benefits of using symmetry-based caching in the safety verification of multi-agent systems.", "venue": "TACAS", "authors": ["Hussein  Sibai", "Navid  Mokhlesi", "Chuchu  Fan", "Sayan  Mitra"], "year": 2020, "n_citations": 5}